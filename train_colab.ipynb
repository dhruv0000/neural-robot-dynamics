{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "B8R6x04hd4Ei",
      "metadata": {
        "id": "B8R6x04hd4Ei"
      },
      "source": [
        "# Neural Robot Dynamics Training on Colab\n",
        "\n",
        "This notebook demonstrates how to setup the environment, generate a dataset, and train the NeRD model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "feb351a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feb351a0",
        "outputId": "47725c52-47aa-40f8-855c-c57890b7ff50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'neural-robot-dynamics'...\n",
            "remote: Enumerating objects: 564, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
            "remote: Total 564 (delta 63), reused 87 (delta 45), pack-reused 434 (from 1)\u001b[K\n",
            "Receiving objects: 100% (564/564), 21.37 MiB | 16.32 MiB/s, done.\n",
            "Resolving deltas: 100% (150/150), done.\n",
            "Filtering content: 100% (11/11), 202.03 MiB | 9.42 MiB/s, done.\n",
            "/content/neural-robot-dynamics\n",
            "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (4.67.1)\n",
            "Collecting pyglet==2.1.6 (from -r requirements.txt (line 2))\n",
            "  Downloading pyglet-2.1.6-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting ipdb (from -r requirements.txt (line 3))\n",
            "  Downloading ipdb-0.13.13-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting h5py==3.11.0 (from -r requirements.txt (line 4))\n",
            "  Downloading h5py-3.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting pyyaml==6.0.2 (from -r requirements.txt (line 5))\n",
            "  Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting tensorboard==2.14.0 (from -r requirements.txt (line 6))\n",
            "  Downloading tensorboard-2.14.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting matplotlib==3.7.5 (from -r requirements.txt (line 7))\n",
            "  Downloading matplotlib-3.7.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (4.12.0.88)\n",
            "Collecting pycollada==0.9.2 (from -r requirements.txt (line 9))\n",
            "  Downloading pycollada-0.9.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 1.11.0, 1.14.0rc1\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 1.10.0 Requires-Python <3.12,>=3.8; 1.10.0rc1 Requires-Python <3.12,>=3.8; 1.10.0rc2 Requires-Python <3.12,>=3.8; 1.10.1 Requires-Python <3.12,>=3.8; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 1.7.2 Requires-Python >=3.7,<3.11; 1.7.3 Requires-Python >=3.7,<3.11; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11; 1.9.0 Requires-Python >=3.8,<3.12; 1.9.0rc1 Requires-Python >=3.8,<3.12; 1.9.0rc2 Requires-Python >=3.8,<3.12; 1.9.0rc3 Requires-Python >=3.8,<3.12; 1.9.1 Requires-Python >=3.8,<3.12\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement scipy==1.10.1 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0, 1.0.1, 1.1.0, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0, 1.4.1, 1.5.0, 1.5.1, 1.5.2, 1.5.3, 1.5.4, 1.6.0, 1.6.1, 1.9.2, 1.9.3, 1.11.0rc1, 1.11.0rc2, 1.11.1, 1.11.2, 1.11.3, 1.11.4, 1.12.0rc1, 1.12.0rc2, 1.12.0, 1.13.0rc1, 1.13.0, 1.13.1, 1.14.0rc2, 1.14.0, 1.14.1, 1.15.0rc1, 1.15.0rc2, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.16.0rc1, 1.16.0rc2, 1.16.0, 1.16.1, 1.16.2, 1.16.3)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for scipy==1.10.1\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting warp-lang==1.8.0\n",
            "  Downloading warp_lang-1.8.0-py3-none-manylinux_2_28_x86_64.whl.metadata (32 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from warp-lang==1.8.0) (2.0.2)\n",
            "Downloading warp_lang-1.8.0-py3-none-manylinux_2_28_x86_64.whl (129.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m129.9/129.9 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: warp-lang\n",
            "Successfully installed warp-lang-1.8.0\n",
            "Collecting rl_games\n",
            "  Downloading rl-games-1.6.1.tar.gz (14.6 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML<7.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from rl_games) (6.0.3)\n",
            "Collecting gym<0.24.0,>=0.23.0 (from gym[classic-control]<0.24.0,>=0.23.0->rl_games)\n",
            "  Downloading gym-0.23.1.tar.gz (626 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m626.2/626.2 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opencv-python<5.0.0,>=4.5.5 in /usr/local/lib/python3.12/dist-packages (from rl_games) (4.12.0.88)\n",
            "Requirement already satisfied: psutil<6.0.0,>=5.9.0 in /usr/local/lib/python3.12/dist-packages (from rl_games) (5.9.5)\n",
            "Collecting setproctitle<2.0.0,>=1.2.2 (from rl_games)\n",
            "  Downloading setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: tensorboard<3.0.0,>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from rl_games) (2.19.0)\n",
            "Collecting tensorboardX<3.0,>=2.5 (from rl_games)\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting wandb<0.13.0,>=0.12.11 (from rl_games)\n",
            "  Downloading wandb-0.12.21-py2.py3-none-any.whl.metadata (7.2 kB)\n",
            "INFO: pip is looking at multiple versions of rl-games to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting rl_games\n",
            "  Downloading rl-games-1.6.0.tar.gz (14.7 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading rl_games-1.5.2-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.12/dist-packages (from rl_games) (0.25.2)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from rl_games) (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from rl_games) (2.0.2)\n",
            "Collecting ray>=1.1.0 (from rl_games)\n",
            "  Downloading ray-2.52.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gym>=0.17.2->rl_games) (3.1.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from gym>=0.17.2->rl_games) (0.1.0)\n",
            "Collecting click!=8.3.*,>=7.0 (from ray>=1.1.0->rl_games)\n",
            "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (3.20.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (4.25.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (25.0)\n",
            "Requirement already satisfied: protobuf>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (5.29.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (2.32.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3.0.0,>=2.8.0->rl_games) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3.0.0,>=2.8.0->rl_games) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3.0.0,>=2.8.0->rl_games) (3.10)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3.0.0,>=2.8.0->rl_games) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3.0.0,>=2.8.0->rl_games) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3.0.0,>=2.8.0->rl_games) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3.0.0,>=2.8.0->rl_games) (3.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7.0->rl_games) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard<3.0.0,>=2.8.0->rl_games) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=1.1.0->rl_games) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=1.1.0->rl_games) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=1.1.0->rl_games) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=1.1.0->rl_games) (0.29.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->ray>=1.1.0->rl_games) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->ray>=1.1.0->rl_games) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->ray>=1.1.0->rl_games) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->ray>=1.1.0->rl_games) (2025.11.12)\n",
            "Downloading rl_games-1.5.2-py3-none-any.whl (15.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.52.1-cp312-cp312-manylinux2014_x86_64.whl (72.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.3/72.3 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (32 kB)\n",
            "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX, setproctitle, click, ray, rl_games\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.1\n",
            "    Uninstalling click-8.3.1:\n",
            "      Successfully uninstalled click-8.3.1\n",
            "Successfully installed click-8.2.1 ray-2.52.1 rl_games-1.5.2 setproctitle-1.3.7 tensorboardX-2.6.4\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.23.0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.12.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.46.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "# 1. Setup Environment\n",
        "!git clone https://github.com/dhruv0000/neural-robot-dynamics.git\n",
        "%cd neural-robot-dynamics\n",
        "!pip install -r requirements.txt\n",
        "!pip install warp-lang==1.8.0\n",
        "!pip install rl_games\n",
        "!pip install wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "wandb-setup",
      "metadata": {
        "id": "wandb-setup"
      },
      "outputs": [],
      "source": [
        "# Setup WandB\n",
        "import os\n",
        "import wandb\n",
        "# Assuming wandb_key is defined in the environment variables or you can set it here\n",
        "# For Colab, we can try to get it from userdata or assume it's set\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    os.environ['WANDB_API_KEY'] = userdata.get('wandb_key')\n",
        "except:\n",
        "    os.environ['WANDB_API_KEY'] = 'eb2afd65565d8bc1bb3010bcb082ec1e48de6860'  # Replace with your actual key if not using Colab\n",
        "    pass\n",
        "\n",
        "wandb_project = 'neural-robot-dynamics'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "66700684",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66700684",
        "outputId": "787efd4e-9c11-4df9-8b11-b6a5d2a5f3e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/neural-robot-dynamics/generate\n",
            "Loading datasets from Google Drive...\n",
            "/content/neural-robot-dynamics\n"
          ]
        }
      ],
      "source": [
        "# 2. Generate Dataset\n",
        "# We generate a smaller dataset for demonstration purposes.\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd generate\n",
        "\n",
        "# Define paths\n",
        "drive_data_dir = '/content/drive/MyDrive/neural-robot-dynamics/data/datasets/Cartpole/'\n",
        "local_data_dir = '../data/datasets/Cartpole/'\n",
        "train_filename = 'trajectory_len-100_train.hdf5'\n",
        "valid_filename = 'trajectory_len-100_valid.hdf5'\n",
        "\n",
        "os.makedirs(local_data_dir, exist_ok=True)\n",
        "os.makedirs(drive_data_dir, exist_ok=True)\n",
        "\n",
        "# Check if data exists in Drive\n",
        "if os.path.exists(os.path.join(drive_data_dir, train_filename)) and os.path.exists(os.path.join(drive_data_dir, valid_filename)):\n",
        "    print(\"Loading datasets from Google Drive...\")\n",
        "    shutil.copy(os.path.join(drive_data_dir, train_filename), local_data_dir)\n",
        "    shutil.copy(os.path.join(drive_data_dir, valid_filename), local_data_dir)\n",
        "else:\n",
        "    print(\"Generating datasets...\")\n",
        "    # Generate Training Data\n",
        "    !python generate_dataset_contact_free.py --env-name Cartpole --num-transitions 10000 --dataset-dir ../data/datasets/ --dataset-name trajectory_len-100_train.hdf5 --trajectory-length 100 --num-envs 64 --seed 0\n",
        "\n",
        "    # Generate Validation Data\n",
        "    !python generate_dataset_contact_free.py --env-name Cartpole --num-transitions 2000 --dataset-dir ../data/datasets/ --dataset-name trajectory_len-100_valid.hdf5 --trajectory-length 100 --num-envs 64 --seed 10\n",
        "\n",
        "    print(\"Saving datasets to Google Drive...\")\n",
        "    shutil.copy(os.path.join(local_data_dir, train_filename), drive_data_dir)\n",
        "    shutil.copy(os.path.join(local_data_dir, valid_filename), drive_data_dir)\n",
        "\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d0907b67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0907b67",
        "outputId": "a924d6f3-8f53-411a-99b9-ef7b304cd527"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/neural-robot-dynamics/train\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "2025-12-04 22:12:25.732768: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-04 22:12:25.749949: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764886345.771001    2924 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764886345.777458    2924 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764886345.793835    2924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764886345.793862    2924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764886345.793865    2924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764886345.793868    2924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-04 22:12:25.798698: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 512 environments: 100% 512/512 [00:01<00:00, 311.31it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 20201.26 ms  (compiled)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 606.76 ms  (compiled)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 791.41 ms  (compiled)\n",
            "\u001b[91m [NeuralEnvironment] Created a DUMMY Neural Integrator. \u001b[0m\n",
            "number of parameters: 2.69M\n",
            "Model = \n",
            " ModelMixedInput(\n",
            "  (encoders): ModuleDict(\n",
            "    (low_dim): MLPBase(\n",
            "      (body): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (transformer_model): GPT(\n",
            "    (transformer): ModuleDict(\n",
            "      (wte): Linear(in_features=6, out_features=192, bias=True)\n",
            "      (wpe): Embedding(32, 192)\n",
            "      (drop): Dropout(p=0.0, inplace=False)\n",
            "      (h): ModuleList(\n",
            "        (0-5): 6 x Block(\n",
            "          (ln_1): LayerNorm()\n",
            "          (attn): CausalSelfAttention(\n",
            "            (c_attn): Linear(in_features=192, out_features=576, bias=False)\n",
            "            (c_proj): Linear(in_features=192, out_features=192, bias=False)\n",
            "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ln_2): LayerNorm()\n",
            "          (mlp): MLP(\n",
            "            (c_fc): Linear(in_features=192, out_features=768, bias=False)\n",
            "            (gelu): GELU(approximate='none')\n",
            "            (c_proj): Linear(in_features=768, out_features=192, bias=False)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (ln_f): LayerNorm()\n",
            "    )\n",
            "    (lm_head): Linear(in_features=192, out_features=192, bias=False)\n",
            "  )\n",
            "  (model): MLPDeterministic(\n",
            "    (feature_net): MLPBase(\n",
            "      (body): Sequential(\n",
            "        (0): Linear(in_features=192, out_features=64, bias=True)\n",
            "        (1): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (output_net): Linear(in_features=64, out_features=4, bias=True)\n",
            "  )\n",
            ")\n",
            "# Model Parameters =  2713668\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run k9xalyfq (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run k9xalyfq (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run k9xalyfq (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m setting up run k9xalyfq (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251204_221301-k9xalyfq\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbaseline\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics/runs/k9xalyfq\u001b[0m\n",
            "Computing dataset statistics...\n",
            "Finished computing dataset statistics...\n",
            "100% 11/11 [00:00<00:00, 14.95it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions:   0% 0/4 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 16186.30 ms  (compiled)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 1003.32 ms  (compiled)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 677.47 ms  (compiled)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 3167.84 ms  (compiled)\n",
            "Sampling state transitions: 100% 4/4 [00:21<00:00,  5.33s/it]\n",
            "100% 4/4 [00:00<00:00, 11.11it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.57209951, Rollout MSE Error (joint_q) = 0.01352453 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 0 with MSE error 0.572099506855011. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 0 \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.89327041, itemized = {state_0: 0.00767032, state_1: 0.87654409, state_2: 0.24498109, state_3: 0.27191060, state_MSE: 0.35027654, q_error_norm: 0.28657783, qd_error_norm: 0.52501436} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.456 sec, time(other): 0.001 sec, time(dataloader): 0.198 sec, time(compute_loss): 0.536 sec, time(backward): 0.000 sec, time(eval): 21.714 sec \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 0 with loss 0.89327041. \u001b[0m\n",
            "100% 100/100 [00:03<00:00, 26.68it/s]\n",
            "100% 11/11 [00:00<00:00, 28.82it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.37it/s]\n",
            "100% 4/4 [00:00<00:00, 12.92it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.18445516, Rollout MSE Error (joint_q) = 0.00984979 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 1 with MSE error 0.18445515632629395. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 1 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.33159081, itemized = {state_0: 0.00082707, state_1: 0.22903164, state_2: 0.10785045, state_3: 0.21798109, state_MSE: 0.13892260, q_error_norm: 0.07762634, qd_error_norm: 0.37802166} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.14651204, itemized = {state_0: 0.00023233, state_1: 0.18396141, state_2: 0.04228176, state_3: 0.10556958, state_MSE: 0.08301127, q_error_norm: 0.06071997, qd_error_norm: 0.26486687} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 4.758 sec, time(other): 0.010 sec, time(dataloader): 2.019 sec, time(compute_loss): 0.669 sec, time(backward): 1.414 sec, time(eval): 0.514 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(1.022584, device='cuda:0'), grad_norm_after_clip: tensor(0.862109, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 1 with loss 0.14651204. \u001b[0m\n",
            "100% 100/100 [00:03<00:00, 26.45it/s]\n",
            "100% 11/11 [00:00<00:00, 30.99it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.55it/s]\n",
            "100% 4/4 [00:00<00:00, 12.74it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.26165196, Rollout MSE Error (joint_q) = 0.00229373 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 2 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.08510250, itemized = {state_0: 0.00012810, state_1: 0.09838870, state_2: 0.03149561, state_3: 0.05747058, state_MSE: 0.04687075, q_error_norm: 0.03399091, qd_error_norm: 0.20066610} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.06146759, itemized = {state_0: 0.00008312, state_1: 0.08817113, state_2: 0.02777268, state_3: 0.03683216, state_MSE: 0.03821477, q_error_norm: 0.02867698, qd_error_norm: 0.18495432} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 4.747 sec, time(other): 0.010 sec, time(dataloader): 2.222 sec, time(compute_loss): 0.683 sec, time(backward): 1.204 sec, time(eval): 0.484 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.986182, device='cuda:0'), grad_norm_after_clip: tensor(0.897862, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 2 with loss 0.06146759. \u001b[0m\n",
            "100% 100/100 [00:03<00:00, 25.70it/s]\n",
            "100% 11/11 [00:00<00:00, 31.83it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.79it/s]\n",
            "100% 4/4 [00:00<00:00, 12.96it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.04635350, Rollout MSE Error (joint_q) = 0.00222605 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 3 with MSE error 0.046353500336408615. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 3 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.03775427, itemized = {state_0: 0.00006171, state_1: 0.06169559, state_2: 0.01632282, state_3: 0.02291881, state_MSE: 0.02524974, q_error_norm: 0.02167969, qd_error_norm: 0.13308046} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.03035312, itemized = {state_0: 0.00008998, state_1: 0.07772306, state_2: 0.01134498, state_3: 0.01852274, state_MSE: 0.02692019, q_error_norm: 0.02614069, qd_error_norm: 0.11445640} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 4.866 sec, time(other): 0.010 sec, time(dataloader): 2.282 sec, time(compute_loss): 0.679 sec, time(backward): 1.247 sec, time(eval): 0.510 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(1.029525, device='cuda:0'), grad_norm_after_clip: tensor(0.871393, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 3 with loss 0.03035312. \u001b[0m\n",
            "100% 100/100 [00:03<00:00, 25.88it/s]\n",
            "100% 11/11 [00:00<00:00, 30.74it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.56it/s]\n",
            "100% 4/4 [00:00<00:00, 12.85it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.01970157, Rollout MSE Error (joint_q) = 0.00089371 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 4 with MSE error 0.01970156654715538. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 4 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.01793183, itemized = {state_0: 0.00003591, state_1: 0.04723939, state_2: 0.00756623, state_3: 0.01075230, state_MSE: 0.01639846, q_error_norm: 0.01625545, qd_error_norm: 0.09269730} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.01585614, itemized = {state_0: 0.00002801, state_1: 0.06508502, state_2: 0.00532014, state_3: 0.01116374, state_MSE: 0.02039923, q_error_norm: 0.01831762, qd_error_norm: 0.08626971} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 4.859 sec, time(other): 0.010 sec, time(dataloader): 2.279 sec, time(compute_loss): 0.688 sec, time(backward): 1.227 sec, time(eval): 0.515 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.819624, device='cuda:0'), grad_norm_after_clip: tensor(0.737935, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 4 with loss 0.01585614. \u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading output.log 7.2KB/7.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 5.0KB/5.0KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading output.log 7.2KB/7.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 5.0KB/5.0KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading output.log 7.2KB/7.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 5.0KB/5.0KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading output.log 7.2KB/7.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 5.0KB/5.0KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading output.log 7.2KB/7.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 5.0KB/5.0KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading output.log 7.2KB/7.2KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-summary.json 5.0KB/5.0KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.3KB/2.3KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading output.log 7.2KB/7.2KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-summary.json 5.0KB/5.0KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.3KB/2.3KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading output.log 7.2KB/7.2KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-summary.json 5.0KB/5.0KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.3KB/2.3KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading output.log 7.2KB/7.2KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 5.0KB/5.0KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.3KB/2.3KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading output.log 7.2KB/7.2KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 5.0KB/5.0KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.3KB/2.3KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading history steps 2-4, summary, console lines 33-76 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading history steps 2-4, summary, console lines 33-76 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch ‚ñà‚ñÑ‚ñÖ‚ñÇ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch ‚ñà‚ñÉ‚ñÑ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch ‚ñà‚ñá‚ñÇ‚ñÉ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch ‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch ‚ñà‚ñÑ‚ñÖ‚ñÇ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch ‚ñà‚ñÉ‚ñÑ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch ‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch ‚ñà‚ñÑ‚ñÑ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch ‚ñà‚ñÑ‚ñÑ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch ‚ñà‚ñÑ‚ñÖ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch 0.23082\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch 0.0197\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch 0.03509\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch 0.00089\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch 0.22621\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch 0.03851\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch 0.07448\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch 0.1231\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch 0.15835\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch 0.19118\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mbaseline\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics/runs/k9xalyfq\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251204_221301-k9xalyfq/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 3. Train Baseline Model (Transformer)\n",
        "%cd train\n",
        "\n",
        "import yaml\n",
        "import os\n",
        "\n",
        "# Load default config\n",
        "with open('cfg/Cartpole/transformer.yaml', 'r') as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "\n",
        "# Override dataset paths to point to the generated data\n",
        "cfg['algorithm']['dataset']['train_dataset_path'] = '../data/datasets/Cartpole/trajectory_len-100_train.hdf5'\n",
        "cfg['algorithm']['dataset']['valid_datasets']['exp_trajectory'] = '../data/datasets/Cartpole/trajectory_len-100_valid.hdf5'\n",
        "\n",
        "# Reduce training parameters for quick demonstration\n",
        "cfg['algorithm']['num_epochs'] = 5\n",
        "cfg['algorithm']['num_iters_per_epoch'] = 100\n",
        "\n",
        "# Save the modified config\n",
        "with open('colab_config.yaml', 'w') as f:\n",
        "    yaml.dump(cfg, f)\n",
        "\n",
        "# Run training\n",
        "!python train.py --cfg colab_config.yaml --logdir ../data/logs/baseline --wandb-project {wandb_project} --wandb-name baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c69c48d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c69c48d1",
        "outputId": "9abf6c86-2008-44ed-db18-d16eb773d8c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'train'\n",
            "/content/neural-robot-dynamics/train\n",
            "Configuration updated: num_epochs set to 100.\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "2025-12-05 04:20:29.392972: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-05 04:20:29.409842: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764908429.431209    2584 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764908429.437657    2584 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764908429.454047    2584 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764908429.454076    2584 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764908429.454079    2584 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764908429.454082    2584 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-05 04:20:29.459015: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 512 environments: 100% 512/512 [00:01<00:00, 302.23it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 22295.88 ms  (compiled)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 611.95 ms  (compiled)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 812.61 ms  (compiled)\n",
            "\u001b[91m [NeuralEnvironment] Created a DUMMY Neural Integrator. \u001b[0m\n",
            "Model = \n",
            " ModelMixedInput(\n",
            "  (encoders): ModuleDict(\n",
            "    (low_dim): MLPBase(\n",
            "      (body): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (mamba_model): Mamba(\n",
            "    (embedding): Linear(in_features=6, out_features=192, bias=True)\n",
            "    (layers): ModuleList(\n",
            "      (0-5): 6 x MambaBlock(\n",
            "        (in_proj): Linear(in_features=192, out_features=768, bias=False)\n",
            "        (conv1d): Conv1d(384, 384, kernel_size=(4,), stride=(1,), padding=(3,), groups=384)\n",
            "        (x_proj): Linear(in_features=384, out_features=44, bias=False)\n",
            "        (dt_proj): Linear(in_features=12, out_features=384, bias=True)\n",
            "        (out_proj): Linear(in_features=384, out_features=192, bias=False)\n",
            "      )\n",
            "    )\n",
            "    (norm_f): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (model): MLPDeterministic(\n",
            "    (feature_net): MLPBase(\n",
            "      (body): Sequential(\n",
            "        (0): Linear(in_features=192, out_features=64, bias=True)\n",
            "        (1): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (output_net): Linear(in_features=64, out_features=4, bias=True)\n",
            "  )\n",
            ")\n",
            "# Model Parameters =  1523460\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run 79p99k2a (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run 79p99k2a (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run 79p99k2a (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m setting up run 79p99k2a (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251205_042107-79p99k2a\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics/runs/79p99k2a\u001b[0m\n",
            "Computing dataset statistics...\n",
            "Finished computing dataset statistics...\n",
            "100% 11/11 [00:00<00:00, 12.99it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions:   0% 0/4 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 17228.06 ms  (compiled)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 1039.10 ms  (compiled)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 703.51 ms  (compiled)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 3367.52 ms  (compiled)\n",
            "Sampling state transitions: 100% 4/4 [00:22<00:00,  5.65s/it]\n",
            "100% 4/4 [00:00<00:00,  7.38it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 1.43373585, Rollout MSE Error (joint_q) = 0.06781688 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 0 with MSE error 1.4337358474731445. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 0 \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 1.00439644, itemized = {state_0: 0.00870172, state_1: 0.91801999, state_2: 0.25972505, state_3: 0.32500295, state_MSE: 0.37786241, q_error_norm: 0.30157633, qd_error_norm: 0.58810208} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 24.048 sec, time(other): 0.001 sec, time(dataloader): 0.227 sec, time(compute_loss): 0.618 sec, time(backward): 0.000 sec, time(eval): 23.196 sec \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 0 with loss 1.00439644. \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.24it/s]\n",
            "100% 11/11 [00:00<00:00, 22.94it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.61it/s]\n",
            "100% 4/4 [00:00<00:00,  8.08it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.01028648, Rollout MSE Error (joint_q) = 0.00042889 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 1 with MSE error 0.010286478325724602. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 1 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.15960569, itemized = {state_0: 0.00041083, state_1: 0.11955365, state_2: 0.05958495, state_3: 0.09523325, state_MSE: 0.06869565, q_error_norm: 0.04145229, qd_error_norm: 0.22197483} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.01880515, itemized = {state_0: 0.00003375, state_1: 0.03856158, state_2: 0.00784786, state_3: 0.01119122, state_MSE: 0.01440860, q_error_norm: 0.01479512, qd_error_norm: 0.08790811} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.078 sec, time(other): 0.011 sec, time(dataloader): 4.221 sec, time(compute_loss): 1.713 sec, time(backward): 4.268 sec, time(eval): 0.686 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.357529, device='cuda:0'), grad_norm_after_clip: tensor(0.344295, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 1 with loss 0.01880515. \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.17it/s]\n",
            "100% 11/11 [00:00<00:00, 24.58it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.48it/s]\n",
            "100% 4/4 [00:00<00:00,  8.26it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00622430, Rollout MSE Error (joint_q) = 0.00034123 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 2 with MSE error 0.0062243021093308926. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 2 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00814987, itemized = {state_0: 0.00002001, state_1: 0.04085793, state_2: 0.00339309, state_3: 0.00456803, state_MSE: 0.01220977, q_error_norm: 0.01318524, qd_error_norm: 0.05916314} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00707954, itemized = {state_0: 0.00001319, state_1: 0.04337503, state_2: 0.00224260, state_3: 0.00490016, state_MSE: 0.01263274, q_error_norm: 0.01292721, qd_error_norm: 0.05028357} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.128 sec, time(other): 0.011 sec, time(dataloader): 4.425 sec, time(compute_loss): 1.758 sec, time(backward): 4.052 sec, time(eval): 0.686 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.186105, device='cuda:0'), grad_norm_after_clip: tensor(0.186105, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 2 with loss 0.00707954. \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.01it/s]\n",
            "100% 11/11 [00:00<00:00, 24.29it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.67it/s]\n",
            "100% 4/4 [00:00<00:00,  7.95it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00564273, Rollout MSE Error (joint_q) = 0.00017895 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 3 with MSE error 0.005642732605338097. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 3 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00412390, itemized = {state_0: 0.00000938, state_1: 0.02825082, state_2: 0.00164048, state_3: 0.00241569, state_MSE: 0.00807909, q_error_norm: 0.00947066, qd_error_norm: 0.04235130} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00571838, itemized = {state_0: 0.00000926, state_1: 0.04895463, state_2: 0.00174749, state_3: 0.00415528, state_MSE: 0.01371667, q_error_norm: 0.01278511, qd_error_norm: 0.04556713} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.309 sec, time(other): 0.011 sec, time(dataloader): 4.542 sec, time(compute_loss): 1.809 sec, time(backward): 4.053 sec, time(eval): 0.695 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.189074, device='cuda:0'), grad_norm_after_clip: tensor(0.189074, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 3 with loss 0.00571838. \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.10it/s]\n",
            "100% 11/11 [00:00<00:00, 25.01it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.40it/s]\n",
            "100% 4/4 [00:00<00:00,  7.86it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00101372, Rollout MSE Error (joint_q) = 0.00007924 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 4 with MSE error 0.0010137228528037667. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 4 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00190208, itemized = {state_0: 0.00000585, state_1: 0.02341342, state_2: 0.00068107, state_3: 0.00109232, state_MSE: 0.00629816, q_error_norm: 0.00770630, qd_error_norm: 0.02977268} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00395867, itemized = {state_0: 0.00000628, state_1: 0.04054648, state_2: 0.00129455, state_3: 0.00281990, state_MSE: 0.01116680, q_error_norm: 0.01043818, qd_error_norm: 0.03174248} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.199 sec, time(other): 0.011 sec, time(dataloader): 4.479 sec, time(compute_loss): 1.753 sec, time(backward): 4.063 sec, time(eval): 0.703 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.108665, device='cuda:0'), grad_norm_after_clip: tensor(0.108665, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 4 with loss 0.00395867. \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.01it/s]\n",
            "100% 11/11 [00:00<00:00, 22.59it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.42it/s]\n",
            "100% 4/4 [00:00<00:00,  8.20it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00258426, Rollout MSE Error (joint_q) = 0.00013089 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 5 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00436829, itemized = {state_0: 0.00000592, state_1: 0.02387729, state_2: 0.00168114, state_3: 0.00290922, state_MSE: 0.00711839, q_error_norm: 0.00773087, qd_error_norm: 0.03942255} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00938347, itemized = {state_0: 0.00000855, state_1: 0.04266949, state_2: 0.00293529, state_3: 0.00723434, state_MSE: 0.01321191, q_error_norm: 0.01156847, qd_error_norm: 0.05168683} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.308 sec, time(other): 0.011 sec, time(dataloader): 4.547 sec, time(compute_loss): 1.826 sec, time(backward): 4.065 sec, time(eval): 0.659 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.243364, device='cuda:0'), grad_norm_after_clip: tensor(0.243364, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.18it/s]\n",
            "100% 11/11 [00:00<00:00, 24.01it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.69it/s]\n",
            "100% 4/4 [00:00<00:00,  8.12it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00066386, Rollout MSE Error (joint_q) = 0.00006222 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 6 with MSE error 0.0006638583145104349. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 6 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00203289, itemized = {state_0: 0.00000484, state_1: 0.02233842, state_2: 0.00075974, state_3: 0.00124122, state_MSE: 0.00608605, q_error_norm: 0.00706063, qd_error_norm: 0.02805228} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00271150, itemized = {state_0: 0.00000458, state_1: 0.03494656, state_2: 0.00067362, state_3: 0.00212531, state_MSE: 0.00943752, q_error_norm: 0.00898603, qd_error_norm: 0.02417921} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.149 sec, time(other): 0.011 sec, time(dataloader): 4.436 sec, time(compute_loss): 1.712 sec, time(backward): 4.093 sec, time(eval): 0.685 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.101941, device='cuda:0'), grad_norm_after_clip: tensor(0.101941, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 6 with loss 0.00271150. \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.13it/s]\n",
            "100% 11/11 [00:00<00:00, 24.31it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.01it/s]\n",
            "100% 4/4 [00:00<00:00,  7.57it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00053173, Rollout MSE Error (joint_q) = 0.00004931 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 7 with MSE error 0.0005317269242368639. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 7 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00066453, itemized = {state_0: 0.00000292, state_1: 0.01672280, state_2: 0.00021367, state_3: 0.00035263, state_MSE: 0.00432301, q_error_norm: 0.00545320, qd_error_norm: 0.01798892} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00270066, itemized = {state_0: 0.00000406, state_1: 0.03705338, state_2: 0.00069050, state_3: 0.00213622, state_MSE: 0.00997104, q_error_norm: 0.00903708, qd_error_norm: 0.02291676} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.210 sec, time(other): 0.011 sec, time(dataloader): 4.474 sec, time(compute_loss): 1.757 sec, time(backward): 4.056 sec, time(eval): 0.720 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.041661, device='cuda:0'), grad_norm_after_clip: tensor(0.041661, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 7 with loss 0.00270066. \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.95it/s]\n",
            "100% 11/11 [00:00<00:00, 24.66it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.76it/s]\n",
            "100% 4/4 [00:00<00:00,  8.11it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00051668, Rollout MSE Error (joint_q) = 0.00004047 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 8 with MSE error 0.0005166800110600889. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 8 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00057464, itemized = {state_0: 0.00000246, state_1: 0.01448769, state_2: 0.00019152, state_3: 0.00030347, state_MSE: 0.00374628, q_error_norm: 0.00486275, qd_error_norm: 0.01655966} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00249690, itemized = {state_0: 0.00000351, state_1: 0.03845926, state_2: 0.00059992, state_3: 0.00201855, state_MSE: 0.01027031, q_error_norm: 0.00907975, qd_error_norm: 0.02199553} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.349 sec, time(other): 0.011 sec, time(dataloader): 4.544 sec, time(compute_loss): 1.836 sec, time(backward): 4.077 sec, time(eval): 0.683 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.040395, device='cuda:0'), grad_norm_after_clip: tensor(0.040395, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 8 with loss 0.00249690. \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.01it/s]\n",
            "100% 11/11 [00:00<00:00, 24.89it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.19it/s]\n",
            "100% 4/4 [00:00<00:00,  8.21it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00528236, Rollout MSE Error (joint_q) = 0.00007110 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 9 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00181335, itemized = {state_0: 0.00000283, state_1: 0.01487261, state_2: 0.00079866, state_3: 0.00108245, state_MSE: 0.00418914, q_error_norm: 0.00501960, qd_error_norm: 0.02429984} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00787108, itemized = {state_0: 0.00000666, state_1: 0.03427875, state_2: 0.00346909, state_3: 0.00502061, state_MSE: 0.01069377, q_error_norm: 0.00957135, qd_error_norm: 0.04692879} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.255 sec, time(other): 0.011 sec, time(dataloader): 4.532 sec, time(compute_loss): 1.802 sec, time(backward): 4.059 sec, time(eval): 0.654 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.127984, device='cuda:0'), grad_norm_after_clip: tensor(0.127984, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.02it/s]\n",
            "100% 11/11 [00:00<00:00, 23.22it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.32it/s]\n",
            "100% 4/4 [00:00<00:00,  7.63it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00074757, Rollout MSE Error (joint_q) = 0.00003820 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 10 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00144704, itemized = {state_0: 0.00000311, state_1: 0.01548983, state_2: 0.00056381, state_3: 0.00089000, state_MSE: 0.00423668, q_error_norm: 0.00523235, qd_error_norm: 0.02385933} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00276809, itemized = {state_0: 0.00000344, state_1: 0.03425605, state_2: 0.00068441, state_3: 0.00226350, state_MSE: 0.00930185, q_error_norm: 0.00832358, qd_error_norm: 0.02251903} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.316 sec, time(other): 0.011 sec, time(dataloader): 4.524 sec, time(compute_loss): 1.818 sec, time(backward): 4.068 sec, time(eval): 0.696 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.103063, device='cuda:0'), grad_norm_after_clip: tensor(0.103063, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.03it/s]\n",
            "100% 11/11 [00:00<00:00, 24.86it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.83it/s]\n",
            "100% 4/4 [00:00<00:00,  8.19it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00025387, Rollout MSE Error (joint_q) = 0.00002080 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 11 with MSE error 0.0002538688131608069. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 11 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00052788, itemized = {state_0: 0.00000195, state_1: 0.01148591, state_2: 0.00017605, state_3: 0.00030327, state_MSE: 0.00299179, q_error_norm: 0.00405719, qd_error_norm: 0.01589598} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00251101, itemized = {state_0: 0.00000294, state_1: 0.03007081, state_2: 0.00067567, state_3: 0.00200490, state_MSE: 0.00818858, q_error_norm: 0.00734599, qd_error_norm: 0.01966836} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.249 sec, time(other): 0.011 sec, time(dataloader): 4.476 sec, time(compute_loss): 1.797 sec, time(backward): 4.093 sec, time(eval): 0.686 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.059809, device='cuda:0'), grad_norm_after_clip: tensor(0.059809, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.12it/s]\n",
            "100% 11/11 [00:00<00:00, 23.67it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.18it/s]\n",
            "100% 4/4 [00:00<00:00,  8.21it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00048707, Rollout MSE Error (joint_q) = 0.00002592 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 12 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00039894, itemized = {state_0: 0.00000164, state_1: 0.01125485, state_2: 0.00011936, state_3: 0.00023185, state_MSE: 0.00290192, q_error_norm: 0.00385664, qd_error_norm: 0.01416551} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00229170, itemized = {state_0: 0.00000286, state_1: 0.02726108, state_2: 0.00058055, state_3: 0.00185296, state_MSE: 0.00742436, q_error_norm: 0.00683773, qd_error_norm: 0.01880225} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.183 sec, time(other): 0.011 sec, time(dataloader): 4.403 sec, time(compute_loss): 1.767 sec, time(backward): 4.135 sec, time(eval): 0.668 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.046564, device='cuda:0'), grad_norm_after_clip: tensor(0.046564, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 12 with loss 0.00229170. \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.09it/s]\n",
            "100% 11/11 [00:00<00:00, 24.13it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.78it/s]\n",
            "100% 4/4 [00:00<00:00,  7.71it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00027780, Rollout MSE Error (joint_q) = 0.00002617 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 13 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00039524, itemized = {state_0: 0.00000152, state_1: 0.01110019, state_2: 0.00012178, state_3: 0.00023272, state_MSE: 0.00286405, q_error_norm: 0.00375532, qd_error_norm: 0.01397752} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00229348, itemized = {state_0: 0.00000290, state_1: 0.02656706, state_2: 0.00059518, state_3: 0.00184596, state_MSE: 0.00725278, q_error_norm: 0.00674179, qd_error_norm: 0.01828030} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.220 sec, time(other): 0.011 sec, time(dataloader): 4.523 sec, time(compute_loss): 1.755 sec, time(backward): 4.051 sec, time(eval): 0.688 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.048134, device='cuda:0'), grad_norm_after_clip: tensor(0.048134, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.01it/s]\n",
            "100% 11/11 [00:00<00:00, 24.06it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.68it/s]\n",
            "100% 4/4 [00:00<00:00,  8.15it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00119362, Rollout MSE Error (joint_q) = 0.00003193 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 14 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00069622, itemized = {state_0: 0.00000156, state_1: 0.01140839, state_2: 0.00023443, state_3: 0.00045659, state_MSE: 0.00302524, q_error_norm: 0.00389990, qd_error_norm: 0.01750798} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00261100, itemized = {state_0: 0.00000280, state_1: 0.03218563, state_2: 0.00057034, state_3: 0.00224203, state_MSE: 0.00875020, q_error_norm: 0.00749910, qd_error_norm: 0.02134986} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.278 sec, time(other): 0.011 sec, time(dataloader): 4.495 sec, time(compute_loss): 1.814 sec, time(backward): 4.101 sec, time(eval): 0.660 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.087670, device='cuda:0'), grad_norm_after_clip: tensor(0.087670, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.02it/s]\n",
            "100% 11/11 [00:00<00:00, 22.87it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.32it/s]\n",
            "100% 4/4 [00:00<00:00,  8.18it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00091982, Rollout MSE Error (joint_q) = 0.00002901 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 15 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00045509, itemized = {state_0: 0.00000138, state_1: 0.00925017, state_2: 0.00014594, state_3: 0.00028477, state_MSE: 0.00242057, q_error_norm: 0.00338400, qd_error_norm: 0.01466074} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00227137, itemized = {state_0: 0.00000264, state_1: 0.02237880, state_2: 0.00054870, state_3: 0.00188381, state_MSE: 0.00620349, q_error_norm: 0.00594973, qd_error_norm: 0.01900773} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.277 sec, time(other): 0.011 sec, time(dataloader): 4.478 sec, time(compute_loss): 1.816 sec, time(backward): 4.121 sec, time(eval): 0.662 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.061224, device='cuda:0'), grad_norm_after_clip: tensor(0.061224, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 15 with loss 0.00227137. \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.14it/s]\n",
            "100% 11/11 [00:00<00:00, 23.15it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.36it/s]\n",
            "100% 4/4 [00:00<00:00,  7.66it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00148224, Rollout MSE Error (joint_q) = 0.00005589 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 16 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00072159, itemized = {state_0: 0.00000157, state_1: 0.01079114, state_2: 0.00025829, state_3: 0.00046715, state_MSE: 0.00287954, q_error_norm: 0.00371335, qd_error_norm: 0.01790681} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00266330, itemized = {state_0: 0.00000305, state_1: 0.03570386, state_2: 0.00068301, state_3: 0.00218114, state_MSE: 0.00964276, q_error_norm: 0.00817152, qd_error_norm: 0.02296611} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.202 sec, time(other): 0.011 sec, time(dataloader): 4.515 sec, time(compute_loss): 1.739 sec, time(backward): 4.043 sec, time(eval): 0.693 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.096571, device='cuda:0'), grad_norm_after_clip: tensor(0.096571, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.02it/s]\n",
            "100% 11/11 [00:00<00:00, 23.91it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.84it/s]\n",
            "100% 4/4 [00:00<00:00,  8.12it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00104740, Rollout MSE Error (joint_q) = 0.00003841 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 17 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00133265, itemized = {state_0: 0.00000221, state_1: 0.01333152, state_2: 0.00050501, state_3: 0.00087215, state_MSE: 0.00367772, q_error_norm: 0.00452785, qd_error_norm: 0.02308581} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00354139, itemized = {state_0: 0.00000281, state_1: 0.02519210, state_2: 0.00120637, state_3: 0.00265378, state_MSE: 0.00726377, q_error_norm: 0.00642557, qd_error_norm: 0.02524525} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.270 sec, time(other): 0.011 sec, time(dataloader): 4.510 sec, time(compute_loss): 1.805 sec, time(backward): 4.087 sec, time(eval): 0.660 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.129869, device='cuda:0'), grad_norm_after_clip: tensor(0.129869, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.15it/s]\n",
            "100% 11/11 [00:00<00:00, 23.90it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.54it/s]\n",
            "100% 4/4 [00:00<00:00,  8.16it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00021880, Rollout MSE Error (joint_q) = 0.00001361 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 18 with MSE error 0.00021880293206777424. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 18 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00041194, itemized = {state_0: 0.00000132, state_1: 0.01163824, state_2: 0.00013596, state_3: 0.00025042, state_MSE: 0.00300649, q_error_norm: 0.00369492, qd_error_norm: 0.01348465} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00204554, itemized = {state_0: 0.00000211, state_1: 0.02729020, state_2: 0.00051450, state_3: 0.00168794, state_MSE: 0.00737369, q_error_norm: 0.00648944, qd_error_norm: 0.01588603} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.154 sec, time(other): 0.011 sec, time(dataloader): 4.437 sec, time(compute_loss): 1.739 sec, time(backward): 4.095 sec, time(eval): 0.683 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.049092, device='cuda:0'), grad_norm_after_clip: tensor(0.049092, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 18 with loss 0.00204554. \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.04it/s]\n",
            "100% 11/11 [00:00<00:00, 24.18it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.50it/s]\n",
            "100% 4/4 [00:00<00:00,  7.56it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00043173, Rollout MSE Error (joint_q) = 0.00001915 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 19 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00024248, itemized = {state_0: 0.00000099, state_1: 0.01032959, state_2: 0.00007693, state_3: 0.00013518, state_MSE: 0.00263567, q_error_norm: 0.00327616, qd_error_norm: 0.01087656} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00231959, itemized = {state_0: 0.00000225, state_1: 0.02239030, state_2: 0.00057153, state_3: 0.00194229, state_MSE: 0.00622659, q_error_norm: 0.00568802, qd_error_norm: 0.01734618} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.281 sec, time(other): 0.011 sec, time(dataloader): 4.545 sec, time(compute_loss): 1.788 sec, time(backward): 4.040 sec, time(eval): 0.700 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.036912, device='cuda:0'), grad_norm_after_clip: tensor(0.036912, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.91it/s]\n",
            "100% 11/11 [00:00<00:00, 23.73it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.44it/s]\n",
            "100% 4/4 [00:00<00:00,  7.99it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00026365, Rollout MSE Error (joint_q) = 0.00001340 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 20 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00024382, itemized = {state_0: 0.00000096, state_1: 0.01048462, state_2: 0.00007600, state_3: 0.00014150, state_MSE: 0.00267577, q_error_norm: 0.00324677, qd_error_norm: 0.01090973} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00232143, itemized = {state_0: 0.00000224, state_1: 0.02028463, state_2: 0.00063232, state_3: 0.00188932, state_MSE: 0.00570213, q_error_norm: 0.00521231, qd_error_norm: 0.01703934} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.405 sec, time(other): 0.012 sec, time(dataloader): 4.568 sec, time(compute_loss): 1.863 sec, time(backward): 4.082 sec, time(eval): 0.671 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.038933, device='cuda:0'), grad_norm_after_clip: tensor(0.038933, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.95it/s]\n",
            "100% 11/11 [00:00<00:00, 24.05it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.92it/s]\n",
            "100% 4/4 [00:00<00:00,  8.20it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00158778, Rollout MSE Error (joint_q) = 0.00010204 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 21 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00114769, itemized = {state_0: 0.00000169, state_1: 0.01487379, state_2: 0.00042065, state_3: 0.00076637, state_MSE: 0.00401563, q_error_norm: 0.00466988, qd_error_norm: 0.02098227} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00332720, itemized = {state_0: 0.00000273, state_1: 0.02380685, state_2: 0.00090150, state_3: 0.00270857, state_MSE: 0.00685491, q_error_norm: 0.00646216, qd_error_norm: 0.02424359} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.339 sec, time(other): 0.011 sec, time(dataloader): 4.548 sec, time(compute_loss): 1.851 sec, time(backward): 4.070 sec, time(eval): 0.656 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.121192, device='cuda:0'), grad_norm_after_clip: tensor(0.121192, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.13it/s]\n",
            "100% 11/11 [00:00<00:00, 23.88it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.71it/s]\n",
            "100% 4/4 [00:00<00:00,  7.65it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00232467, Rollout MSE Error (joint_q) = 0.00004884 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 22 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00066864, itemized = {state_0: 0.00000129, state_1: 0.01263876, state_2: 0.00024150, state_3: 0.00043011, state_MSE: 0.00332791, q_error_norm: 0.00396626, qd_error_norm: 0.01651714} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00280942, itemized = {state_0: 0.00000245, state_1: 0.03360597, state_2: 0.00076984, state_3: 0.00227711, state_MSE: 0.00916384, q_error_norm: 0.00779801, qd_error_norm: 0.02518412} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.187 sec, time(other): 0.011 sec, time(dataloader): 4.469 sec, time(compute_loss): 1.748 sec, time(backward): 4.071 sec, time(eval): 0.693 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.081894, device='cuda:0'), grad_norm_after_clip: tensor(0.081894, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.99it/s]\n",
            "100% 11/11 [00:00<00:00, 24.06it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.60it/s]\n",
            "100% 4/4 [00:00<00:00,  8.23it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00030527, Rollout MSE Error (joint_q) = 0.00001346 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 23 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00053624, itemized = {state_0: 0.00000116, state_1: 0.01279356, state_2: 0.00018869, state_3: 0.00034248, state_MSE: 0.00333147, q_error_norm: 0.00387227, qd_error_norm: 0.01501839} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00259847, itemized = {state_0: 0.00000200, state_1: 0.02099143, state_2: 0.00057905, state_3: 0.00227867, state_MSE: 0.00596279, q_error_norm: 0.00534475, qd_error_norm: 0.01718560} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.300 sec, time(other): 0.011 sec, time(dataloader): 4.563 sec, time(compute_loss): 1.802 sec, time(backward): 4.060 sec, time(eval): 0.655 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.068808, device='cuda:0'), grad_norm_after_clip: tensor(0.068808, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.10it/s]\n",
            "100% 11/11 [00:00<00:00, 22.07it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.51it/s]\n",
            "100% 4/4 [00:00<00:00,  8.10it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00016460, Rollout MSE Error (joint_q) = 0.00002268 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 24 with MSE error 0.00016460104961879551. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 24 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00024848, itemized = {state_0: 0.00000084, state_1: 0.01148516, state_2: 0.00008124, state_3: 0.00014780, state_MSE: 0.00292876, q_error_norm: 0.00332778, qd_error_norm: 0.01074654} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00231240, itemized = {state_0: 0.00000198, state_1: 0.01538824, state_2: 0.00059998, state_3: 0.00192663, state_MSE: 0.00447921, q_error_norm: 0.00439503, qd_error_norm: 0.01504633} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.263 sec, time(other): 0.011 sec, time(dataloader): 4.478 sec, time(compute_loss): 1.772 sec, time(backward): 4.104 sec, time(eval): 0.687 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.039724, device='cuda:0'), grad_norm_after_clip: tensor(0.039724, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.10it/s]\n",
            "100% 11/11 [00:00<00:00, 23.57it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.74it/s]\n",
            "100% 4/4 [00:00<00:00,  7.50it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00033794, Rollout MSE Error (joint_q) = 0.00001166 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 25 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00022323, itemized = {state_0: 0.00000078, state_1: 0.01241040, state_2: 0.00007334, state_3: 0.00013026, state_MSE: 0.00315370, q_error_norm: 0.00343315, qd_error_norm: 0.01010017} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00239934, itemized = {state_0: 0.00000185, state_1: 0.01819801, state_2: 0.00068891, state_3: 0.00193844, state_MSE: 0.00520680, q_error_norm: 0.00473815, qd_error_norm: 0.01622182} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.240 sec, time(other): 0.011 sec, time(dataloader): 4.520 sec, time(compute_loss): 1.768 sec, time(backward): 4.035 sec, time(eval): 0.705 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.040214, device='cuda:0'), grad_norm_after_clip: tensor(0.040214, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.95it/s]\n",
            "100% 11/11 [00:00<00:00, 24.73it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.67it/s]\n",
            "100% 4/4 [00:00<00:00,  7.98it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00024526, Rollout MSE Error (joint_q) = 0.00001599 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 26 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00027181, itemized = {state_0: 0.00000080, state_1: 0.01056039, state_2: 0.00008559, state_3: 0.00017186, state_MSE: 0.00270466, q_error_norm: 0.00317365, qd_error_norm: 0.01125262} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00223378, itemized = {state_0: 0.00000189, state_1: 0.01470942, state_2: 0.00065836, state_3: 0.00176637, state_MSE: 0.00428401, q_error_norm: 0.00434076, qd_error_norm: 0.01535389} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.341 sec, time(other): 0.011 sec, time(dataloader): 4.556 sec, time(compute_loss): 1.837 sec, time(backward): 4.059 sec, time(eval): 0.677 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.046384, device='cuda:0'), grad_norm_after_clip: tensor(0.046384, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.90it/s]\n",
            "100% 11/11 [00:00<00:00, 23.72it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.73it/s]\n",
            "100% 4/4 [00:00<00:00,  8.07it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00278426, Rollout MSE Error (joint_q) = 0.00005791 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 27 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00064927, itemized = {state_0: 0.00000106, state_1: 0.01225449, state_2: 0.00024332, state_3: 0.00042387, state_MSE: 0.00323069, q_error_norm: 0.00372069, qd_error_norm: 0.01547146} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00506239, itemized = {state_0: 0.00000307, state_1: 0.01819780, state_2: 0.00156291, state_3: 0.00401982, state_MSE: 0.00594590, q_error_norm: 0.00557049, qd_error_norm: 0.03269226} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.392 sec, time(other): 0.011 sec, time(dataloader): 4.559 sec, time(compute_loss): 1.848 sec, time(backward): 4.110 sec, time(eval): 0.664 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.087475, device='cuda:0'), grad_norm_after_clip: tensor(0.087475, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.91it/s]\n",
            "100% 11/11 [00:00<00:00, 24.91it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.33it/s]\n",
            "100% 4/4 [00:00<00:00,  7.79it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00056587, Rollout MSE Error (joint_q) = 0.00002054 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 28 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00213884, itemized = {state_0: 0.00000271, state_1: 0.01940990, state_2: 0.00083780, state_3: 0.00140951, state_MSE: 0.00541498, q_error_norm: 0.00581569, qd_error_norm: 0.02696212} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00237702, itemized = {state_0: 0.00000207, state_1: 0.02171292, state_2: 0.00065863, state_3: 0.00191893, state_MSE: 0.00607314, q_error_norm: 0.00566087, qd_error_norm: 0.01793190} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.391 sec, time(other): 0.011 sec, time(dataloader): 4.604 sec, time(compute_loss): 1.812 sec, time(backward): 4.072 sec, time(eval): 0.685 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.140570, device='cuda:0'), grad_norm_after_clip: tensor(0.140570, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.95it/s]\n",
            "100% 11/11 [00:00<00:00, 24.13it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.41it/s]\n",
            "100% 4/4 [00:00<00:00,  8.16it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00013416, Rollout MSE Error (joint_q) = 0.00002491 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 29 with MSE error 0.00013416146975941956. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 29 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00038457, itemized = {state_0: 0.00000093, state_1: 0.01264111, state_2: 0.00014657, state_3: 0.00022730, state_MSE: 0.00325398, q_error_norm: 0.00365469, qd_error_norm: 0.01247042} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00251933, itemized = {state_0: 0.00000178, state_1: 0.01469913, state_2: 0.00066546, state_3: 0.00210392, state_MSE: 0.00436757, q_error_norm: 0.00424654, qd_error_norm: 0.01677278} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.353 sec, time(other): 0.011 sec, time(dataloader): 4.535 sec, time(compute_loss): 1.822 sec, time(backward): 4.102 sec, time(eval): 0.682 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.058287, device='cuda:0'), grad_norm_after_clip: tensor(0.058287, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.97it/s]\n",
            "100% 11/11 [00:00<00:00, 24.26it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.65it/s]\n",
            "100% 4/4 [00:00<00:00,  8.18it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00027922, Rollout MSE Error (joint_q) = 0.00000686 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 30 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00028255, itemized = {state_0: 0.00000078, state_1: 0.01348912, state_2: 0.00010128, state_3: 0.00016816, state_MSE: 0.00343984, q_error_norm: 0.00363468, qd_error_norm: 0.01103724} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00217827, itemized = {state_0: 0.00000159, state_1: 0.01679640, state_2: 0.00054720, state_3: 0.00185011, state_MSE: 0.00479882, q_error_norm: 0.00441493, qd_error_norm: 0.01550872} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.321 sec, time(other): 0.011 sec, time(dataloader): 4.523 sec, time(compute_loss): 1.832 sec, time(backward): 4.091 sec, time(eval): 0.658 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.047022, device='cuda:0'), grad_norm_after_clip: tensor(0.047022, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.06it/s]\n",
            "100% 11/11 [00:00<00:00, 24.15it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.34it/s]\n",
            "100% 4/4 [00:00<00:00,  7.86it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00015140, Rollout MSE Error (joint_q) = 0.00001485 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 31 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00021118, itemized = {state_0: 0.00000066, state_1: 0.01179303, state_2: 0.00007142, state_3: 0.00012397, state_MSE: 0.00299727, q_error_norm: 0.00326175, qd_error_norm: 0.00970724} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00213652, itemized = {state_0: 0.00000152, state_1: 0.01609703, state_2: 0.00055900, state_3: 0.00178782, state_MSE: 0.00461135, q_error_norm: 0.00427092, qd_error_norm: 0.01382860} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.236 sec, time(other): 0.011 sec, time(dataloader): 4.521 sec, time(compute_loss): 1.756 sec, time(backward): 4.075 sec, time(eval): 0.681 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.038087, device='cuda:0'), grad_norm_after_clip: tensor(0.038087, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.99it/s]\n",
            "100% 11/11 [00:00<00:00, 23.68it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.41it/s]\n",
            "100% 4/4 [00:00<00:00,  8.13it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00020339, Rollout MSE Error (joint_q) = 0.00001018 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 32 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00018291, itemized = {state_0: 0.00000061, state_1: 0.01048359, state_2: 0.00006339, state_3: 0.00010459, state_MSE: 0.00266305, q_error_norm: 0.00296935, qd_error_norm: 0.00922016} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00198294, itemized = {state_0: 0.00000142, state_1: 0.01820714, state_2: 0.00054373, state_3: 0.00163301, state_MSE: 0.00509632, q_error_norm: 0.00457641, qd_error_norm: 0.01395254} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.298 sec, time(other): 0.011 sec, time(dataloader): 4.576 sec, time(compute_loss): 1.808 sec, time(backward): 4.049 sec, time(eval): 0.662 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.037485, device='cuda:0'), grad_norm_after_clip: tensor(0.037485, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 32 with loss 0.00198294. \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.92it/s]\n",
            "100% 11/11 [00:00<00:00, 24.26it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.77it/s]\n",
            "100% 4/4 [00:00<00:00,  8.16it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00012742, Rollout MSE Error (joint_q) = 0.00001168 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 33 with MSE error 0.00012741585669573396. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 33 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00014067, itemized = {state_0: 0.00000055, state_1: 0.01094635, state_2: 0.00003970, state_3: 0.00008530, state_MSE: 0.00276797, q_error_norm: 0.00295683, qd_error_norm: 0.00827991} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00210849, itemized = {state_0: 0.00000146, state_1: 0.02380301, state_2: 0.00060338, state_3: 0.00171638, state_MSE: 0.00653106, q_error_norm: 0.00547978, qd_error_norm: 0.01411165} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.385 sec, time(other): 0.011 sec, time(dataloader): 4.579 sec, time(compute_loss): 1.840 sec, time(backward): 4.069 sec, time(eval): 0.681 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.024112, device='cuda:0'), grad_norm_after_clip: tensor(0.024112, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.12it/s]\n",
            "100% 11/11 [00:00<00:00, 23.14it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.15it/s]\n",
            "100% 4/4 [00:00<00:00,  7.95it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00059254, Rollout MSE Error (joint_q) = 0.00002243 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 34 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00040480, itemized = {state_0: 0.00000082, state_1: 0.01225577, state_2: 0.00016123, state_3: 0.00024179, state_MSE: 0.00316490, q_error_norm: 0.00351186, qd_error_norm: 0.01248295} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00202363, itemized = {state_0: 0.00000161, state_1: 0.01470023, state_2: 0.00056145, state_3: 0.00166215, state_MSE: 0.00423136, q_error_norm: 0.00408406, qd_error_norm: 0.01657535} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.210 sec, time(other): 0.011 sec, time(dataloader): 4.489 sec, time(compute_loss): 1.760 sec, time(backward): 4.062 sec, time(eval): 0.691 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.065176, device='cuda:0'), grad_norm_after_clip: tensor(0.065176, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.03it/s]\n",
            "100% 11/11 [00:00<00:00, 24.23it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.31it/s]\n",
            "100% 4/4 [00:00<00:00,  8.05it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00030657, Rollout MSE Error (joint_q) = 0.00000913 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 35 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00016381, itemized = {state_0: 0.00000059, state_1: 0.01133127, state_2: 0.00005319, state_3: 0.00009520, state_MSE: 0.00287006, q_error_norm: 0.00306062, qd_error_norm: 0.00856188} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00215202, itemized = {state_0: 0.00000135, state_1: 0.02101036, state_2: 0.00061491, state_3: 0.00175877, state_MSE: 0.00584635, q_error_norm: 0.00505645, qd_error_norm: 0.01499662} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.259 sec, time(other): 0.011 sec, time(dataloader): 4.483 sec, time(compute_loss): 1.776 sec, time(backward): 4.117 sec, time(eval): 0.669 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.030295, device='cuda:0'), grad_norm_after_clip: tensor(0.030295, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.95it/s]\n",
            "100% 11/11 [00:00<00:00, 24.17it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.24it/s]\n",
            "100% 4/4 [00:00<00:00,  8.09it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00110493, Rollout MSE Error (joint_q) = 0.00000961 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 36 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00036083, itemized = {state_0: 0.00000072, state_1: 0.01225499, state_2: 0.00014774, state_3: 0.00021424, state_MSE: 0.00315442, q_error_norm: 0.00335989, qd_error_norm: 0.01199599} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00248490, itemized = {state_0: 0.00000195, state_1: 0.01749788, state_2: 0.00069275, state_3: 0.00203391, state_MSE: 0.00505662, q_error_norm: 0.00459213, qd_error_norm: 0.01754530} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.339 sec, time(other): 0.011 sec, time(dataloader): 4.546 sec, time(compute_loss): 1.818 sec, time(backward): 4.096 sec, time(eval): 0.668 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.062546, device='cuda:0'), grad_norm_after_clip: tensor(0.062546, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.14it/s]\n",
            "100% 11/11 [00:00<00:00, 23.72it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.32it/s]\n",
            "100% 4/4 [00:00<00:00,  7.92it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00061777, Rollout MSE Error (joint_q) = 0.00002163 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 37 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00080788, itemized = {state_0: 0.00000112, state_1: 0.01209984, state_2: 0.00029811, state_3: 0.00054506, state_MSE: 0.00323603, q_error_norm: 0.00375412, qd_error_norm: 0.01796933} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00276376, itemized = {state_0: 0.00000218, state_1: 0.03641178, state_2: 0.00100035, state_3: 0.00202042, state_MSE: 0.00985868, q_error_norm: 0.00798135, qd_error_norm: 0.01876092} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.166 sec, time(other): 0.011 sec, time(dataloader): 4.506 sec, time(compute_loss): 1.756 sec, time(backward): 4.025 sec, time(eval): 0.677 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.093275, device='cuda:0'), grad_norm_after_clip: tensor(0.093275, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.97it/s]\n",
            "100% 11/11 [00:00<00:00, 24.64it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.58it/s]\n",
            "100% 4/4 [00:00<00:00,  8.17it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00039235, Rollout MSE Error (joint_q) = 0.00003671 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 38 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00031159, itemized = {state_0: 0.00000068, state_1: 0.01217783, state_2: 0.00010641, state_3: 0.00019961, state_MSE: 0.00312113, q_error_norm: 0.00339197, qd_error_norm: 0.01131269} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00223155, itemized = {state_0: 0.00000128, state_1: 0.01470482, state_2: 0.00059132, state_3: 0.00187601, state_MSE: 0.00429336, q_error_norm: 0.00408469, qd_error_norm: 0.01416553} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.302 sec, time(other): 0.011 sec, time(dataloader): 4.533 sec, time(compute_loss): 1.820 sec, time(backward): 4.079 sec, time(eval): 0.659 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.049802, device='cuda:0'), grad_norm_after_clip: tensor(0.049802, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.97it/s]\n",
            "100% 11/11 [00:00<00:00, 24.12it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.40it/s]\n",
            "100% 4/4 [00:00<00:00,  8.13it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00007870, Rollout MSE Error (joint_q) = 0.00000570 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 39 with MSE error 7.870317494962364e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 39 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00011070, itemized = {state_0: 0.00000046, state_1: 0.01079274, state_2: 0.00003410, state_3: 0.00006196, state_MSE: 0.00272231, q_error_norm: 0.00283327, qd_error_norm: 0.00730121} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00214461, itemized = {state_0: 0.00000121, state_1: 0.01260098, state_2: 0.00058368, state_3: 0.00179652, state_MSE: 0.00374560, q_error_norm: 0.00347783, qd_error_norm: 0.01237936} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.346 sec, time(other): 0.011 sec, time(dataloader): 4.556 sec, time(compute_loss): 1.804 sec, time(backward): 4.084 sec, time(eval): 0.683 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.021529, device='cuda:0'), grad_norm_after_clip: tensor(0.021529, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.10it/s]\n",
            "100% 11/11 [00:00<00:00, 23.97it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.83it/s]\n",
            "100% 4/4 [00:00<00:00,  8.06it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00010162, Rollout MSE Error (joint_q) = 0.00000528 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 40 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00009761, itemized = {state_0: 0.00000041, state_1: 0.01086979, state_2: 0.00003009, state_3: 0.00005420, state_MSE: 0.00273862, q_error_norm: 0.00278359, qd_error_norm: 0.00685838} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00216121, itemized = {state_0: 0.00000121, state_1: 0.01469969, state_2: 0.00061244, state_3: 0.00178708, state_MSE: 0.00427510, q_error_norm: 0.00379450, qd_error_norm: 0.01246062} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.191 sec, time(other): 0.011 sec, time(dataloader): 4.506 sec, time(compute_loss): 1.757 sec, time(backward): 4.057 sec, time(eval): 0.665 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.020559, device='cuda:0'), grad_norm_after_clip: tensor(0.020559, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.06it/s]\n",
            "100% 11/11 [00:00<00:00, 24.42it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.54it/s]\n",
            "100% 4/4 [00:00<00:00,  8.07it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00090677, Rollout MSE Error (joint_q) = 0.00008869 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 41 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00017587, itemized = {state_0: 0.00000046, state_1: 0.01156325, state_2: 0.00005747, state_3: 0.00011213, state_MSE: 0.00293332, q_error_norm: 0.00297714, qd_error_norm: 0.00853834} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00255475, itemized = {state_0: 0.00000133, state_1: 0.02450308, state_2: 0.00067453, state_3: 0.00213521, state_MSE: 0.00682854, q_error_norm: 0.00611737, qd_error_norm: 0.01717484} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.218 sec, time(other): 0.011 sec, time(dataloader): 4.502 sec, time(compute_loss): 1.765 sec, time(backward): 4.078 sec, time(eval): 0.665 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.037091, device='cuda:0'), grad_norm_after_clip: tensor(0.037091, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.99it/s]\n",
            "100% 11/11 [00:00<00:00, 23.56it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.78it/s]\n",
            "100% 4/4 [00:00<00:00,  8.20it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00025984, Rollout MSE Error (joint_q) = 0.00000824 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 42 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00024676, itemized = {state_0: 0.00000064, state_1: 0.01333357, state_2: 0.00007469, state_3: 0.00015924, state_MSE: 0.00339204, q_error_norm: 0.00357388, qd_error_norm: 0.01034407} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00225217, itemized = {state_0: 0.00000117, state_1: 0.01679773, state_2: 0.00062576, state_3: 0.00187977, state_MSE: 0.00482611, q_error_norm: 0.00418254, qd_error_norm: 0.01403324} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.316 sec, time(other): 0.011 sec, time(dataloader): 4.520 sec, time(compute_loss): 1.808 sec, time(backward): 4.110 sec, time(eval): 0.655 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.043221, device='cuda:0'), grad_norm_after_clip: tensor(0.043221, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.08it/s]\n",
            "100% 11/11 [00:00<00:00, 24.66it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.87it/s]\n",
            "100% 4/4 [00:00<00:00,  7.96it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00015169, Rollout MSE Error (joint_q) = 0.00000524 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 43 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00011431, itemized = {state_0: 0.00000042, state_1: 0.01117744, state_2: 0.00003654, state_3: 0.00006477, state_MSE: 0.00281979, q_error_norm: 0.00288252, qd_error_norm: 0.00730868} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00220667, itemized = {state_0: 0.00000104, state_1: 0.01610689, state_2: 0.00066067, state_3: 0.00179609, state_MSE: 0.00464117, q_error_norm: 0.00399517, qd_error_norm: 0.01286042} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.196 sec, time(other): 0.011 sec, time(dataloader): 4.529 sec, time(compute_loss): 1.754 sec, time(backward): 4.040 sec, time(eval): 0.670 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.026045, device='cuda:0'), grad_norm_after_clip: tensor(0.026045, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.96it/s]\n",
            "100% 11/11 [00:00<00:00, 22.76it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.13it/s]\n",
            "100% 4/4 [00:00<00:00,  7.74it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00273480, Rollout MSE Error (joint_q) = 0.00002438 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 44 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00081669, itemized = {state_0: 0.00000098, state_1: 0.01333361, state_2: 0.00034810, state_3: 0.00050860, state_MSE: 0.00354782, q_error_norm: 0.00379848, qd_error_norm: 0.01648249} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00378072, itemized = {state_0: 0.00000282, state_1: 0.02029855, state_2: 0.00112523, state_3: 0.00303954, state_MSE: 0.00611654, q_error_norm: 0.00560143, qd_error_norm: 0.02806894} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.384 sec, time(other): 0.011 sec, time(dataloader): 4.569 sec, time(compute_loss): 1.826 sec, time(backward): 4.083 sec, time(eval): 0.690 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.096412, device='cuda:0'), grad_norm_after_clip: tensor(0.096412, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.99it/s]\n",
            "100% 11/11 [00:00<00:00, 24.45it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.99it/s]\n",
            "100% 4/4 [00:00<00:00,  7.98it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00022638, Rollout MSE Error (joint_q) = 0.00000895 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 45 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00051008, itemized = {state_0: 0.00000099, state_1: 0.01348730, state_2: 0.00018040, state_3: 0.00032867, state_MSE: 0.00349934, q_error_norm: 0.00385365, qd_error_norm: 0.01365980} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00230171, itemized = {state_0: 0.00000121, state_1: 0.01330879, state_2: 0.00059249, state_3: 0.00197414, state_MSE: 0.00396916, q_error_norm: 0.00367874, qd_error_norm: 0.01372699} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.309 sec, time(other): 0.011 sec, time(dataloader): 4.541 sec, time(compute_loss): 1.809 sec, time(backward): 4.071 sec, time(eval): 0.674 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.059320, device='cuda:0'), grad_norm_after_clip: tensor(0.059320, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.07it/s]\n",
            "100% 11/11 [00:00<00:00, 24.27it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.41it/s]\n",
            "100% 4/4 [00:00<00:00,  7.76it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00023546, Rollout MSE Error (joint_q) = 0.00001762 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 46 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00018267, itemized = {state_0: 0.00000043, state_1: 0.01102325, state_2: 0.00006403, state_3: 0.00011429, state_MSE: 0.00280050, q_error_norm: 0.00287236, qd_error_norm: 0.00859869} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00214960, itemized = {state_0: 0.00000117, state_1: 0.02871416, state_2: 0.00062103, state_3: 0.00175391, state_MSE: 0.00777257, q_error_norm: 0.00639573, qd_error_norm: 0.01371235} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.246 sec, time(other): 0.011 sec, time(dataloader): 4.521 sec, time(compute_loss): 1.782 sec, time(backward): 4.040 sec, time(eval): 0.687 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.038791, device='cuda:0'), grad_norm_after_clip: tensor(0.038791, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.07it/s]\n",
            "100% 11/11 [00:00<00:00, 24.26it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.76it/s]\n",
            "100% 4/4 [00:00<00:00,  8.27it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00019627, Rollout MSE Error (joint_q) = 0.00000458 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 47 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00015699, itemized = {state_0: 0.00000044, state_1: 0.01140807, state_2: 0.00005098, state_3: 0.00009733, state_MSE: 0.00288920, q_error_norm: 0.00295898, qd_error_norm: 0.00834915} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00215545, itemized = {state_0: 0.00000107, state_1: 0.01470385, state_2: 0.00056305, state_3: 0.00184018, state_MSE: 0.00427703, q_error_norm: 0.00374667, qd_error_norm: 0.01240620} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.199 sec, time(other): 0.011 sec, time(dataloader): 4.537 sec, time(compute_loss): 1.758 sec, time(backward): 4.045 sec, time(eval): 0.652 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.032392, device='cuda:0'), grad_norm_after_clip: tensor(0.032392, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.93it/s]\n",
            "100% 11/11 [00:00<00:00, 24.32it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.81it/s]\n",
            "100% 4/4 [00:00<00:00,  8.21it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00049145, Rollout MSE Error (joint_q) = 0.00001019 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 48 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00014232, itemized = {state_0: 0.00000041, state_1: 0.01086865, state_2: 0.00004550, state_3: 0.00008704, state_MSE: 0.00275040, q_error_norm: 0.00286867, qd_error_norm: 0.00801628} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00215890, itemized = {state_0: 0.00000113, state_1: 0.01330155, state_2: 0.00059212, state_3: 0.00181131, state_MSE: 0.00392653, q_error_norm: 0.00361493, qd_error_norm: 0.01451038} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.363 sec, time(other): 0.011 sec, time(dataloader): 4.555 sec, time(compute_loss): 1.855 sec, time(backward): 4.072 sec, time(eval): 0.657 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.036279, device='cuda:0'), grad_norm_after_clip: tensor(0.036279, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.10it/s]\n",
            "100% 11/11 [00:00<00:00, 24.09it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.60it/s]\n",
            "100% 4/4 [00:00<00:00,  7.83it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00021704, Rollout MSE Error (joint_q) = 0.00000339 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 49 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00011901, itemized = {state_0: 0.00000037, state_1: 0.01125472, state_2: 0.00003873, state_3: 0.00007193, state_MSE: 0.00284144, q_error_norm: 0.00281429, qd_error_norm: 0.00729187} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00244717, itemized = {state_0: 0.00000104, state_1: 0.01190537, state_2: 0.00076872, state_3: 0.00196286, state_MSE: 0.00365950, q_error_norm: 0.00329677, qd_error_norm: 0.01440794} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.212 sec, time(other): 0.011 sec, time(dataloader): 4.498 sec, time(compute_loss): 1.757 sec, time(backward): 4.061 sec, time(eval): 0.681 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.028596, device='cuda:0'), grad_norm_after_clip: tensor(0.028596, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.96it/s]\n",
            "100% 11/11 [00:00<00:00, 23.48it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.88it/s]\n",
            "100% 4/4 [00:00<00:00,  8.05it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00046491, Rollout MSE Error (joint_q) = 0.00001546 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 50 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00032212, itemized = {state_0: 0.00000058, state_1: 0.01210058, state_2: 0.00010600, state_3: 0.00021674, state_MSE: 0.00310597, q_error_norm: 0.00335658, qd_error_norm: 0.01169100} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00288752, itemized = {state_0: 0.00000204, state_1: 0.01751223, state_2: 0.00092723, state_3: 0.00226175, state_MSE: 0.00517581, q_error_norm: 0.00466997, qd_error_norm: 0.01836185} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.326 sec, time(other): 0.011 sec, time(dataloader): 4.562 sec, time(compute_loss): 1.832 sec, time(backward): 4.068 sec, time(eval): 0.664 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.059335, device='cuda:0'), grad_norm_after_clip: tensor(0.059335, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.93it/s]\n",
            "100% 11/11 [00:00<00:00, 23.03it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.34it/s]\n",
            "100% 4/4 [00:00<00:00,  8.03it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00013586, Rollout MSE Error (joint_q) = 0.00000486 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 51 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00018883, itemized = {state_0: 0.00000050, state_1: 0.01102248, state_2: 0.00005823, state_3: 0.00012035, state_MSE: 0.00280039, q_error_norm: 0.00300828, qd_error_norm: 0.00894920} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00229061, itemized = {state_0: 0.00000093, state_1: 0.01120109, state_2: 0.00063036, state_3: 0.00193670, state_MSE: 0.00344227, q_error_norm: 0.00308072, qd_error_norm: 0.01222889} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.378 sec, time(other): 0.011 sec, time(dataloader): 4.552 sec, time(compute_loss): 1.862 sec, time(backward): 4.088 sec, time(eval): 0.669 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.036943, device='cuda:0'), grad_norm_after_clip: tensor(0.036943, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.99it/s]\n",
            "100% 11/11 [00:00<00:00, 23.93it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.60it/s]\n",
            "100% 4/4 [00:00<00:00,  7.63it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00006895, Rollout MSE Error (joint_q) = 0.00000345 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 52 with MSE error 6.895209662616253e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 52 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00011083, itemized = {state_0: 0.00000034, state_1: 0.01163943, state_2: 0.00003775, state_3: 0.00006276, state_MSE: 0.00293507, q_error_norm: 0.00291380, qd_error_norm: 0.00690119} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00233158, itemized = {state_0: 0.00000094, state_1: 0.01050266, state_2: 0.00066077, state_3: 0.00195007, state_MSE: 0.00327861, q_error_norm: 0.00293327, qd_error_norm: 0.01129733} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.353 sec, time(other): 0.011 sec, time(dataloader): 4.536 sec, time(compute_loss): 1.803 sec, time(backward): 4.095 sec, time(eval): 0.717 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.030004, device='cuda:0'), grad_norm_after_clip: tensor(0.030004, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.14it/s]\n",
            "100% 11/11 [00:00<00:00, 22.94it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.64it/s]\n",
            "100% 4/4 [00:00<00:00,  8.00it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00008730, Rollout MSE Error (joint_q) = 0.00000486 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 53 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00006337, itemized = {state_0: 0.00000029, state_1: 0.01086988, state_2: 0.00001951, state_3: 0.00003399, state_MSE: 0.00273092, q_error_norm: 0.00260379, qd_error_norm: 0.00549660} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00228204, itemized = {state_0: 0.00000089, state_1: 0.01259970, state_2: 0.00065227, state_3: 0.00190461, state_MSE: 0.00378937, q_error_norm: 0.00328100, qd_error_norm: 0.01183595} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.180 sec, time(other): 0.011 sec, time(dataloader): 4.447 sec, time(compute_loss): 1.753 sec, time(backward): 4.095 sec, time(eval): 0.669 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.015547, device='cuda:0'), grad_norm_after_clip: tensor(0.015547, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.01it/s]\n",
            "100% 11/11 [00:00<00:00, 24.43it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.08it/s]\n",
            "100% 4/4 [00:00<00:00,  7.62it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00012670, Rollout MSE Error (joint_q) = 0.00000717 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 54 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00010608, itemized = {state_0: 0.00000030, state_1: 0.01056112, state_2: 0.00003439, state_3: 0.00006416, state_MSE: 0.00266499, q_error_norm: 0.00266654, qd_error_norm: 0.00688518} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00252394, itemized = {state_0: 0.00000092, state_1: 0.01400037, state_2: 0.00074881, state_3: 0.00208298, state_MSE: 0.00420827, q_error_norm: 0.00350236, qd_error_norm: 0.01409312} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.317 sec, time(other): 0.011 sec, time(dataloader): 4.562 sec, time(compute_loss): 1.798 sec, time(backward): 4.043 sec, time(eval): 0.698 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.027909, device='cuda:0'), grad_norm_after_clip: tensor(0.027909, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.09it/s]\n",
            "100% 11/11 [00:00<00:00, 24.26it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.24it/s]\n",
            "100% 4/4 [00:00<00:00,  7.91it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00023914, Rollout MSE Error (joint_q) = 0.00002539 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 55 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00041889, itemized = {state_0: 0.00000061, state_1: 0.01279514, state_2: 0.00017486, state_3: 0.00025665, state_MSE: 0.00330681, q_error_norm: 0.00342136, qd_error_norm: 0.01261345} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00256554, itemized = {state_0: 0.00000118, state_1: 0.02100224, state_2: 0.00070450, state_3: 0.00216034, state_MSE: 0.00596706, q_error_norm: 0.00501173, qd_error_norm: 0.01399876} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.217 sec, time(other): 0.011 sec, time(dataloader): 4.552 sec, time(compute_loss): 1.750 sec, time(backward): 4.026 sec, time(eval): 0.679 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.067662, device='cuda:0'), grad_norm_after_clip: tensor(0.067662, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.03it/s]\n",
            "100% 11/11 [00:00<00:00, 23.88it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.16it/s]\n",
            "100% 4/4 [00:00<00:00,  8.17it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00016651, Rollout MSE Error (joint_q) = 0.00000882 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 56 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00017325, itemized = {state_0: 0.00000041, state_1: 0.01156211, state_2: 0.00005964, state_3: 0.00010889, state_MSE: 0.00293276, q_error_norm: 0.00295373, qd_error_norm: 0.00868886} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00231167, itemized = {state_0: 0.00000091, state_1: 0.01470499, state_2: 0.00060756, state_3: 0.00198221, state_MSE: 0.00432392, q_error_norm: 0.00371402, qd_error_norm: 0.01304104} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.255 sec, time(other): 0.011 sec, time(dataloader): 4.537 sec, time(compute_loss): 1.794 sec, time(backward): 4.057 sec, time(eval): 0.663 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.039322, device='cuda:0'), grad_norm_after_clip: tensor(0.039322, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.97it/s]\n",
            "100% 11/11 [00:00<00:00, 24.37it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.69it/s]\n",
            "100% 4/4 [00:00<00:00,  8.07it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00024113, Rollout MSE Error (joint_q) = 0.00001348 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 57 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00014830, itemized = {state_0: 0.00000035, state_1: 0.01194756, state_2: 0.00004842, state_3: 0.00009365, state_MSE: 0.00302249, q_error_norm: 0.00299689, qd_error_norm: 0.00806532} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00249057, itemized = {state_0: 0.00000088, state_1: 0.01190235, state_2: 0.00073816, state_3: 0.00205082, state_MSE: 0.00367306, q_error_norm: 0.00331869, qd_error_norm: 0.01284804} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.320 sec, time(other): 0.011 sec, time(dataloader): 4.506 sec, time(compute_loss): 1.808 sec, time(backward): 4.124 sec, time(eval): 0.665 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.035596, device='cuda:0'), grad_norm_after_clip: tensor(0.035596, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.06it/s]\n",
            "100% 11/11 [00:00<00:00, 23.30it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.82it/s]\n",
            "100% 4/4 [00:00<00:00,  7.88it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00006584, Rollout MSE Error (joint_q) = 0.00001499 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 58 with MSE error 6.58447970636189e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 58 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00020106, itemized = {state_0: 0.00000039, state_1: 0.01140789, state_2: 0.00006520, state_3: 0.00013159, state_MSE: 0.00290127, q_error_norm: 0.00301618, qd_error_norm: 0.00917766} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00241384, itemized = {state_0: 0.00000087, state_1: 0.00840082, state_2: 0.00070415, state_3: 0.00200037, state_MSE: 0.00277655, q_error_norm: 0.00272338, qd_error_norm: 0.01189459} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.280 sec, time(other): 0.011 sec, time(dataloader): 4.521 sec, time(compute_loss): 1.804 sec, time(backward): 4.045 sec, time(eval): 0.700 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.044999, device='cuda:0'), grad_norm_after_clip: tensor(0.044999, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.15it/s]\n",
            "100% 11/11 [00:00<00:00, 24.88it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.47it/s]\n",
            "100% 4/4 [00:00<00:00,  8.08it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00019104, Rollout MSE Error (joint_q) = 0.00000422 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 59 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00014832, itemized = {state_0: 0.00000034, state_1: 0.01133061, state_2: 0.00004871, state_3: 0.00009528, state_MSE: 0.00286873, q_error_norm: 0.00285831, qd_error_norm: 0.00813494} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00234959, itemized = {state_0: 0.00000097, state_1: 0.01469923, state_2: 0.00070910, state_3: 0.00192082, state_MSE: 0.00433253, q_error_norm: 0.00363078, qd_error_norm: 0.01270045} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.138 sec, time(other): 0.011 sec, time(dataloader): 4.477 sec, time(compute_loss): 1.731 sec, time(backward): 4.048 sec, time(eval): 0.666 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.038462, device='cuda:0'), grad_norm_after_clip: tensor(0.038462, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.96it/s]\n",
            "100% 11/11 [00:00<00:00, 23.28it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.66it/s]\n",
            "100% 4/4 [00:00<00:00,  8.18it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00015612, Rollout MSE Error (joint_q) = 0.00000899 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 60 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00009110, itemized = {state_0: 0.00000031, state_1: 0.00886524, state_2: 0.00002839, state_3: 0.00005592, state_MSE: 0.00223746, q_error_norm: 0.00230763, qd_error_norm: 0.00650945} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00241749, itemized = {state_0: 0.00000086, state_1: 0.01260244, state_2: 0.00072702, state_3: 0.00198435, state_MSE: 0.00382867, q_error_norm: 0.00324007, qd_error_norm: 0.01153439} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.349 sec, time(other): 0.011 sec, time(dataloader): 4.570 sec, time(compute_loss): 1.833 sec, time(backward): 4.068 sec, time(eval): 0.659 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.026248, device='cuda:0'), grad_norm_after_clip: tensor(0.026248, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.07it/s]\n",
            "100% 11/11 [00:00<00:00, 24.56it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.71it/s]\n",
            "100% 4/4 [00:00<00:00,  8.08it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00031931, Rollout MSE Error (joint_q) = 0.00001685 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 61 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00036100, itemized = {state_0: 0.00000072, state_1: 0.00963524, state_2: 0.00014449, state_3: 0.00022251, state_MSE: 0.00250074, q_error_norm: 0.00280216, qd_error_norm: 0.01135132} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00313038, itemized = {state_0: 0.00000116, state_1: 0.01470892, state_2: 0.00084033, state_3: 0.00267678, state_MSE: 0.00455680, q_error_norm: 0.00393362, qd_error_norm: 0.01801383} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.213 sec, time(other): 0.011 sec, time(dataloader): 4.533 sec, time(compute_loss): 1.758 sec, time(backward): 4.048 sec, time(eval): 0.665 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.061372, device='cuda:0'), grad_norm_after_clip: tensor(0.061372, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.97it/s]\n",
            "100% 11/11 [00:00<00:00, 24.75it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.64it/s]\n",
            "100% 4/4 [00:00<00:00,  8.12it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00031903, Rollout MSE Error (joint_q) = 0.00000831 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 62 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00019775, itemized = {state_0: 0.00000041, state_1: 0.01194654, state_2: 0.00006744, state_3: 0.00012790, state_MSE: 0.00303557, q_error_norm: 0.00302433, qd_error_norm: 0.00851746} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00255094, itemized = {state_0: 0.00000083, state_1: 0.01260311, state_2: 0.00073718, state_3: 0.00213095, state_MSE: 0.00386802, q_error_norm: 0.00321094, qd_error_norm: 0.01259552} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.306 sec, time(other): 0.011 sec, time(dataloader): 4.516 sec, time(compute_loss): 1.806 sec, time(backward): 4.109 sec, time(eval): 0.662 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.039032, device='cuda:0'), grad_norm_after_clip: tensor(0.039032, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.01it/s]\n",
            "100% 11/11 [00:00<00:00, 22.21it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.03it/s]\n",
            "100% 4/4 [00:00<00:00,  8.01it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00007261, Rollout MSE Error (joint_q) = 0.00000543 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 63 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00007728, itemized = {state_0: 0.00000026, state_1: 0.01025270, state_2: 0.00002455, state_3: 0.00004659, state_MSE: 0.00258102, q_error_norm: 0.00247071, qd_error_norm: 0.00600325} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00247787, itemized = {state_0: 0.00000081, state_1: 0.01470266, state_2: 0.00072240, state_3: 0.00206183, state_MSE: 0.00437193, q_error_norm: 0.00355829, qd_error_norm: 0.01073664} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.322 sec, time(other): 0.011 sec, time(dataloader): 4.526 sec, time(compute_loss): 1.820 sec, time(backward): 4.091 sec, time(eval): 0.673 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.023930, device='cuda:0'), grad_norm_after_clip: tensor(0.023930, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.12it/s]\n",
            "100% 11/11 [00:00<00:00, 24.39it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.19it/s]\n",
            "100% 4/4 [00:00<00:00,  8.10it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00006002, Rollout MSE Error (joint_q) = 0.00000503 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 64 with MSE error 6.0021469835191965e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 64 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00006680, itemized = {state_0: 0.00000024, state_1: 0.01017524, state_2: 0.00002114, state_3: 0.00003763, state_MSE: 0.00255856, q_error_norm: 0.00248181, qd_error_norm: 0.00553834} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00245332, itemized = {state_0: 0.00000076, state_1: 0.01400183, state_2: 0.00070404, state_3: 0.00205539, state_MSE: 0.00419050, q_error_norm: 0.00341648, qd_error_norm: 0.01071939} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.186 sec, time(other): 0.011 sec, time(dataloader): 4.504 sec, time(compute_loss): 1.762 sec, time(backward): 4.025 sec, time(eval): 0.688 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.022137, device='cuda:0'), grad_norm_after_clip: tensor(0.022137, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.08it/s]\n",
            "100% 11/11 [00:00<00:00, 24.60it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.83it/s]\n",
            "100% 4/4 [00:00<00:00,  8.18it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003786, Rollout MSE Error (joint_q) = 0.00000254 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 65 with MSE error 3.786183879128657e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 65 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00004629, itemized = {state_0: 0.00000021, state_1: 0.00871158, state_2: 0.00001451, state_3: 0.00002453, state_MSE: 0.00218771, q_error_norm: 0.00212752, qd_error_norm: 0.00471864} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00241029, itemized = {state_0: 0.00000075, state_1: 0.01190165, state_2: 0.00071736, state_3: 0.00199349, state_MSE: 0.00365331, q_error_norm: 0.00304723, qd_error_norm: 0.01053018} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.211 sec, time(other): 0.011 sec, time(dataloader): 4.471 sec, time(compute_loss): 1.770 sec, time(backward): 4.087 sec, time(eval): 0.679 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.012564, device='cuda:0'), grad_norm_after_clip: tensor(0.012564, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.01it/s]\n",
            "100% 11/11 [00:00<00:00, 22.87it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.98it/s]\n",
            "100% 4/4 [00:00<00:00,  8.18it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004771, Rollout MSE Error (joint_q) = 0.00000406 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 66 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00004297, itemized = {state_0: 0.00000020, state_1: 0.00832591, state_2: 0.00001280, state_3: 0.00002303, state_MSE: 0.00209048, q_error_norm: 0.00205192, qd_error_norm: 0.00458068} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00181126, itemized = {state_0: 0.00000069, state_1: 0.01400332, state_2: 0.00052536, state_3: 0.00150474, state_MSE: 0.00400853, q_error_norm: 0.00334102, qd_error_norm: 0.01015838} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.304 sec, time(other): 0.011 sec, time(dataloader): 4.585 sec, time(compute_loss): 1.798 sec, time(backward): 4.049 sec, time(eval): 0.656 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.012122, device='cuda:0'), grad_norm_after_clip: tensor(0.012122, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 66 with loss 0.00181126. \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.04it/s]\n",
            "100% 11/11 [00:00<00:00, 24.01it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.80it/s]\n",
            "100% 4/4 [00:00<00:00,  8.09it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00008137, Rollout MSE Error (joint_q) = 0.00000431 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 67 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00006141, itemized = {state_0: 0.00000021, state_1: 0.00901944, state_2: 0.00001910, state_3: 0.00003698, state_MSE: 0.00226893, q_error_norm: 0.00219251, qd_error_norm: 0.00524768} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00266848, itemized = {state_0: 0.00000078, state_1: 0.01751042, state_2: 0.00079693, state_3: 0.00220419, state_MSE: 0.00512808, q_error_norm: 0.00402979, qd_error_norm: 0.01136493} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.258 sec, time(other): 0.011 sec, time(dataloader): 4.553 sec, time(compute_loss): 1.786 sec, time(backward): 4.041 sec, time(eval): 0.671 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.018491, device='cuda:0'), grad_norm_after_clip: tensor(0.018491, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00, 10.00it/s]\n",
            "100% 11/11 [00:00<00:00, 24.06it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.12it/s]\n",
            "100% 4/4 [00:00<00:00,  8.10it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00065857, Rollout MSE Error (joint_q) = 0.00001845 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 68 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00033813, itemized = {state_0: 0.00000051, state_1: 0.01148491, state_2: 0.00013371, state_3: 0.00021518, state_MSE: 0.00295858, q_error_norm: 0.00304576, qd_error_norm: 0.01113566} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00294124, itemized = {state_0: 0.00000145, state_1: 0.01121075, state_2: 0.00094244, state_3: 0.00231969, state_MSE: 0.00361858, q_error_norm: 0.00382846, qd_error_norm: 0.01762230} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.286 sec, time(other): 0.011 sec, time(dataloader): 4.497 sec, time(compute_loss): 1.818 sec, time(backward): 4.101 sec, time(eval): 0.660 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.063688, device='cuda:0'), grad_norm_after_clip: tensor(0.063688, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.94it/s]\n",
            "100% 11/11 [00:00<00:00, 23.06it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.65it/s]\n",
            "100% 4/4 [00:00<00:00,  8.32it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00029214, Rollout MSE Error (joint_q) = 0.00000398 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 69 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00069880, itemized = {state_0: 0.00000094, state_1: 0.01271696, state_2: 0.00029766, state_3: 0.00043506, state_MSE: 0.00336265, q_error_norm: 0.00358472, qd_error_norm: 0.01533048} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00276838, itemized = {state_0: 0.00000103, state_1: 0.01470684, state_2: 0.00077818, state_3: 0.00233414, state_MSE: 0.00445505, q_error_norm: 0.00373254, qd_error_norm: 0.01343218} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.368 sec, time(other): 0.011 sec, time(dataloader): 4.582 sec, time(compute_loss): 1.847 sec, time(backward): 4.067 sec, time(eval): 0.650 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.086943, device='cuda:0'), grad_norm_after_clip: tensor(0.086943, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.06it/s]\n",
            "100% 11/11 [00:00<00:00, 24.56it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.89it/s]\n",
            "100% 4/4 [00:00<00:00,  8.12it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003770, Rollout MSE Error (joint_q) = 0.00000237 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 70 with MSE error 3.7704809074057266e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 70 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00007845, itemized = {state_0: 0.00000027, state_1: 0.01071458, state_2: 0.00002716, state_3: 0.00004466, state_MSE: 0.00269667, q_error_norm: 0.00253485, qd_error_norm: 0.00581070} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00207285, itemized = {state_0: 0.00000070, state_1: 0.01330053, state_2: 0.00057616, state_3: 0.00175623, state_MSE: 0.00390840, q_error_norm: 0.00322805, qd_error_norm: 0.01034457} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.250 sec, time(other): 0.011 sec, time(dataloader): 4.521 sec, time(compute_loss): 1.789 sec, time(backward): 4.035 sec, time(eval): 0.689 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.019449, device='cuda:0'), grad_norm_after_clip: tensor(0.019449, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.07it/s]\n",
            "100% 11/11 [00:00<00:00, 23.98it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.60it/s]\n",
            "100% 4/4 [00:00<00:00,  8.13it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003117, Rollout MSE Error (joint_q) = 0.00000249 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 71 with MSE error 3.116708467132412e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 71 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003753, itemized = {state_0: 0.00000019, state_1: 0.00840324, state_2: 0.00001154, state_3: 0.00001908, state_MSE: 0.00210851, q_error_norm: 0.00203048, qd_error_norm: 0.00428164} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00236092, itemized = {state_0: 0.00000070, state_1: 0.01470268, state_2: 0.00068365, state_3: 0.00197709, state_MSE: 0.00434103, q_error_norm: 0.00343386, qd_error_norm: 0.01014177} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.238 sec, time(other): 0.011 sec, time(dataloader): 4.519 sec, time(compute_loss): 1.760 sec, time(backward): 4.064 sec, time(eval): 0.685 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.008973, device='cuda:0'), grad_norm_after_clip: tensor(0.008973, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.99it/s]\n",
            "100% 11/11 [00:00<00:00, 21.89it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.77it/s]\n",
            "100% 4/4 [00:00<00:00,  8.20it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003154, Rollout MSE Error (joint_q) = 0.00000177 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 72 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003286, itemized = {state_0: 0.00000018, state_1: 0.00832605, state_2: 0.00000961, state_3: 0.00001630, state_MSE: 0.00208803, q_error_norm: 0.00200055, qd_error_norm: 0.00401112} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00240423, itemized = {state_0: 0.00000070, state_1: 0.01260298, state_2: 0.00070266, state_3: 0.00200685, state_MSE: 0.00382830, q_error_norm: 0.00307548, qd_error_norm: 0.01004801} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.334 sec, time(other): 0.011 sec, time(dataloader): 4.555 sec, time(compute_loss): 1.827 sec, time(backward): 4.087 sec, time(eval): 0.656 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.007089, device='cuda:0'), grad_norm_after_clip: tensor(0.007089, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.05it/s]\n",
            "100% 11/11 [00:00<00:00, 24.20it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.80it/s]\n",
            "100% 4/4 [00:00<00:00,  8.08it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003149, Rollout MSE Error (joint_q) = 0.00000187 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 73 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003454, itemized = {state_0: 0.00000017, state_1: 0.00716998, state_2: 0.00001043, state_3: 0.00001757, state_MSE: 0.00179954, q_error_norm: 0.00181222, qd_error_norm: 0.00408542} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00245793, itemized = {state_0: 0.00000070, state_1: 0.01190318, state_2: 0.00072853, state_3: 0.00204226, state_MSE: 0.00366867, q_error_norm: 0.00295872, qd_error_norm: 0.01003047} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.233 sec, time(other): 0.011 sec, time(dataloader): 4.490 sec, time(compute_loss): 1.784 sec, time(backward): 4.087 sec, time(eval): 0.664 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.009261, device='cuda:0'), grad_norm_after_clip: tensor(0.009261, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.97it/s]\n",
            "100% 11/11 [00:00<00:00, 24.46it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.63it/s]\n",
            "100% 4/4 [00:00<00:00,  8.07it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003278, Rollout MSE Error (joint_q) = 0.00000225 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 74 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003272, itemized = {state_0: 0.00000017, state_1: 0.00740140, state_2: 0.00000966, state_3: 0.00001643, state_MSE: 0.00185691, q_error_norm: 0.00184348, qd_error_norm: 0.00398380} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00240403, itemized = {state_0: 0.00000067, state_1: 0.01330383, state_2: 0.00070062, state_3: 0.00201128, state_MSE: 0.00400410, q_error_norm: 0.00317434, qd_error_norm: 0.00996807} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.319 sec, time(other): 0.011 sec, time(dataloader): 4.525 sec, time(compute_loss): 1.821 sec, time(backward): 4.089 sec, time(eval): 0.672 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.007212, device='cuda:0'), grad_norm_after_clip: tensor(0.007212, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.01it/s]\n",
            "100% 11/11 [00:00<00:00, 23.35it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.74it/s]\n",
            "100% 4/4 [00:00<00:00,  8.11it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004836, Rollout MSE Error (joint_q) = 0.00000201 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 75 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003097, itemized = {state_0: 0.00000016, state_1: 0.00786386, state_2: 0.00000914, state_3: 0.00001552, state_MSE: 0.00197217, q_error_norm: 0.00190041, qd_error_norm: 0.00390759} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00223825, itemized = {state_0: 0.00000067, state_1: 0.01330452, state_2: 0.00066347, state_3: 0.00185682, state_MSE: 0.00395637, q_error_norm: 0.00316908, qd_error_norm: 0.00982054} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.303 sec, time(other): 0.011 sec, time(dataloader): 4.541 sec, time(compute_loss): 1.814 sec, time(backward): 4.068 sec, time(eval): 0.663 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.008016, device='cuda:0'), grad_norm_after_clip: tensor(0.008016, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.61it/s]\n",
            "100% 11/11 [00:00<00:00, 24.62it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.85it/s]\n",
            "100% 4/4 [00:00<00:00,  7.78it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003816, Rollout MSE Error (joint_q) = 0.00000152 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 76 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002976, itemized = {state_0: 0.00000016, state_1: 0.00717006, state_2: 0.00000876, state_3: 0.00001478, state_MSE: 0.00179844, q_error_norm: 0.00178252, qd_error_norm: 0.00382962} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00237949, itemized = {state_0: 0.00000066, state_1: 0.01330448, state_2: 0.00069849, state_3: 0.00198603, state_MSE: 0.00399742, q_error_norm: 0.00316216, qd_error_norm: 0.01012688} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.978 sec, time(other): 0.011 sec, time(dataloader): 5.014 sec, time(compute_loss): 1.740 sec, time(backward): 4.055 sec, time(eval): 0.682 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.007668, device='cuda:0'), grad_norm_after_clip: tensor(0.007668, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.35it/s]\n",
            "100% 11/11 [00:00<00:00, 24.27it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.12it/s]\n",
            "100% 4/4 [00:00<00:00,  8.23it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00007506, Rollout MSE Error (joint_q) = 0.00000319 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 77 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003612, itemized = {state_0: 0.00000017, state_1: 0.00709273, state_2: 0.00001161, state_3: 0.00001883, state_MSE: 0.00178084, q_error_norm: 0.00178142, qd_error_norm: 0.00419766} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00237833, itemized = {state_0: 0.00000067, state_1: 0.01260527, state_2: 0.00070221, state_3: 0.00197906, state_MSE: 0.00382180, q_error_norm: 0.00306732, qd_error_norm: 0.01017532} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.974 sec, time(other): 0.011 sec, time(dataloader): 5.290 sec, time(compute_loss): 1.763 sec, time(backward): 4.058 sec, time(eval): 0.652 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.011703, device='cuda:0'), grad_norm_after_clip: tensor(0.011703, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:11<00:00,  8.92it/s]\n",
            "100% 11/11 [00:00<00:00, 23.50it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.54it/s]\n",
            "100% 4/4 [00:00<00:00,  8.24it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003822, Rollout MSE Error (joint_q) = 0.00000231 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 78 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003743, itemized = {state_0: 0.00000016, state_1: 0.00670707, state_2: 0.00001165, state_3: 0.00002017, state_MSE: 0.00168476, q_error_norm: 0.00173124, qd_error_norm: 0.00427419} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00236644, itemized = {state_0: 0.00000063, state_1: 0.01260500, state_2: 0.00069981, state_3: 0.00196977, state_MSE: 0.00381880, q_error_norm: 0.00304789, qd_error_norm: 0.00993642} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 13.042 sec, time(other): 0.011 sec, time(dataloader): 5.682 sec, time(compute_loss): 1.829 sec, time(backward): 4.122 sec, time(eval): 0.657 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.013296, device='cuda:0'), grad_norm_after_clip: tensor(0.013296, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.20it/s]\n",
            "100% 11/11 [00:00<00:00, 23.39it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.22it/s]\n",
            "100% 4/4 [00:00<00:00,  7.58it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003454, Rollout MSE Error (joint_q) = 0.00000205 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 79 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003030, itemized = {state_0: 0.00000015, state_1: 0.00716994, state_2: 0.00000897, state_3: 0.00001565, state_MSE: 0.00179868, q_error_norm: 0.00176796, qd_error_norm: 0.00386551} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00233851, itemized = {state_0: 0.00000063, state_1: 0.01260398, state_2: 0.00070337, state_3: 0.00193419, state_MSE: 0.00381054, q_error_norm: 0.00302348, qd_error_norm: 0.00962641} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 12.787 sec, time(other): 0.011 sec, time(dataloader): 5.425 sec, time(compute_loss): 1.807 sec, time(backward): 4.071 sec, time(eval): 0.707 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.008519, device='cuda:0'), grad_norm_after_clip: tensor(0.008519, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:11<00:00,  8.89it/s]\n",
            "100% 11/11 [00:00<00:00, 23.52it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.37it/s]\n",
            "100% 4/4 [00:00<00:00,  7.99it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003242, Rollout MSE Error (joint_q) = 0.00000192 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 80 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002973, itemized = {state_0: 0.00000015, state_1: 0.00786382, state_2: 0.00000882, state_3: 0.00001532, state_MSE: 0.00197203, q_error_norm: 0.00187213, qd_error_norm: 0.00381244} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00214472, itemized = {state_0: 0.00000061, state_1: 0.01330437, state_2: 0.00064996, state_3: 0.00176534, state_MSE: 0.00393007, q_error_norm: 0.00315885, qd_error_norm: 0.00958461} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 12.557 sec, time(other): 0.011 sec, time(dataloader): 5.834 sec, time(compute_loss): 1.773 sec, time(backward): 4.071 sec, time(eval): 0.671 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.008407, device='cuda:0'), grad_norm_after_clip: tensor(0.008407, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:12<00:00,  8.20it/s]\n",
            "100% 11/11 [00:01<00:00, 10.99it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.30it/s]\n",
            "100% 4/4 [00:00<00:00,  8.16it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004645, Rollout MSE Error (joint_q) = 0.00000307 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 81 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003437, itemized = {state_0: 0.00000015, state_1: 0.00647619, state_2: 0.00001134, state_3: 0.00001797, state_MSE: 0.00162641, q_error_norm: 0.00165586, qd_error_norm: 0.00403407} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00238134, itemized = {state_0: 0.00000062, state_1: 0.01260356, state_2: 0.00072951, state_3: 0.00195593, state_MSE: 0.00382241, q_error_norm: 0.00303892, qd_error_norm: 0.00994875} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 14.056 sec, time(other): 0.011 sec, time(dataloader): 7.117 sec, time(compute_loss): 1.886 sec, time(backward): 4.150 sec, time(eval): 0.661 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.012252, device='cuda:0'), grad_norm_after_clip: tensor(0.012252, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:12<00:00,  7.99it/s]\n",
            "100% 11/11 [00:00<00:00, 24.02it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.00it/s]\n",
            "100% 4/4 [00:00<00:00,  7.96it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00007042, Rollout MSE Error (joint_q) = 0.00000283 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 82 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00005443, itemized = {state_0: 0.00000017, state_1: 0.00894252, state_2: 0.00001820, state_3: 0.00003261, state_MSE: 0.00224837, q_error_norm: 0.00210008, qd_error_norm: 0.00482211} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00243682, itemized = {state_0: 0.00000064, state_1: 0.01330269, state_2: 0.00073522, state_3: 0.00201464, state_MSE: 0.00401330, q_error_norm: 0.00317139, qd_error_norm: 0.01038227} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 13.848 sec, time(other): 0.011 sec, time(dataloader): 7.017 sec, time(compute_loss): 1.825 sec, time(backward): 4.095 sec, time(eval): 0.676 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.017219, device='cuda:0'), grad_norm_after_clip: tensor(0.017219, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:12<00:00,  8.06it/s]\n",
            "100% 11/11 [00:01<00:00, 10.47it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.36it/s]\n",
            "100% 4/4 [00:00<00:00,  8.17it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004352, Rollout MSE Error (joint_q) = 0.00000157 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 83 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00006197, itemized = {state_0: 0.00000018, state_1: 0.00925077, state_2: 0.00001865, state_3: 0.00003989, state_MSE: 0.00232737, q_error_norm: 0.00218783, qd_error_norm: 0.00533457} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00220855, itemized = {state_0: 0.00000060, state_1: 0.01190342, state_2: 0.00065176, state_3: 0.00183892, state_MSE: 0.00359868, q_error_norm: 0.00289608, qd_error_norm: 0.00969056} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 14.325 sec, time(other): 0.011 sec, time(dataloader): 7.595 sec, time(compute_loss): 1.746 sec, time(backward): 4.080 sec, time(eval): 0.661 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.020262, device='cuda:0'), grad_norm_after_clip: tensor(0.020262, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:12<00:00,  8.00it/s]\n",
            "100% 11/11 [00:01<00:00, 10.47it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.90it/s]\n",
            "100% 4/4 [00:00<00:00,  8.13it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002925, Rollout MSE Error (joint_q) = 0.00000390 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 84 with MSE error 2.9254708351800218e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 84 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003315, itemized = {state_0: 0.00000015, state_1: 0.00701557, state_2: 0.00000982, state_3: 0.00001823, state_MSE: 0.00176094, q_error_norm: 0.00174527, qd_error_norm: 0.00403496} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00237334, itemized = {state_0: 0.00000060, state_1: 0.01260455, state_2: 0.00071107, state_3: 0.00196816, state_MSE: 0.00382110, q_error_norm: 0.00302404, qd_error_norm: 0.00951940} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 14.470 sec, time(other): 0.011 sec, time(dataloader): 7.521 sec, time(compute_loss): 1.847 sec, time(backward): 4.146 sec, time(eval): 0.697 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.011666, device='cuda:0'), grad_norm_after_clip: tensor(0.011666, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:12<00:00,  7.99it/s]\n",
            "100% 11/11 [00:01<00:00, 10.29it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.99it/s]\n",
            "100% 4/4 [00:00<00:00,  7.62it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003295, Rollout MSE Error (joint_q) = 0.00000236 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 85 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003368, itemized = {state_0: 0.00000015, state_1: 0.00678443, state_2: 0.00001077, state_3: 0.00001788, state_MSE: 0.00170330, q_error_norm: 0.00170899, qd_error_norm: 0.00405804} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00231515, itemized = {state_0: 0.00000059, state_1: 0.01400414, state_2: 0.00068256, state_3: 0.00193250, state_MSE: 0.00415495, q_error_norm: 0.00323213, qd_error_norm: 0.00954780} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 14.514 sec, time(other): 0.011 sec, time(dataloader): 7.695 sec, time(compute_loss): 1.811 sec, time(backward): 4.043 sec, time(eval): 0.706 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.013596, device='cuda:0'), grad_norm_after_clip: tensor(0.013596, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:12<00:00,  7.78it/s]\n",
            "100% 11/11 [00:01<00:00, 10.84it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.89it/s]\n",
            "100% 4/4 [00:00<00:00,  7.58it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002537, Rollout MSE Error (joint_q) = 0.00000129 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 86 with MSE error 2.536526881158352e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 86 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003053, itemized = {state_0: 0.00000014, state_1: 0.00770961, state_2: 0.00000924, state_3: 0.00001665, state_MSE: 0.00193391, q_error_norm: 0.00182154, qd_error_norm: 0.00386184} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00234860, itemized = {state_0: 0.00000059, state_1: 0.01330399, state_2: 0.00068272, state_3: 0.00197204, state_MSE: 0.00398983, q_error_norm: 0.00309096, qd_error_norm: 0.00954115} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 14.805 sec, time(other): 0.011 sec, time(dataloader): 8.018 sec, time(compute_loss): 1.763 sec, time(backward): 4.050 sec, time(eval): 0.734 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.010612, device='cuda:0'), grad_norm_after_clip: tensor(0.010612, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:12<00:00,  7.85it/s]\n",
            "100% 11/11 [00:01<00:00, 10.74it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.56it/s]\n",
            "100% 4/4 [00:00<00:00,  8.06it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004534, Rollout MSE Error (joint_q) = 0.00000135 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 87 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003576, itemized = {state_0: 0.00000015, state_1: 0.00794087, state_2: 0.00001113, state_3: 0.00002042, state_MSE: 0.00199314, q_error_norm: 0.00187112, qd_error_norm: 0.00415944} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00231104, itemized = {state_0: 0.00000057, state_1: 0.01190418, state_2: 0.00069157, state_3: 0.00191952, state_MSE: 0.00362896, q_error_norm: 0.00286742, qd_error_norm: 0.00957137} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 14.641 sec, time(other): 0.011 sec, time(dataloader): 7.902 sec, time(compute_loss): 1.772 sec, time(backward): 4.054 sec, time(eval): 0.666 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.014195, device='cuda:0'), grad_norm_after_clip: tensor(0.014195, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:11<00:00,  8.59it/s]\n",
            "100% 11/11 [00:00<00:00, 23.93it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.45it/s]\n",
            "100% 4/4 [00:00<00:00,  8.04it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00007347, Rollout MSE Error (joint_q) = 0.00000245 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 88 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003233, itemized = {state_0: 0.00000014, state_1: 0.00701580, state_2: 0.00000955, state_3: 0.00001850, state_MSE: 0.00176100, q_error_norm: 0.00170947, qd_error_norm: 0.00398530} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00209136, itemized = {state_0: 0.00000055, state_1: 0.01260478, state_2: 0.00062717, state_3: 0.00173276, state_MSE: 0.00374131, q_error_norm: 0.00298014, qd_error_norm: 0.00960397} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 12.937 sec, time(other): 0.011 sec, time(dataloader): 5.765 sec, time(compute_loss): 2.250 sec, time(backward): 4.048 sec, time(eval): 0.675 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.011239, device='cuda:0'), grad_norm_after_clip: tensor(0.011239, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.09it/s]\n",
            "100% 11/11 [00:00<00:00, 23.38it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.55it/s]\n",
            "100% 4/4 [00:00<00:00,  8.18it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00005287, Rollout MSE Error (joint_q) = 0.00000293 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 89 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00004846, itemized = {state_0: 0.00000015, state_1: 0.00732399, state_2: 0.00001679, state_3: 0.00002805, state_MSE: 0.00184225, q_error_norm: 0.00182201, qd_error_norm: 0.00473438} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00231393, itemized = {state_0: 0.00000055, state_1: 0.01400770, state_2: 0.00068876, state_3: 0.00192549, state_MSE: 0.00415562, q_error_norm: 0.00324371, qd_error_norm: 0.00961995} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.210 sec, time(other): 0.011 sec, time(dataloader): 4.494 sec, time(compute_loss): 1.737 sec, time(backward): 4.108 sec, time(eval): 0.666 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.019914, device='cuda:0'), grad_norm_after_clip: tensor(0.019914, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.01it/s]\n",
            "100% 11/11 [00:00<00:00, 23.58it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.64it/s]\n",
            "100% 4/4 [00:00<00:00,  8.03it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00008801, Rollout MSE Error (joint_q) = 0.00000187 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 90 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002986, itemized = {state_0: 0.00000013, state_1: 0.00701576, state_2: 0.00000919, state_3: 0.00001645, state_MSE: 0.00176038, q_error_norm: 0.00169538, qd_error_norm: 0.00376806} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00225586, itemized = {state_0: 0.00000055, state_1: 0.01190524, state_2: 0.00067935, state_3: 0.00186856, state_MSE: 0.00361342, q_error_norm: 0.00284346, qd_error_norm: 0.00960362} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.310 sec, time(other): 0.011 sec, time(dataloader): 4.552 sec, time(compute_loss): 1.789 sec, time(backward): 4.078 sec, time(eval): 0.682 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.011023, device='cuda:0'), grad_norm_after_clip: tensor(0.011023, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.92it/s]\n",
            "100% 11/11 [00:00<00:00, 24.08it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.87it/s]\n",
            "100% 4/4 [00:00<00:00,  8.14it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002114, Rollout MSE Error (joint_q) = 0.00000146 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 91 with MSE error 2.1139740056241862e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 91 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002356, itemized = {state_0: 0.00000012, state_1: 0.00663036, state_2: 0.00000701, state_3: 0.00001192, state_MSE: 0.00166235, q_error_norm: 0.00161589, qd_error_norm: 0.00339934} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00215042, itemized = {state_0: 0.00000054, state_1: 0.01260462, state_2: 0.00063603, state_3: 0.00179263, state_MSE: 0.00375846, q_error_norm: 0.00294808, qd_error_norm: 0.00902660} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.396 sec, time(other): 0.011 sec, time(dataloader): 4.581 sec, time(compute_loss): 1.823 sec, time(backward): 4.096 sec, time(eval): 0.683 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.008393, device='cuda:0'), grad_norm_after_clip: tensor(0.008393, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.97it/s]\n",
            "100% 11/11 [00:00<00:00, 22.49it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.89it/s]\n",
            "100% 4/4 [00:00<00:00,  8.19it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002499, Rollout MSE Error (joint_q) = 0.00000121 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 92 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002509, itemized = {state_0: 0.00000012, state_1: 0.00709283, state_2: 0.00000747, state_3: 0.00001334, state_MSE: 0.00177844, q_error_norm: 0.00168368, qd_error_norm: 0.00350113} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00229806, itemized = {state_0: 0.00000054, state_1: 0.01190573, state_2: 0.00069181, state_3: 0.00190469, state_MSE: 0.00362569, q_error_norm: 0.00285191, qd_error_norm: 0.00909271} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.360 sec, time(other): 0.011 sec, time(dataloader): 4.541 sec, time(compute_loss): 1.831 sec, time(backward): 4.108 sec, time(eval): 0.664 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.009170, device='cuda:0'), grad_norm_after_clip: tensor(0.009170, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.04it/s]\n",
            "100% 11/11 [00:00<00:00, 24.56it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.87it/s]\n",
            "100% 4/4 [00:00<00:00,  8.08it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002173, Rollout MSE Error (joint_q) = 0.00000216 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 93 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002213, itemized = {state_0: 0.00000012, state_1: 0.00724711, state_2: 0.00000637, state_3: 0.00001136, state_MSE: 0.00181624, q_error_norm: 0.00169730, qd_error_norm: 0.00329380} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00229912, itemized = {state_0: 0.00000054, state_1: 0.01260414, state_2: 0.00069170, state_3: 0.00190690, state_MSE: 0.00380082, q_error_norm: 0.00295247, qd_error_norm: 0.00902102} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.241 sec, time(other): 0.011 sec, time(dataloader): 4.543 sec, time(compute_loss): 1.777 sec, time(backward): 4.051 sec, time(eval): 0.669 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.006971, device='cuda:0'), grad_norm_after_clip: tensor(0.006971, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.96it/s]\n",
            "100% 11/11 [00:00<00:00, 23.78it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.24it/s]\n",
            "100% 4/4 [00:00<00:00,  8.14it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002315, Rollout MSE Error (joint_q) = 0.00000091 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 94 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002190, itemized = {state_0: 0.00000011, state_1: 0.00655333, state_2: 0.00000644, state_3: 0.00001114, state_MSE: 0.00164276, q_error_norm: 0.00158209, qd_error_norm: 0.00328935} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00213304, itemized = {state_0: 0.00000053, state_1: 0.01260518, state_2: 0.00064094, state_3: 0.00176756, state_MSE: 0.00375355, q_error_norm: 0.00293314, qd_error_norm: 0.00898267} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.343 sec, time(other): 0.011 sec, time(dataloader): 4.587 sec, time(compute_loss): 1.799 sec, time(backward): 4.075 sec, time(eval): 0.669 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.007626, device='cuda:0'), grad_norm_after_clip: tensor(0.007626, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.15it/s]\n",
            "100% 11/11 [00:00<00:00, 21.04it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.58it/s]\n",
            "100% 4/4 [00:00<00:00,  7.81it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002594, Rollout MSE Error (joint_q) = 0.00000109 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 95 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002013, itemized = {state_0: 0.00000011, state_1: 0.00686170, state_2: 0.00000582, state_3: 0.00001005, state_MSE: 0.00171942, q_error_norm: 0.00161747, qd_error_norm: 0.00316007} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00210107, itemized = {state_0: 0.00000051, state_1: 0.01190434, state_2: 0.00062131, state_3: 0.00175330, state_MSE: 0.00356987, q_error_norm: 0.00280933, qd_error_norm: 0.00889971} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.233 sec, time(other): 0.011 sec, time(dataloader): 4.491 sec, time(compute_loss): 1.744 sec, time(backward): 4.092 sec, time(eval): 0.688 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.005796, device='cuda:0'), grad_norm_after_clip: tensor(0.005796, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.06it/s]\n",
            "100% 11/11 [00:00<00:00, 24.01it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.76it/s]\n",
            "100% 4/4 [00:00<00:00,  8.02it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002916, Rollout MSE Error (joint_q) = 0.00000095 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 96 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002117, itemized = {state_0: 0.00000011, state_1: 0.00747837, state_2: 0.00000624, state_3: 0.00001085, state_MSE: 0.00187389, q_error_norm: 0.00171575, qd_error_norm: 0.00324707} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00230237, itemized = {state_0: 0.00000052, state_1: 0.01190533, state_2: 0.00069720, state_3: 0.00190582, state_MSE: 0.00362722, q_error_norm: 0.00281405, qd_error_norm: 0.00906494} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.229 sec, time(other): 0.011 sec, time(dataloader): 4.473 sec, time(compute_loss): 1.784 sec, time(backward): 4.102 sec, time(eval): 0.667 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.007825, device='cuda:0'), grad_norm_after_clip: tensor(0.007825, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.91it/s]\n",
            "100% 11/11 [00:00<00:00, 23.49it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.50it/s]\n",
            "100% 4/4 [00:00<00:00,  8.12it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00001987, Rollout MSE Error (joint_q) = 0.00000104 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 97 with MSE error 1.986932875297498e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 97 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001993, itemized = {state_0: 0.00000011, state_1: 0.00663043, state_2: 0.00000581, state_3: 0.00000989, state_MSE: 0.00166156, q_error_norm: 0.00157931, qd_error_norm: 0.00313716} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00218407, itemized = {state_0: 0.00000051, state_1: 0.01260471, state_2: 0.00065615, state_3: 0.00181206, state_MSE: 0.00376836, q_error_norm: 0.00291852, qd_error_norm: 0.00882448} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.410 sec, time(other): 0.011 sec, time(dataloader): 4.592 sec, time(compute_loss): 1.838 sec, time(backward): 4.086 sec, time(eval): 0.687 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.006572, device='cuda:0'), grad_norm_after_clip: tensor(0.006572, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.95it/s]\n",
            "100% 11/11 [00:00<00:00, 24.13it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.29it/s]\n",
            "100% 4/4 [00:00<00:00,  8.13it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002444, Rollout MSE Error (joint_q) = 0.00000112 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 98 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001955, itemized = {state_0: 0.00000011, state_1: 0.00647617, state_2: 0.00000545, state_3: 0.00000998, state_MSE: 0.00162292, q_error_norm: 0.00155085, qd_error_norm: 0.00311457} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00225569, itemized = {state_0: 0.00000051, state_1: 0.01260539, state_2: 0.00068280, state_3: 0.00186729, state_MSE: 0.00378900, q_error_norm: 0.00291569, qd_error_norm: 0.00887282} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.343 sec, time(other): 0.011 sec, time(dataloader): 4.582 sec, time(compute_loss): 1.826 sec, time(backward): 4.057 sec, time(eval): 0.664 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.006032, device='cuda:0'), grad_norm_after_clip: tensor(0.006032, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.09it/s]\n",
            "100% 11/11 [00:00<00:00, 22.31it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.61it/s]\n",
            "100% 4/4 [00:00<00:00,  8.15it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002006, Rollout MSE Error (joint_q) = 0.00000115 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 99 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001859, itemized = {state_0: 0.00000010, state_1: 0.00724731, state_2: 0.00000518, state_3: 0.00000931, state_MSE: 0.00181548, q_error_norm: 0.00166473, qd_error_norm: 0.00303153} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00209275, itemized = {state_0: 0.00000050, state_1: 0.01190432, state_2: 0.00062459, state_3: 0.00174050, state_MSE: 0.00356748, q_error_norm: 0.00279256, qd_error_norm: 0.00868593} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.236 sec, time(other): 0.011 sec, time(dataloader): 4.522 sec, time(compute_loss): 1.784 sec, time(backward): 4.060 sec, time(eval): 0.661 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.004989, device='cuda:0'), grad_norm_after_clip: tensor(0.004989, device='cuda:0')} \u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading output.log 133.0KB/133.0KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading output.log 133.0KB/133.0KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading output.log 133.0KB/133.0KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading output.log 133.0KB/133.0KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading output.log 133.0KB/133.0KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading output.log 133.0KB/133.0KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading output.log 133.0KB/133.0KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading output.log 133.0KB/133.0KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading output.log 133.0KB/133.0KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading output.log 133.0KB/133.0KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading output.log 133.0KB/133.0KB (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading output.log 133.0KB/133.0KB (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading output.log 133.0KB/133.0KB (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading output.log 133.0KB/133.0KB (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading output.log 133.0KB/133.0KB (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading history steps 99-99, summary, console lines 1327-1339 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading history steps 99-99, summary, console lines 1327-1339 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch ‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch ‚ñà‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch 0.00712\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch 2e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch 0.00122\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch 0.00694\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch 4e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch 0.00261\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch 0.0037\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch 0.00481\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch 0.00588\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mmamba\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics/runs/79p99k2a\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251205_042107-79p99k2a/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "import os\n",
        "\n",
        "# Ensure the current working directory is 'train'\n",
        "%cd train\n",
        "\n",
        "# --- Step 1: Re-generate and Force Config to 100 Epochs ---\n",
        "# Load default config (which was the base for colab_config.yaml)\n",
        "with open('cfg/Cartpole/transformer.yaml', 'r') as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "\n",
        "# Apply dataset path overrides, as done in the initial config creation\n",
        "cfg['algorithm']['dataset']['train_dataset_path'] = '../data/datasets/Cartpole/trajectory_len-100_train.hdf5'\n",
        "cfg['algorithm']['dataset']['valid_datasets']['exp_trajectory'] = '../data/datasets/Cartpole/trajectory_len-100_valid.hdf5'\n",
        "\n",
        "# Force num_epochs to 100 and num_iters_per_epoch to 100\n",
        "cfg['algorithm']['num_epochs'] = 100\n",
        "cfg['algorithm']['num_iters_per_epoch'] = 100\n",
        "\n",
        "# Save the modified config\n",
        "with open('colab_config.yaml', 'w') as f:\n",
        "    yaml.dump(cfg, f)\n",
        "print(\"Configuration updated: num_epochs set to 100.\")\n",
        "\n",
        "# --- Step 2: Run Training ---\n",
        "!python train.py --cfg colab_config.yaml --novelty mamba --logdir ../data/logs/mamba --wandb-project {wandb_project} --wandb-name mamba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a32b3a28",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a32b3a28",
        "outputId": "92a8ac99-929e-473b-a088-553b73ce4efa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updating configuration to 100 epochs...\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "2025-12-05 04:40:52.068519: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-05 04:40:52.086046: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764909652.107200   17414 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764909652.113663   17414 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764909652.129968   17414 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764909652.129995   17414 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764909652.129998   17414 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764909652.130001   17414 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-05 04:40:52.134928: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 512 environments: 100% 512/512 [00:01<00:00, 304.14it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 4.06 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.50 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.58 ms  (cached)\n",
            "\u001b[91m [NeuralEnvironment] Created a DUMMY Neural Integrator. \u001b[0m\n",
            "Model = \n",
            " ModelMixedInput(\n",
            "  (encoders): ModuleDict(\n",
            "    (low_dim): MLPBase(\n",
            "      (body): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (mamba_model): Mamba(\n",
            "    (embedding): Linear(in_features=6, out_features=192, bias=True)\n",
            "    (layers): ModuleList(\n",
            "      (0-5): 6 x MambaBlock(\n",
            "        (in_proj): Linear(in_features=192, out_features=768, bias=False)\n",
            "        (conv1d): Conv1d(384, 384, kernel_size=(4,), stride=(1,), padding=(3,), groups=384)\n",
            "        (x_proj): Linear(in_features=384, out_features=44, bias=False)\n",
            "        (dt_proj): Linear(in_features=12, out_features=384, bias=True)\n",
            "        (out_proj): Linear(in_features=384, out_features=192, bias=False)\n",
            "      )\n",
            "    )\n",
            "    (norm_f): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (model): MLPDeterministic(\n",
            "    (feature_net): MLPBase(\n",
            "      (body): Sequential(\n",
            "        (0): Linear(in_features=192, out_features=64, bias=True)\n",
            "        (1): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (output_net): Linear(in_features=64, out_features=4, bias=True)\n",
            "  )\n",
            ")\n",
            "# Model Parameters =  1523460\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run m7xnn318 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run m7xnn318 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run m7xnn318 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251205_044102-m7xnn318\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba_100\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics/runs/m7xnn318\u001b[0m\n",
            "Computing dataset statistics...\n",
            "Finished computing dataset statistics...\n",
            "100% 11/11 [00:00<00:00, 20.53it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions:   0% 0/4 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.65 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.44 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.45 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.78 ms  (cached)\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 18.05it/s]\n",
            "100% 4/4 [00:00<00:00,  7.83it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 1.43373585, Rollout MSE Error (joint_q) = 0.06781688 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 0 with MSE error 1.4337358474731445. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 0 \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 1.00439644, itemized = {state_0: 0.00870172, state_1: 0.91801999, state_2: 0.25972505, state_3: 0.32500295, state_MSE: 0.37786241, q_error_norm: 0.30157633, qd_error_norm: 0.58810208} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 1.313 sec, time(other): 0.001 sec, time(dataloader): 0.174 sec, time(compute_loss): 0.359 sec, time(backward): 0.000 sec, time(eval): 0.773 sec \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 0 with loss 1.00439644. \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.27it/s]\n",
            "100% 11/11 [00:00<00:00, 21.60it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.84it/s]\n",
            "100% 4/4 [00:00<00:00,  7.61it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.01028648, Rollout MSE Error (joint_q) = 0.00042889 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 1 with MSE error 0.010286478325724602. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 1 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.15960569, itemized = {state_0: 0.00041083, state_1: 0.11955365, state_2: 0.05958495, state_3: 0.09523325, state_MSE: 0.06869565, q_error_norm: 0.04145229, qd_error_norm: 0.22197483} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.01880515, itemized = {state_0: 0.00003375, state_1: 0.03856158, state_2: 0.00784786, state_3: 0.01119122, state_MSE: 0.01440860, q_error_norm: 0.01479512, qd_error_norm: 0.08790811} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.139 sec, time(other): 0.011 sec, time(dataloader): 4.343 sec, time(compute_loss): 1.716 sec, time(backward): 4.148 sec, time(eval): 0.726 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.357529, device='cuda:0'), grad_norm_after_clip: tensor(0.344295, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 1 with loss 0.01880515. \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.09it/s]\n",
            "100% 11/11 [00:00<00:00, 23.57it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.61it/s]\n",
            "100% 4/4 [00:00<00:00,  8.07it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00622430, Rollout MSE Error (joint_q) = 0.00034123 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 2 with MSE error 0.0062243021093308926. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 2 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00814987, itemized = {state_0: 0.00002001, state_1: 0.04085793, state_2: 0.00339309, state_3: 0.00456803, state_MSE: 0.01220977, q_error_norm: 0.01318524, qd_error_norm: 0.05916314} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00707954, itemized = {state_0: 0.00001319, state_1: 0.04337503, state_2: 0.00224260, state_3: 0.00490016, state_MSE: 0.01263274, q_error_norm: 0.01292721, qd_error_norm: 0.05028357} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.234 sec, time(other): 0.011 sec, time(dataloader): 4.538 sec, time(compute_loss): 1.741 sec, time(backward): 4.062 sec, time(eval): 0.685 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.186105, device='cuda:0'), grad_norm_after_clip: tensor(0.186105, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 2 with loss 0.00707954. \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.92it/s]\n",
            "100% 11/11 [00:00<00:00, 24.16it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.82it/s]\n",
            "100% 4/4 [00:00<00:00,  8.08it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00564273, Rollout MSE Error (joint_q) = 0.00017895 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 3 with MSE error 0.005642732605338097. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 3 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00412390, itemized = {state_0: 0.00000938, state_1: 0.02825082, state_2: 0.00164048, state_3: 0.00241569, state_MSE: 0.00807909, q_error_norm: 0.00947066, qd_error_norm: 0.04235130} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00571838, itemized = {state_0: 0.00000926, state_1: 0.04895463, state_2: 0.00174749, state_3: 0.00415528, state_MSE: 0.01371667, q_error_norm: 0.01278511, qd_error_norm: 0.04556713} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.391 sec, time(other): 0.011 sec, time(dataloader): 4.624 sec, time(compute_loss): 1.798 sec, time(backward): 4.067 sec, time(eval): 0.684 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.189074, device='cuda:0'), grad_norm_after_clip: tensor(0.189074, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 3 with loss 0.00571838. \u001b[0m\n",
            "100% 100/100 [00:10<00:00, 10.00it/s]\n",
            "100% 11/11 [00:00<00:00, 23.30it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.93it/s]\n",
            "100% 4/4 [00:00<00:00,  7.68it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00101372, Rollout MSE Error (joint_q) = 0.00007924 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 4 with MSE error 0.0010137228528037667. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 4 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00190208, itemized = {state_0: 0.00000585, state_1: 0.02341342, state_2: 0.00068107, state_3: 0.00109232, state_MSE: 0.00629816, q_error_norm: 0.00770630, qd_error_norm: 0.02977268} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00395867, itemized = {state_0: 0.00000628, state_1: 0.04054648, state_2: 0.00129455, state_3: 0.00281990, state_MSE: 0.01116680, q_error_norm: 0.01043818, qd_error_norm: 0.03174248} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.380 sec, time(other): 0.011 sec, time(dataloader): 4.611 sec, time(compute_loss): 1.762 sec, time(backward): 4.064 sec, time(eval): 0.724 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.108665, device='cuda:0'), grad_norm_after_clip: tensor(0.108665, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 4 with loss 0.00395867. \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.98it/s]\n",
            "100% 11/11 [00:00<00:00, 23.58it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.49it/s]\n",
            "100% 4/4 [00:00<00:00,  8.15it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00258426, Rollout MSE Error (joint_q) = 0.00013089 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 5 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00436829, itemized = {state_0: 0.00000592, state_1: 0.02387729, state_2: 0.00168114, state_3: 0.00290922, state_MSE: 0.00711839, q_error_norm: 0.00773087, qd_error_norm: 0.03942255} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00938347, itemized = {state_0: 0.00000855, state_1: 0.04266949, state_2: 0.00293529, state_3: 0.00723434, state_MSE: 0.01321191, q_error_norm: 0.01156847, qd_error_norm: 0.05168683} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.320 sec, time(other): 0.011 sec, time(dataloader): 4.612 sec, time(compute_loss): 1.775 sec, time(backward): 4.063 sec, time(eval): 0.661 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.243364, device='cuda:0'), grad_norm_after_clip: tensor(0.243364, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.09it/s]\n",
            "100% 11/11 [00:00<00:00, 22.96it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.49it/s]\n",
            "100% 4/4 [00:00<00:00,  8.12it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00066386, Rollout MSE Error (joint_q) = 0.00006222 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 6 with MSE error 0.0006638583145104349. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 6 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00203289, itemized = {state_0: 0.00000484, state_1: 0.02233842, state_2: 0.00075974, state_3: 0.00124122, state_MSE: 0.00608605, q_error_norm: 0.00706063, qd_error_norm: 0.02805228} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00271150, itemized = {state_0: 0.00000458, state_1: 0.03494656, state_2: 0.00067362, state_3: 0.00212531, state_MSE: 0.00943752, q_error_norm: 0.00898603, qd_error_norm: 0.02417921} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.248 sec, time(other): 0.011 sec, time(dataloader): 4.547 sec, time(compute_loss): 1.715 sec, time(backward): 4.088 sec, time(eval): 0.683 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.101941, device='cuda:0'), grad_norm_after_clip: tensor(0.101941, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 6 with loss 0.00271150. \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.01it/s]\n",
            "100% 11/11 [00:00<00:00, 22.50it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.23it/s]\n",
            "100% 4/4 [00:00<00:00,  7.60it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00053173, Rollout MSE Error (joint_q) = 0.00004931 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 7 with MSE error 0.0005317269242368639. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 7 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00066453, itemized = {state_0: 0.00000292, state_1: 0.01672280, state_2: 0.00021367, state_3: 0.00035263, state_MSE: 0.00432301, q_error_norm: 0.00545320, qd_error_norm: 0.01798892} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00270066, itemized = {state_0: 0.00000406, state_1: 0.03705338, state_2: 0.00069050, state_3: 0.00213622, state_MSE: 0.00997104, q_error_norm: 0.00903708, qd_error_norm: 0.02291676} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.393 sec, time(other): 0.011 sec, time(dataloader): 4.624 sec, time(compute_loss): 1.769 sec, time(backward): 4.043 sec, time(eval): 0.727 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.041661, device='cuda:0'), grad_norm_after_clip: tensor(0.041661, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 7 with loss 0.00270066. \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.02it/s]\n",
            "100% 11/11 [00:00<00:00, 23.67it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.28it/s]\n",
            "100% 4/4 [00:00<00:00,  8.03it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00051668, Rollout MSE Error (joint_q) = 0.00004047 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 8 with MSE error 0.0005166800110600889. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 8 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00057464, itemized = {state_0: 0.00000246, state_1: 0.01448769, state_2: 0.00019152, state_3: 0.00030347, state_MSE: 0.00374628, q_error_norm: 0.00486275, qd_error_norm: 0.01655966} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00249690, itemized = {state_0: 0.00000351, state_1: 0.03845926, state_2: 0.00059992, state_3: 0.00201855, state_MSE: 0.01027031, q_error_norm: 0.00907975, qd_error_norm: 0.02199553} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.302 sec, time(other): 0.010 sec, time(dataloader): 4.622 sec, time(compute_loss): 1.743 sec, time(backward): 4.037 sec, time(eval): 0.690 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.040395, device='cuda:0'), grad_norm_after_clip: tensor(0.040395, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 8 with loss 0.00249690. \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.97it/s]\n",
            "100% 11/11 [00:00<00:00, 23.79it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.60it/s]\n",
            "100% 4/4 [00:00<00:00,  8.11it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00528236, Rollout MSE Error (joint_q) = 0.00007110 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 9 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00181335, itemized = {state_0: 0.00000283, state_1: 0.01487261, state_2: 0.00079866, state_3: 0.00108245, state_MSE: 0.00418914, q_error_norm: 0.00501960, qd_error_norm: 0.02429984} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00787108, itemized = {state_0: 0.00000666, state_1: 0.03427875, state_2: 0.00346909, state_3: 0.00502061, state_MSE: 0.01069377, q_error_norm: 0.00957135, qd_error_norm: 0.04692879} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.330 sec, time(other): 0.011 sec, time(dataloader): 4.597 sec, time(compute_loss): 1.779 sec, time(backward): 4.077 sec, time(eval): 0.662 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.127984, device='cuda:0'), grad_norm_after_clip: tensor(0.127984, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.97it/s]\n",
            "100% 11/11 [00:00<00:00, 22.95it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.94it/s]\n",
            "100% 4/4 [00:00<00:00,  7.63it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00074757, Rollout MSE Error (joint_q) = 0.00003820 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 10 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00144704, itemized = {state_0: 0.00000311, state_1: 0.01548983, state_2: 0.00056381, state_3: 0.00089000, state_MSE: 0.00423668, q_error_norm: 0.00523235, qd_error_norm: 0.02385933} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00276809, itemized = {state_0: 0.00000344, state_1: 0.03425605, state_2: 0.00068441, state_3: 0.00226350, state_MSE: 0.00930185, q_error_norm: 0.00832358, qd_error_norm: 0.02251903} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.385 sec, time(other): 0.011 sec, time(dataloader): 4.647 sec, time(compute_loss): 1.760 sec, time(backward): 4.060 sec, time(eval): 0.699 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.103063, device='cuda:0'), grad_norm_after_clip: tensor(0.103063, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.99it/s]\n",
            "100% 11/11 [00:00<00:00, 24.15it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.57it/s]\n",
            "100% 4/4 [00:00<00:00,  8.05it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00025387, Rollout MSE Error (joint_q) = 0.00002080 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 11 with MSE error 0.0002538688131608069. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 11 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00052788, itemized = {state_0: 0.00000195, state_1: 0.01148591, state_2: 0.00017605, state_3: 0.00030327, state_MSE: 0.00299179, q_error_norm: 0.00405719, qd_error_norm: 0.01589598} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00251101, itemized = {state_0: 0.00000294, state_1: 0.03007081, state_2: 0.00067567, state_3: 0.00200490, state_MSE: 0.00818858, q_error_norm: 0.00734599, qd_error_norm: 0.01966836} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.336 sec, time(other): 0.011 sec, time(dataloader): 4.600 sec, time(compute_loss): 1.764 sec, time(backward): 4.062 sec, time(eval): 0.694 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.059809, device='cuda:0'), grad_norm_after_clip: tensor(0.059809, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.10it/s]\n",
            "100% 11/11 [00:00<00:00, 23.92it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.68it/s]\n",
            "100% 4/4 [00:00<00:00,  8.09it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00048707, Rollout MSE Error (joint_q) = 0.00002592 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 12 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00039894, itemized = {state_0: 0.00000164, state_1: 0.01125485, state_2: 0.00011936, state_3: 0.00023185, state_MSE: 0.00290192, q_error_norm: 0.00385664, qd_error_norm: 0.01416551} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00229170, itemized = {state_0: 0.00000286, state_1: 0.02726108, state_2: 0.00058055, state_3: 0.00185296, state_MSE: 0.00742436, q_error_norm: 0.00683773, qd_error_norm: 0.01880225} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.185 sec, time(other): 0.011 sec, time(dataloader): 4.540 sec, time(compute_loss): 1.698 sec, time(backward): 4.076 sec, time(eval): 0.664 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.046564, device='cuda:0'), grad_norm_after_clip: tensor(0.046564, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 12 with loss 0.00229170. \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.97it/s]\n",
            "100% 11/11 [00:00<00:00, 22.35it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.23it/s]\n",
            "100% 4/4 [00:00<00:00,  7.49it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00027780, Rollout MSE Error (joint_q) = 0.00002617 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 13 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00039524, itemized = {state_0: 0.00000152, state_1: 0.01110019, state_2: 0.00012178, state_3: 0.00023272, state_MSE: 0.00286405, q_error_norm: 0.00375532, qd_error_norm: 0.01397752} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00229348, itemized = {state_0: 0.00000290, state_1: 0.02656706, state_2: 0.00059518, state_3: 0.00184596, state_MSE: 0.00725278, q_error_norm: 0.00674179, qd_error_norm: 0.01828030} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.417 sec, time(other): 0.011 sec, time(dataloader): 4.652 sec, time(compute_loss): 1.774 sec, time(backward): 4.057 sec, time(eval): 0.713 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.048134, device='cuda:0'), grad_norm_after_clip: tensor(0.048134, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.04it/s]\n",
            "100% 11/11 [00:00<00:00, 23.04it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.71it/s]\n",
            "100% 4/4 [00:00<00:00,  8.02it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00119362, Rollout MSE Error (joint_q) = 0.00003193 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 14 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00069622, itemized = {state_0: 0.00000156, state_1: 0.01140839, state_2: 0.00023443, state_3: 0.00045659, state_MSE: 0.00302524, q_error_norm: 0.00389990, qd_error_norm: 0.01750798} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00261100, itemized = {state_0: 0.00000280, state_1: 0.03218563, state_2: 0.00057034, state_3: 0.00224203, state_MSE: 0.00875020, q_error_norm: 0.00749910, qd_error_norm: 0.02134986} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.283 sec, time(other): 0.011 sec, time(dataloader): 4.611 sec, time(compute_loss): 1.744 sec, time(backward): 4.047 sec, time(eval): 0.668 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.087670, device='cuda:0'), grad_norm_after_clip: tensor(0.087670, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.86it/s]\n",
            "100% 11/11 [00:00<00:00, 22.75it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.88it/s]\n",
            "100% 4/4 [00:00<00:00,  8.10it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00091982, Rollout MSE Error (joint_q) = 0.00002901 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 15 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00045509, itemized = {state_0: 0.00000138, state_1: 0.00925017, state_2: 0.00014594, state_3: 0.00028477, state_MSE: 0.00242057, q_error_norm: 0.00338400, qd_error_norm: 0.01466074} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00227137, itemized = {state_0: 0.00000264, state_1: 0.02237880, state_2: 0.00054870, state_3: 0.00188381, state_MSE: 0.00620349, q_error_norm: 0.00594973, qd_error_norm: 0.01900773} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.470 sec, time(other): 0.011 sec, time(dataloader): 4.683 sec, time(compute_loss): 1.816 sec, time(backward): 4.085 sec, time(eval): 0.670 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.061224, device='cuda:0'), grad_norm_after_clip: tensor(0.061224, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 15 with loss 0.00227137. \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.03it/s]\n",
            "100% 11/11 [00:00<00:00, 22.37it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.18it/s]\n",
            "100% 4/4 [00:00<00:00,  7.65it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00148224, Rollout MSE Error (joint_q) = 0.00005589 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 16 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00072159, itemized = {state_0: 0.00000157, state_1: 0.01079114, state_2: 0.00025829, state_3: 0.00046715, state_MSE: 0.00287954, q_error_norm: 0.00371335, qd_error_norm: 0.01790681} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00266330, itemized = {state_0: 0.00000305, state_1: 0.03570386, state_2: 0.00068301, state_3: 0.00218114, state_MSE: 0.00964276, q_error_norm: 0.00817152, qd_error_norm: 0.02296611} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.353 sec, time(other): 0.011 sec, time(dataloader): 4.626 sec, time(compute_loss): 1.750 sec, time(backward): 4.047 sec, time(eval): 0.702 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.096571, device='cuda:0'), grad_norm_after_clip: tensor(0.096571, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.03it/s]\n",
            "100% 11/11 [00:00<00:00, 23.80it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.51it/s]\n",
            "100% 4/4 [00:00<00:00,  8.03it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00104740, Rollout MSE Error (joint_q) = 0.00003841 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 17 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00133265, itemized = {state_0: 0.00000221, state_1: 0.01333152, state_2: 0.00050501, state_3: 0.00087215, state_MSE: 0.00367772, q_error_norm: 0.00452785, qd_error_norm: 0.02308581} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00354139, itemized = {state_0: 0.00000281, state_1: 0.02519210, state_2: 0.00120637, state_3: 0.00265378, state_MSE: 0.00726377, q_error_norm: 0.00642557, qd_error_norm: 0.02524525} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.287 sec, time(other): 0.011 sec, time(dataloader): 4.609 sec, time(compute_loss): 1.747 sec, time(backward): 4.032 sec, time(eval): 0.680 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.129869, device='cuda:0'), grad_norm_after_clip: tensor(0.129869, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.04it/s]\n",
            "100% 11/11 [00:00<00:00, 24.21it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.22it/s]\n",
            "100% 4/4 [00:00<00:00,  8.02it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00021880, Rollout MSE Error (joint_q) = 0.00001361 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 18 with MSE error 0.00021880293206777424. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 18 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00041194, itemized = {state_0: 0.00000132, state_1: 0.01163824, state_2: 0.00013596, state_3: 0.00025042, state_MSE: 0.00300649, q_error_norm: 0.00369492, qd_error_norm: 0.01348465} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00204554, itemized = {state_0: 0.00000211, state_1: 0.02729020, state_2: 0.00051450, state_3: 0.00168794, state_MSE: 0.00737369, q_error_norm: 0.00648944, qd_error_norm: 0.01588603} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.272 sec, time(other): 0.011 sec, time(dataloader): 4.568 sec, time(compute_loss): 1.738 sec, time(backward): 4.065 sec, time(eval): 0.691 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.049092, device='cuda:0'), grad_norm_after_clip: tensor(0.049092, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 18 with loss 0.00204554. \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.94it/s]\n",
            "100% 11/11 [00:00<00:00, 22.54it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.65it/s]\n",
            "100% 4/4 [00:00<00:00,  7.68it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00043173, Rollout MSE Error (joint_q) = 0.00001915 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 19 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00024248, itemized = {state_0: 0.00000099, state_1: 0.01032959, state_2: 0.00007693, state_3: 0.00013518, state_MSE: 0.00263567, q_error_norm: 0.00327616, qd_error_norm: 0.01087656} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00231959, itemized = {state_0: 0.00000225, state_1: 0.02239030, state_2: 0.00057153, state_3: 0.00194229, state_MSE: 0.00622659, q_error_norm: 0.00568802, qd_error_norm: 0.01734618} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.423 sec, time(other): 0.011 sec, time(dataloader): 4.653 sec, time(compute_loss): 1.799 sec, time(backward): 4.052 sec, time(eval): 0.697 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.036912, device='cuda:0'), grad_norm_after_clip: tensor(0.036912, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.00it/s]\n",
            "100% 11/11 [00:00<00:00, 23.70it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.63it/s]\n",
            "100% 4/4 [00:00<00:00,  8.17it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00026365, Rollout MSE Error (joint_q) = 0.00001340 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 20 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00024382, itemized = {state_0: 0.00000096, state_1: 0.01048462, state_2: 0.00007600, state_3: 0.00014150, state_MSE: 0.00267577, q_error_norm: 0.00324677, qd_error_norm: 0.01090973} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00232143, itemized = {state_0: 0.00000224, state_1: 0.02028463, state_2: 0.00063232, state_3: 0.00188932, state_MSE: 0.00570213, q_error_norm: 0.00521231, qd_error_norm: 0.01703934} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.291 sec, time(other): 0.011 sec, time(dataloader): 4.646 sec, time(compute_loss): 1.742 sec, time(backward): 4.033 sec, time(eval): 0.658 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.038933, device='cuda:0'), grad_norm_after_clip: tensor(0.038933, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.90it/s]\n",
            "100% 11/11 [00:00<00:00, 23.82it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.51it/s]\n",
            "100% 4/4 [00:00<00:00,  8.12it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00158778, Rollout MSE Error (joint_q) = 0.00010204 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 21 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00114769, itemized = {state_0: 0.00000169, state_1: 0.01487379, state_2: 0.00042065, state_3: 0.00076637, state_MSE: 0.00401563, q_error_norm: 0.00466988, qd_error_norm: 0.02098227} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00332720, itemized = {state_0: 0.00000273, state_1: 0.02380685, state_2: 0.00090150, state_3: 0.00270857, state_MSE: 0.00685491, q_error_norm: 0.00646216, qd_error_norm: 0.02424359} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.400 sec, time(other): 0.011 sec, time(dataloader): 4.651 sec, time(compute_loss): 1.802 sec, time(backward): 4.068 sec, time(eval): 0.662 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.121192, device='cuda:0'), grad_norm_after_clip: tensor(0.121192, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.96it/s]\n",
            "100% 11/11 [00:00<00:00, 22.68it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.20it/s]\n",
            "100% 4/4 [00:00<00:00,  7.51it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00232467, Rollout MSE Error (joint_q) = 0.00004884 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 22 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00066864, itemized = {state_0: 0.00000129, state_1: 0.01263876, state_2: 0.00024150, state_3: 0.00043011, state_MSE: 0.00332791, q_error_norm: 0.00396626, qd_error_norm: 0.01651714} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00280942, itemized = {state_0: 0.00000245, state_1: 0.03360597, state_2: 0.00076984, state_3: 0.00227711, state_MSE: 0.00916384, q_error_norm: 0.00779801, qd_error_norm: 0.02518412} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.403 sec, time(other): 0.011 sec, time(dataloader): 4.632 sec, time(compute_loss): 1.783 sec, time(backward): 4.064 sec, time(eval): 0.705 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.081894, device='cuda:0'), grad_norm_after_clip: tensor(0.081894, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.03it/s]\n",
            "100% 11/11 [00:00<00:00, 23.92it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.60it/s]\n",
            "100% 4/4 [00:00<00:00,  8.13it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00030527, Rollout MSE Error (joint_q) = 0.00001346 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 23 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00053624, itemized = {state_0: 0.00000116, state_1: 0.01279356, state_2: 0.00018869, state_3: 0.00034248, state_MSE: 0.00333147, q_error_norm: 0.00387227, qd_error_norm: 0.01501839} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00259847, itemized = {state_0: 0.00000200, state_1: 0.02099143, state_2: 0.00057905, state_3: 0.00227867, state_MSE: 0.00596279, q_error_norm: 0.00534475, qd_error_norm: 0.01718560} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.262 sec, time(other): 0.011 sec, time(dataloader): 4.577 sec, time(compute_loss): 1.737 sec, time(backward): 4.074 sec, time(eval): 0.666 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.068808, device='cuda:0'), grad_norm_after_clip: tensor(0.068808, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.08it/s]\n",
            "100% 11/11 [00:00<00:00, 24.34it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.73it/s]\n",
            "100% 4/4 [00:00<00:00,  8.16it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00016460, Rollout MSE Error (joint_q) = 0.00002268 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 24 with MSE error 0.00016460104961879551. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 24 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00024848, itemized = {state_0: 0.00000084, state_1: 0.01148516, state_2: 0.00008124, state_3: 0.00014780, state_MSE: 0.00292876, q_error_norm: 0.00332778, qd_error_norm: 0.01074654} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00231240, itemized = {state_0: 0.00000198, state_1: 0.01538824, state_2: 0.00059998, state_3: 0.00192663, state_MSE: 0.00447921, q_error_norm: 0.00439503, qd_error_norm: 0.01504633} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.236 sec, time(other): 0.011 sec, time(dataloader): 4.537 sec, time(compute_loss): 1.716 sec, time(backward): 4.083 sec, time(eval): 0.679 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.039724, device='cuda:0'), grad_norm_after_clip: tensor(0.039724, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.96it/s]\n",
            "100% 11/11 [00:00<00:00, 22.45it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.78it/s]\n",
            "100% 4/4 [00:00<00:00,  7.44it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00033794, Rollout MSE Error (joint_q) = 0.00001166 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 25 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00022323, itemized = {state_0: 0.00000078, state_1: 0.01241040, state_2: 0.00007334, state_3: 0.00013026, state_MSE: 0.00315370, q_error_norm: 0.00343315, qd_error_norm: 0.01010017} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00239934, itemized = {state_0: 0.00000185, state_1: 0.01819801, state_2: 0.00068891, state_3: 0.00193844, state_MSE: 0.00520680, q_error_norm: 0.00473815, qd_error_norm: 0.01622182} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.438 sec, time(other): 0.011 sec, time(dataloader): 4.610 sec, time(compute_loss): 1.800 sec, time(backward): 4.085 sec, time(eval): 0.722 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.040214, device='cuda:0'), grad_norm_after_clip: tensor(0.040214, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.01it/s]\n",
            "100% 11/11 [00:00<00:00, 24.07it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.49it/s]\n",
            "100% 4/4 [00:00<00:00,  8.09it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00024526, Rollout MSE Error (joint_q) = 0.00001599 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 26 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00027181, itemized = {state_0: 0.00000080, state_1: 0.01056039, state_2: 0.00008559, state_3: 0.00017186, state_MSE: 0.00270466, q_error_norm: 0.00317365, qd_error_norm: 0.01125262} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00223378, itemized = {state_0: 0.00000189, state_1: 0.01470942, state_2: 0.00065836, state_3: 0.00176637, state_MSE: 0.00428401, q_error_norm: 0.00434076, qd_error_norm: 0.01535389} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.283 sec, time(other): 0.011 sec, time(dataloader): 4.616 sec, time(compute_loss): 1.741 sec, time(backward): 4.046 sec, time(eval): 0.665 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.046384, device='cuda:0'), grad_norm_after_clip: tensor(0.046384, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.92it/s]\n",
            "100% 11/11 [00:00<00:00, 23.06it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.39it/s]\n",
            "100% 4/4 [00:00<00:00,  7.90it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00278426, Rollout MSE Error (joint_q) = 0.00005791 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 27 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00064927, itemized = {state_0: 0.00000106, state_1: 0.01225449, state_2: 0.00024332, state_3: 0.00042387, state_MSE: 0.00323069, q_error_norm: 0.00372069, qd_error_norm: 0.01547146} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00506239, itemized = {state_0: 0.00000307, state_1: 0.01819780, state_2: 0.00156291, state_3: 0.00401982, state_MSE: 0.00594590, q_error_norm: 0.00557049, qd_error_norm: 0.03269226} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.412 sec, time(other): 0.011 sec, time(dataloader): 4.636 sec, time(compute_loss): 1.781 sec, time(backward): 4.097 sec, time(eval): 0.677 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.087475, device='cuda:0'), grad_norm_after_clip: tensor(0.087475, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.03it/s]\n",
            "100% 11/11 [00:00<00:00, 21.56it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.27it/s]\n",
            "100% 4/4 [00:00<00:00,  7.41it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00056587, Rollout MSE Error (joint_q) = 0.00002054 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 28 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00213884, itemized = {state_0: 0.00000271, state_1: 0.01940990, state_2: 0.00083780, state_3: 0.00140951, state_MSE: 0.00541498, q_error_norm: 0.00581569, qd_error_norm: 0.02696212} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00237702, itemized = {state_0: 0.00000207, state_1: 0.02171292, state_2: 0.00065863, state_3: 0.00191893, state_MSE: 0.00607314, q_error_norm: 0.00566087, qd_error_norm: 0.01793190} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.392 sec, time(other): 0.011 sec, time(dataloader): 4.646 sec, time(compute_loss): 1.755 sec, time(backward): 4.042 sec, time(eval): 0.727 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.140570, device='cuda:0'), grad_norm_after_clip: tensor(0.140570, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.98it/s]\n",
            "100% 11/11 [00:00<00:00, 22.69it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.42it/s]\n",
            "100% 4/4 [00:00<00:00,  7.93it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00013416, Rollout MSE Error (joint_q) = 0.00002491 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 29 with MSE error 0.00013416146975941956. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 29 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00038457, itemized = {state_0: 0.00000093, state_1: 0.01264111, state_2: 0.00014657, state_3: 0.00022730, state_MSE: 0.00325398, q_error_norm: 0.00365469, qd_error_norm: 0.01247042} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00251933, itemized = {state_0: 0.00000178, state_1: 0.01469913, state_2: 0.00066546, state_3: 0.00210392, state_MSE: 0.00436757, q_error_norm: 0.00424654, qd_error_norm: 0.01677278} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.397 sec, time(other): 0.011 sec, time(dataloader): 4.643 sec, time(compute_loss): 1.756 sec, time(backward): 4.068 sec, time(eval): 0.704 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.058287, device='cuda:0'), grad_norm_after_clip: tensor(0.058287, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.09it/s]\n",
            "100% 11/11 [00:00<00:00, 23.16it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.37it/s]\n",
            "100% 4/4 [00:00<00:00,  8.09it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00027922, Rollout MSE Error (joint_q) = 0.00000686 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 30 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00028255, itemized = {state_0: 0.00000078, state_1: 0.01348912, state_2: 0.00010128, state_3: 0.00016816, state_MSE: 0.00343984, q_error_norm: 0.00363468, qd_error_norm: 0.01103724} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00217827, itemized = {state_0: 0.00000159, state_1: 0.01679640, state_2: 0.00054720, state_3: 0.00185011, state_MSE: 0.00479882, q_error_norm: 0.00441493, qd_error_norm: 0.01550872} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.227 sec, time(other): 0.011 sec, time(dataloader): 4.535 sec, time(compute_loss): 1.729 sec, time(backward): 4.077 sec, time(eval): 0.665 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.047022, device='cuda:0'), grad_norm_after_clip: tensor(0.047022, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.93it/s]\n",
            "100% 11/11 [00:00<00:00, 22.08it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.40it/s]\n",
            "100% 4/4 [00:00<00:00,  7.61it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00015140, Rollout MSE Error (joint_q) = 0.00001485 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 31 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00021118, itemized = {state_0: 0.00000066, state_1: 0.01179303, state_2: 0.00007142, state_3: 0.00012397, state_MSE: 0.00299727, q_error_norm: 0.00326175, qd_error_norm: 0.00970724} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00213652, itemized = {state_0: 0.00000152, state_1: 0.01609703, state_2: 0.00055900, state_3: 0.00178782, state_MSE: 0.00461135, q_error_norm: 0.00427092, qd_error_norm: 0.01382860} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.448 sec, time(other): 0.011 sec, time(dataloader): 4.644 sec, time(compute_loss): 1.809 sec, time(backward): 4.078 sec, time(eval): 0.696 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.038087, device='cuda:0'), grad_norm_after_clip: tensor(0.038087, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.95it/s]\n",
            "100% 11/11 [00:00<00:00, 23.60it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.70it/s]\n",
            "100% 4/4 [00:00<00:00,  8.19it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00020339, Rollout MSE Error (joint_q) = 0.00001018 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 32 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00018291, itemized = {state_0: 0.00000061, state_1: 0.01048359, state_2: 0.00006339, state_3: 0.00010459, state_MSE: 0.00266305, q_error_norm: 0.00296935, qd_error_norm: 0.00922016} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00198294, itemized = {state_0: 0.00000142, state_1: 0.01820714, state_2: 0.00054373, state_3: 0.00163301, state_MSE: 0.00509632, q_error_norm: 0.00457641, qd_error_norm: 0.01395254} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.351 sec, time(other): 0.011 sec, time(dataloader): 4.652 sec, time(compute_loss): 1.774 sec, time(backward): 4.051 sec, time(eval): 0.657 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.037485, device='cuda:0'), grad_norm_after_clip: tensor(0.037485, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 32 with loss 0.00198294. \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.93it/s]\n",
            "100% 11/11 [00:00<00:00, 23.77it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.41it/s]\n",
            "100% 4/4 [00:00<00:00,  8.19it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00012742, Rollout MSE Error (joint_q) = 0.00001168 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 33 with MSE error 0.00012741585669573396. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 33 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00014067, itemized = {state_0: 0.00000055, state_1: 0.01094635, state_2: 0.00003970, state_3: 0.00008530, state_MSE: 0.00276797, q_error_norm: 0.00295683, qd_error_norm: 0.00827991} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00210849, itemized = {state_0: 0.00000146, state_1: 0.02380301, state_2: 0.00060338, state_3: 0.00171638, state_MSE: 0.00653106, q_error_norm: 0.00547978, qd_error_norm: 0.01411165} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.381 sec, time(other): 0.011 sec, time(dataloader): 4.630 sec, time(compute_loss): 1.788 sec, time(backward): 4.070 sec, time(eval): 0.679 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.024112, device='cuda:0'), grad_norm_after_clip: tensor(0.024112, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.95it/s]\n",
            "100% 11/11 [00:00<00:00, 22.69it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.83it/s]\n",
            "100% 4/4 [00:00<00:00,  7.53it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00059254, Rollout MSE Error (joint_q) = 0.00002243 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 34 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00040480, itemized = {state_0: 0.00000082, state_1: 0.01225577, state_2: 0.00016123, state_3: 0.00024179, state_MSE: 0.00316490, q_error_norm: 0.00351186, qd_error_norm: 0.01248295} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00202363, itemized = {state_0: 0.00000161, state_1: 0.01470023, state_2: 0.00056145, state_3: 0.00166215, state_MSE: 0.00423136, q_error_norm: 0.00408406, qd_error_norm: 0.01657535} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.426 sec, time(other): 0.011 sec, time(dataloader): 4.619 sec, time(compute_loss): 1.797 sec, time(backward): 4.075 sec, time(eval): 0.713 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.065176, device='cuda:0'), grad_norm_after_clip: tensor(0.065176, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.07it/s]\n",
            "100% 11/11 [00:00<00:00, 24.20it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.69it/s]\n",
            "100% 4/4 [00:00<00:00,  8.12it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00030657, Rollout MSE Error (joint_q) = 0.00000913 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 35 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00016381, itemized = {state_0: 0.00000059, state_1: 0.01133127, state_2: 0.00005319, state_3: 0.00009520, state_MSE: 0.00287006, q_error_norm: 0.00306062, qd_error_norm: 0.00856188} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00215202, itemized = {state_0: 0.00000135, state_1: 0.02101036, state_2: 0.00061491, state_3: 0.00175877, state_MSE: 0.00584635, q_error_norm: 0.00505645, qd_error_norm: 0.01499662} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.225 sec, time(other): 0.010 sec, time(dataloader): 4.584 sec, time(compute_loss): 1.727 sec, time(backward): 4.036 sec, time(eval): 0.663 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.030295, device='cuda:0'), grad_norm_after_clip: tensor(0.030295, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.88it/s]\n",
            "100% 11/11 [00:00<00:00, 23.83it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.77it/s]\n",
            "100% 4/4 [00:00<00:00,  8.16it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00110493, Rollout MSE Error (joint_q) = 0.00000961 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 36 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00036083, itemized = {state_0: 0.00000072, state_1: 0.01225499, state_2: 0.00014774, state_3: 0.00021424, state_MSE: 0.00315442, q_error_norm: 0.00335989, qd_error_norm: 0.01199599} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00248490, itemized = {state_0: 0.00000195, state_1: 0.01749788, state_2: 0.00069275, state_3: 0.00203391, state_MSE: 0.00505662, q_error_norm: 0.00459213, qd_error_norm: 0.01754530} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.416 sec, time(other): 0.011 sec, time(dataloader): 4.644 sec, time(compute_loss): 1.824 sec, time(backward): 4.072 sec, time(eval): 0.658 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.062546, device='cuda:0'), grad_norm_after_clip: tensor(0.062546, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.89it/s]\n",
            "100% 11/11 [00:00<00:00, 22.77it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.85it/s]\n",
            "100% 4/4 [00:00<00:00,  7.71it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00061777, Rollout MSE Error (joint_q) = 0.00002163 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 37 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00080788, itemized = {state_0: 0.00000112, state_1: 0.01209984, state_2: 0.00029811, state_3: 0.00054506, state_MSE: 0.00323603, q_error_norm: 0.00375412, qd_error_norm: 0.01796933} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00276376, itemized = {state_0: 0.00000218, state_1: 0.03641178, state_2: 0.00100035, state_3: 0.00202042, state_MSE: 0.00985868, q_error_norm: 0.00798135, qd_error_norm: 0.01876092} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.473 sec, time(other): 0.011 sec, time(dataloader): 4.672 sec, time(compute_loss): 1.817 sec, time(backward): 4.059 sec, time(eval): 0.700 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.093275, device='cuda:0'), grad_norm_after_clip: tensor(0.093275, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.07it/s]\n",
            "100% 11/11 [00:00<00:00, 23.49it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.98it/s]\n",
            "100% 4/4 [00:00<00:00,  8.10it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00039235, Rollout MSE Error (joint_q) = 0.00003671 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 38 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00031159, itemized = {state_0: 0.00000068, state_1: 0.01217783, state_2: 0.00010641, state_3: 0.00019961, state_MSE: 0.00312113, q_error_norm: 0.00339197, qd_error_norm: 0.01131269} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00223155, itemized = {state_0: 0.00000128, state_1: 0.01470482, state_2: 0.00059132, state_3: 0.00187601, state_MSE: 0.00429336, q_error_norm: 0.00408469, qd_error_norm: 0.01416553} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.237 sec, time(other): 0.011 sec, time(dataloader): 4.589 sec, time(compute_loss): 1.724 sec, time(backward): 4.042 sec, time(eval): 0.662 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.049802, device='cuda:0'), grad_norm_after_clip: tensor(0.049802, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.90it/s]\n",
            "100% 11/11 [00:00<00:00, 23.32it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.37it/s]\n",
            "100% 4/4 [00:00<00:00,  7.94it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00007870, Rollout MSE Error (joint_q) = 0.00000570 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 39 with MSE error 7.870317494962364e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 39 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00011070, itemized = {state_0: 0.00000046, state_1: 0.01079274, state_2: 0.00003410, state_3: 0.00006196, state_MSE: 0.00272231, q_error_norm: 0.00283327, qd_error_norm: 0.00730121} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00214461, itemized = {state_0: 0.00000121, state_1: 0.01260098, state_2: 0.00058368, state_3: 0.00179652, state_MSE: 0.00374560, q_error_norm: 0.00347783, qd_error_norm: 0.01237936} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.428 sec, time(other): 0.011 sec, time(dataloader): 4.653 sec, time(compute_loss): 1.792 sec, time(backward): 4.084 sec, time(eval): 0.694 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.021529, device='cuda:0'), grad_norm_after_clip: tensor(0.021529, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.89it/s]\n",
            "100% 11/11 [00:00<00:00, 22.32it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.77it/s]\n",
            "100% 4/4 [00:00<00:00,  8.09it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00010162, Rollout MSE Error (joint_q) = 0.00000528 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 40 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00009761, itemized = {state_0: 0.00000041, state_1: 0.01086979, state_2: 0.00003009, state_3: 0.00005420, state_MSE: 0.00273862, q_error_norm: 0.00278359, qd_error_norm: 0.00685838} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00216121, itemized = {state_0: 0.00000121, state_1: 0.01469969, state_2: 0.00061244, state_3: 0.00178708, state_MSE: 0.00427510, q_error_norm: 0.00379450, qd_error_norm: 0.01246062} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.453 sec, time(other): 0.011 sec, time(dataloader): 4.672 sec, time(compute_loss): 1.829 sec, time(backward): 4.062 sec, time(eval): 0.669 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.020559, device='cuda:0'), grad_norm_after_clip: tensor(0.020559, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.01it/s]\n",
            "100% 11/11 [00:00<00:00, 23.45it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.44it/s]\n",
            "100% 4/4 [00:00<00:00,  8.13it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00090677, Rollout MSE Error (joint_q) = 0.00008869 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 41 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00017587, itemized = {state_0: 0.00000046, state_1: 0.01156325, state_2: 0.00005747, state_3: 0.00011213, state_MSE: 0.00293332, q_error_norm: 0.00297714, qd_error_norm: 0.00853834} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00255475, itemized = {state_0: 0.00000133, state_1: 0.02450308, state_2: 0.00067453, state_3: 0.00213521, state_MSE: 0.00682854, q_error_norm: 0.00611737, qd_error_norm: 0.01717484} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.303 sec, time(other): 0.011 sec, time(dataloader): 4.614 sec, time(compute_loss): 1.749 sec, time(backward): 4.056 sec, time(eval): 0.664 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.037091, device='cuda:0'), grad_norm_after_clip: tensor(0.037091, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.88it/s]\n",
            "100% 11/11 [00:00<00:00, 23.41it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.58it/s]\n",
            "100% 4/4 [00:00<00:00,  8.13it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00025984, Rollout MSE Error (joint_q) = 0.00000824 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 42 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00024676, itemized = {state_0: 0.00000064, state_1: 0.01333357, state_2: 0.00007469, state_3: 0.00015924, state_MSE: 0.00339204, q_error_norm: 0.00357388, qd_error_norm: 0.01034407} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00225217, itemized = {state_0: 0.00000117, state_1: 0.01679773, state_2: 0.00062576, state_3: 0.00187977, state_MSE: 0.00482611, q_error_norm: 0.00418254, qd_error_norm: 0.01403324} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.439 sec, time(other): 0.011 sec, time(dataloader): 4.674 sec, time(compute_loss): 1.807 sec, time(backward): 4.070 sec, time(eval): 0.662 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.043221, device='cuda:0'), grad_norm_after_clip: tensor(0.043221, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.89it/s]\n",
            "100% 11/11 [00:00<00:00, 22.79it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.73it/s]\n",
            "100% 4/4 [00:00<00:00,  8.04it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00015169, Rollout MSE Error (joint_q) = 0.00000524 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 43 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00011431, itemized = {state_0: 0.00000042, state_1: 0.01117744, state_2: 0.00003654, state_3: 0.00006477, state_MSE: 0.00281979, q_error_norm: 0.00288252, qd_error_norm: 0.00730868} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00220667, itemized = {state_0: 0.00000104, state_1: 0.01610689, state_2: 0.00066067, state_3: 0.00179609, state_MSE: 0.00464117, q_error_norm: 0.00399517, qd_error_norm: 0.01286042} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.438 sec, time(other): 0.011 sec, time(dataloader): 4.654 sec, time(compute_loss): 1.836 sec, time(backward): 4.063 sec, time(eval): 0.666 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.026045, device='cuda:0'), grad_norm_after_clip: tensor(0.026045, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.01it/s]\n",
            "100% 11/11 [00:00<00:00, 22.90it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.57it/s]\n",
            "100% 4/4 [00:00<00:00,  8.06it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00273480, Rollout MSE Error (joint_q) = 0.00002438 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 44 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00081669, itemized = {state_0: 0.00000098, state_1: 0.01333361, state_2: 0.00034810, state_3: 0.00050860, state_MSE: 0.00354782, q_error_norm: 0.00379848, qd_error_norm: 0.01648249} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00378072, itemized = {state_0: 0.00000282, state_1: 0.02029855, state_2: 0.00112523, state_3: 0.00303954, state_MSE: 0.00611654, q_error_norm: 0.00560143, qd_error_norm: 0.02806894} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.308 sec, time(other): 0.011 sec, time(dataloader): 4.622 sec, time(compute_loss): 1.764 sec, time(backward): 4.043 sec, time(eval): 0.667 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.096412, device='cuda:0'), grad_norm_after_clip: tensor(0.096412, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.92it/s]\n",
            "100% 11/11 [00:00<00:00, 23.75it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.53it/s]\n",
            "100% 4/4 [00:00<00:00,  8.06it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00022638, Rollout MSE Error (joint_q) = 0.00000895 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 45 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00051008, itemized = {state_0: 0.00000099, state_1: 0.01348730, state_2: 0.00018040, state_3: 0.00032867, state_MSE: 0.00349934, q_error_norm: 0.00385365, qd_error_norm: 0.01365980} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00230171, itemized = {state_0: 0.00000121, state_1: 0.01330879, state_2: 0.00059249, state_3: 0.00197414, state_MSE: 0.00396916, q_error_norm: 0.00367874, qd_error_norm: 0.01372699} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.392 sec, time(other): 0.011 sec, time(dataloader): 4.627 sec, time(compute_loss): 1.813 sec, time(backward): 4.066 sec, time(eval): 0.675 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.059320, device='cuda:0'), grad_norm_after_clip: tensor(0.059320, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.84it/s]\n",
            "100% 11/11 [00:00<00:00, 23.38it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.52it/s]\n",
            "100% 4/4 [00:00<00:00,  8.13it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00023546, Rollout MSE Error (joint_q) = 0.00001762 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 46 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00018267, itemized = {state_0: 0.00000043, state_1: 0.01102325, state_2: 0.00006403, state_3: 0.00011429, state_MSE: 0.00280050, q_error_norm: 0.00287236, qd_error_norm: 0.00859869} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00214960, itemized = {state_0: 0.00000117, state_1: 0.02871416, state_2: 0.00062103, state_3: 0.00175391, state_MSE: 0.00777257, q_error_norm: 0.00639573, qd_error_norm: 0.01371235} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.470 sec, time(other): 0.011 sec, time(dataloader): 4.675 sec, time(compute_loss): 1.844 sec, time(backward): 4.071 sec, time(eval): 0.662 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.038791, device='cuda:0'), grad_norm_after_clip: tensor(0.038791, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.08it/s]\n",
            "100% 11/11 [00:00<00:00, 21.45it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.60it/s]\n",
            "100% 4/4 [00:00<00:00,  7.87it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00019627, Rollout MSE Error (joint_q) = 0.00000458 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 47 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00015699, itemized = {state_0: 0.00000044, state_1: 0.01140807, state_2: 0.00005098, state_3: 0.00009733, state_MSE: 0.00288920, q_error_norm: 0.00295898, qd_error_norm: 0.00834915} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00215545, itemized = {state_0: 0.00000107, state_1: 0.01470385, state_2: 0.00056305, state_3: 0.00184018, state_MSE: 0.00427703, q_error_norm: 0.00374667, qd_error_norm: 0.01240620} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.285 sec, time(other): 0.011 sec, time(dataloader): 4.600 sec, time(compute_loss): 1.722 sec, time(backward): 4.071 sec, time(eval): 0.678 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.032392, device='cuda:0'), grad_norm_after_clip: tensor(0.032392, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.92it/s]\n",
            "100% 11/11 [00:00<00:00, 22.96it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.48it/s]\n",
            "100% 4/4 [00:00<00:00,  8.12it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00049145, Rollout MSE Error (joint_q) = 0.00001019 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 48 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00014232, itemized = {state_0: 0.00000041, state_1: 0.01086865, state_2: 0.00004550, state_3: 0.00008704, state_MSE: 0.00275040, q_error_norm: 0.00286867, qd_error_norm: 0.00801628} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00215890, itemized = {state_0: 0.00000113, state_1: 0.01330155, state_2: 0.00059212, state_3: 0.00181131, state_MSE: 0.00392653, q_error_norm: 0.00361493, qd_error_norm: 0.01451038} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.394 sec, time(other): 0.011 sec, time(dataloader): 4.642 sec, time(compute_loss): 1.820 sec, time(backward): 4.056 sec, time(eval): 0.663 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.036279, device='cuda:0'), grad_norm_after_clip: tensor(0.036279, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.94it/s]\n",
            "100% 11/11 [00:00<00:00, 22.90it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.45it/s]\n",
            "100% 4/4 [00:00<00:00,  7.91it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00021704, Rollout MSE Error (joint_q) = 0.00000339 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 49 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00011901, itemized = {state_0: 0.00000037, state_1: 0.01125472, state_2: 0.00003873, state_3: 0.00007193, state_MSE: 0.00284144, q_error_norm: 0.00281429, qd_error_norm: 0.00729187} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00244717, itemized = {state_0: 0.00000104, state_1: 0.01190537, state_2: 0.00076872, state_3: 0.00196286, state_MSE: 0.00365950, q_error_norm: 0.00329677, qd_error_norm: 0.01440794} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.395 sec, time(other): 0.011 sec, time(dataloader): 4.627 sec, time(compute_loss): 1.808 sec, time(backward): 4.069 sec, time(eval): 0.677 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.028596, device='cuda:0'), grad_norm_after_clip: tensor(0.028596, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.04it/s]\n",
            "100% 11/11 [00:00<00:00, 23.96it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.79it/s]\n",
            "100% 4/4 [00:00<00:00,  7.75it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00046491, Rollout MSE Error (joint_q) = 0.00001546 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 50 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00032212, itemized = {state_0: 0.00000058, state_1: 0.01210058, state_2: 0.00010600, state_3: 0.00021674, state_MSE: 0.00310597, q_error_norm: 0.00335658, qd_error_norm: 0.01169100} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00288752, itemized = {state_0: 0.00000204, state_1: 0.01751223, state_2: 0.00092723, state_3: 0.00226175, state_MSE: 0.00517581, q_error_norm: 0.00466997, qd_error_norm: 0.01836185} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.283 sec, time(other): 0.011 sec, time(dataloader): 4.599 sec, time(compute_loss): 1.722 sec, time(backward): 4.055 sec, time(eval): 0.692 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.059335, device='cuda:0'), grad_norm_after_clip: tensor(0.059335, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.85it/s]\n",
            "100% 11/11 [00:00<00:00, 23.97it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.40it/s]\n",
            "100% 4/4 [00:00<00:00,  7.95it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00013586, Rollout MSE Error (joint_q) = 0.00000486 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 51 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00018883, itemized = {state_0: 0.00000050, state_1: 0.01102248, state_2: 0.00005823, state_3: 0.00012035, state_MSE: 0.00280039, q_error_norm: 0.00300828, qd_error_norm: 0.00894920} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00229061, itemized = {state_0: 0.00000093, state_1: 0.01120109, state_2: 0.00063036, state_3: 0.00193670, state_MSE: 0.00344227, q_error_norm: 0.00308072, qd_error_norm: 0.01222889} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.475 sec, time(other): 0.011 sec, time(dataloader): 4.679 sec, time(compute_loss): 1.828 sec, time(backward): 4.064 sec, time(eval): 0.683 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.036943, device='cuda:0'), grad_norm_after_clip: tensor(0.036943, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.87it/s]\n",
            "100% 11/11 [00:00<00:00, 23.67it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.43it/s]\n",
            "100% 4/4 [00:00<00:00,  8.09it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00006895, Rollout MSE Error (joint_q) = 0.00000345 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 52 with MSE error 6.895209662616253e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 52 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00011083, itemized = {state_0: 0.00000034, state_1: 0.01163943, state_2: 0.00003775, state_3: 0.00006276, state_MSE: 0.00293507, q_error_norm: 0.00291380, qd_error_norm: 0.00690119} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00233158, itemized = {state_0: 0.00000094, state_1: 0.01050266, state_2: 0.00066077, state_3: 0.00195007, state_MSE: 0.00327861, q_error_norm: 0.00293327, qd_error_norm: 0.01129733} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.461 sec, time(other): 0.011 sec, time(dataloader): 4.636 sec, time(compute_loss): 1.811 sec, time(backward): 4.102 sec, time(eval): 0.685 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.030004, device='cuda:0'), grad_norm_after_clip: tensor(0.030004, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.01it/s]\n",
            "100% 11/11 [00:00<00:00, 23.43it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.29it/s]\n",
            "100% 4/4 [00:00<00:00,  7.67it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00008730, Rollout MSE Error (joint_q) = 0.00000486 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 53 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00006337, itemized = {state_0: 0.00000029, state_1: 0.01086988, state_2: 0.00001951, state_3: 0.00003399, state_MSE: 0.00273092, q_error_norm: 0.00260379, qd_error_norm: 0.00549660} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00228204, itemized = {state_0: 0.00000089, state_1: 0.01259970, state_2: 0.00065227, state_3: 0.00190461, state_MSE: 0.00378937, q_error_norm: 0.00328100, qd_error_norm: 0.01183595} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.327 sec, time(other): 0.011 sec, time(dataloader): 4.603 sec, time(compute_loss): 1.761 sec, time(backward): 4.056 sec, time(eval): 0.693 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.015547, device='cuda:0'), grad_norm_after_clip: tensor(0.015547, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.83it/s]\n",
            "100% 11/11 [00:00<00:00, 22.37it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.72it/s]\n",
            "100% 4/4 [00:00<00:00,  7.87it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00012670, Rollout MSE Error (joint_q) = 0.00000717 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 54 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00010608, itemized = {state_0: 0.00000030, state_1: 0.01056112, state_2: 0.00003439, state_3: 0.00006416, state_MSE: 0.00266499, q_error_norm: 0.00266654, qd_error_norm: 0.00688518} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00252394, itemized = {state_0: 0.00000092, state_1: 0.01400037, state_2: 0.00074881, state_3: 0.00208298, state_MSE: 0.00420827, q_error_norm: 0.00350236, qd_error_norm: 0.01409312} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.532 sec, time(other): 0.011 sec, time(dataloader): 4.673 sec, time(compute_loss): 1.849 sec, time(backward): 4.105 sec, time(eval): 0.683 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.027909, device='cuda:0'), grad_norm_after_clip: tensor(0.027909, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.81it/s]\n",
            "100% 11/11 [00:00<00:00, 22.26it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.41it/s]\n",
            "100% 4/4 [00:00<00:00,  8.04it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00023914, Rollout MSE Error (joint_q) = 0.00002539 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 55 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00041889, itemized = {state_0: 0.00000061, state_1: 0.01279514, state_2: 0.00017486, state_3: 0.00025665, state_MSE: 0.00330681, q_error_norm: 0.00342136, qd_error_norm: 0.01261345} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00256554, itemized = {state_0: 0.00000118, state_1: 0.02100224, state_2: 0.00070450, state_3: 0.00216034, state_MSE: 0.00596706, q_error_norm: 0.00501173, qd_error_norm: 0.01399876} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.534 sec, time(other): 0.012 sec, time(dataloader): 4.732 sec, time(compute_loss): 1.840 sec, time(backward): 4.072 sec, time(eval): 0.668 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.067662, device='cuda:0'), grad_norm_after_clip: tensor(0.067662, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.94it/s]\n",
            "100% 11/11 [00:00<00:00, 23.30it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.98it/s]\n",
            "100% 4/4 [00:00<00:00,  7.66it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00016651, Rollout MSE Error (joint_q) = 0.00000882 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 56 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00017325, itemized = {state_0: 0.00000041, state_1: 0.01156211, state_2: 0.00005964, state_3: 0.00010889, state_MSE: 0.00293276, q_error_norm: 0.00295373, qd_error_norm: 0.00868886} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00231167, itemized = {state_0: 0.00000091, state_1: 0.01470499, state_2: 0.00060756, state_3: 0.00198221, state_MSE: 0.00432392, q_error_norm: 0.00371402, qd_error_norm: 0.01304104} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.398 sec, time(other): 0.011 sec, time(dataloader): 4.647 sec, time(compute_loss): 1.776 sec, time(backward): 4.070 sec, time(eval): 0.690 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.039322, device='cuda:0'), grad_norm_after_clip: tensor(0.039322, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.85it/s]\n",
            "100% 11/11 [00:00<00:00, 23.66it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.39it/s]\n",
            "100% 4/4 [00:00<00:00,  8.17it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00024113, Rollout MSE Error (joint_q) = 0.00001348 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 57 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00014830, itemized = {state_0: 0.00000035, state_1: 0.01194756, state_2: 0.00004842, state_3: 0.00009365, state_MSE: 0.00302249, q_error_norm: 0.00299689, qd_error_norm: 0.00806532} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00249057, itemized = {state_0: 0.00000088, state_1: 0.01190235, state_2: 0.00073816, state_3: 0.00205082, state_MSE: 0.00367306, q_error_norm: 0.00331869, qd_error_norm: 0.01284804} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.445 sec, time(other): 0.011 sec, time(dataloader): 4.639 sec, time(compute_loss): 1.836 sec, time(backward): 4.096 sec, time(eval): 0.660 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.035596, device='cuda:0'), grad_norm_after_clip: tensor(0.035596, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.92it/s]\n",
            "100% 11/11 [00:00<00:00, 22.58it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.80it/s]\n",
            "100% 4/4 [00:00<00:00,  7.95it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00006584, Rollout MSE Error (joint_q) = 0.00001499 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 58 with MSE error 6.58447970636189e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 58 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00020106, itemized = {state_0: 0.00000039, state_1: 0.01140789, state_2: 0.00006520, state_3: 0.00013159, state_MSE: 0.00290127, q_error_norm: 0.00301618, qd_error_norm: 0.00917766} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00241384, itemized = {state_0: 0.00000087, state_1: 0.00840082, state_2: 0.00070415, state_3: 0.00200037, state_MSE: 0.00277655, q_error_norm: 0.00272338, qd_error_norm: 0.01189459} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.449 sec, time(other): 0.011 sec, time(dataloader): 4.618 sec, time(compute_loss): 1.799 sec, time(backward): 4.111 sec, time(eval): 0.693 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.044999, device='cuda:0'), grad_norm_after_clip: tensor(0.044999, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.14it/s]\n",
            "100% 11/11 [00:00<00:00, 23.32it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.54it/s]\n",
            "100% 4/4 [00:00<00:00,  7.46it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00019104, Rollout MSE Error (joint_q) = 0.00000422 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 59 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00014832, itemized = {state_0: 0.00000034, state_1: 0.01133061, state_2: 0.00004871, state_3: 0.00009528, state_MSE: 0.00286873, q_error_norm: 0.00285831, qd_error_norm: 0.00813494} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00234959, itemized = {state_0: 0.00000097, state_1: 0.01469923, state_2: 0.00070910, state_3: 0.00192082, state_MSE: 0.00433253, q_error_norm: 0.00363078, qd_error_norm: 0.01270045} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.222 sec, time(other): 0.011 sec, time(dataloader): 4.549 sec, time(compute_loss): 1.680 sec, time(backward): 4.067 sec, time(eval): 0.707 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.038462, device='cuda:0'), grad_norm_after_clip: tensor(0.038462, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.89it/s]\n",
            "100% 11/11 [00:00<00:00, 23.58it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.64it/s]\n",
            "100% 4/4 [00:00<00:00,  8.09it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00015612, Rollout MSE Error (joint_q) = 0.00000899 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 60 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00009110, itemized = {state_0: 0.00000031, state_1: 0.00886524, state_2: 0.00002839, state_3: 0.00005592, state_MSE: 0.00223746, q_error_norm: 0.00230763, qd_error_norm: 0.00650945} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00241749, itemized = {state_0: 0.00000086, state_1: 0.01260244, state_2: 0.00072702, state_3: 0.00198435, state_MSE: 0.00382867, q_error_norm: 0.00324007, qd_error_norm: 0.01153439} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.411 sec, time(other): 0.011 sec, time(dataloader): 4.642 sec, time(compute_loss): 1.797 sec, time(backward): 4.092 sec, time(eval): 0.665 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.026248, device='cuda:0'), grad_norm_after_clip: tensor(0.026248, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.90it/s]\n",
            "100% 11/11 [00:00<00:00, 23.51it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.84it/s]\n",
            "100% 4/4 [00:00<00:00,  8.14it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00031931, Rollout MSE Error (joint_q) = 0.00001685 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 61 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00036100, itemized = {state_0: 0.00000072, state_1: 0.00963524, state_2: 0.00014449, state_3: 0.00022251, state_MSE: 0.00250074, q_error_norm: 0.00280216, qd_error_norm: 0.01135132} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00313038, itemized = {state_0: 0.00000116, state_1: 0.01470892, state_2: 0.00084033, state_3: 0.00267678, state_MSE: 0.00455680, q_error_norm: 0.00393362, qd_error_norm: 0.01801383} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.399 sec, time(other): 0.011 sec, time(dataloader): 4.653 sec, time(compute_loss): 1.813 sec, time(backward): 4.059 sec, time(eval): 0.660 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.061372, device='cuda:0'), grad_norm_after_clip: tensor(0.061372, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00, 10.00it/s]\n",
            "100% 11/11 [00:00<00:00, 23.41it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.65it/s]\n",
            "100% 4/4 [00:00<00:00,  7.52it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00031903, Rollout MSE Error (joint_q) = 0.00000831 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 62 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00019775, itemized = {state_0: 0.00000041, state_1: 0.01194654, state_2: 0.00006744, state_3: 0.00012790, state_MSE: 0.00303557, q_error_norm: 0.00302433, qd_error_norm: 0.00851746} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00255094, itemized = {state_0: 0.00000083, state_1: 0.01260311, state_2: 0.00073718, state_3: 0.00213095, state_MSE: 0.00386802, q_error_norm: 0.00321094, qd_error_norm: 0.01259552} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.367 sec, time(other): 0.010 sec, time(dataloader): 4.627 sec, time(compute_loss): 1.742 sec, time(backward): 4.066 sec, time(eval): 0.715 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.039032, device='cuda:0'), grad_norm_after_clip: tensor(0.039032, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.94it/s]\n",
            "100% 11/11 [00:00<00:00, 23.21it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.68it/s]\n",
            "100% 4/4 [00:00<00:00,  8.13it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00007261, Rollout MSE Error (joint_q) = 0.00000543 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 63 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00007728, itemized = {state_0: 0.00000026, state_1: 0.01025270, state_2: 0.00002455, state_3: 0.00004659, state_MSE: 0.00258102, q_error_norm: 0.00247071, qd_error_norm: 0.00600325} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00247787, itemized = {state_0: 0.00000081, state_1: 0.01470266, state_2: 0.00072240, state_3: 0.00206183, state_MSE: 0.00437193, q_error_norm: 0.00355829, qd_error_norm: 0.01073664} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.373 sec, time(other): 0.011 sec, time(dataloader): 4.623 sec, time(compute_loss): 1.810 sec, time(backward): 4.064 sec, time(eval): 0.660 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.023930, device='cuda:0'), grad_norm_after_clip: tensor(0.023930, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.86it/s]\n",
            "100% 11/11 [00:00<00:00, 23.41it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.70it/s]\n",
            "100% 4/4 [00:00<00:00,  8.09it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00006002, Rollout MSE Error (joint_q) = 0.00000503 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 64 with MSE error 6.0021469835191965e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 64 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00006680, itemized = {state_0: 0.00000024, state_1: 0.01017524, state_2: 0.00002114, state_3: 0.00003763, state_MSE: 0.00255856, q_error_norm: 0.00248181, qd_error_norm: 0.00553834} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00245332, itemized = {state_0: 0.00000076, state_1: 0.01400183, state_2: 0.00070404, state_3: 0.00205539, state_MSE: 0.00419050, q_error_norm: 0.00341648, qd_error_norm: 0.01071939} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.468 sec, time(other): 0.011 sec, time(dataloader): 4.652 sec, time(compute_loss): 1.838 sec, time(backward): 4.082 sec, time(eval): 0.683 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.022137, device='cuda:0'), grad_norm_after_clip: tensor(0.022137, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.21it/s]\n",
            "100% 11/11 [00:00<00:00, 22.95it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.99it/s]\n",
            "100% 4/4 [00:00<00:00,  7.53it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003786, Rollout MSE Error (joint_q) = 0.00000254 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 65 with MSE error 3.786183879128657e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 65 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00004629, itemized = {state_0: 0.00000021, state_1: 0.00871158, state_2: 0.00001451, state_3: 0.00002453, state_MSE: 0.00218771, q_error_norm: 0.00212752, qd_error_norm: 0.00471864} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00241029, itemized = {state_0: 0.00000075, state_1: 0.01190165, state_2: 0.00071736, state_3: 0.00199349, state_MSE: 0.00365331, q_error_norm: 0.00304723, qd_error_norm: 0.01053018} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.174 sec, time(other): 0.011 sec, time(dataloader): 4.518 sec, time(compute_loss): 1.664 sec, time(backward): 4.047 sec, time(eval): 0.726 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.012564, device='cuda:0'), grad_norm_after_clip: tensor(0.012564, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.90it/s]\n",
            "100% 11/11 [00:00<00:00, 24.08it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.69it/s]\n",
            "100% 4/4 [00:00<00:00,  8.12it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004771, Rollout MSE Error (joint_q) = 0.00000406 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 66 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00004297, itemized = {state_0: 0.00000020, state_1: 0.00832591, state_2: 0.00001280, state_3: 0.00002303, state_MSE: 0.00209048, q_error_norm: 0.00205192, qd_error_norm: 0.00458068} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00181126, itemized = {state_0: 0.00000069, state_1: 0.01400332, state_2: 0.00052536, state_3: 0.00150474, state_MSE: 0.00400853, q_error_norm: 0.00334102, qd_error_norm: 0.01015838} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.393 sec, time(other): 0.011 sec, time(dataloader): 4.604 sec, time(compute_loss): 1.798 sec, time(backward): 4.114 sec, time(eval): 0.662 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.012122, device='cuda:0'), grad_norm_after_clip: tensor(0.012122, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 66 with loss 0.00181126. \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.86it/s]\n",
            "100% 11/11 [00:00<00:00, 23.85it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.58it/s]\n",
            "100% 4/4 [00:00<00:00,  8.06it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00008137, Rollout MSE Error (joint_q) = 0.00000431 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 67 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00006141, itemized = {state_0: 0.00000021, state_1: 0.00901944, state_2: 0.00001910, state_3: 0.00003698, state_MSE: 0.00226893, q_error_norm: 0.00219251, qd_error_norm: 0.00524768} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00266848, itemized = {state_0: 0.00000078, state_1: 0.01751042, state_2: 0.00079693, state_3: 0.00220419, state_MSE: 0.00512808, q_error_norm: 0.00402979, qd_error_norm: 0.01136493} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.443 sec, time(other): 0.011 sec, time(dataloader): 4.629 sec, time(compute_loss): 1.820 sec, time(backward): 4.108 sec, time(eval): 0.673 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.018491, device='cuda:0'), grad_norm_after_clip: tensor(0.018491, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.04it/s]\n",
            "100% 11/11 [00:00<00:00, 23.16it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.31it/s]\n",
            "100% 4/4 [00:00<00:00,  7.42it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00065857, Rollout MSE Error (joint_q) = 0.00001845 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 68 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00033813, itemized = {state_0: 0.00000051, state_1: 0.01148491, state_2: 0.00013371, state_3: 0.00021518, state_MSE: 0.00295858, q_error_norm: 0.00304576, qd_error_norm: 0.01113566} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00294124, itemized = {state_0: 0.00000145, state_1: 0.01121075, state_2: 0.00094244, state_3: 0.00231969, state_MSE: 0.00361858, q_error_norm: 0.00382846, qd_error_norm: 0.01762230} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.333 sec, time(other): 0.011 sec, time(dataloader): 4.603 sec, time(compute_loss): 1.749 sec, time(backward): 4.045 sec, time(eval): 0.718 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.063688, device='cuda:0'), grad_norm_after_clip: tensor(0.063688, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.91it/s]\n",
            "100% 11/11 [00:00<00:00, 22.99it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.54it/s]\n",
            "100% 4/4 [00:00<00:00,  8.08it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00029214, Rollout MSE Error (joint_q) = 0.00000398 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 69 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00069880, itemized = {state_0: 0.00000094, state_1: 0.01271696, state_2: 0.00029766, state_3: 0.00043506, state_MSE: 0.00336265, q_error_norm: 0.00358472, qd_error_norm: 0.01533048} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00276838, itemized = {state_0: 0.00000103, state_1: 0.01470684, state_2: 0.00077818, state_3: 0.00233414, state_MSE: 0.00445505, q_error_norm: 0.00373254, qd_error_norm: 0.01343218} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.407 sec, time(other): 0.011 sec, time(dataloader): 4.645 sec, time(compute_loss): 1.800 sec, time(backward): 4.086 sec, time(eval): 0.665 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.086943, device='cuda:0'), grad_norm_after_clip: tensor(0.086943, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.90it/s]\n",
            "100% 11/11 [00:00<00:00, 22.50it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.05it/s]\n",
            "100% 4/4 [00:00<00:00,  8.14it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003770, Rollout MSE Error (joint_q) = 0.00000237 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 70 with MSE error 3.7704809074057266e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 70 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00007845, itemized = {state_0: 0.00000027, state_1: 0.01071458, state_2: 0.00002716, state_3: 0.00004466, state_MSE: 0.00269667, q_error_norm: 0.00253485, qd_error_norm: 0.00581070} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00207285, itemized = {state_0: 0.00000070, state_1: 0.01330053, state_2: 0.00057616, state_3: 0.00175623, state_MSE: 0.00390840, q_error_norm: 0.00322805, qd_error_norm: 0.01034457} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.445 sec, time(other): 0.011 sec, time(dataloader): 4.644 sec, time(compute_loss): 1.829 sec, time(backward): 4.074 sec, time(eval): 0.679 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.019449, device='cuda:0'), grad_norm_after_clip: tensor(0.019449, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.14it/s]\n",
            "100% 11/11 [00:00<00:00, 23.12it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.72it/s]\n",
            "100% 4/4 [00:00<00:00,  7.46it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003117, Rollout MSE Error (joint_q) = 0.00000249 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 71 with MSE error 3.116708467132412e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 71 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003753, itemized = {state_0: 0.00000019, state_1: 0.00840324, state_2: 0.00001154, state_3: 0.00001908, state_MSE: 0.00210851, q_error_norm: 0.00203048, qd_error_norm: 0.00428164} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00236092, itemized = {state_0: 0.00000070, state_1: 0.01470268, state_2: 0.00068365, state_3: 0.00197709, state_MSE: 0.00434103, q_error_norm: 0.00343386, qd_error_norm: 0.01014177} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.251 sec, time(other): 0.011 sec, time(dataloader): 4.519 sec, time(compute_loss): 1.739 sec, time(backward): 4.034 sec, time(eval): 0.742 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.008973, device='cuda:0'), grad_norm_after_clip: tensor(0.008973, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.91it/s]\n",
            "100% 11/11 [00:00<00:00, 23.43it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.73it/s]\n",
            "100% 4/4 [00:00<00:00,  8.10it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003154, Rollout MSE Error (joint_q) = 0.00000177 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 72 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003286, itemized = {state_0: 0.00000018, state_1: 0.00832605, state_2: 0.00000961, state_3: 0.00001630, state_MSE: 0.00208803, q_error_norm: 0.00200055, qd_error_norm: 0.00401112} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00240423, itemized = {state_0: 0.00000070, state_1: 0.01260298, state_2: 0.00070266, state_3: 0.00200685, state_MSE: 0.00382830, q_error_norm: 0.00307548, qd_error_norm: 0.01004801} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.398 sec, time(other): 0.011 sec, time(dataloader): 4.637 sec, time(compute_loss): 1.806 sec, time(backward): 4.074 sec, time(eval): 0.663 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.007089, device='cuda:0'), grad_norm_after_clip: tensor(0.007089, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.87it/s]\n",
            "100% 11/11 [00:00<00:00, 23.15it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.68it/s]\n",
            "100% 4/4 [00:00<00:00,  8.06it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003149, Rollout MSE Error (joint_q) = 0.00000187 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 73 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003454, itemized = {state_0: 0.00000017, state_1: 0.00716998, state_2: 0.00001043, state_3: 0.00001757, state_MSE: 0.00179954, q_error_norm: 0.00181222, qd_error_norm: 0.00408542} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00245793, itemized = {state_0: 0.00000070, state_1: 0.01190318, state_2: 0.00072853, state_3: 0.00204226, state_MSE: 0.00366867, q_error_norm: 0.00295872, qd_error_norm: 0.01003047} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.448 sec, time(other): 0.011 sec, time(dataloader): 4.668 sec, time(compute_loss): 1.819 sec, time(backward): 4.081 sec, time(eval): 0.665 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.009261, device='cuda:0'), grad_norm_after_clip: tensor(0.009261, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.99it/s]\n",
            "100% 11/11 [00:00<00:00, 22.13it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.40it/s]\n",
            "100% 4/4 [00:00<00:00,  7.53it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003278, Rollout MSE Error (joint_q) = 0.00000225 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 74 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003272, itemized = {state_0: 0.00000017, state_1: 0.00740140, state_2: 0.00000966, state_3: 0.00001643, state_MSE: 0.00185691, q_error_norm: 0.00184348, qd_error_norm: 0.00398380} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00240403, itemized = {state_0: 0.00000067, state_1: 0.01330383, state_2: 0.00070062, state_3: 0.00201128, state_MSE: 0.00400410, q_error_norm: 0.00317434, qd_error_norm: 0.00996807} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.393 sec, time(other): 0.011 sec, time(dataloader): 4.626 sec, time(compute_loss): 1.785 sec, time(backward): 4.056 sec, time(eval): 0.710 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.007212, device='cuda:0'), grad_norm_after_clip: tensor(0.007212, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.97it/s]\n",
            "100% 11/11 [00:00<00:00, 23.33it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.83it/s]\n",
            "100% 4/4 [00:00<00:00,  8.18it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004836, Rollout MSE Error (joint_q) = 0.00000201 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 75 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003097, itemized = {state_0: 0.00000016, state_1: 0.00786386, state_2: 0.00000914, state_3: 0.00001552, state_MSE: 0.00197217, q_error_norm: 0.00190041, qd_error_norm: 0.00390759} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00223825, itemized = {state_0: 0.00000067, state_1: 0.01330452, state_2: 0.00066347, state_3: 0.00185682, state_MSE: 0.00395637, q_error_norm: 0.00316908, qd_error_norm: 0.00982054} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.322 sec, time(other): 0.011 sec, time(dataloader): 4.616 sec, time(compute_loss): 1.774 sec, time(backward): 4.065 sec, time(eval): 0.656 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.008016, device='cuda:0'), grad_norm_after_clip: tensor(0.008016, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.87it/s]\n",
            "100% 11/11 [00:00<00:00, 23.90it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.85it/s]\n",
            "100% 4/4 [00:00<00:00,  8.17it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003816, Rollout MSE Error (joint_q) = 0.00000152 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 76 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002976, itemized = {state_0: 0.00000016, state_1: 0.00717006, state_2: 0.00000876, state_3: 0.00001478, state_MSE: 0.00179844, q_error_norm: 0.00178252, qd_error_norm: 0.00382962} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00237949, itemized = {state_0: 0.00000066, state_1: 0.01330448, state_2: 0.00069849, state_3: 0.00198603, state_MSE: 0.00399742, q_error_norm: 0.00316216, qd_error_norm: 0.01012688} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.435 sec, time(other): 0.011 sec, time(dataloader): 4.669 sec, time(compute_loss): 1.781 sec, time(backward): 4.102 sec, time(eval): 0.657 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.007668, device='cuda:0'), grad_norm_after_clip: tensor(0.007668, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.22it/s]\n",
            "100% 11/11 [00:00<00:00, 23.01it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.72it/s]\n",
            "100% 4/4 [00:00<00:00,  7.63it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00007506, Rollout MSE Error (joint_q) = 0.00000319 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 77 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003612, itemized = {state_0: 0.00000017, state_1: 0.00709273, state_2: 0.00001161, state_3: 0.00001883, state_MSE: 0.00178084, q_error_norm: 0.00178142, qd_error_norm: 0.00419766} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00237833, itemized = {state_0: 0.00000067, state_1: 0.01260527, state_2: 0.00070221, state_3: 0.00197906, state_MSE: 0.00382180, q_error_norm: 0.00306732, qd_error_norm: 0.01017532} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.145 sec, time(other): 0.011 sec, time(dataloader): 4.536 sec, time(compute_loss): 1.652 sec, time(backward): 4.039 sec, time(eval): 0.700 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.011703, device='cuda:0'), grad_norm_after_clip: tensor(0.011703, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.92it/s]\n",
            "100% 11/11 [00:00<00:00, 23.89it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.46it/s]\n",
            "100% 4/4 [00:00<00:00,  8.01it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003822, Rollout MSE Error (joint_q) = 0.00000231 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 78 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003743, itemized = {state_0: 0.00000016, state_1: 0.00670707, state_2: 0.00001165, state_3: 0.00002017, state_MSE: 0.00168476, q_error_norm: 0.00173124, qd_error_norm: 0.00427419} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00236644, itemized = {state_0: 0.00000063, state_1: 0.01260500, state_2: 0.00069981, state_3: 0.00196977, state_MSE: 0.00381880, q_error_norm: 0.00304789, qd_error_norm: 0.00993642} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.382 sec, time(other): 0.011 sec, time(dataloader): 4.605 sec, time(compute_loss): 1.807 sec, time(backward): 4.084 sec, time(eval): 0.670 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.013296, device='cuda:0'), grad_norm_after_clip: tensor(0.013296, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.87it/s]\n",
            "100% 11/11 [00:00<00:00, 23.64it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.42it/s]\n",
            "100% 4/4 [00:00<00:00,  8.12it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003454, Rollout MSE Error (joint_q) = 0.00000205 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 79 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003030, itemized = {state_0: 0.00000015, state_1: 0.00716994, state_2: 0.00000897, state_3: 0.00001565, state_MSE: 0.00179868, q_error_norm: 0.00176796, qd_error_norm: 0.00386551} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00233851, itemized = {state_0: 0.00000063, state_1: 0.01260398, state_2: 0.00070337, state_3: 0.00193419, state_MSE: 0.00381054, q_error_norm: 0.00302348, qd_error_norm: 0.00962641} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.431 sec, time(other): 0.011 sec, time(dataloader): 4.626 sec, time(compute_loss): 1.800 sec, time(backward): 4.126 sec, time(eval): 0.663 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.008519, device='cuda:0'), grad_norm_after_clip: tensor(0.008519, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.98it/s]\n",
            "100% 11/11 [00:00<00:00, 22.21it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.30it/s]\n",
            "100% 4/4 [00:00<00:00,  7.47it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003242, Rollout MSE Error (joint_q) = 0.00000192 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 80 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002973, itemized = {state_0: 0.00000015, state_1: 0.00786382, state_2: 0.00000882, state_3: 0.00001532, state_MSE: 0.00197203, q_error_norm: 0.00187213, qd_error_norm: 0.00381244} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00214472, itemized = {state_0: 0.00000061, state_1: 0.01330437, state_2: 0.00064996, state_3: 0.00176534, state_MSE: 0.00393007, q_error_norm: 0.00315885, qd_error_norm: 0.00958461} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.419 sec, time(other): 0.011 sec, time(dataloader): 4.623 sec, time(compute_loss): 1.803 sec, time(backward): 4.049 sec, time(eval): 0.717 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.008407, device='cuda:0'), grad_norm_after_clip: tensor(0.008407, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.94it/s]\n",
            "100% 11/11 [00:00<00:00, 23.41it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.53it/s]\n",
            "100% 4/4 [00:00<00:00,  8.13it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004645, Rollout MSE Error (joint_q) = 0.00000307 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 81 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003437, itemized = {state_0: 0.00000015, state_1: 0.00647619, state_2: 0.00001134, state_3: 0.00001797, state_MSE: 0.00162641, q_error_norm: 0.00165586, qd_error_norm: 0.00403407} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00238134, itemized = {state_0: 0.00000062, state_1: 0.01260356, state_2: 0.00072951, state_3: 0.00195593, state_MSE: 0.00382241, q_error_norm: 0.00303892, qd_error_norm: 0.00994875} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.368 sec, time(other): 0.011 sec, time(dataloader): 4.625 sec, time(compute_loss): 1.794 sec, time(backward): 4.073 sec, time(eval): 0.662 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.012252, device='cuda:0'), grad_norm_after_clip: tensor(0.012252, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.86it/s]\n",
            "100% 11/11 [00:00<00:00, 22.67it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.45it/s]\n",
            "100% 4/4 [00:00<00:00,  8.22it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00007042, Rollout MSE Error (joint_q) = 0.00000283 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 82 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00005443, itemized = {state_0: 0.00000017, state_1: 0.00894252, state_2: 0.00001820, state_3: 0.00003261, state_MSE: 0.00224837, q_error_norm: 0.00210008, qd_error_norm: 0.00482211} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00243682, itemized = {state_0: 0.00000064, state_1: 0.01330269, state_2: 0.00073522, state_3: 0.00201464, state_MSE: 0.00401330, q_error_norm: 0.00317139, qd_error_norm: 0.01038227} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.466 sec, time(other): 0.011 sec, time(dataloader): 4.689 sec, time(compute_loss): 1.836 sec, time(backward): 4.060 sec, time(eval): 0.665 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.017219, device='cuda:0'), grad_norm_after_clip: tensor(0.017219, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.19it/s]\n",
            "100% 11/11 [00:00<00:00, 22.16it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.87it/s]\n",
            "100% 4/4 [00:00<00:00,  7.40it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004352, Rollout MSE Error (joint_q) = 0.00000157 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 83 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00006197, itemized = {state_0: 0.00000018, state_1: 0.00925077, state_2: 0.00001865, state_3: 0.00003989, state_MSE: 0.00232737, q_error_norm: 0.00218783, qd_error_norm: 0.00533457} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00220855, itemized = {state_0: 0.00000060, state_1: 0.01190342, state_2: 0.00065176, state_3: 0.00183892, state_MSE: 0.00359868, q_error_norm: 0.00289608, qd_error_norm: 0.00969056} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.213 sec, time(other): 0.011 sec, time(dataloader): 4.519 sec, time(compute_loss): 1.692 sec, time(backward): 4.060 sec, time(eval): 0.722 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.020262, device='cuda:0'), grad_norm_after_clip: tensor(0.020262, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.94it/s]\n",
            "100% 11/11 [00:00<00:00, 23.19it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.69it/s]\n",
            "100% 4/4 [00:00<00:00,  8.15it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002925, Rollout MSE Error (joint_q) = 0.00000390 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 84 with MSE error 2.9254708351800218e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 84 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003315, itemized = {state_0: 0.00000015, state_1: 0.00701557, state_2: 0.00000982, state_3: 0.00001823, state_MSE: 0.00176094, q_error_norm: 0.00174527, qd_error_norm: 0.00403496} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00237334, itemized = {state_0: 0.00000060, state_1: 0.01260455, state_2: 0.00071107, state_3: 0.00196816, state_MSE: 0.00382110, q_error_norm: 0.00302404, qd_error_norm: 0.00951940} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.387 sec, time(other): 0.011 sec, time(dataloader): 4.595 sec, time(compute_loss): 1.782 sec, time(backward): 4.112 sec, time(eval): 0.681 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.011666, device='cuda:0'), grad_norm_after_clip: tensor(0.011666, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.89it/s]\n",
            "100% 11/11 [00:00<00:00, 24.22it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.38it/s]\n",
            "100% 4/4 [00:00<00:00,  8.16it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003295, Rollout MSE Error (joint_q) = 0.00000236 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 85 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003368, itemized = {state_0: 0.00000015, state_1: 0.00678443, state_2: 0.00001077, state_3: 0.00001788, state_MSE: 0.00170330, q_error_norm: 0.00170899, qd_error_norm: 0.00405804} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00231515, itemized = {state_0: 0.00000059, state_1: 0.01400414, state_2: 0.00068256, state_3: 0.00193250, state_MSE: 0.00415495, q_error_norm: 0.00323213, qd_error_norm: 0.00954780} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.403 sec, time(other): 0.011 sec, time(dataloader): 4.610 sec, time(compute_loss): 1.829 sec, time(backward): 4.087 sec, time(eval): 0.661 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.013596, device='cuda:0'), grad_norm_after_clip: tensor(0.013596, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.98it/s]\n",
            "100% 11/11 [00:00<00:00, 21.61it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.08it/s]\n",
            "100% 4/4 [00:00<00:00,  7.64it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002537, Rollout MSE Error (joint_q) = 0.00000129 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 86 with MSE error 2.536526881158352e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 86 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003053, itemized = {state_0: 0.00000014, state_1: 0.00770961, state_2: 0.00000924, state_3: 0.00001665, state_MSE: 0.00193391, q_error_norm: 0.00182154, qd_error_norm: 0.00386184} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00234860, itemized = {state_0: 0.00000059, state_1: 0.01330399, state_2: 0.00068272, state_3: 0.00197204, state_MSE: 0.00398983, q_error_norm: 0.00309096, qd_error_norm: 0.00954115} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.428 sec, time(other): 0.011 sec, time(dataloader): 4.626 sec, time(compute_loss): 1.792 sec, time(backward): 4.068 sec, time(eval): 0.724 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.010612, device='cuda:0'), grad_norm_after_clip: tensor(0.010612, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.95it/s]\n",
            "100% 11/11 [00:00<00:00, 24.02it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.76it/s]\n",
            "100% 4/4 [00:00<00:00,  8.17it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004534, Rollout MSE Error (joint_q) = 0.00000135 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 87 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003576, itemized = {state_0: 0.00000015, state_1: 0.00794087, state_2: 0.00001113, state_3: 0.00002042, state_MSE: 0.00199314, q_error_norm: 0.00187112, qd_error_norm: 0.00415944} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00231104, itemized = {state_0: 0.00000057, state_1: 0.01190418, state_2: 0.00069157, state_3: 0.00191952, state_MSE: 0.00362896, q_error_norm: 0.00286742, qd_error_norm: 0.00957137} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.336 sec, time(other): 0.011 sec, time(dataloader): 4.570 sec, time(compute_loss): 1.792 sec, time(backward): 4.105 sec, time(eval): 0.658 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.014195, device='cuda:0'), grad_norm_after_clip: tensor(0.014195, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.91it/s]\n",
            "100% 11/11 [00:00<00:00, 23.52it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.74it/s]\n",
            "100% 4/4 [00:00<00:00,  8.14it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00007347, Rollout MSE Error (joint_q) = 0.00000245 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 88 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003233, itemized = {state_0: 0.00000014, state_1: 0.00701580, state_2: 0.00000955, state_3: 0.00001850, state_MSE: 0.00176100, q_error_norm: 0.00170947, qd_error_norm: 0.00398530} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00209136, itemized = {state_0: 0.00000055, state_1: 0.01260478, state_2: 0.00062717, state_3: 0.00173276, state_MSE: 0.00374131, q_error_norm: 0.00298014, qd_error_norm: 0.00960397} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.398 sec, time(other): 0.012 sec, time(dataloader): 4.563 sec, time(compute_loss): 1.812 sec, time(backward): 4.139 sec, time(eval): 0.661 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.011239, device='cuda:0'), grad_norm_after_clip: tensor(0.011239, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.17it/s]\n",
            "100% 11/11 [00:00<00:00, 22.45it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.15it/s]\n",
            "100% 4/4 [00:00<00:00,  7.51it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00005287, Rollout MSE Error (joint_q) = 0.00000293 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 89 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00004846, itemized = {state_0: 0.00000015, state_1: 0.00732399, state_2: 0.00001679, state_3: 0.00002805, state_MSE: 0.00184225, q_error_norm: 0.00182201, qd_error_norm: 0.00473438} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00231393, itemized = {state_0: 0.00000055, state_1: 0.01400770, state_2: 0.00068876, state_3: 0.00192549, state_MSE: 0.00415562, q_error_norm: 0.00324371, qd_error_norm: 0.00961995} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.231 sec, time(other): 0.012 sec, time(dataloader): 4.522 sec, time(compute_loss): 1.693 sec, time(backward): 4.068 sec, time(eval): 0.714 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.019914, device='cuda:0'), grad_norm_after_clip: tensor(0.019914, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.97it/s]\n",
            "100% 11/11 [00:00<00:00, 23.01it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.78it/s]\n",
            "100% 4/4 [00:00<00:00,  8.11it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00008801, Rollout MSE Error (joint_q) = 0.00000187 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 90 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002986, itemized = {state_0: 0.00000013, state_1: 0.00701576, state_2: 0.00000919, state_3: 0.00001645, state_MSE: 0.00176038, q_error_norm: 0.00169538, qd_error_norm: 0.00376806} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00225586, itemized = {state_0: 0.00000055, state_1: 0.01190524, state_2: 0.00067935, state_3: 0.00186856, state_MSE: 0.00361342, q_error_norm: 0.00284346, qd_error_norm: 0.00960362} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.346 sec, time(other): 0.011 sec, time(dataloader): 4.622 sec, time(compute_loss): 1.760 sec, time(backward): 4.090 sec, time(eval): 0.662 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.011023, device='cuda:0'), grad_norm_after_clip: tensor(0.011023, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.91it/s]\n",
            "100% 11/11 [00:00<00:00, 23.76it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.37it/s]\n",
            "100% 4/4 [00:00<00:00,  8.09it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002114, Rollout MSE Error (joint_q) = 0.00000146 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 91 with MSE error 2.1139740056241862e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 91 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002356, itemized = {state_0: 0.00000012, state_1: 0.00663036, state_2: 0.00000701, state_3: 0.00001192, state_MSE: 0.00166235, q_error_norm: 0.00161589, qd_error_norm: 0.00339934} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00215042, itemized = {state_0: 0.00000054, state_1: 0.01260462, state_2: 0.00063603, state_3: 0.00179263, state_MSE: 0.00375846, q_error_norm: 0.00294808, qd_error_norm: 0.00902660} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.425 sec, time(other): 0.011 sec, time(dataloader): 4.645 sec, time(compute_loss): 1.806 sec, time(backward): 4.067 sec, time(eval): 0.686 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.008393, device='cuda:0'), grad_norm_after_clip: tensor(0.008393, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.78it/s]\n",
            "100% 11/11 [00:00<00:00, 22.30it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.76it/s]\n",
            "100% 4/4 [00:00<00:00,  7.37it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002499, Rollout MSE Error (joint_q) = 0.00000121 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 92 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002509, itemized = {state_0: 0.00000012, state_1: 0.00709283, state_2: 0.00000747, state_3: 0.00001334, state_MSE: 0.00177844, q_error_norm: 0.00168368, qd_error_norm: 0.00350113} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00229806, itemized = {state_0: 0.00000054, state_1: 0.01190573, state_2: 0.00069181, state_3: 0.00190469, state_MSE: 0.00362569, q_error_norm: 0.00285191, qd_error_norm: 0.00909271} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.624 sec, time(other): 0.011 sec, time(dataloader): 4.877 sec, time(compute_loss): 1.758 sec, time(backward): 4.047 sec, time(eval): 0.726 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.009170, device='cuda:0'), grad_norm_after_clip: tensor(0.009170, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.75it/s]\n",
            "100% 11/11 [00:00<00:00, 23.15it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.45it/s]\n",
            "100% 4/4 [00:00<00:00,  8.10it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002173, Rollout MSE Error (joint_q) = 0.00000216 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 93 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002213, itemized = {state_0: 0.00000012, state_1: 0.00724711, state_2: 0.00000637, state_3: 0.00001136, state_MSE: 0.00181624, q_error_norm: 0.00169730, qd_error_norm: 0.00329380} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00229912, itemized = {state_0: 0.00000054, state_1: 0.01260414, state_2: 0.00069170, state_3: 0.00190690, state_MSE: 0.00380082, q_error_norm: 0.00295247, qd_error_norm: 0.00902102} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.572 sec, time(other): 0.011 sec, time(dataloader): 4.819 sec, time(compute_loss): 1.817 sec, time(backward): 4.054 sec, time(eval): 0.664 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.006971, device='cuda:0'), grad_norm_after_clip: tensor(0.006971, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.46it/s]\n",
            "100% 11/11 [00:00<00:00, 23.98it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.44it/s]\n",
            "100% 4/4 [00:00<00:00,  8.11it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002315, Rollout MSE Error (joint_q) = 0.00000091 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 94 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002190, itemized = {state_0: 0.00000011, state_1: 0.00655333, state_2: 0.00000644, state_3: 0.00001114, state_MSE: 0.00164276, q_error_norm: 0.00158209, qd_error_norm: 0.00328935} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00213304, itemized = {state_0: 0.00000053, state_1: 0.01260518, state_2: 0.00064094, state_3: 0.00176756, state_MSE: 0.00375355, q_error_norm: 0.00293314, qd_error_norm: 0.00898267} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.871 sec, time(other): 0.011 sec, time(dataloader): 5.118 sec, time(compute_loss): 1.782 sec, time(backward): 4.084 sec, time(eval): 0.670 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.007626, device='cuda:0'), grad_norm_after_clip: tensor(0.007626, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.18it/s]\n",
            "100% 11/11 [00:00<00:00, 22.26it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.09it/s]\n",
            "100% 4/4 [00:00<00:00,  7.66it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002594, Rollout MSE Error (joint_q) = 0.00000109 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 95 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002013, itemized = {state_0: 0.00000011, state_1: 0.00686170, state_2: 0.00000582, state_3: 0.00001005, state_MSE: 0.00171942, q_error_norm: 0.00161747, qd_error_norm: 0.00316007} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00210107, itemized = {state_0: 0.00000051, state_1: 0.01190434, state_2: 0.00062131, state_3: 0.00175330, state_MSE: 0.00356987, q_error_norm: 0.00280933, qd_error_norm: 0.00889971} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 12.281 sec, time(other): 0.011 sec, time(dataloader): 5.584 sec, time(compute_loss): 1.720 sec, time(backward): 4.045 sec, time(eval): 0.702 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.005796, device='cuda:0'), grad_norm_after_clip: tensor(0.005796, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.45it/s]\n",
            "100% 11/11 [00:00<00:00, 24.29it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.42it/s]\n",
            "100% 4/4 [00:00<00:00,  8.16it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002916, Rollout MSE Error (joint_q) = 0.00000095 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 96 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002117, itemized = {state_0: 0.00000011, state_1: 0.00747837, state_2: 0.00000624, state_3: 0.00001085, state_MSE: 0.00187389, q_error_norm: 0.00171575, qd_error_norm: 0.00324707} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00230237, itemized = {state_0: 0.00000052, state_1: 0.01190533, state_2: 0.00069720, state_3: 0.00190582, state_MSE: 0.00362722, q_error_norm: 0.00281405, qd_error_norm: 0.00906494} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.874 sec, time(other): 0.011 sec, time(dataloader): 5.163 sec, time(compute_loss): 1.759 sec, time(backward): 4.068 sec, time(eval): 0.661 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.007825, device='cuda:0'), grad_norm_after_clip: tensor(0.007825, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:11<00:00,  8.87it/s]\n",
            "100% 11/11 [00:00<00:00, 23.02it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.87it/s]\n",
            "100% 4/4 [00:00<00:00,  8.17it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00001987, Rollout MSE Error (joint_q) = 0.00000104 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 97 with MSE error 1.986932875297498e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 97 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001993, itemized = {state_0: 0.00000011, state_1: 0.00663043, state_2: 0.00000581, state_3: 0.00000989, state_MSE: 0.00166156, q_error_norm: 0.00157931, qd_error_norm: 0.00313716} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00218407, itemized = {state_0: 0.00000051, state_1: 0.01260471, state_2: 0.00065615, state_3: 0.00181206, state_MSE: 0.00376836, q_error_norm: 0.00291852, qd_error_norm: 0.00882448} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 13.131 sec, time(other): 0.011 sec, time(dataloader): 5.797 sec, time(compute_loss): 1.836 sec, time(backward): 4.076 sec, time(eval): 0.678 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.006572, device='cuda:0'), grad_norm_after_clip: tensor(0.006572, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:11<00:00,  8.74it/s]\n",
            "100% 11/11 [00:01<00:00, 10.69it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.93it/s]\n",
            "100% 4/4 [00:00<00:00,  7.93it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002444, Rollout MSE Error (joint_q) = 0.00000112 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 98 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001955, itemized = {state_0: 0.00000011, state_1: 0.00647617, state_2: 0.00000545, state_3: 0.00000998, state_MSE: 0.00162292, q_error_norm: 0.00155085, qd_error_norm: 0.00311457} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00225569, itemized = {state_0: 0.00000051, state_1: 0.01260539, state_2: 0.00068280, state_3: 0.00186729, state_MSE: 0.00378900, q_error_norm: 0.00291569, qd_error_norm: 0.00887282} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 13.322 sec, time(other): 0.011 sec, time(dataloader): 6.523 sec, time(compute_loss): 1.808 sec, time(backward): 4.100 sec, time(eval): 0.672 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.006032, device='cuda:0'), grad_norm_after_clip: tensor(0.006032, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:11<00:00,  8.99it/s]\n",
            "100% 11/11 [00:00<00:00, 22.66it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.26it/s]\n",
            "100% 4/4 [00:00<00:00,  7.58it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002006, Rollout MSE Error (joint_q) = 0.00000115 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 99 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001859, itemized = {state_0: 0.00000010, state_1: 0.00724731, state_2: 0.00000518, state_3: 0.00000931, state_MSE: 0.00181548, q_error_norm: 0.00166473, qd_error_norm: 0.00303153} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00209275, itemized = {state_0: 0.00000050, state_1: 0.01190432, state_2: 0.00062459, state_3: 0.00174050, state_MSE: 0.00356748, q_error_norm: 0.00279256, qd_error_norm: 0.00868593} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 12.770 sec, time(other): 0.011 sec, time(dataloader): 5.647 sec, time(compute_loss): 1.820 sec, time(backward): 4.096 sec, time(eval): 0.707 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.004989, device='cuda:0'), grad_norm_after_clip: tensor(0.004989, device='cuda:0')} \u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading output.log 132.9KB/132.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading output.log 132.9KB/132.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading output.log 132.9KB/132.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading output.log 132.9KB/132.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading output.log 132.9KB/132.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading output.log 132.9KB/132.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading output.log 132.9KB/132.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading output.log 132.9KB/132.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading output.log 132.9KB/132.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading output.log 132.9KB/132.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading history steps 99-99, summary, console lines 1327-1339 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading history steps 99-99, summary, console lines 1327-1339 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading history steps 99-99, summary, console lines 1327-1339 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch ‚ñà‚ñÖ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch ‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch ‚ñà‚ñÜ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch 0.00712\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch 2e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch 0.00122\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch 0.00694\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch 4e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch 0.00261\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch 0.0037\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch 0.00481\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch 0.00588\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mmamba_100\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics/runs/m7xnn318\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251205_044102-m7xnn318/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 5. Train Unroll Model\n",
        "# We use the same config but add the --novelty unroll flag\n",
        "# !python train.py --cfg colab_config.yaml --novelty unroll --logdir ../data/logs/unroll --wandb-project {wandb_project} --wandb-name unroll\n",
        "# 4. Train Mamba Model (100 Epochs)\n",
        "import yaml\n",
        "\n",
        "# 1. Load the current config\n",
        "with open('colab_config.yaml', 'r') as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "\n",
        "# 2. FORCE 100 Epochs\n",
        "print(\"Updating configuration to 100 epochs...\")\n",
        "cfg['algorithm']['num_epochs'] = 100\n",
        "cfg['algorithm']['num_iters_per_epoch'] = 100  # Ensure we have enough iterations per epoch\n",
        "\n",
        "# 3. Save the config back to disk\n",
        "with open('colab_config.yaml', 'w') as f:\n",
        "    yaml.dump(cfg, f)\n",
        "\n",
        "# 4. Run the training\n",
        "# The --cfg flag will now load the file we just saved with 100 epochs\n",
        "!python train.py --cfg colab_config.yaml --novelty mamba --logdir ../data/logs/mamba --wandb-project {wandb_project} --wandb-name mamba_100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "save_models_drive",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "save_models_drive",
        "outputId": "1e343192-0637-4721-cb13-9e5f972adb4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Local log directory for baseline not found. Skipping save.\n",
            "Saving mamba model to Google Drive...\n",
            "Local log directory for unroll not found. Skipping save.\n"
          ]
        }
      ],
      "source": [
        "# 6. Save Models to Google Drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "models = ['baseline', 'mamba', 'unroll']\n",
        "drive_base_dir = '/content/drive/MyDrive/neural-robot-dynamics/data/logs'\n",
        "local_base_dir = '../data/logs'\n",
        "\n",
        "for model in models:\n",
        "    local_dir = os.path.join(local_base_dir, model)\n",
        "    drive_dir = os.path.join(drive_base_dir, model)\n",
        "\n",
        "    if os.path.exists(local_dir):\n",
        "        print(f\"Saving {model} model to Google Drive...\")\n",
        "        if os.path.exists(drive_dir):\n",
        "            shutil.rmtree(drive_dir)\n",
        "        shutil.copytree(local_dir, drive_dir)\n",
        "    else:\n",
        "        print(f\"Local log directory for {model} not found. Skipping save.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "load_models_drive",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "load_models_drive",
        "outputId": "599c2ccc-7efc-47de-9cb5-d8aeeb5ecaff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading baseline model from Google Drive...\n",
            "Loading mamba model from Google Drive...\n",
            "Loading unroll model from Google Drive...\n"
          ]
        }
      ],
      "source": [
        "# 7. Load Models from Google Drive (Optional)\n",
        "# Run this cell if you want to load pre-trained models from Drive instead of training them.\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "models = ['baseline', 'mamba', 'unroll']\n",
        "drive_base_dir = '/content/drive/MyDrive/neural-robot-dynamics/data/logs'\n",
        "local_base_dir = '../data/logs'\n",
        "\n",
        "for model in models:\n",
        "    local_dir = os.path.join(local_base_dir, model)\n",
        "    drive_dir = os.path.join(drive_base_dir, model)\n",
        "\n",
        "    if os.path.exists(drive_dir):\n",
        "        print(f\"Loading {model} model from Google Drive...\")\n",
        "        if os.path.exists(local_dir):\n",
        "            shutil.rmtree(local_dir)\n",
        "        shutil.copytree(drive_dir, local_dir)\n",
        "    else:\n",
        "        print(f\"Drive log directory for {model} not found. Skipping load.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "quantitative-analysis-header",
      "metadata": {
        "id": "quantitative-analysis-header"
      },
      "source": [
        "# 7. Quantitative Analysis\n",
        "\n",
        "We now perform the quantitative analysis as described in the paper experiments.\n",
        "We evaluate:\n",
        "1. **Long-Horizon Passive Motion**: Accuracy of the trained NeRD models over 100, 500, and 1000 steps.\n",
        "2. **RL Policy Evaluation**: Performance of the pretrained RL policy using the NeRD models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "passive-motion-eval",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "passive-motion-eval",
        "outputId": "15d5022e-19a2-48b4-a19b-29fd1d9043c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== Evaluating Baseline Model ====================\n",
            "\n",
            "--- Horizon: 100 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  2713668\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 303.09it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.95 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.40 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.50 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.35 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.83 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:00<00:00,  2.40it/s]\n",
            "100% 1/1 [00:02<00:00,  2.21s/it]\n",
            "=========================================\n",
            "Base position error mean       = 0.338502\n",
            "Base position error std        = 0.367016\n",
            "Joint position error mean      = 0.383423 rad (21.968496 deg)\n",
            "Joint position Error per dof   = tensor([0.383423], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run beejvltx (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run beejvltx (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run beejvltx (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251205_050134-beejvltx\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbaseline_passive_eval_100\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics/runs/beejvltx\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading history steps 0-0, summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading history steps 0-0, summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 0.3385\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 0.36702\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.38342\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mbaseline_passive_eval_100\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics/runs/beejvltx\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251205_050134-beejvltx/logs\u001b[0m\n",
            "\n",
            "--- Horizon: 500 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  2713668\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 304.03it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 3.11 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.42 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.56 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.34 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.83 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:01<00:00,  1.56s/it]\n",
            "100% 1/1 [00:09<00:00,  9.99s/it]\n",
            "=========================================\n",
            "Base position error mean       = 1.877724\n",
            "Base position error std        = 1.821935\n",
            "Joint position error mean      = 0.981049 rad (56.209947 deg)\n",
            "Joint position Error per dof   = tensor([0.981049], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run otwrf2cy (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run otwrf2cy (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run otwrf2cy (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251205_050202-otwrf2cy\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbaseline_passive_eval_500\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics/runs/otwrf2cy\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-summary.json 221B/221B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-summary.json 221B/221B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-summary.json 221B/221B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 221B/221B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 221B/221B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 1.87772\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 1.82193\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.98105\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mbaseline_passive_eval_500\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics/runs/otwrf2cy\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251205_050202-otwrf2cy/logs\u001b[0m\n",
            "\n",
            "==================== Evaluating Mamba Model ====================\n",
            "\n",
            "--- Horizon: 100 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  1523460\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 301.89it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.92 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.51 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.37 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.86 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:00<00:00,  2.26it/s]\n",
            "100% 1/1 [00:05<00:00,  5.03s/it]\n",
            "=========================================\n",
            "Base position error mean       = 0.017606\n",
            "Base position error std        = 0.023499\n",
            "Joint position error mean      = 0.016787 rad (0.961839 deg)\n",
            "Joint position Error per dof   = tensor([0.016787], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run czt13qxu (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run czt13qxu (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251205_050224-czt13qxu\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba_passive_eval_100\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics/runs/czt13qxu\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-summary.json 225B/225B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-summary.json 225B/225B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-summary.json 225B/225B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 225B/225B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 225B/225B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading history steps 0-0, summary (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 0.01761\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 0.0235\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.01679\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mmamba_passive_eval_100\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics/runs/czt13qxu\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251205_050224-czt13qxu/logs\u001b[0m\n",
            "\n",
            "--- Horizon: 500 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  1523460\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 304.49it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.87 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.56 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.37 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.40 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.81 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:01<00:00,  1.54s/it]\n",
            "100% 1/1 [00:25<00:00, 25.37s/it]\n",
            "=========================================\n",
            "Base position error mean       = 0.352381\n",
            "Base position error std        = 0.404723\n",
            "Joint position error mean      = 0.327471 rad (18.762707 deg)\n",
            "Joint position Error per dof   = tensor([0.327471], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run tv2x404l (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run tv2x404l (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251205_050308-tv2x404l\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba_passive_eval_500\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics/runs/tv2x404l\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-summary.json 221B/221B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-summary.json 221B/221B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-summary.json 221B/221B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 221B/221B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 221B/221B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 0.35238\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 0.40472\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.32747\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mmamba_passive_eval_500\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics/runs/tv2x404l\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251205_050308-tv2x404l/logs\u001b[0m\n",
            "\n",
            "==================== Evaluating Unroll Model ====================\n",
            "\n",
            "--- Horizon: 100 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  2713668\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 297.93it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.84 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.36 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.51 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.33 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.38 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.81 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:00<00:00,  2.50it/s]\n",
            "100% 1/1 [00:02<00:00,  2.08s/it]\n",
            "=========================================\n",
            "Base position error mean       = 0.490143\n",
            "Base position error std        = 0.486737\n",
            "Joint position error mean      = 1.223201 rad (70.084271 deg)\n",
            "Joint position Error per dof   = tensor([1.223201], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run zf2u5p67 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run zf2u5p67 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run zf2u5p67 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m setting up run zf2u5p67 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251205_050327-zf2u5p67\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33munroll_passive_eval_100\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics/runs/zf2u5p67\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading data (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading data (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading data (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading data (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading data (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-summary.json 221B/221B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-summary.json 221B/221B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-summary.json 221B/221B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 221B/221B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 221B/221B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 0.49014\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 0.48674\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 1.2232\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33munroll_passive_eval_100\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics/runs/zf2u5p67\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251205_050327-zf2u5p67/logs\u001b[0m\n",
            "\n",
            "--- Horizon: 500 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  2713668\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 301.96it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 3.09 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.51 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.33 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.38 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.84 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:01<00:00,  1.54s/it]\n",
            "100% 1/1 [00:09<00:00,  9.89s/it]\n",
            "=========================================\n",
            "Base position error mean       = 1.981910\n",
            "Base position error std        = 1.806999\n",
            "Joint position error mean      = 1.504634 rad (86.209193 deg)\n",
            "Joint position Error per dof   = tensor([1.504634], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run byatxd9m (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run byatxd9m (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run byatxd9m (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251205_050354-byatxd9m\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33munroll_passive_eval_500\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics/runs/byatxd9m\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-summary.json 220B/220B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-summary.json 220B/220B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-summary.json 220B/220B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 220B/220B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 220B/220B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading history steps 0-0, summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading history steps 0-0, summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 1.98191\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 1.807\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 1.50463\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33munroll_passive_eval_500\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics/runs/byatxd9m\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251205_050354-byatxd9m/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 7.1 Long-Horizon Passive Motion Evaluation\n",
        "# We evaluate the Baseline, Mamba, and Unroll models on Cartpole for 100, 500, and 1000 steps.\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def find_latest_model(model_type):\n",
        "    base_log_dir = f'../data/logs/{model_type}'\n",
        "    if not os.path.exists(base_log_dir):\n",
        "        return None\n",
        "    dirs = [d for d in glob.glob(os.path.join(base_log_dir, '*')) if os.path.isdir(d)]\n",
        "    if not dirs:\n",
        "        return None\n",
        "    latest_dir = sorted(dirs)[-1]\n",
        "    model_path = os.path.join(latest_dir, 'nn', 'best_eval_model.pt')\n",
        "    if not os.path.exists(model_path):\n",
        "        return None\n",
        "    return model_path\n",
        "\n",
        "models = ['baseline', 'mamba', 'unroll']\n",
        "horizons = [100, 500]\n",
        "\n",
        "for model_name in models:\n",
        "    model_path = find_latest_model(model_name)\n",
        "    if not model_path:\n",
        "        print(f\"Skipping {model_name} (model not found)\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n{'='*20} Evaluating {model_name.capitalize()} Model {'='*20}\")\n",
        "    for horizon in horizons:\n",
        "        print(f\"\\n--- Horizon: {horizon} ---\")\n",
        "        # We use !python to ensure output is printed to the cell\n",
        "        !python ../eval/eval_passive/eval_passive_motion.py \\\n",
        "            --env-name Cartpole \\\n",
        "            --model-path {model_path} \\\n",
        "            --env-mode neural \\\n",
        "            --num-envs 2048 \\\n",
        "            --num-rollouts 2048 \\\n",
        "            --rollout-horizon {horizon} \\\n",
        "            --seed 500 \\\n",
        "            --wandb-project {wandb_project} \\\n",
        "            --wandb-name {model_name}_passive_eval_{horizon}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "rl-policy-eval-quant",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rl-policy-eval-quant",
        "outputId": "9b7ea458-b617-4250-ad34-283a77b1b1d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== RL Evaluation: Ground Truth ====================\n",
            "teps: 56.0\n",
            "reward: 98.16722106933594 steps: 61.0\n",
            "reward: 57.463932037353516 steps: 62.0\n",
            "reward: -94.28485107421875 steps: 94.0\n",
            "reward: -85.14854431152344 steps: 100.0\n",
            "reward: 1225.2821979114867 steps: 300.0\n",
            "2461286.372443199\n",
            "av reward: 1201.7999865445308 av steps: 295.4072265625\n",
            "visited states range:\n",
            "State 0: [-4.084732532501221, 4.017726421356201]\n",
            "State 1: [-3.14152193069458, 3.1415481567382812]\n",
            "State 2: [-10.378299713134766, 8.506926536560059]\n",
            "State 3: [-10.652486801147461, 9.790891647338867]\n",
            "\n",
            "\n",
            "==================== RL Evaluation: Baseline ====================\n",
            " 86.0\n",
            "reward: -192.524169921875 steps: 89.0\n",
            "reward: -186.01626586914062 steps: 72.0\n",
            "reward: -209.2667236328125 steps: 79.0\n",
            "reward: -197.86050415039062 steps: 78.0\n",
            "reward: 1153.081923076923 steps: 300.0\n",
            "2232099.523797512\n",
            "av reward: 1087.7677991215946 av steps: 288.57943469785573\n",
            "visited states range:\n",
            "State 0: [-4.065162658691406, 4.016059398651123]\n",
            "State 1: [-3.1415622234344482, 3.141571521759033]\n",
            "State 2: [-10.362022399902344, 8.674454689025879]\n",
            "State 3: [-9.923949241638184, 10.296359062194824]\n",
            "\n",
            "\n",
            "==================== RL Evaluation: Mamba ====================\n",
            " steps: 56.0\n",
            "reward: -70.604248046875 steps: 61.0\n",
            "reward: -83.99386596679688 steps: 62.0\n",
            "reward: 108.7665023803711 steps: 66.0\n",
            "reward: -142.6519012451172 steps: 97.0\n",
            "reward: 1220.3997518610422 steps: 300.0\n",
            "2456159.773744583\n",
            "av reward: 1199.2967645237222 av steps: 295.88720703125\n",
            "visited states range:\n",
            "State 0: [-4.106268405914307, 4.000430583953857]\n",
            "State 1: [-3.1414527893066406, 3.141583204269409]\n",
            "State 2: [-10.140372276306152, 8.559327125549316]\n",
            "State 3: [-10.72725772857666, 9.203709602355957]\n",
            "\n",
            "\n",
            "==================== RL Evaluation: Unroll ====================\n",
            ".596188354492185 steps: 296.0\n",
            "reward: 185.62440708705358 steps: 297.0\n",
            "reward: 169.79156494140625 steps: 298.0\n",
            "reward: 8.71860376993815 steps: 299.0\n",
            "reward: 187.68745769404333 steps: 299.4620938628159\n",
            "-392549.4409561157\n",
            "av reward: -191.58098631338004 av steps: 228.88823816495852\n",
            "visited states range:\n",
            "State 0: [-0.9902818202972412, 3.041213274002075]\n",
            "State 1: [-3.141587257385254, 3.1415855884552]\n",
            "State 2: [-1.5647481679916382, 10.074750900268555]\n",
            "State 3: [-3.5842249393463135, 1.2496739625930786]\n",
            "\n",
            "\n",
            "Final Evaluation Comparison:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          Model       Reward   Error (%)\n",
              "0  Ground Truth  1201.799987    0.000000\n",
              "1      Baseline  1087.767799   -9.488450\n",
              "2         Mamba  1199.296765   -0.208289\n",
              "3        Unroll  -191.580986 -115.941171"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dfa566b8-b330-46bf-9abf-afded4494c5f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Reward</th>\n",
              "      <th>Error (%)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ground Truth</td>\n",
              "      <td>1201.799987</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Baseline</td>\n",
              "      <td>1087.767799</td>\n",
              "      <td>-9.488450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mamba</td>\n",
              "      <td>1199.296765</td>\n",
              "      <td>-0.208289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Unroll</td>\n",
              "      <td>-191.580986</td>\n",
              "      <td>-115.941171</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfa566b8-b330-46bf-9abf-afded4494c5f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dfa566b8-b330-46bf-9abf-afded4494c5f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dfa566b8-b330-46bf-9abf-afded4494c5f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-de7b9e70-51b5-4395-bb33-cf6d1d22a665\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-de7b9e70-51b5-4395-bb33-cf6d1d22a665')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-de7b9e70-51b5-4395-bb33-cf6d1d22a665 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_e61da1b5-d147-4be8-ad38-4083bf2d9617\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e61da1b5-d147-4be8-ad38-4083bf2d9617 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Baseline\",\n          \"Unroll\",\n          \"Ground Truth\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Reward\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 679.3522088543059,\n        \"min\": -191.58098631338004,\n        \"max\": 1201.7999865445308,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1087.7677991215946,\n          -191.58098631338004,\n          1201.7999865445308\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Error (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 56.527892865734664,\n        \"min\": -115.94117061560488,\n        \"max\": 0.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -9.488449717062043,\n          -115.94117061560488,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 7.2 RL Policy Evaluation (Quantitative)\n",
        "# We evaluate the policy using the trained NeRD models and compare with Ground Truth.\n",
        "# We run for more games (2048) to get a statistically significant result as in the paper.\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "def run_eval(model_path=None, env_mode='neural', label='Model'):\n",
        "    print(f\"\\n{'='*20} RL Evaluation: {label} {'='*20}\")\n",
        "\n",
        "    # Use absolute paths\n",
        "    abs_playback_path = os.path.abspath('../pretrained_models/RL_policies/Cartpole/0/nn/CartpolePPO.pth')\n",
        "    abs_rl_cfg_path = os.path.abspath('../eval/eval_rl/cfg/Cartpole/cartpole.yaml')\n",
        "\n",
        "    cmd = [\n",
        "        'python', 'run_rl.py',\n",
        "        '--rl-cfg', abs_rl_cfg_path,\n",
        "        '--playback', abs_playback_path,\n",
        "        '--num-envs', '2048',\n",
        "        '--num-games', '2048',\n",
        "        '--env-mode', env_mode,\n",
        "        '--wandb-project', wandb_project,\n",
        "        '--wandb-name', f'{model_name}_rl_eval'\n",
        "    ]\n",
        "\n",
        "    if model_path:\n",
        "        abs_model_path = os.path.abspath(model_path)\n",
        "        cmd.extend([\n",
        "            '--nerd-model-path', abs_model_path\n",
        "        ])\n",
        "\n",
        "    try:\n",
        "        result = subprocess.run(cmd, cwd='../eval/eval_rl', check=True, capture_output=True, text=True)\n",
        "        output = result.stdout\n",
        "        print(output[-500:]) # Print last 500 chars to see result\n",
        "\n",
        "        # Parse reward\n",
        "        # Look for 'av reward: <value> av steps: <value>'\n",
        "        match = re.search(r'av reward:\\s*([-\\d\\.]+)', output)\n",
        "        if match:\n",
        "            reward = float(match.group(1))\n",
        "            return reward\n",
        "        else:\n",
        "            print(\"Could not parse reward from output.\")\n",
        "            return None\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f'Error running RL evaluation for {label}:')\n",
        "        print('STDOUT:', e.stdout)\n",
        "        print('STDERR:', e.stderr)\n",
        "        return None\n",
        "\n",
        "results = []\n",
        "\n",
        "# 1. Evaluate Ground Truth\n",
        "gt_reward = run_eval(env_mode='ground-truth', label='Ground Truth')\n",
        "if gt_reward is not None:\n",
        "    results.append({'Model': 'Ground Truth', 'Reward': gt_reward, 'Error (%)': 0.0})\n",
        "\n",
        "# 2. Evaluate NeRD Models\n",
        "for model_name in models:\n",
        "    model_path = find_latest_model(model_name)\n",
        "    if not model_path:\n",
        "        continue\n",
        "\n",
        "    reward = run_eval(model_path=model_path, env_mode='neural', label=model_name.capitalize())\n",
        "\n",
        "    if reward is not None and gt_reward is not None:\n",
        "        error = (reward - gt_reward) / gt_reward * 100\n",
        "        results.append({'Model': model_name.capitalize(), 'Reward': reward, 'Error (%)': error})\n",
        "    elif reward is not None:\n",
        "        results.append({'Model': model_name.capitalize(), 'Reward': reward, 'Error (%)': float('nan')})\n",
        "\n",
        "# 3. Create Table\n",
        "df = pd.DataFrame(results)\n",
        "print(\"\\nFinal Evaluation Comparison:\")\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fps-eval-header",
      "metadata": {
        "id": "fps-eval-header"
      },
      "source": [
        "# 7.3 Inference Throughput (FPS) Evaluation\n",
        "\n",
        "We measure the inference throughput (FPS) of the different models. This metric measures the raw speed of the simulation, expressed in Frames Per Second (FPS).\n",
        "We measure the wall-clock time required to roll out a large batch of parallel environments (2048 robots) for a fixed number of steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "fps-eval-code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fps-eval-code",
        "outputId": "03409983-34ff-4397-fc18-20911910a8e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== FPS Evaluation: Analytical (Warp) ====================\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.71 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.46 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.50 ms  (cached)\n",
            "\u001b[91m [NeuralEnvironment] Created a DUMMY Neural Integrator. \u001b[0m\n",
            "Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.32 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.38 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.80 ms  (cached)\n",
            "time(collision_detection): 0.000 sec, time(dynamics): 0.189 sec\n",
            "FPS: 727312.1413790417\n",
            "\n",
            "\n",
            "==================== FPS Evaluation: Baseline ====================\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.78 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.50 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.33 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.40 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.81 ms  (cached)\n",
            "time(collision_detection): 0.000 sec, time(dynamics): 1.791 sec\n",
            "FPS: 108440.69665156817\n",
            "\n",
            "\n",
            "==================== FPS Evaluation: Mamba ====================\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.69 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.35 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.50 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.34 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.38 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.81 ms  (cached)\n",
            "time(collision_detection): 0.000 sec, time(dynamics): 4.752 sec\n",
            "FPS: 42164.88328632167\n",
            "\n",
            "\n",
            "==================== FPS Evaluation: Unroll ====================\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.88 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.52 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.35 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.38 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.93 ms  (cached)\n",
            "time(collision_detection): 0.000 sec, time(dynamics): 1.793 sec\n",
            "FPS: 108270.48608524595\n",
            "\n",
            "\n",
            "Inference Throughput Comparison:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "               Model            FPS\n",
              "0  Analytical (Warp)  727312.141379\n",
              "1           Baseline  108440.696652\n",
              "2              Mamba   42164.883286\n",
              "3             Unroll  108270.486085"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-390f5ded-393d-4dca-8fb1-a910f06e8acc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>FPS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Analytical (Warp)</td>\n",
              "      <td>727312.141379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Baseline</td>\n",
              "      <td>108440.696652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mamba</td>\n",
              "      <td>42164.883286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Unroll</td>\n",
              "      <td>108270.486085</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-390f5ded-393d-4dca-8fb1-a910f06e8acc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-390f5ded-393d-4dca-8fb1-a910f06e8acc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-390f5ded-393d-4dca-8fb1-a910f06e8acc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d08d5c44-a228-4bf1-9c4b-7b99087a1d3b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d08d5c44-a228-4bf1-9c4b-7b99087a1d3b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d08d5c44-a228-4bf1-9c4b-7b99087a1d3b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_184760ec-090b-44ac-8c81-7f6fb22227d1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_fps')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_184760ec-090b-44ac-8c81-7f6fb22227d1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_fps');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_fps",
              "summary": "{\n  \"name\": \"df_fps\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Baseline\",\n          \"Unroll\",\n          \"Analytical (Warp)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FPS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 322025.3179086747,\n        \"min\": 42164.88328632167,\n        \"max\": 727312.1413790417,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          108440.69665156817,\n          108270.48608524595,\n          727312.1413790417\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "def run_fps_eval(model_path=None, env_mode='neural', label='Model'):\n",
        "    print(f\"\\n{'='*20} FPS Evaluation: {label} {'='*20}\")\n",
        "\n",
        "    cmd = [\n",
        "        'python', 'eval_fps.py',\n",
        "        '--env-name', 'Cartpole',\n",
        "        '--num-envs', '2048',\n",
        "        '--rollout-horizon', '100',\n",
        "        '--env-mode', env_mode\n",
        "    ]\n",
        "\n",
        "    if model_path:\n",
        "        abs_model_path = os.path.abspath(model_path)\n",
        "        cmd.extend(['--model-path', abs_model_path])\n",
        "\n",
        "    try:\n",
        "        result = subprocess.run(cmd, cwd='../eval/eval_fps', check=True, capture_output=True, text=True)\n",
        "        output = result.stdout\n",
        "        print(output)\n",
        "\n",
        "        # Parse FPS\n",
        "        match = re.search(r'FPS:\\s*([-\\d\\.]+)', output)\n",
        "        if match:\n",
        "            fps = float(match.group(1))\n",
        "            return fps\n",
        "        else:\n",
        "            print(\"Could not parse FPS from output.\")\n",
        "            return None\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f'Error running FPS evaluation for {label}:')\n",
        "        print('STDOUT:', e.stdout)\n",
        "        print('STDERR:', e.stderr)\n",
        "        return None\n",
        "\n",
        "fps_results = []\n",
        "\n",
        "# 1. Evaluate Ground Truth (Analytical Simulator)\n",
        "gt_fps = run_fps_eval(env_mode='ground-truth', label='Analytical (Warp)')\n",
        "if gt_fps is not None:\n",
        "    fps_results.append({'Model': 'Analytical (Warp)', 'FPS': gt_fps})\n",
        "\n",
        "# 2. Evaluate NeRD Models\n",
        "models = ['baseline', 'mamba', 'unroll']\n",
        "for model_name in models:\n",
        "    model_path = find_latest_model(model_name)\n",
        "    if not model_path:\n",
        "        continue\n",
        "\n",
        "    fps = run_fps_eval(model_path=model_path, env_mode='neural', label=model_name.capitalize())\n",
        "\n",
        "    if fps is not None:\n",
        "        fps_results.append({'Model': model_name.capitalize(), 'FPS': fps})\n",
        "\n",
        "# 3. Create Table\n",
        "df_fps = pd.DataFrame(fps_results)\n",
        "print(\"\\nInference Throughput Comparison:\")\n",
        "display(df_fps)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}