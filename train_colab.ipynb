{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "B8R6x04hd4Ei",
      "metadata": {
        "id": "B8R6x04hd4Ei"
      },
      "source": [
        "# Neural Robot Dynamics Training on Colab\n",
        "\n",
        "This notebook demonstrates how to setup the environment, generate a dataset, and train the NeRD model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "feb351a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feb351a0",
        "outputId": "0c63bbb0-6247-4e6c-d8b3-c5ba67fb70d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'neural-robot-dynamics' already exists and is not an empty directory.\n",
            "/content/neural-robot-dynamics\n",
            "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (4.67.1)\n",
            "Collecting pyglet==2.1.6 (from -r requirements.txt (line 2))\n",
            "  Using cached pyglet-2.1.6-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting ipdb (from -r requirements.txt (line 3))\n",
            "  Using cached ipdb-0.13.13-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting h5py==3.11.0 (from -r requirements.txt (line 4))\n",
            "  Using cached h5py-3.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting pyyaml==6.0.2 (from -r requirements.txt (line 5))\n",
            "  Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting tensorboard==2.14.0 (from -r requirements.txt (line 6))\n",
            "  Using cached tensorboard-2.14.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting matplotlib==3.7.5 (from -r requirements.txt (line 7))\n",
            "  Using cached matplotlib-3.7.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (4.12.0.88)\n",
            "Collecting pycollada==0.9.2 (from -r requirements.txt (line 9))\n",
            "  Using cached pycollada-0.9.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 1.11.0, 1.14.0rc1\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 1.10.0 Requires-Python <3.12,>=3.8; 1.10.0rc1 Requires-Python <3.12,>=3.8; 1.10.0rc2 Requires-Python <3.12,>=3.8; 1.10.1 Requires-Python <3.12,>=3.8; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 1.7.2 Requires-Python >=3.7,<3.11; 1.7.3 Requires-Python >=3.7,<3.11; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11; 1.9.0 Requires-Python >=3.8,<3.12; 1.9.0rc1 Requires-Python >=3.8,<3.12; 1.9.0rc2 Requires-Python >=3.8,<3.12; 1.9.0rc3 Requires-Python >=3.8,<3.12; 1.9.1 Requires-Python >=3.8,<3.12\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement scipy==1.10.1 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0, 1.0.1, 1.1.0, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0, 1.4.1, 1.5.0, 1.5.1, 1.5.2, 1.5.3, 1.5.4, 1.6.0, 1.6.1, 1.9.2, 1.9.3, 1.11.0rc1, 1.11.0rc2, 1.11.1, 1.11.2, 1.11.3, 1.11.4, 1.12.0rc1, 1.12.0rc2, 1.12.0, 1.13.0rc1, 1.13.0, 1.13.1, 1.14.0rc2, 1.14.0, 1.14.1, 1.15.0rc1, 1.15.0rc2, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.16.0rc1, 1.16.0rc2, 1.16.0, 1.16.1, 1.16.2, 1.16.3)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for scipy==1.10.1\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: warp-lang==1.8.0 in /usr/local/lib/python3.12/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from warp-lang==1.8.0) (2.0.2)\n",
            "Requirement already satisfied: rl_games in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.12/dist-packages (from rl_games) (0.25.2)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from rl_games) (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from rl_games) (2.0.2)\n",
            "Requirement already satisfied: ray>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from rl_games) (2.52.1)\n",
            "Requirement already satisfied: tensorboard>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rl_games) (2.19.0)\n",
            "Requirement already satisfied: tensorboardX>=1.6 in /usr/local/lib/python3.12/dist-packages (from rl_games) (2.6.4)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.12/dist-packages (from rl_games) (1.3.7)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from rl_games) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from rl_games) (6.0.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gym>=0.17.2->rl_games) (3.1.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from gym>=0.17.2->rl_games) (0.1.0)\n",
            "Requirement already satisfied: click!=8.3.*,>=7.0 in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (8.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (3.20.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (4.25.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (25.0)\n",
            "Requirement already satisfied: protobuf>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (5.29.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (2.32.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=1.14.0->rl_games) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=1.14.0->rl_games) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=1.14.0->rl_games) (3.10)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=1.14.0->rl_games) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=1.14.0->rl_games) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=1.14.0->rl_games) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=1.14.0->rl_games) (3.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7.0->rl_games) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard>=1.14.0->rl_games) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=1.1.0->rl_games) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=1.1.0->rl_games) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=1.1.0->rl_games) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=1.1.0->rl_games) (0.29.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->ray>=1.1.0->rl_games) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->ray>=1.1.0->rl_games) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->ray>=1.1.0->rl_games) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->ray>=1.1.0->rl_games) (2025.11.12)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.23.0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.12.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.46.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "# 1. Setup Environment\n",
        "!git clone https://github.com/dhruv0000/neural-robot-dynamics.git\n",
        "%cd neural-robot-dynamics\n",
        "!pip install -r requirements.txt\n",
        "!pip install warp-lang==1.8.0\n",
        "!pip install rl_games\n",
        "!pip install wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "wandb-setup",
      "metadata": {
        "id": "wandb-setup"
      },
      "outputs": [],
      "source": [
        "# Setup WandB\n",
        "import os\n",
        "import wandb\n",
        "# Assuming wandb_key is defined in the environment variables or you can set it here\n",
        "# For Colab, we can try to get it from userdata or assume it's set\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    os.environ['WANDB_API_KEY'] = userdata.get('wandb_key')\n",
        "except:\n",
        "    os.environ['WANDB_API_KEY'] = 'eb2afd65565d8bc1bb3010bcb082ec1e48de6860'  # Replace with your actual key if not using Colab\n",
        "    pass\n",
        "\n",
        "wandb_project = 'neural-robot-dynamics-big'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "66700684",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66700684",
        "outputId": "ddcebc0e-bb62-4b3a-c54e-a201be71d986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/neural-robot-dynamics/generate\n",
            "Loading datasets from Google Drive...\n",
            "/content/neural-robot-dynamics\n"
          ]
        }
      ],
      "source": [
        "# 2. Generate Dataset\n",
        "# We generate a smaller dataset for demonstration purposes.\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd generate\n",
        "\n",
        "# Define paths\n",
        "drive_data_dir = '/content/drive/MyDrive/neural-robot-dynamics/data/datasets/Cartpole/'\n",
        "local_data_dir = '../data/datasets/Cartpole/'\n",
        "train_filename = 'trajectory_len-100_train.hdf5'\n",
        "valid_filename = 'trajectory_len-100_valid.hdf5'\n",
        "\n",
        "os.makedirs(local_data_dir, exist_ok=True)\n",
        "os.makedirs(drive_data_dir, exist_ok=True)\n",
        "\n",
        "# Check if data exists in Drive\n",
        "if os.path.exists(os.path.join(drive_data_dir, train_filename)) and os.path.exists(os.path.join(drive_data_dir, valid_filename)):\n",
        "    print(\"Loading datasets from Google Drive...\")\n",
        "    shutil.copy(os.path.join(drive_data_dir, train_filename), local_data_dir)\n",
        "    shutil.copy(os.path.join(drive_data_dir, valid_filename), local_data_dir)\n",
        "else:\n",
        "    print(\"Generating datasets...\")\n",
        "    # Generate Training Data\n",
        "    !python generate_dataset_contact_free.py --env-name Cartpole --num-transitions 1000000 --dataset-dir ../data/datasets/ --dataset-name trajectory_len-100_train.hdf5 --trajectory-length 100 --num-envs 2048 --seed 0\n",
        "\n",
        "    # Generate Validation Data\n",
        "    !python generate_dataset_contact_free.py --env-name Cartpole --num-transitions 100000 --dataset-dir ../data/datasets/ --dataset-name trajectory_len-100_valid.hdf5 --trajectory-length 100 --num-envs 2048 --seed 10\n",
        "\n",
        "    print(\"Saving datasets to Google Drive...\")\n",
        "    shutil.copy(os.path.join(local_data_dir, train_filename), drive_data_dir)\n",
        "    shutil.copy(os.path.join(local_data_dir, valid_filename), drive_data_dir)\n",
        "\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d0907b67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0907b67",
        "outputId": "d3804f16-0818-4711-a38e-3975c4815c8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/neural-robot-dynamics/train\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "2025-12-08 16:12:51.559690: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765210371.579236    5593 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765210371.585204    5593 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765210371.600225    5593 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765210371.600255    5593 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765210371.600259    5593 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765210371.600263    5593 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-08 16:12:51.604897: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 512 environments: 100% 512/512 [00:01<00:00, 323.72it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 4.99 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.40 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.47 ms  (cached)\n",
            "\u001b[91m [NeuralEnvironment] Created a DUMMY Neural Integrator. \u001b[0m\n",
            "number of parameters: 2.69M\n",
            "Model = \n",
            " ModelMixedInput(\n",
            "  (encoders): ModuleDict(\n",
            "    (low_dim): MLPBase(\n",
            "      (body): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (transformer_model): GPT(\n",
            "    (transformer): ModuleDict(\n",
            "      (wte): Linear(in_features=6, out_features=192, bias=True)\n",
            "      (wpe): Embedding(32, 192)\n",
            "      (drop): Dropout(p=0.0, inplace=False)\n",
            "      (h): ModuleList(\n",
            "        (0-5): 6 x Block(\n",
            "          (ln_1): LayerNorm()\n",
            "          (attn): CausalSelfAttention(\n",
            "            (c_attn): Linear(in_features=192, out_features=576, bias=False)\n",
            "            (c_proj): Linear(in_features=192, out_features=192, bias=False)\n",
            "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ln_2): LayerNorm()\n",
            "          (mlp): MLP(\n",
            "            (c_fc): Linear(in_features=192, out_features=768, bias=False)\n",
            "            (gelu): GELU(approximate='none')\n",
            "            (c_proj): Linear(in_features=768, out_features=192, bias=False)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (ln_f): LayerNorm()\n",
            "    )\n",
            "    (lm_head): Linear(in_features=192, out_features=192, bias=False)\n",
            "  )\n",
            "  (model): MLPDeterministic(\n",
            "    (feature_net): MLPBase(\n",
            "      (body): Sequential(\n",
            "        (0): Linear(in_features=192, out_features=64, bias=True)\n",
            "        (1): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (output_net): Linear(in_features=64, out_features=4, bias=True)\n",
            "  )\n",
            ")\n",
            "# Model Parameters =  2713668\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m setting up run gh926vb0 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m setting up run gh926vb0 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m setting up run gh926vb0 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_161303-gh926vb0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbaseline\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/gh926vb0\u001b[0m\n",
            "Computing dataset statistics...\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Finished computing dataset statistics...\n",
            "100% 100/100 [00:18<00:00,  5.36it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions:   0% 0/4 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 8.04 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 10.37 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 3.57 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 10.03 ms  (cached)\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00,  9.21it/s]\n",
            "100% 4/4 [00:00<00:00,  6.14it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.56948280, Rollout MSE Error (joint_q) = 0.01602413 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 0 with MSE error 0.5694828033447266. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 0 \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 1.00524704, itemized = {state_0: 0.00854769, state_1: 0.86074593, state_2: 0.26696484, state_3: 0.29262514, state_MSE: 0.35722084, q_error_norm: 0.28917101, qd_error_norm: 0.53359058} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 19.836 sec, time(other): 0.013 sec, time(dataloader): 12.441 sec, time(compute_loss): 5.854 sec, time(backward): 0.004 sec, time(eval): 1.156 sec \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 0 with loss 1.00524704. \u001b[0m\n",
            "100% 100/100 [00:18<00:00,  5.30it/s]\n",
            "100% 100/100 [00:13<00:00,  7.55it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 14.89it/s]\n",
            "100% 4/4 [00:00<00:00,  4.90it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.18201892, Rollout MSE Error (joint_q) = 0.00831350 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 1 with MSE error 0.1820189207792282. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 1 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.31374649, itemized = {state_0: 0.00078919, state_1: 0.20352896, state_2: 0.09643035, state_3: 0.20127464, state_MSE: 0.12550573, q_error_norm: 0.07124903, qd_error_norm: 0.35585220} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.12683178, itemized = {state_0: 0.00012201, state_1: 0.14160707, state_2: 0.04125328, state_3: 0.08754141, state_MSE: 0.06763095, q_error_norm: 0.04671877, qd_error_norm: 0.22897827} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 34.058 sec, time(other): 0.060 sec, time(dataloader): 17.660 sec, time(compute_loss): 8.316 sec, time(backward): 5.634 sec, time(eval): 1.143 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(1.013372, device='cuda:0'), grad_norm_after_clip: tensor(0.870292, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 1 with loss 0.12683178. \u001b[0m\n",
            "100% 100/100 [00:14<00:00,  6.97it/s]\n",
            "100% 100/100 [00:16<00:00,  5.90it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.26it/s]\n",
            "100% 4/4 [00:00<00:00,  6.28it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.03386643, Rollout MSE Error (joint_q) = 0.00416638 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 2 with MSE error 0.03386642783880234. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 2 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.07252118, itemized = {state_0: 0.00009149, state_1: 0.09536145, state_2: 0.02730082, state_3: 0.04621978, state_MSE: 0.04224339, q_error_norm: 0.03175514, qd_error_norm: 0.17688938} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.04479114, itemized = {state_0: 0.00004531, state_1: 0.09087609, state_2: 0.01884864, state_3: 0.02640956, state_MSE: 0.03404490, q_error_norm: 0.02797517, qd_error_norm: 0.13107671} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 33.373 sec, time(other): 0.056 sec, time(dataloader): 17.901 sec, time(compute_loss): 8.627 sec, time(backward): 4.151 sec, time(eval): 0.845 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(1.078740, device='cuda:0'), grad_norm_after_clip: tensor(0.942172, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 2 with loss 0.04479114. \u001b[0m\n",
            "100% 100/100 [00:14<00:00,  6.95it/s]\n",
            "100% 100/100 [00:16<00:00,  6.17it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.59it/s]\n",
            "100% 4/4 [00:00<00:00,  6.35it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.05684681, Rollout MSE Error (joint_q) = 0.00098896 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 3 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.03327762, itemized = {state_0: 0.00005130, state_1: 0.06090040, state_2: 0.01445274, state_3: 0.01886735, state_MSE: 0.02356794, q_error_norm: 0.02056142, qd_error_norm: 0.11749816} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.02604577, itemized = {state_0: 0.00003687, state_1: 0.05367863, state_2: 0.01140636, state_3: 0.01461862, state_MSE: 0.01993513, q_error_norm: 0.01832814, qd_error_norm: 0.10665565} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 32.609 sec, time(other): 0.076 sec, time(dataloader): 16.792 sec, time(compute_loss): 8.616 sec, time(backward): 4.501 sec, time(eval): 0.809 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(1.218557, device='cuda:0'), grad_norm_after_clip: tensor(0.934893, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 3 with loss 0.02604577. \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.11it/s]\n",
            "100% 100/100 [00:16<00:00,  6.15it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 28.34it/s]\n",
            "100% 4/4 [00:00<00:00,  6.72it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.03291615, Rollout MSE Error (joint_q) = 0.00050779 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 4 with MSE error 0.032916147261857986. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 4 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.01673674, itemized = {state_0: 0.00002533, state_1: 0.04862208, state_2: 0.00702653, state_3: 0.00947655, state_MSE: 0.01628762, q_error_norm: 0.01633813, qd_error_norm: 0.08430216} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.01516150, itemized = {state_0: 0.00002201, state_1: 0.04676998, state_2: 0.00649704, state_3: 0.00862601, state_MSE: 0.01547876, q_error_norm: 0.01487863, qd_error_norm: 0.08329696} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 33.973 sec, time(other): 0.068 sec, time(dataloader): 18.468 sec, time(compute_loss): 8.535 sec, time(backward): 4.981 sec, time(eval): 0.790 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.999075, device='cuda:0'), grad_norm_after_clip: tensor(0.813779, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 4 with loss 0.01516150. \u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading output.log 7.7KB/7.7KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading output.log 7.7KB/7.7KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading output.log 7.7KB/7.7KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading output.log 7.7KB/7.7KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading output.log 7.7KB/7.7KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading output.log 7.7KB/7.7KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.3KB/2.3KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading output.log 7.7KB/7.7KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.3KB/2.3KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading output.log 7.7KB/7.7KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading config.yaml 2.3KB/2.3KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading output.log 7.7KB/7.7KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading config.yaml 2.3KB/2.3KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading output.log 7.7KB/7.7KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading config.yaml 2.3KB/2.3KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading history steps 4-4, summary, console lines 65-78 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading history steps 4-4, summary, console lines 65-78 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading history steps 4-4, summary, console lines 65-78 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch â–ˆâ–„â–â–‚â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch â–ˆâ–ƒâ–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch â–ˆâ–†â–„â–‚â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch â–ˆâ–…â–ƒâ–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch â–ˆâ–ƒâ–â–‚â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch â–ˆâ–ƒâ–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch â–ˆâ–ƒâ–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch â–ˆâ–ƒâ–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch â–ˆâ–ƒâ–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch â–ˆâ–ƒâ–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch 0.28446\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch 0.03292\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch 0.02583\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch 0.00051\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch 0.28253\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch 0.06532\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch 0.06629\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch 0.11979\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch 0.16602\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch 0.20908\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mbaseline\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/gh926vb0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_161303-gh926vb0/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 3. Train Baseline Model (Transformer)\n",
        "%cd train\n",
        "\n",
        "import yaml\n",
        "import os\n",
        "\n",
        "# Load default config\n",
        "with open('cfg/Cartpole/transformer.yaml', 'r') as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "\n",
        "# Override dataset paths to point to the generated data\n",
        "cfg['algorithm']['dataset']['train_dataset_path'] = '../data/datasets/Cartpole/trajectory_len-100_train.hdf5'\n",
        "cfg['algorithm']['dataset']['valid_datasets']['exp_trajectory'] = '../data/datasets/Cartpole/trajectory_len-100_valid.hdf5'\n",
        "\n",
        "# Reduce training parameters for quick demonstration\n",
        "cfg['algorithm']['num_epochs'] = 5\n",
        "cfg['algorithm']['num_iters_per_epoch'] = 100\n",
        "cfg['algorithm']['batch_size'] = 1024\n",
        "cfg['algorithm']['dataset']['num_data_workers'] = 8\n",
        "\n",
        "# Save the modified config\n",
        "with open('colab_config.yaml', 'w') as f:\n",
        "    yaml.dump(cfg, f)\n",
        "\n",
        "# Run training\n",
        "!python train.py --cfg colab_config.yaml --logdir ../data/logs/baseline --wandb-project {wandb_project} --wandb-name baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "mamba-6-train",
      "metadata": {
        "id": "mamba-6-train",
        "outputId": "68447d2e-63e0-4c18-eac9-bc857be3bd44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "2025-12-08 16:17:47.091190: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765210667.111727    7104 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765210667.117791    7104 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765210667.133441    7104 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765210667.133469    7104 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765210667.133473    7104 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765210667.133479    7104 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-08 16:17:47.138346: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 512 environments: 100% 512/512 [00:01<00:00, 322.09it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 5.02 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.42 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.47 ms  (cached)\n",
            "\u001b[91m [NeuralEnvironment] Created a DUMMY Neural Integrator. \u001b[0m\n",
            "Model = \n",
            " ModelMixedInput(\n",
            "  (encoders): ModuleDict(\n",
            "    (low_dim): MLPBase(\n",
            "      (body): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (mamba_model): Mamba(\n",
            "    (embedding): Linear(in_features=6, out_features=192, bias=True)\n",
            "    (layers): ModuleList(\n",
            "      (0-5): 6 x MambaBlock(\n",
            "        (in_proj): Linear(in_features=192, out_features=768, bias=False)\n",
            "        (conv1d): Conv1d(384, 384, kernel_size=(4,), stride=(1,), padding=(3,), groups=384)\n",
            "        (x_proj): Linear(in_features=384, out_features=44, bias=False)\n",
            "        (dt_proj): Linear(in_features=12, out_features=384, bias=True)\n",
            "        (out_proj): Linear(in_features=384, out_features=192, bias=False)\n",
            "      )\n",
            "    )\n",
            "    (norm_f): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (model): MLPDeterministic(\n",
            "    (feature_net): MLPBase(\n",
            "      (body): Sequential(\n",
            "        (0): Linear(in_features=192, out_features=64, bias=True)\n",
            "        (1): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (output_net): Linear(in_features=64, out_features=4, bias=True)\n",
            "  )\n",
            ")\n",
            "# Model Parameters =  1523460\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m setting up run lqutqsk0 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m setting up run lqutqsk0 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m setting up run lqutqsk0 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m setting up run lqutqsk0 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m setting up run lqutqsk0 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_161800-lqutqsk0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba-6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/lqutqsk0\u001b[0m\n",
            "Computing dataset statistics...\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Finished computing dataset statistics...\n",
            "100% 100/100 [00:22<00:00,  4.37it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions:   0% 0/4 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 7.88 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 6.56 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.55 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.97 ms  (cached)\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00,  6.18it/s]\n",
            "100% 4/4 [00:01<00:00,  2.44it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 1.37107885, Rollout MSE Error (joint_q) = 0.06962701 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 0 with MSE error 1.3710788488388062. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 0 \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 1.11946175, itemized = {state_0: 0.00979180, state_1: 0.85542801, state_2: 0.28697836, state_3: 0.35225052, state_MSE: 0.37611217, q_error_norm: 0.29391603, qd_error_norm: 0.59967022} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 25.299 sec, time(other): 0.026 sec, time(dataloader): 8.125 sec, time(compute_loss): 14.558 sec, time(backward): 0.000 sec, time(eval): 2.354 sec \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 0 with loss 1.11946175. \u001b[0m\n",
            "100% 100/100 [01:32<00:00,  1.08it/s]\n",
            "100% 100/100 [00:19<00:00,  5.12it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 27.90it/s]\n",
            "100% 4/4 [00:01<00:00,  2.48it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.01237547, Rollout MSE Error (joint_q) = 0.00056169 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 1 with MSE error 0.01237547304481268. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 1 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.17619310, itemized = {state_0: 0.00044072, state_1: 0.13188238, state_2: 0.06189744, state_3: 0.10269538, state_MSE: 0.07422900, q_error_norm: 0.04468997, qd_error_norm: 0.23091061} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.01896067, itemized = {state_0: 0.00003758, state_1: 0.04902472, state_2: 0.00797441, state_3: 0.01004328, state_MSE: 0.01677000, q_error_norm: 0.01694968, qd_error_norm: 0.08985875} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 114.895 sec, time(other): 0.492 sec, time(dataloader): 38.501 sec, time(compute_loss): 26.867 sec, time(backward): 46.410 sec, time(eval): 1.810 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.351840, device='cuda:0'), grad_norm_after_clip: tensor(0.335077, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 1 with loss 0.01896067. \u001b[0m\n",
            "100% 100/100 [01:32<00:00,  1.08it/s]\n",
            "100% 100/100 [00:20<00:00,  4.96it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 28.04it/s]\n",
            "100% 4/4 [00:01<00:00,  2.47it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00355150, Rollout MSE Error (joint_q) = 0.00020544 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 2 with MSE error 0.0035515010822564363. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 2 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.01002637, itemized = {state_0: 0.00002620, state_1: 0.04204734, state_2: 0.00400086, state_3: 0.00507096, state_MSE: 0.01278634, q_error_norm: 0.01432612, qd_error_norm: 0.06269037} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00524534, itemized = {state_0: 0.00001627, state_1: 0.02823725, state_2: 0.00190298, state_3: 0.00271398, state_MSE: 0.00821762, q_error_norm: 0.01073986, qd_error_norm: 0.04744567} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 115.967 sec, time(other): 0.510 sec, time(dataloader): 39.382 sec, time(compute_loss): 26.756 sec, time(backward): 45.965 sec, time(eval): 1.803 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.138647, device='cuda:0'), grad_norm_after_clip: tensor(0.138647, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 2 with loss 0.00524534. \u001b[0m\n",
            "100% 100/100 [01:32<00:00,  1.08it/s]\n",
            "100% 100/100 [00:21<00:00,  4.75it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.10it/s]\n",
            "100% 4/4 [00:01<00:00,  2.47it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00211483, Rollout MSE Error (joint_q) = 0.00016701 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 3 with MSE error 0.002114825416356325. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 3 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00398477, itemized = {state_0: 0.00001255, state_1: 0.02944062, state_2: 0.00142727, state_3: 0.00207093, state_MSE: 0.00823784, q_error_norm: 0.01014555, qd_error_norm: 0.04067879} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00307434, itemized = {state_0: 0.00000970, state_1: 0.02254486, state_2: 0.00103885, state_3: 0.00167997, state_MSE: 0.00631834, q_error_norm: 0.00847798, qd_error_norm: 0.03672362} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 116.239 sec, time(other): 0.513 sec, time(dataloader): 40.171 sec, time(compute_loss): 26.830 sec, time(backward): 45.961 sec, time(eval): 1.817 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.089157, device='cuda:0'), grad_norm_after_clip: tensor(0.089157, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 3 with loss 0.00307434. \u001b[0m\n",
            "100% 100/100 [01:32<00:00,  1.08it/s]\n",
            "100% 100/100 [00:18<00:00,  5.41it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 28.59it/s]\n",
            "100% 4/4 [00:01<00:00,  2.47it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00144699, Rollout MSE Error (joint_q) = 0.00011897 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 4 with MSE error 0.0014469885500147939. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 4 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00242979, itemized = {state_0: 0.00000827, state_1: 0.02231586, state_2: 0.00077782, state_3: 0.00131901, state_MSE: 0.00610523, q_error_norm: 0.00810672, qd_error_norm: 0.03200901} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00189179, itemized = {state_0: 0.00000714, state_1: 0.02062435, state_2: 0.00058452, state_3: 0.00100638, state_MSE: 0.00555560, q_error_norm: 0.00758727, qd_error_norm: 0.02921678} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 113.649 sec, time(other): 0.495 sec, time(dataloader): 37.796 sec, time(compute_loss): 26.733 sec, time(backward): 45.978 sec, time(eval): 1.817 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.059511, device='cuda:0'), grad_norm_after_clip: tensor(0.059511, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 4 with loss 0.00189179. \u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading output.log 7.8KB/7.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading output.log 7.8KB/7.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading output.log 7.8KB/7.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading output.log 7.8KB/7.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading output.log 7.8KB/7.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading output.log 7.8KB/7.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading output.log 7.8KB/7.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading output.log 7.8KB/7.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading output.log 7.8KB/7.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading output.log 7.8KB/7.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading history steps 4-4, summary, console lines 66-79 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading history steps 4-4, summary, console lines 66-79 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch â–ˆâ–‚â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch â–ˆâ–‚â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch â–ˆâ–‚â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch 0.06302\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch 0.00145\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch 0.01265\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch 0.00012\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch 0.0609\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch 0.00278\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch 0.02129\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch 0.03355\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch 0.04477\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch 0.05285\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mmamba-6\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/lqutqsk0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_161800-lqutqsk0/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 4a. Train Mamba-6 Model (6 layers)\n",
        "# This is the full 6-layer Mamba model\n",
        "!python train.py --cfg colab_config.yaml --novelty mamba-6 --logdir ../data/logs/mamba_6 --wandb-project {wandb_project} --wandb-name mamba-6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "mamba-3-train",
      "metadata": {
        "id": "mamba-3-train",
        "outputId": "214dd6b0-5469-4791-f9fd-383993ea0e08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "2025-12-08 16:28:18.788561: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765211298.808321   10050 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765211298.814349   10050 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765211298.829536   10050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765211298.829564   10050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765211298.829568   10050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765211298.829571   10050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-08 16:28:18.834288: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 512 environments: 100% 512/512 [00:02<00:00, 216.62it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 4.29 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.42 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.46 ms  (cached)\n",
            "\u001b[91m [NeuralEnvironment] Created a DUMMY Neural Integrator. \u001b[0m\n",
            "Model = \n",
            " ModelMixedInput(\n",
            "  (encoders): ModuleDict(\n",
            "    (low_dim): MLPBase(\n",
            "      (body): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (mamba_model): Mamba(\n",
            "    (embedding): Linear(in_features=6, out_features=192, bias=True)\n",
            "    (layers): ModuleList(\n",
            "      (0-2): 3 x MambaBlock(\n",
            "        (in_proj): Linear(in_features=192, out_features=768, bias=False)\n",
            "        (conv1d): Conv1d(384, 384, kernel_size=(4,), stride=(1,), padding=(3,), groups=384)\n",
            "        (x_proj): Linear(in_features=384, out_features=44, bias=False)\n",
            "        (dt_proj): Linear(in_features=12, out_features=384, bias=True)\n",
            "        (out_proj): Linear(in_features=384, out_features=192, bias=False)\n",
            "      )\n",
            "    )\n",
            "    (norm_f): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (model): MLPDeterministic(\n",
            "    (feature_net): MLPBase(\n",
            "      (body): Sequential(\n",
            "        (0): Linear(in_features=192, out_features=64, bias=True)\n",
            "        (1): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (output_net): Linear(in_features=64, out_features=4, bias=True)\n",
            "  )\n",
            ")\n",
            "# Model Parameters =  768900\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m setting up run apayl9th (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m setting up run apayl9th (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m setting up run apayl9th (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_162833-apayl9th\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba-3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/apayl9th\u001b[0m\n",
            "Computing dataset statistics...\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Finished computing dataset statistics...\n",
            "100% 100/100 [00:15<00:00,  6.32it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions:   0% 0/4 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 9.27 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 8.65 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.61 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 12.16 ms  (cached)\n",
            "Sampling state transitions: 100% 4/4 [00:01<00:00,  3.32it/s]\n",
            "100% 4/4 [00:01<00:00,  2.51it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.53409415, Rollout MSE Error (joint_q) = 0.04594289 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 0 with MSE error 0.5340941548347473. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 0 \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 1.07838898, itemized = {state_0: 0.01025044, state_1: 0.85045799, state_2: 0.28694530, state_3: 0.28220556, state_MSE: 0.35746490, q_error_norm: 0.29537218, qd_error_norm: 0.53744297} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 18.705 sec, time(other): 0.020 sec, time(dataloader): 7.271 sec, time(compute_loss): 8.239 sec, time(backward): 0.002 sec, time(eval): 2.868 sec \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 0 with loss 1.07838898. \u001b[0m\n",
            "100% 100/100 [00:47<00:00,  2.11it/s]\n",
            "100% 100/100 [00:16<00:00,  6.13it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 27.40it/s]\n",
            "100% 4/4 [00:00<00:00,  4.49it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00849829, Rollout MSE Error (joint_q) = 0.00050440 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 1 with MSE error 0.008498290553689003. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 1 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.18685579, itemized = {state_0: 0.00054419, state_1: 0.15567453, state_2: 0.06227041, state_3: 0.10778728, state_MSE: 0.08156911, q_error_norm: 0.05144212, qd_error_norm: 0.23423456} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.01605656, itemized = {state_0: 0.00004380, state_1: 0.06581295, state_2: 0.00598463, state_3: 0.00854234, state_MSE: 0.02009593, q_error_norm: 0.02029772, qd_error_norm: 0.08090275} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 65.594 sec, time(other): 0.050 sec, time(dataloader): 45.609 sec, time(compute_loss): 14.126 sec, time(backward): 3.677 sec, time(eval): 1.072 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.389591, device='cuda:0'), grad_norm_after_clip: tensor(0.370524, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 1 with loss 0.01605656. \u001b[0m\n",
            "100% 100/100 [00:46<00:00,  2.14it/s]\n",
            "100% 100/100 [00:15<00:00,  6.35it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 16.41it/s]\n",
            "100% 4/4 [00:01<00:00,  3.97it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00656081, Rollout MSE Error (joint_q) = 0.00033201 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 2 with MSE error 0.006560811307281256. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 2 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00994451, itemized = {state_0: 0.00002827, state_1: 0.04656664, state_2: 0.00381836, state_3: 0.00511248, state_MSE: 0.01388143, q_error_norm: 0.01536879, qd_error_norm: 0.06436958} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00673637, itemized = {state_0: 0.00001931, state_1: 0.03881382, state_2: 0.00250287, state_3: 0.00357523, state_MSE: 0.01122781, q_error_norm: 0.01296739, qd_error_norm: 0.05510114} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 67.018 sec, time(other): 0.034 sec, time(dataloader): 45.633 sec, time(compute_loss): 14.284 sec, time(backward): 1.984 sec, time(eval): 1.294 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.214176, device='cuda:0'), grad_norm_after_clip: tensor(0.214176, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 2 with loss 0.00673637. \u001b[0m\n",
            "100% 100/100 [00:46<00:00,  2.14it/s]\n",
            "100% 100/100 [00:15<00:00,  6.31it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 21.99it/s]\n",
            "100% 4/4 [00:00<00:00,  4.31it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00527604, Rollout MSE Error (joint_q) = 0.00028375 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 3 with MSE error 0.005276036448776722. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 3 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00521360, itemized = {state_0: 0.00001632, state_1: 0.03828726, state_2: 0.00190175, state_3: 0.00268784, state_MSE: 0.01072330, q_error_norm: 0.01231246, qd_error_norm: 0.04760021} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00408780, itemized = {state_0: 0.00001366, state_1: 0.03256217, state_2: 0.00141027, state_3: 0.00217198, state_MSE: 0.00903952, q_error_norm: 0.01092007, qd_error_norm: 0.04363298} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 66.043 sec, time(other): 0.042 sec, time(dataloader): 45.831 sec, time(compute_loss): 14.177 sec, time(backward): 2.032 sec, time(eval): 1.147 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.109241, device='cuda:0'), grad_norm_after_clip: tensor(0.109241, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 3 with loss 0.00408780. \u001b[0m\n",
            "100% 100/100 [00:46<00:00,  2.13it/s]\n",
            "100% 100/100 [00:16<00:00,  6.18it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 18.53it/s]\n",
            "100% 4/4 [00:00<00:00,  4.31it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00366055, Rollout MSE Error (joint_q) = 0.00020453 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 4 with MSE error 0.003660545451566577. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 4 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00351405, itemized = {state_0: 0.00001246, state_1: 0.03352265, state_2: 0.00120637, state_3: 0.00181900, state_MSE: 0.00914012, q_error_norm: 0.01079355, qd_error_norm: 0.03952631} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00299978, itemized = {state_0: 0.00001109, state_1: 0.02817001, state_2: 0.00100967, state_3: 0.00154023, state_MSE: 0.00768275, q_error_norm: 0.00968099, qd_error_norm: 0.03719864} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 65.371 sec, time(other): 0.037 sec, time(dataloader): 45.983 sec, time(compute_loss): 14.166 sec, time(backward): 2.468 sec, time(eval): 1.186 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.058302, device='cuda:0'), grad_norm_after_clip: tensor(0.058302, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 4 with loss 0.00299978. \u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading output.log 7.8KB/7.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading output.log 7.8KB/7.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading output.log 7.8KB/7.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading output.log 7.8KB/7.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading output.log 7.8KB/7.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading output.log 7.8KB/7.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading output.log 7.8KB/7.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading output.log 7.8KB/7.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading output.log 7.8KB/7.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading output.log 7.8KB/7.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading data (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading data (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading data (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading data (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch â–ˆâ–‚â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch 0.09809\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch 0.00366\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch 0.01623\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch 0.0002\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch 0.09569\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch 0.00712\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch 0.02908\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch 0.04571\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch 0.06087\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch 0.07463\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mmamba-3\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/apayl9th\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_162833-apayl9th/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 4b. Train Mamba-3 Model (3 layers)\n",
        "# Reduced parameter count version for comparison\n",
        "!python train.py --cfg colab_config.yaml --novelty mamba-3 --logdir ../data/logs/mamba_3 --wandb-project {wandb_project} --wandb-name mamba-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a32b3a28",
      "metadata": {
        "id": "a32b3a28"
      },
      "outputs": [],
      "source": [
        "# 5. Train Unroll Model\n",
        "# We use the same config but add the --novelty unroll flag\n",
        "# !python train.py --cfg colab_config.yaml --novelty unroll --logdir ../data/logs/unroll --wandb-project {wandb_project} --wandb-name unroll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "jamba-train",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jamba-train",
        "outputId": "d2019975-9194-41f6-e732-c48a8518f4bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "2025-12-08 16:35:27.001274: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765211727.020968   12133 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765211727.027272   12133 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765211727.042897   12133 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765211727.042925   12133 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765211727.042931   12133 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765211727.042935   12133 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-08 16:35:27.047859: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 512 environments: 100% 512/512 [00:01<00:00, 324.42it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 4.29 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.41 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.47 ms  (cached)\n",
            "\u001b[91m [NeuralEnvironment] Created a DUMMY Neural Integrator. \u001b[0m\n",
            "Model = \n",
            " ModelMixedInput(\n",
            "  (encoders): ModuleDict(\n",
            "    (low_dim): MLPBase(\n",
            "      (body): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (jamba_model): Jamba(\n",
            "    (embedding): Linear(in_features=6, out_features=192, bias=True)\n",
            "    (layers): ModuleList(\n",
            "      (0-1): 2 x JambaBlock(\n",
            "        (layers): ModuleList(\n",
            "          (0-1): 2 x MambaBlock(\n",
            "            (in_proj): Linear(in_features=192, out_features=768, bias=False)\n",
            "            (conv1d): Conv1d(384, 384, kernel_size=(4,), stride=(1,), padding=(3,), groups=384)\n",
            "            (x_proj): Linear(in_features=384, out_features=44, bias=False)\n",
            "            (dt_proj): Linear(in_features=12, out_features=384, bias=True)\n",
            "            (out_proj): Linear(in_features=384, out_features=192, bias=False)\n",
            "          )\n",
            "          (2): Block(\n",
            "            (ln_1): LayerNorm()\n",
            "            (attn): CausalSelfAttention(\n",
            "              (c_attn): Linear(in_features=192, out_features=576, bias=False)\n",
            "              (c_proj): Linear(in_features=192, out_features=192, bias=False)\n",
            "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "              (resid_dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ln_2): LayerNorm()\n",
            "            (mlp): MLP(\n",
            "              (c_fc): Linear(in_features=192, out_features=768, bias=False)\n",
            "              (gelu): GELU(approximate='none')\n",
            "              (c_proj): Linear(in_features=768, out_features=192, bias=False)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (norm_f): LayerNorm()\n",
            "  )\n",
            "  (model): MLPDeterministic(\n",
            "    (feature_net): MLPBase(\n",
            "      (body): Sequential(\n",
            "        (0): Linear(in_features=192, out_features=64, bias=True)\n",
            "        (1): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (output_net): Linear(in_features=64, out_features=4, bias=True)\n",
            "  )\n",
            ")\n",
            "# Model Parameters =  1905732\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m setting up run 9t1f6fai (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m setting up run 9t1f6fai (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m setting up run 9t1f6fai (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_163539-9t1f6fai\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mjamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/9t1f6fai\u001b[0m\n",
            "Computing dataset statistics...\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Finished computing dataset statistics...\n",
            "100% 100/100 [00:19<00:00,  5.12it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions:   0% 0/4 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 2.02 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.51 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.49 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.94 ms  (cached)\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 16.51it/s]\n",
            "100% 4/4 [00:01<00:00,  3.08it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 1.11537457, Rollout MSE Error (joint_q) = 0.02400387 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 0 with MSE error 1.1153745651245117. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 0 \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 1.01956238, itemized = {state_0: 0.00806507, state_1: 0.84628326, state_2: 0.28853807, state_3: 0.29622520, state_MSE: 0.35977795, q_error_norm: 0.28620197, qd_error_norm: 0.57340996} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.200 sec, time(other): 0.034 sec, time(dataloader): 8.324 sec, time(compute_loss): 10.948 sec, time(backward): 0.000 sec, time(eval): 1.591 sec \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 0 with loss 1.01956238. \u001b[0m\n",
            "100% 100/100 [01:05<00:00,  1.52it/s]\n",
            "100% 100/100 [00:16<00:00,  6.14it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.25it/s]\n",
            "100% 4/4 [00:01<00:00,  3.11it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00967687, Rollout MSE Error (joint_q) = 0.00067140 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 1 with MSE error 0.009676866233348846. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 1 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.12421777, itemized = {state_0: 0.00023811, state_1: 0.11436196, state_2: 0.04420949, state_3: 0.07467041, state_MSE: 0.05836998, q_error_norm: 0.03692426, qd_error_norm: 0.18936632} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.01533379, itemized = {state_0: 0.00002431, state_1: 0.05791345, state_2: 0.00628203, state_3: 0.00862205, state_MSE: 0.01821046, q_error_norm: 0.01685743, qd_error_norm: 0.07770318} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 84.357 sec, time(other): 0.548 sec, time(dataloader): 40.451 sec, time(compute_loss): 20.122 sec, time(backward): 20.880 sec, time(eval): 1.497 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.445747, device='cuda:0'), grad_norm_after_clip: tensor(0.432071, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 1 with loss 0.01533379. \u001b[0m\n",
            "100% 100/100 [01:06<00:00,  1.51it/s]\n",
            "100% 100/100 [00:19<00:00,  5.02it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 28.03it/s]\n",
            "100% 4/4 [00:01<00:00,  3.12it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.01099444, Rollout MSE Error (joint_q) = 0.00011837 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 2 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00763385, itemized = {state_0: 0.00001588, state_1: 0.03847010, state_2: 0.00272720, state_3: 0.00454972, state_MSE: 0.01144072, q_error_norm: 0.01220026, qd_error_norm: 0.05693898} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00496839, itemized = {state_0: 0.00000994, state_1: 0.02456001, state_2: 0.00180563, state_3: 0.00299745, state_MSE: 0.00734326, q_error_norm: 0.00855592, qd_error_norm: 0.05129227} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 88.142 sec, time(other): 0.541 sec, time(dataloader): 44.211 sec, time(compute_loss): 20.404 sec, time(backward): 20.468 sec, time(eval): 1.447 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.251363, device='cuda:0'), grad_norm_after_clip: tensor(0.251363, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 2 with loss 0.00496839. \u001b[0m\n",
            "100% 100/100 [01:05<00:00,  1.52it/s]\n",
            "100% 100/100 [00:16<00:00,  6.00it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 28.16it/s]\n",
            "100% 4/4 [00:01<00:00,  3.12it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00389686, Rollout MSE Error (joint_q) = 0.00015993 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 3 with MSE error 0.0038968592416495085. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 3 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00325273, itemized = {state_0: 0.00000789, state_1: 0.02445518, state_2: 0.00110220, state_3: 0.00195914, state_MSE: 0.00688110, q_error_norm: 0.00803221, qd_error_norm: 0.03758996} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00248071, itemized = {state_0: 0.00000669, state_1: 0.02300610, state_2: 0.00080271, state_3: 0.00149731, state_MSE: 0.00632820, q_error_norm: 0.00755792, qd_error_norm: 0.03423240} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 84.672 sec, time(other): 0.541 sec, time(dataloader): 40.788 sec, time(compute_loss): 20.410 sec, time(backward): 20.454 sec, time(eval): 1.480 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.142538, device='cuda:0'), grad_norm_after_clip: tensor(0.142538, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 3 with loss 0.00248071. \u001b[0m\n",
            "100% 100/100 [01:05<00:00,  1.52it/s]\n",
            "100% 100/100 [00:18<00:00,  5.28it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.71it/s]\n",
            "100% 4/4 [00:01<00:00,  3.11it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00111708, Rollout MSE Error (joint_q) = 0.00008125 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 4 with MSE error 0.0011170837096869946. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 4 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00194173, itemized = {state_0: 0.00000580, state_1: 0.01984487, state_2: 0.00061934, state_3: 0.00114537, state_MSE: 0.00540385, q_error_norm: 0.00666342, qd_error_norm: 0.02859479} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00160231, itemized = {state_0: 0.00000504, state_1: 0.01839292, state_2: 0.00050602, state_3: 0.00094021, state_MSE: 0.00496105, q_error_norm: 0.00623114, qd_error_norm: 0.02655284} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 87.654 sec, time(other): 0.564 sec, time(dataloader): 43.047 sec, time(compute_loss): 20.420 sec, time(backward): 20.449 sec, time(eval): 1.485 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.061344, device='cuda:0'), grad_norm_after_clip: tensor(0.061344, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 4 with loss 0.00160231. \u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading output.log 7.7KB/7.7KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading output.log 7.7KB/7.7KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading output.log 7.7KB/7.7KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading output.log 7.7KB/7.7KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading output.log 7.7KB/7.7KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading output.log 7.7KB/7.7KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading output.log 7.7KB/7.7KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading output.log 7.7KB/7.7KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading output.log 7.7KB/7.7KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading output.log 7.7KB/7.7KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading history steps 4-4, summary, console lines 65-78 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading history steps 4-4, summary, console lines 65-78 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading history steps 4-4, summary, console lines 65-78 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch â–ˆâ–‚â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch â–ˆâ–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch 0.05471\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch 0.00112\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch 0.00998\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch 8e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch 0.05331\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch 0.00215\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch 0.01787\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch 0.03126\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch 0.04124\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch 0.04814\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mjamba\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/9t1f6fai\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_163539-9t1f6fai/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 5. Train Jamba Model\n",
        "# We use the same config but add the --novelty jamba flag\n",
        "!python train.py --cfg colab_config.yaml --novelty jamba --logdir ../data/logs/jamba --wandb-project {wandb_project} --wandb-name jamba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "save_models_drive",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "save_models_drive",
        "outputId": "44bea26f-848f-469b-c09f-3738e98ff489"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving baseline model to Google Drive...\n",
            "Saving mamba_6 model to Google Drive...\n",
            "Saving mamba_3 model to Google Drive...\n",
            "Local log directory for unroll not found. Skipping save.\n",
            "Saving jamba model to Google Drive...\n"
          ]
        }
      ],
      "source": [
        "# 6. Save Models to Google Drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "models = ['baseline', 'mamba_6', 'mamba_3', 'unroll', 'jamba']\n",
        "drive_base_dir = '/content/drive/MyDrive/neural-robot-dynamics/data/logs'\n",
        "local_base_dir = '../data/logs'\n",
        "\n",
        "for model in models:\n",
        "    local_dir = os.path.join(local_base_dir, model)\n",
        "    drive_dir = os.path.join(drive_base_dir, model)\n",
        "\n",
        "    if os.path.exists(local_dir):\n",
        "        print(f\"Saving {model} model to Google Drive...\")\n",
        "        if os.path.exists(drive_dir):\n",
        "            shutil.rmtree(drive_dir)\n",
        "        shutil.copytree(local_dir, drive_dir)\n",
        "    else:\n",
        "        print(f\"Local log directory for {model} not found. Skipping save.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "load_models_drive",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "load_models_drive",
        "outputId": "cc4086a1-4d03-4e4f-ec43-df0a53736eb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading baseline model from Google Drive...\n",
            "Loading mamba_6 model from Google Drive...\n",
            "Loading mamba_3 model from Google Drive...\n",
            "Drive log directory for unroll not found. Skipping load.\n",
            "Loading jamba model from Google Drive...\n"
          ]
        }
      ],
      "source": [
        "# 7. Load Models from Google Drive (Optional)\n",
        "# Run this cell if you want to load pre-trained models from Drive instead of training them.\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "models = ['baseline', 'mamba_6', 'mamba_3', 'unroll', 'jamba']\n",
        "drive_base_dir = '/content/drive/MyDrive/neural-robot-dynamics/data/logs'\n",
        "local_base_dir = '../data/logs'\n",
        "\n",
        "for model in models:\n",
        "    local_dir = os.path.join(local_base_dir, model)\n",
        "    drive_dir = os.path.join(drive_base_dir, model)\n",
        "\n",
        "    if os.path.exists(drive_dir):\n",
        "        print(f\"Loading {model} model from Google Drive...\")\n",
        "        if os.path.exists(local_dir):\n",
        "            shutil.rmtree(local_dir)\n",
        "        shutil.copytree(drive_dir, local_dir)\n",
        "    else:\n",
        "        print(f\"Drive log directory for {model} not found. Skipping load.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "quantitative-analysis-header",
      "metadata": {
        "id": "quantitative-analysis-header"
      },
      "source": [
        "# 7. Quantitative Analysis\n",
        "\n",
        "We now perform the quantitative analysis as described in the paper experiments.\n",
        "We evaluate:\n",
        "1. **Long-Horizon Passive Motion**: Accuracy of the trained NeRD models over 100, 500, and 1000 steps.\n",
        "2. **RL Policy Evaluation**: Performance of the pretrained RL policy using the NeRD models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "passive-motion-eval",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "passive-motion-eval",
        "outputId": "409c3ab5-e3e1-4230-c76e-d6cdb018ee88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== Evaluating Baseline Model ====================\n",
            "\n",
            "--- Horizon: 100 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  2713668\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 320.91it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 4.42 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.48 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.38 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.34 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.34 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.79 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:00<00:00,  2.42it/s]\n",
            "100% 1/1 [00:06<00:00,  6.94s/it]\n",
            "=========================================\n",
            "Base position error mean       = 0.762344\n",
            "Base position error std        = 0.844682\n",
            "Joint position error mean      = 0.355609 rad (20.374902 deg)\n",
            "Joint position Error per dof   = tensor([0.355609], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m setting up run 6csvpoob (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m setting up run 6csvpoob (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m setting up run 6csvpoob (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m setting up run 6csvpoob (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_164416-6csvpoob\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbaseline_passive_eval_100\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/6csvpoob\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-summary.json 221B/221B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-summary.json 221B/221B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-summary.json 221B/221B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-summary.json 221B/221B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-summary.json 221B/221B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading history steps 0-0, summary (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading history steps 0-0, summary (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 0.76234\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 0.84468\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.35561\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mbaseline_passive_eval_100\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/6csvpoob\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_164416-6csvpoob/logs\u001b[0m\n",
            "\n",
            "--- Horizon: 500 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  2713668\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 305.23it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 3.54 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.34 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.49 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.29 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.34 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.74 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:01<00:00,  1.49s/it]\n",
            "100% 1/1 [00:35<00:00, 35.29s/it]\n",
            "=========================================\n",
            "Base position error mean       = 2.378470\n",
            "Base position error std        = 2.112418\n",
            "Joint position error mean      = 1.203295 rad (68.943745 deg)\n",
            "Joint position Error per dof   = tensor([1.203295], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m setting up run dd8ybpyj (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m setting up run dd8ybpyj (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m setting up run dd8ybpyj (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m setting up run dd8ybpyj (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_164510-dd8ybpyj\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbaseline_passive_eval_500\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/dd8ybpyj\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-summary.json 219B/219B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-summary.json 219B/219B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-summary.json 219B/219B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-summary.json 219B/219B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-summary.json 219B/219B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 2.37847\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 2.11242\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 1.2033\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mbaseline_passive_eval_500\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/dd8ybpyj\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_164510-dd8ybpyj/logs\u001b[0m\n",
            "\n",
            "--- Horizon: 1000 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  2713668\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 316.33it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 3.56 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.45 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.32 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.33 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.35 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.78 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:03<00:00,  3.90s/it]\n",
            "100% 1/1 [01:09<00:00, 69.54s/it]\n",
            "=========================================\n",
            "Base position error mean       = 2.941214\n",
            "Base position error std        = 2.258574\n",
            "Joint position error mean      = 1.352953 rad (77.518508 deg)\n",
            "Joint position Error per dof   = tensor([1.352953], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m setting up run wjvbdhub (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m setting up run wjvbdhub (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m setting up run wjvbdhub (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_164640-wjvbdhub\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbaseline_passive_eval_1000\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/wjvbdhub\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-summary.json 220B/220B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-summary.json 220B/220B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-summary.json 220B/220B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-summary.json 220B/220B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-summary.json 220B/220B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 2.94121\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 2.25857\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 1.35295\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mbaseline_passive_eval_1000\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/wjvbdhub\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_164640-wjvbdhub/logs\u001b[0m\n",
            "\n",
            "==================== Evaluating Mamba_6 Model ====================\n",
            "\n",
            "--- Horizon: 100 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  1523460\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 317.31it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 3.51 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.32 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.44 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.43 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.33 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.36 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.75 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:00<00:00,  2.66it/s]\n",
            "100% 1/1 [00:25<00:00, 25.39s/it]\n",
            "=========================================\n",
            "Base position error mean       = 0.117429\n",
            "Base position error std        = 0.154029\n",
            "Joint position error mean      = 0.095823 rad (5.490233 deg)\n",
            "Joint position Error per dof   = tensor([0.095823], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m setting up run 56n54nez (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m setting up run 56n54nez (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m setting up run 56n54nez (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_164723-56n54nez\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba_6_passive_eval_100\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/56n54nez\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m updating run metadata (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m updating run metadata (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m updating run metadata (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m updating run metadata (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading summary (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m updating run metadata (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading summary (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m updating run metadata (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading summary (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m updating run metadata (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading summary (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading summary (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-summary.json 224B/224B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-summary.json 224B/224B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-summary.json 224B/224B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-summary.json 224B/224B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-summary.json 224B/224B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 0.11743\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 0.15403\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.09582\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mmamba_6_passive_eval_100\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/56n54nez\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_164723-56n54nez/logs\u001b[0m\n",
            "\n",
            "--- Horizon: 500 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  1523460\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:07<00:00, 271.73it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 4.71 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.53 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.65 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.72 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.44 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.47 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.97 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:01<00:00,  1.70s/it]\n",
            "100% 1/1 [02:11<00:00, 131.88s/it]\n",
            "=========================================\n",
            "Base position error mean       = 1.283956\n",
            "Base position error std        = 1.516289\n",
            "Joint position error mean      = 0.567745 rad (32.529394 deg)\n",
            "Joint position Error per dof   = tensor([0.567745], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m setting up run obt1ov2a (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m setting up run obt1ov2a (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m setting up run obt1ov2a (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_164954-obt1ov2a\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba_6_passive_eval_500\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/obt1ov2a\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m updating run metadata (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m updating run metadata (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m updating run metadata (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m updating run metadata (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m updating run metadata (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m updating run metadata (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m updating run metadata (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-summary.json 218B/218B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-summary.json 218B/218B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-summary.json 218B/218B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-summary.json 218B/218B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-summary.json 218B/218B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading history steps 0-0, summary (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 1.28396\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 1.51629\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.56775\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mmamba_6_passive_eval_500\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/obt1ov2a\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_164954-obt1ov2a/logs\u001b[0m\n",
            "\n",
            "--- Horizon: 1000 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  1523460\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 320.98it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 3.54 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.33 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.47 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.37 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.36 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.35 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.77 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:02<00:00,  2.76s/it]\n",
            "100% 1/1 [04:24<00:00, 264.64s/it]\n",
            "=========================================\n",
            "Base position error mean       = 2.053185\n",
            "Base position error std        = 1.924505\n",
            "Joint position error mean      = 0.867847 rad (49.723955 deg)\n",
            "Joint position Error per dof   = tensor([0.867847], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m setting up run 0jk5jrhv (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m setting up run 0jk5jrhv (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m setting up run 0jk5jrhv (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_165438-0jk5jrhv\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba_6_passive_eval_1000\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/0jk5jrhv\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-summary.json 220B/220B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-summary.json 220B/220B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-summary.json 220B/220B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-summary.json 220B/220B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-summary.json 220B/220B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading history steps 0-0, summary (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 2.05318\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 1.92451\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.86785\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mmamba_6_passive_eval_1000\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/0jk5jrhv\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_165438-0jk5jrhv/logs\u001b[0m\n",
            "\n",
            "==================== Evaluating Mamba_3 Model ====================\n",
            "\n",
            "--- Horizon: 100 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  768900\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:07<00:00, 266.20it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 3.55 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.33 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.48 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.64 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.46 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.46 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.81 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:00<00:00,  2.50it/s]\n",
            "100% 1/1 [00:12<00:00, 12.97s/it]\n",
            "=========================================\n",
            "Base position error mean       = 0.196793\n",
            "Base position error std        = 0.227407\n",
            "Joint position error mean      = 0.162073 rad (9.286087 deg)\n",
            "Joint position Error per dof   = tensor([0.162073], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m setting up run 2wyac1iy (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m setting up run 2wyac1iy (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m setting up run 2wyac1iy (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m setting up run 2wyac1iy (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_165509-2wyac1iy\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba_3_passive_eval_100\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/2wyac1iy\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-summary.json 222B/222B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-summary.json 222B/222B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-summary.json 222B/222B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-summary.json 222B/222B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-summary.json 222B/222B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 0.19679\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 0.22741\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.16207\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mmamba_3_passive_eval_100\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/2wyac1iy\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_165509-2wyac1iy/logs\u001b[0m\n",
            "\n",
            "--- Horizon: 500 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  768900\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 311.74it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 3.56 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.33 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.47 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.32 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.33 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.38 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.74 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:01<00:00,  1.81s/it]\n",
            "100% 1/1 [01:07<00:00, 67.45s/it]\n",
            "=========================================\n",
            "Base position error mean       = 1.919383\n",
            "Base position error std        = 1.930494\n",
            "Joint position error mean      = 0.653860 rad (37.463400 deg)\n",
            "Joint position Error per dof   = tensor([0.653860], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m setting up run 7bekflw1 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m setting up run 7bekflw1 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m setting up run 7bekflw1 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_165635-7bekflw1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba_3_passive_eval_500\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/7bekflw1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-summary.json 219B/219B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-summary.json 219B/219B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-summary.json 219B/219B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-summary.json 219B/219B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-summary.json 219B/219B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 1.91938\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 1.93049\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.65386\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mmamba_3_passive_eval_500\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/7bekflw1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_165635-7bekflw1/logs\u001b[0m\n",
            "\n",
            "--- Horizon: 1000 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  768900\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:07<00:00, 257.48it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 3.59 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.33 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.44 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.39 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.33 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.34 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.77 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:02<00:00,  2.76s/it]\n",
            "100% 1/1 [02:15<00:00, 135.10s/it]\n",
            "=========================================\n",
            "Base position error mean       = 2.393147\n",
            "Base position error std        = 2.026525\n",
            "Joint position error mean      = 0.946981 rad (54.258029 deg)\n",
            "Joint position Error per dof   = tensor([0.946981], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m setting up run 6t19sofg (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m setting up run 6t19sofg (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m setting up run 6t19sofg (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_165910-6t19sofg\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba_3_passive_eval_1000\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/6t19sofg\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-summary.json 220B/220B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-summary.json 220B/220B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-summary.json 220B/220B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-summary.json 220B/220B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-summary.json 220B/220B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading history steps 0-0, summary (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading history steps 0-0, summary (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading history steps 0-0, summary (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 2.39315\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 2.02652\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.94698\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mmamba_3_passive_eval_1000\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/6t19sofg\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_165910-6t19sofg/logs\u001b[0m\n",
            "Skipping unroll (model not found)\n",
            "\n",
            "==================== Evaluating Jamba Model ====================\n",
            "\n",
            "--- Horizon: 100 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  1905732\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:07<00:00, 258.41it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 3.62 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.32 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.47 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.37 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.34 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.36 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.83 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:00<00:00,  2.58it/s]\n",
            "100% 1/1 [00:19<00:00, 19.22s/it]\n",
            "=========================================\n",
            "Base position error mean       = 0.148068\n",
            "Base position error std        = 0.171379\n",
            "Joint position error mean      = 0.106143 rad (6.081538 deg)\n",
            "Joint position Error per dof   = tensor([0.106143], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m setting up run wf2mnzor (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m setting up run wf2mnzor (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m setting up run wf2mnzor (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_165948-wf2mnzor\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mjamba_passive_eval_100\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/wf2mnzor\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m updating run metadata (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m updating run metadata (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m updating run metadata (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m updating run metadata (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m updating run metadata (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m updating run metadata (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m updating run metadata (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-summary.json 222B/222B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-summary.json 222B/222B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-summary.json 222B/222B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-summary.json 222B/222B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-summary.json 222B/222B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading history steps 0-0, summary (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 0.14807\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 0.17138\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.10614\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mjamba_passive_eval_100\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/wf2mnzor\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_165948-wf2mnzor/logs\u001b[0m\n",
            "\n",
            "--- Horizon: 500 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  1905732\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:08<00:00, 251.84it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 4.31 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.34 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.50 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.40 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.34 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.74 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:01<00:00,  1.45s/it]\n",
            "100% 1/1 [01:39<00:00, 99.90s/it]\n",
            "=========================================\n",
            "Base position error mean       = 1.956888\n",
            "Base position error std        = 1.970388\n",
            "Joint position error mean      = 0.541555 rad (31.028839 deg)\n",
            "Joint position Error per dof   = tensor([0.541555], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m setting up run lip7wxjg (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m setting up run lip7wxjg (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_170148-lip7wxjg\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mjamba_passive_eval_500\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/lip7wxjg\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-summary.json 219B/219B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-summary.json 219B/219B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-summary.json 219B/219B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-summary.json 219B/219B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-summary.json 219B/219B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 1.95689\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 1.97039\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.54156\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mjamba_passive_eval_500\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/lip7wxjg\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_170148-lip7wxjg/logs\u001b[0m\n",
            "\n",
            "--- Horizon: 1000 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  1905732\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:08<00:00, 252.43it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 4.42 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.31 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.45 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.35 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.34 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.34 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.79 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:02<00:00,  2.67s/it]\n",
            "100% 1/1 [03:19<00:00, 199.84s/it]\n",
            "=========================================\n",
            "Base position error mean       = 2.515661\n",
            "Base position error std        = 2.122565\n",
            "Joint position error mean      = 0.855729 rad (49.029676 deg)\n",
            "Joint position Error per dof   = tensor([0.855729], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m setting up run xgwew2hu (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m setting up run xgwew2hu (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m setting up run xgwew2hu (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m setting up run xgwew2hu (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_170528-xgwew2hu\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mjamba_passive_eval_1000\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/xgwew2hu\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading wandb-summary.json 221B/221B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading wandb-summary.json 221B/221B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading wandb-summary.json 221B/221B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading wandb-summary.json 221B/221B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading wandb-summary.json 221B/221B (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¯\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£Ÿ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¡¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 2.51566\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 2.12257\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.85573\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mjamba_passive_eval_1000\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/xgwew2hu\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_170528-xgwew2hu/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 7.1 Long-Horizon Passive Motion Evaluation\n",
        "# We evaluate the Baseline, Mamba, and Unroll models on Cartpole for 100, 500, and 1000 steps.\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def find_latest_model(model_type):\n",
        "    base_log_dir = f'../data/logs/{model_type}'\n",
        "    if not os.path.exists(base_log_dir):\n",
        "        return None\n",
        "    dirs = [d for d in glob.glob(os.path.join(base_log_dir, '*')) if os.path.isdir(d)]\n",
        "    if not dirs:\n",
        "        return None\n",
        "    latest_dir = sorted(dirs)[-1]\n",
        "    model_path = os.path.join(latest_dir, 'nn', 'best_eval_model.pt')\n",
        "    if not os.path.exists(model_path):\n",
        "        return None\n",
        "    return model_path\n",
        "\n",
        "models = ['baseline', 'mamba_6', 'mamba_3', 'unroll', 'jamba']\n",
        "horizons = [100, 500, 1000]\n",
        "\n",
        "for model_name in models:\n",
        "    model_path = find_latest_model(model_name)\n",
        "    if not model_path:\n",
        "        print(f\"Skipping {model_name} (model not found)\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n{'='*20} Evaluating {model_name.capitalize()} Model {'='*20}\")\n",
        "    for horizon in horizons:\n",
        "        print(f\"\\n--- Horizon: {horizon} ---\")\n",
        "        # We use !python to ensure output is printed to the cell\n",
        "        !python ../eval/eval_passive/eval_passive_motion.py \\\n",
        "            --env-name Cartpole \\\n",
        "            --model-path {model_path} \\\n",
        "            --env-mode neural \\\n",
        "            --num-envs 2048 \\\n",
        "            --num-rollouts 2048 \\\n",
        "            --rollout-horizon {horizon} \\\n",
        "            --seed 500 \\\n",
        "            --wandb-project {wandb_project} \\\n",
        "            --wandb-name {model_name}_passive_eval_{horizon}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "rl-policy-eval-quant",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rl-policy-eval-quant",
        "outputId": "3e9adf0c-1f47-4fba-9337-f7d23b90f8fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== RL Evaluation: Ground Truth ====================\n",
            "teps: 56.0\n",
            "reward: 98.16730499267578 steps: 61.0\n",
            "reward: 57.46388244628906 steps: 62.0\n",
            "reward: -94.28440856933594 steps: 94.0\n",
            "reward: -85.1441421508789 steps: 100.0\n",
            "reward: 1225.2821979114867 steps: 300.0\n",
            "2461286.3829221725\n",
            "av reward: 1201.799991661217 av steps: 295.4072265625\n",
            "visited states range:\n",
            "State 0: [-4.084733486175537, 4.017707347869873]\n",
            "State 1: [-3.1415224075317383, 3.1415481567382812]\n",
            "State 2: [-10.378302574157715, 8.506925582885742]\n",
            "State 3: [-10.652484893798828, 9.791386604309082]\n",
            "\n",
            "\n",
            "==================== RL Evaluation: Baseline ====================\n",
            "steps: 53.0\n",
            "reward: -75.79667663574219 steps: 54.0\n",
            "reward: 33.006324768066406 steps: 56.0\n",
            "reward: 38.0755500793457 steps: 58.0\n",
            "reward: 25.99689483642578 steps: 62.0\n",
            "reward: 1184.9815136476427 steps: 300.0\n",
            "2387004.834780693\n",
            "av reward: 1165.5297044827603 av steps: 295.96240234375\n",
            "visited states range:\n",
            "State 0: [-4.060269832611084, 4.058303356170654]\n",
            "State 1: [-3.141566514968872, 3.1414971351623535]\n",
            "State 2: [-9.040142059326172, 9.202550888061523]\n",
            "State 3: [-10.964652061462402, 10.010231971740723]\n",
            "\n",
            "\n",
            "==================== RL Evaluation: Mamba_6 ====================\n",
            "s: 68.0\n",
            "reward: 10.448670387268066 steps: 70.0\n",
            "reward: 74.48284403483073 steps: 71.0\n",
            "reward: -166.72515869140625 steps: 75.0\n",
            "reward: -26.84813690185547 steps: 95.0\n",
            "reward: 1204.126610505451 steps: 300.0\n",
            "2427568.8943252563\n",
            "av reward: 1185.336374182254 av steps: 296.31591796875\n",
            "visited states range:\n",
            "State 0: [-4.087972164154053, 4.0153937339782715]\n",
            "State 1: [-3.1414973735809326, 3.141467571258545]\n",
            "State 2: [-10.345799446105957, 8.560831069946289]\n",
            "State 3: [-10.640399932861328, 10.220194816589355]\n",
            "\n",
            "\n",
            "==================== RL Evaluation: Mamba_3 ====================\n",
            "ard: 1222.245361328125 steps: 296.0\n",
            "reward: 1063.44091796875 steps: 257.2\n",
            "reward: 747.1614990234375 steps: 187.0\n",
            "reward: 1238.276123046875 steps: 299.0\n",
            "reward: 1044.1592019543973 steps: 299.6978827361564\n",
            "1744732.41162014\n",
            "av reward: 799.6023884601925 av steps: 235.84463794683776\n",
            "visited states range:\n",
            "State 0: [-4.0876078605651855, 4.044830322265625]\n",
            "State 1: [-3.141587972640991, 3.141528367996216]\n",
            "State 2: [-10.358580589294434, 8.569950103759766]\n",
            "State 3: [-10.875702857971191, 9.138437271118164]\n",
            "\n",
            "\n",
            "==================== RL Evaluation: Jamba ====================\n",
            "s: 61.0\n",
            "reward: 92.37872314453125 steps: 64.0\n",
            "reward: 24.388330459594727 steps: 71.0\n",
            "reward: -124.47351837158203 steps: 91.0\n",
            "reward: -68.35792541503906 steps: 93.0\n",
            "reward: 1196.699203187251 steps: 300.0\n",
            "2401140.4646320343\n",
            "av reward: 1172.4318674961105 av steps: 295.07568359375\n",
            "visited states range:\n",
            "State 0: [-4.076175212860107, 4.0189104080200195]\n",
            "State 1: [-3.1414735317230225, 3.1415600776672363]\n",
            "State 2: [-10.31357479095459, 8.380670547485352]\n",
            "State 3: [-10.697846412658691, 9.356134414672852]\n",
            "\n",
            "\n",
            "Final Evaluation Comparison:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          Model       Reward  Error (%)\n",
              "0  Ground Truth  1201.799992   0.000000\n",
              "1      Baseline  1165.529704  -3.017997\n",
              "2       Mamba_6  1185.336374  -1.369913\n",
              "3       Mamba_3   799.602388 -33.466268\n",
              "4         Jamba  1172.431867  -2.443678"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9dcdcf71-4a01-4646-b7bd-12030df2d893\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Reward</th>\n",
              "      <th>Error (%)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ground Truth</td>\n",
              "      <td>1201.799992</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Baseline</td>\n",
              "      <td>1165.529704</td>\n",
              "      <td>-3.017997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mamba_6</td>\n",
              "      <td>1185.336374</td>\n",
              "      <td>-1.369913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mamba_3</td>\n",
              "      <td>799.602388</td>\n",
              "      <td>-33.466268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jamba</td>\n",
              "      <td>1172.431867</td>\n",
              "      <td>-2.443678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9dcdcf71-4a01-4646-b7bd-12030df2d893')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9dcdcf71-4a01-4646-b7bd-12030df2d893 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9dcdcf71-4a01-4646-b7bd-12030df2d893');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-91cc9bc1-1c2e-48c1-a31e-6249511ab782\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-91cc9bc1-1c2e-48c1-a31e-6249511ab782')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-91cc9bc1-1c2e-48c1-a31e-6249511ab782 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_9d780088-ff7a-43b6-be6f-66071c8eb579\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9d780088-ff7a-43b6-be6f-66071c8eb579 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Baseline\",\n          \"Jamba\",\n          \"Mamba_6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Reward\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 171.24744994780062,\n        \"min\": 799.6023884601925,\n        \"max\": 1201.799991661217,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1165.5297044827603,\n          1172.4318674961105,\n          1185.336374182254\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Error (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.249247057415078,\n        \"min\": -33.46626776432884,\n        \"max\": 0.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -3.017996957074472,\n          -2.4436781801364273,\n          -1.3699132628721153\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 7.2 RL Policy Evaluation (Quantitative)\n",
        "# We evaluate the policy using the trained NeRD models and compare with Ground Truth.\n",
        "# We run for more games (2048) to get a statistically significant result as in the paper.\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "def run_eval(model_path=None, env_mode='neural', label='Model'):\n",
        "    print(f\"\\n{'='*20} RL Evaluation: {label} {'='*20}\")\n",
        "\n",
        "    # Use absolute paths\n",
        "    abs_playback_path = os.path.abspath('../pretrained_models/RL_policies/Cartpole/0/nn/CartpolePPO.pth')\n",
        "    abs_rl_cfg_path = os.path.abspath('../eval/eval_rl/cfg/Cartpole/cartpole.yaml')\n",
        "\n",
        "    cmd = [\n",
        "        'python', 'run_rl.py',\n",
        "        '--rl-cfg', abs_rl_cfg_path,\n",
        "        '--playback', abs_playback_path,\n",
        "        '--num-envs', '2048',\n",
        "        '--num-games', '2048',\n",
        "        '--env-mode', env_mode,\n",
        "        '--wandb-project', wandb_project,\n",
        "        '--wandb-name', f'{model_name}_rl_eval'\n",
        "    ]\n",
        "\n",
        "    if model_path:\n",
        "        abs_model_path = os.path.abspath(model_path)\n",
        "        cmd.extend([\n",
        "            '--nerd-model-path', abs_model_path\n",
        "        ])\n",
        "\n",
        "    try:\n",
        "        result = subprocess.run(cmd, cwd='../eval/eval_rl', check=True, capture_output=True, text=True)\n",
        "        output = result.stdout\n",
        "        print(output[-500:]) # Print last 500 chars to see result\n",
        "\n",
        "        # Parse reward\n",
        "        # Look for 'av reward: <value> av steps: <value>'\n",
        "        match = re.search(r'av reward:\\s*([-\\d\\.]+)', output)\n",
        "        if match:\n",
        "            reward = float(match.group(1))\n",
        "            return reward\n",
        "        else:\n",
        "            print(\"Could not parse reward from output.\")\n",
        "            return None\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f'Error running RL evaluation for {label}:')\n",
        "        print('STDOUT:', e.stdout)\n",
        "        print('STDERR:', e.stderr)\n",
        "        return None\n",
        "\n",
        "results = []\n",
        "\n",
        "# 1. Evaluate Ground Truth\n",
        "gt_reward = run_eval(env_mode='ground-truth', label='Ground Truth')\n",
        "if gt_reward is not None:\n",
        "    results.append({'Model': 'Ground Truth', 'Reward': gt_reward, 'Error (%)': 0.0})\n",
        "\n",
        "# 2. Evaluate NeRD Models\n",
        "for model_name in models:\n",
        "    model_path = find_latest_model(model_name)\n",
        "    if not model_path:\n",
        "        continue\n",
        "\n",
        "    reward = run_eval(model_path=model_path, env_mode='neural', label=model_name.capitalize())\n",
        "\n",
        "    if reward is not None and gt_reward is not None:\n",
        "        error = (reward - gt_reward) / gt_reward * 100\n",
        "        results.append({'Model': model_name.capitalize(), 'Reward': reward, 'Error (%)': error})\n",
        "    elif reward is not None:\n",
        "        results.append({'Model': model_name.capitalize(), 'Reward': reward, 'Error (%)': float('nan')})\n",
        "\n",
        "# 3. Create Table\n",
        "df = pd.DataFrame(results)\n",
        "print(\"\\nFinal Evaluation Comparison:\")\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fps-eval-header",
      "metadata": {
        "id": "fps-eval-header"
      },
      "source": [
        "# 7.3 Inference Throughput (FPS) Evaluation\n",
        "\n",
        "We measure the inference throughput (FPS) of the different models. This metric measures the raw speed of the simulation, expressed in Frames Per Second (FPS).\n",
        "We measure the wall-clock time required to roll out a large batch of parallel environments (2048 robots) for a fixed number of steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "fps-eval-code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fps-eval-code",
        "outputId": "4276f365-7fdb-4af2-e5c3-43c425c424e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== FPS Evaluation: Analytical (Warp) ====================\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 4.80 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.55 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.68 ms  (cached)\n",
            "\u001b[91m [NeuralEnvironment] Created a DUMMY Neural Integrator. \u001b[0m\n",
            "Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.71 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.48 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.48 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 1.01 ms  (cached)\n",
            "time(collision_detection): 0.000 sec, time(dynamics): 0.173 sec\n",
            "FPS: 806172.247379451\n",
            "\n",
            "\n",
            "==================== FPS Evaluation: Baseline ====================\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 5.33 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.48 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.62 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.67 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.44 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 1.01 ms  (cached)\n",
            "time(collision_detection): 0.000 sec, time(dynamics): 6.763 sec\n",
            "FPS: 29821.089086269665\n",
            "\n",
            "\n",
            "==================== FPS Evaluation: Mamba_6 ====================\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 4.29 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.44 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.48 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.33 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.36 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.79 ms  (cached)\n",
            "time(collision_detection): 0.000 sec, time(dynamics): 25.459 sec\n",
            "FPS: 8008.946249417342\n",
            "\n",
            "\n",
            "==================== FPS Evaluation: Mamba_3 ====================\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 3.59 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.36 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.46 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.28 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.33 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.34 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.79 ms  (cached)\n",
            "time(collision_detection): 0.000 sec, time(dynamics): 12.771 sec\n",
            "FPS: 15909.713691316718\n",
            "\n",
            "\n",
            "==================== FPS Evaluation: Jamba ====================\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 4.75 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.50 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.64 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.76 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.50 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.45 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 1.04 ms  (cached)\n",
            "time(collision_detection): 0.001 sec, time(dynamics): 19.708 sec\n",
            "FPS: 10329.628894974665\n",
            "\n",
            "\n",
            "Inference Throughput Comparison:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "               Model            FPS\n",
              "0  Analytical (Warp)  806172.247379\n",
              "1           Baseline   29821.089086\n",
              "2            Mamba_6    8008.946249\n",
              "3            Mamba_3   15909.713691\n",
              "4              Jamba   10329.628895"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea59216f-6a5a-42f2-bc66-0340bf7173d3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>FPS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Analytical (Warp)</td>\n",
              "      <td>806172.247379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Baseline</td>\n",
              "      <td>29821.089086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mamba_6</td>\n",
              "      <td>8008.946249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mamba_3</td>\n",
              "      <td>15909.713691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jamba</td>\n",
              "      <td>10329.628895</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea59216f-6a5a-42f2-bc66-0340bf7173d3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ea59216f-6a5a-42f2-bc66-0340bf7173d3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ea59216f-6a5a-42f2-bc66-0340bf7173d3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b5fb2521-4928-4ae4-ad13-a8a21aa27376\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b5fb2521-4928-4ae4-ad13-a8a21aa27376')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b5fb2521-4928-4ae4-ad13-a8a21aa27376 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_1d28d8ea-0276-46db-80e6-b86f7b916ce1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_fps')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1d28d8ea-0276-46db-80e6-b86f7b916ce1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_fps');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_fps",
              "summary": "{\n  \"name\": \"df_fps\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Baseline\",\n          \"Jamba\",\n          \"Mamba_6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FPS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 353469.5375702639,\n        \"min\": 8008.946249417342,\n        \"max\": 806172.247379451,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          29821.089086269665,\n          10329.628894974665,\n          8008.946249417342\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "def run_fps_eval(model_path=None, env_mode='neural', label='Model'):\n",
        "    print(f\"\\n{'='*20} FPS Evaluation: {label} {'='*20}\")\n",
        "\n",
        "    cmd = [\n",
        "        'python', 'eval_fps.py',\n",
        "        '--env-name', 'Cartpole',\n",
        "        '--num-envs', '2048',\n",
        "        '--rollout-horizon', '100',\n",
        "        '--env-mode', env_mode\n",
        "    ]\n",
        "\n",
        "    if model_path:\n",
        "        abs_model_path = os.path.abspath(model_path)\n",
        "        cmd.extend(['--model-path', abs_model_path])\n",
        "\n",
        "    try:\n",
        "        result = subprocess.run(cmd, cwd='../eval/eval_fps', check=True, capture_output=True, text=True)\n",
        "        output = result.stdout\n",
        "        print(output)\n",
        "\n",
        "        # Parse FPS\n",
        "        match = re.search(r'FPS:\\s*([-\\d\\.]+)', output)\n",
        "        if match:\n",
        "            fps = float(match.group(1))\n",
        "            return fps\n",
        "        else:\n",
        "            print(\"Could not parse FPS from output.\")\n",
        "            return None\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f'Error running FPS evaluation for {label}:')\n",
        "        print('STDOUT:', e.stdout)\n",
        "        print('STDERR:', e.stderr)\n",
        "        return None\n",
        "\n",
        "fps_results = []\n",
        "\n",
        "# 1. Evaluate Ground Truth (Analytical Simulator)\n",
        "gt_fps = run_fps_eval(env_mode='ground-truth', label='Analytical (Warp)')\n",
        "if gt_fps is not None:\n",
        "    fps_results.append({'Model': 'Analytical (Warp)', 'FPS': gt_fps})\n",
        "\n",
        "# 2. Evaluate NeRD Models\n",
        "for model_name in models:\n",
        "    model_path = find_latest_model(model_name)\n",
        "    if not model_path:\n",
        "        continue\n",
        "\n",
        "    fps = run_fps_eval(model_path=model_path, env_mode='neural', label=model_name.capitalize())\n",
        "\n",
        "    if fps is not None:\n",
        "        fps_results.append({'Model': model_name.capitalize(), 'FPS': fps})\n",
        "\n",
        "# 3. Create Table\n",
        "df_fps = pd.DataFrame(fps_results)\n",
        "print(\"\\nInference Throughput Comparison:\")\n",
        "display(df_fps)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}