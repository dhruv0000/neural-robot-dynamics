{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1KmdUuRpv7uY",
        "outputId": "0a9e5741-5503-4d95-f721-9117caa16eed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'neural-robot-dynamics'...\n",
            "remote: Enumerating objects: 608, done.\u001b[K\n",
            "remote: Counting objects: 100% (174/174), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 608 (delta 91), reused 118 (delta 59), pack-reused 434 (from 1)\u001b[K\n",
            "Receiving objects: 100% (608/608), 21.43 MiB | 16.64 MiB/s, done.\n",
            "Resolving deltas: 100% (178/178), done.\n",
            "Filtering content: 100% (11/11), 202.03 MiB | 51.73 MiB/s, done.\n",
            "/content/neural-robot-dynamics\n",
            "Branch 'exp1' set up to track remote branch 'exp1' from 'origin'.\n",
            "Switched to a new branch 'exp1'\n",
            "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (4.67.1)\n",
            "Collecting pyglet==2.1.6 (from -r requirements.txt (line 2))\n",
            "  Downloading pyglet-2.1.6-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting ipdb (from -r requirements.txt (line 3))\n",
            "  Downloading ipdb-0.13.13-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting h5py==3.11.0 (from -r requirements.txt (line 4))\n",
            "  Downloading h5py-3.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting pyyaml==6.0.2 (from -r requirements.txt (line 5))\n",
            "  Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting tensorboard==2.14.0 (from -r requirements.txt (line 6))\n",
            "  Downloading tensorboard-2.14.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting matplotlib==3.7.5 (from -r requirements.txt (line 7))\n",
            "  Downloading matplotlib-3.7.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (4.12.0.88)\n",
            "Collecting pycollada==0.9.2 (from -r requirements.txt (line 9))\n",
            "  Downloading pycollada-0.9.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 1.11.0, 1.14.0rc1\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 1.10.0 Requires-Python <3.12,>=3.8; 1.10.0rc1 Requires-Python <3.12,>=3.8; 1.10.0rc2 Requires-Python <3.12,>=3.8; 1.10.1 Requires-Python <3.12,>=3.8; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 1.7.2 Requires-Python >=3.7,<3.11; 1.7.3 Requires-Python >=3.7,<3.11; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11; 1.9.0 Requires-Python >=3.8,<3.12; 1.9.0rc1 Requires-Python >=3.8,<3.12; 1.9.0rc2 Requires-Python >=3.8,<3.12; 1.9.0rc3 Requires-Python >=3.8,<3.12; 1.9.1 Requires-Python >=3.8,<3.12\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement scipy==1.10.1 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0, 1.0.1, 1.1.0, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0, 1.4.1, 1.5.0, 1.5.1, 1.5.2, 1.5.3, 1.5.4, 1.6.0, 1.6.1, 1.9.2, 1.9.3, 1.11.0rc1, 1.11.0rc2, 1.11.1, 1.11.2, 1.11.3, 1.11.4, 1.12.0rc1, 1.12.0rc2, 1.12.0, 1.13.0rc1, 1.13.0, 1.13.1, 1.14.0rc2, 1.14.0, 1.14.1, 1.15.0rc1, 1.15.0rc2, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.16.0rc1, 1.16.0rc2, 1.16.0, 1.16.1, 1.16.2, 1.16.3)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for scipy==1.10.1\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting warp-lang==1.8.0\n",
            "  Downloading warp_lang-1.8.0-py3-none-manylinux_2_28_x86_64.whl.metadata (32 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from warp-lang==1.8.0) (2.0.2)\n",
            "Downloading warp_lang-1.8.0-py3-none-manylinux_2_28_x86_64.whl (129.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: warp-lang\n",
            "Successfully installed warp-lang-1.8.0\n",
            "Collecting rl_games\n",
            "  Downloading rl-games-1.6.1.tar.gz (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML<7.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from rl_games) (6.0.3)\n",
            "Collecting gym<0.24.0,>=0.23.0 (from gym[classic-control]<0.24.0,>=0.23.0->rl_games)\n",
            "  Downloading gym-0.23.1.tar.gz (626 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.2/626.2 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opencv-python<5.0.0,>=4.5.5 in /usr/local/lib/python3.12/dist-packages (from rl_games) (4.12.0.88)\n",
            "Requirement already satisfied: psutil<6.0.0,>=5.9.0 in /usr/local/lib/python3.12/dist-packages (from rl_games) (5.9.5)\n",
            "Collecting setproctitle<2.0.0,>=1.2.2 (from rl_games)\n",
            "  Downloading setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: tensorboard<3.0.0,>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from rl_games) (2.19.0)\n",
            "Collecting tensorboardX<3.0,>=2.5 (from rl_games)\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting wandb<0.13.0,>=0.12.11 (from rl_games)\n",
            "  Downloading wandb-0.12.21-py2.py3-none-any.whl.metadata (7.2 kB)\n",
            "INFO: pip is looking at multiple versions of rl-games to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting rl_games\n",
            "  Downloading rl-games-1.6.0.tar.gz (14.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading rl_games-1.5.2-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.12/dist-packages (from rl_games) (0.25.2)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from rl_games) (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from rl_games) (2.0.2)\n",
            "Collecting ray>=1.1.0 (from rl_games)\n",
            "  Downloading ray-2.52.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gym>=0.17.2->rl_games) (3.1.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from gym>=0.17.2->rl_games) (0.1.0)\n",
            "Collecting click!=8.3.*,>=7.0 (from ray>=1.1.0->rl_games)\n",
            "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (3.20.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (4.25.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (25.0)\n",
            "Requirement already satisfied: protobuf>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (5.29.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (2.32.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3.0.0,>=2.8.0->rl_games) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3.0.0,>=2.8.0->rl_games) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3.0.0,>=2.8.0->rl_games) (3.10)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3.0.0,>=2.8.0->rl_games) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3.0.0,>=2.8.0->rl_games) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3.0.0,>=2.8.0->rl_games) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3.0.0,>=2.8.0->rl_games) (3.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7.0->rl_games) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard<3.0.0,>=2.8.0->rl_games) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=1.1.0->rl_games) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=1.1.0->rl_games) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=1.1.0->rl_games) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=1.1.0->rl_games) (0.29.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->ray>=1.1.0->rl_games) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->ray>=1.1.0->rl_games) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->ray>=1.1.0->rl_games) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->ray>=1.1.0->rl_games) (2025.11.12)\n",
            "Downloading rl_games-1.5.2-py3-none-any.whl (15.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.52.1-cp312-cp312-manylinux2014_x86_64.whl (72.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.3/72.3 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (32 kB)\n",
            "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX, setproctitle, click, ray, rl_games\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.1\n",
            "    Uninstalling click-8.3.1:\n",
            "      Successfully uninstalled click-8.3.1\n",
            "Successfully installed click-8.2.1 ray-2.52.1 rl_games-1.5.2 setproctitle-1.3.7 tensorboardX-2.6.4\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.23.0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.12.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.46.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# 1. Clean up any old runs to avoid conflicts\n",
        "if os.path.exists(\"neural-robot-dynamics\"):\n",
        "    shutil.rmtree(\"neural-robot-dynamics\")\n",
        "\n",
        "# 2. Clone YOUR specific repository\n",
        "!git clone https://github.com/bhargavee13678/neural-robot-dynamics.git\n",
        "\n",
        "%cd neural-robot-dynamics\n",
        "\n",
        "# 3. Switch to your experiment branch\n",
        "!git checkout exp1\n",
        "\n",
        "# 4. Install Dependencies\n",
        "!pip install -r requirements.txt\n",
        "!pip install warp-lang==1.8.0\n",
        "!pip install rl_games\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Completing the changes in jamba"
      ],
      "metadata": {
        "id": "XonbyJX7wC9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 1. FIX MODELS/JAMBA.PY (Adds evaluate, init_rnn, and dimension fixes)\n",
        "# ---------------------------------------------------------\n",
        "jamba_content = r'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_head, max_len=2048):\n",
        "        super().__init__()\n",
        "        self.c_attn = nn.Linear(d_model, 3 * d_model)\n",
        "        self.c_proj = nn.Linear(d_model, d_model)\n",
        "        self.n_head = n_head\n",
        "        self.d_model = d_model\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(max_len, max_len)).view(1, 1, max_len, max_len))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size()\n",
        "        q, k, v = self.c_attn(x).split(self.d_model, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        y = att @ v\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        return self.c_proj(y)\n",
        "\n",
        "class MambaLayer(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.in_proj = nn.Linear(d_model, d_model * 2)\n",
        "        self.conv1d = nn.Conv1d(in_channels=d_model * 2, out_channels=d_model * 2, kernel_size=4, groups=d_model * 2, padding=3)\n",
        "        self.out_proj = nn.Linear(d_model * 2, d_model)\n",
        "        self.act = nn.SiLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, L, D = x.shape\n",
        "        x_proj = self.in_proj(x)\n",
        "        x_conv = x_proj.transpose(1, 2)\n",
        "        x_conv = self.conv1d(x_conv)[:, :, :L]\n",
        "        x_conv = x_conv.transpose(1, 2)\n",
        "        return self.out_proj(self.act(x_conv))\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(nn.Linear(d_model, 4 * d_model), nn.GELU(), nn.Linear(4 * d_model, d_model))\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class JambaBlock(nn.Module):\n",
        "    def __init__(self, d_model, layer_idx, use_attention=False):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.mixer = CausalSelfAttention(d_model, n_head=4) if use_attention else MambaLayer(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.mlp = MLP(d_model)\n",
        "    def forward(self, x):\n",
        "        x = x + self.mixer(self.norm1(x))\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "        return x\n",
        "\n",
        "class JambaModel(nn.Module):\n",
        "    def __init__(self, input_dim, d_model, n_layers, vocab_size=None):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Linear(input_dim, d_model)\n",
        "        self.layers = nn.ModuleList([])\n",
        "        self.normalize_output = False\n",
        "        self.input_rms = None\n",
        "        self.output_rms = None\n",
        "        self.is_rnn = False\n",
        "        attn_interval = 8\n",
        "        for i in range(n_layers):\n",
        "            self.layers.append(JambaBlock(d_model, i, (i + 1) % attn_interval == 0))\n",
        "        self.norm_f = nn.LayerNorm(d_model)\n",
        "        self.head = nn.Linear(d_model, input_dim, bias=False)\n",
        "\n",
        "    def set_input_rms(self, input_rms): self.input_rms = input_rms\n",
        "    def set_output_rms(self, output_rms): self.output_rms = output_rms\n",
        "    def init_rnn(self, batch_size): pass\n",
        "    def evaluate(self, x): return self.forward(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if isinstance(x, dict):\n",
        "            x = x.get('net_input', x.get('states', list(x.values())[0]))\n",
        "\n",
        "        # Squeeze/Unsqueeze Fix for Dimension Mismatch\n",
        "        is_2d = (x.dim() == 2)\n",
        "        if is_2d: x = x.unsqueeze(1)\n",
        "\n",
        "        x = self.embed(x)\n",
        "        for layer in self.layers: x = layer(x)\n",
        "        x = self.norm_f(x)\n",
        "        x = self.head(x)\n",
        "\n",
        "        if is_2d: x = x.squeeze(1)\n",
        "        return x\n",
        "'''\n",
        "with open(\"/content/neural-robot-dynamics/models/jamba.py\", \"w\") as f: f.write(jamba_content)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. FIX ALGORITHMS/VANILLA_TRAINER.PY (Adds input_dim dict check)\n",
        "# ---------------------------------------------------------\n",
        "trainer_content = r'''\n",
        "import sys, os, time, shutil, yaml, numpy as np, torch, warp as wp\n",
        "from typing import Optional\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.clip_grad import clip_grad_norm_\n",
        "from tqdm import tqdm\n",
        "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(os.path.abspath(__file__)), '../')))\n",
        "\n",
        "from envs.neural_environment import NeuralEnvironment\n",
        "from models.models import ModelMixedInput\n",
        "from models.jamba import JambaModel\n",
        "from utils.datasets import BatchTransitionDataset, collate_fn_BatchTransitionDataset\n",
        "from utils.evaluator import NeuralSimEvaluator\n",
        "from utils.python_utils import set_random_seed, print_info, print_ok, print_white, print_warning, format_dict\n",
        "from utils.torch_utils import num_params_torch_model, grad_norm\n",
        "from utils.running_mean_std import RunningMeanStd\n",
        "from utils.time_report import TimeReport, TimeProfiler\n",
        "from utils.logger import Logger\n",
        "\n",
        "class VanillaTrainer:\n",
        "    def __init__(self, neural_env, cfg, model_checkpoint_path=None, device='cuda:0', novelty=None, wandb_project=None, wandb_name=None):\n",
        "        self.novelty = novelty\n",
        "        self.wandb_project = wandb_project\n",
        "        self.wandb_name = wandb_name\n",
        "        self.seed = cfg['algorithm'].get('seed', 0)\n",
        "        self.device = device\n",
        "        set_random_seed(self.seed)\n",
        "        self.neural_env = neural_env\n",
        "        self.neural_integrator = neural_env.integrator_neural\n",
        "\n",
        "        if model_checkpoint_path is None:\n",
        "            input_sample = self.neural_integrator.get_neural_model_inputs()\n",
        "            # FIX: Check if input is dict or tensor\n",
        "            if isinstance(input_sample, dict):\n",
        "                input_dim = input_sample.get('states', list(input_sample.values())[0]).shape[-1]\n",
        "            else:\n",
        "                input_dim = input_sample.shape[-1]\n",
        "\n",
        "            if 'jamba' in cfg['network']:\n",
        "                print(f\"Initializing Jamba Model with Input Dim: {input_dim}\")\n",
        "                self.neural_model = JambaModel(input_dim, cfg['network'].get('d_model', 128), cfg['network'].get('n_layers', 4))\n",
        "                self.neural_model.to(self.device)\n",
        "            else:\n",
        "                self.neural_model = ModelMixedInput(input_sample, self.neural_integrator.prediction_dim, cfg['inputs'], cfg['network'], device=self.device, novelty=self.novelty)\n",
        "        else:\n",
        "            checkpoint = torch.load(model_checkpoint_path, map_location=self.device)\n",
        "            self.neural_model = checkpoint[0]\n",
        "            self.neural_model.to(self.device)\n",
        "\n",
        "        self.neural_integrator.set_neural_model(self.neural_model)\n",
        "        self.batch_size = int(cfg['algorithm']['batch_size'])\n",
        "        self.dataset_max_capacity = cfg['algorithm']['dataset'].get('max_capacity', 100000000)\n",
        "        self.num_data_workers = cfg['algorithm']['dataset'].get('num_data_workers', 4)\n",
        "        self.get_datasets(cfg['algorithm']['dataset'].get('train_dataset_path'), cfg['algorithm']['dataset'].get('valid_datasets'))\n",
        "\n",
        "        if cfg['cli']['train']:\n",
        "            self.num_epochs = int(cfg['algorithm']['num_epochs'])\n",
        "            self.num_iters_per_epoch = int(cfg['algorithm'].get('num_iters_per_epoch', -1))\n",
        "            self.optimizer = torch.optim.Adam(self.neural_model.parameters(), lr=float(cfg['algorithm']['optimizer']['lr_start']))\n",
        "            self.log_dir = cfg['cli']['logdir']\n",
        "            os.makedirs(self.log_dir, exist_ok=True)\n",
        "            self.model_log_dir = os.path.join(self.log_dir, 'nn')\n",
        "            os.makedirs(self.model_log_dir, exist_ok=True)\n",
        "            self.logger = Logger()\n",
        "            if self.wandb_project: self.logger.init_wandb(self.wandb_project, self.wandb_name)\n",
        "            self.save_interval = cfg['cli'].get(\"save_interval\", 50)\n",
        "\n",
        "            if cfg['algorithm'].get(\"compute_dataset_statistics\", True):\n",
        "                print('Computing dataset statistics...')\n",
        "                self.compute_dataset_statistics(self.train_dataset)\n",
        "                self.neural_model.set_input_rms(self.dataset_rms)\n",
        "                self.neural_model.set_output_rms(self.dataset_rms['target'])\n",
        "\n",
        "        self.evaluator = NeuralSimEvaluator(self.neural_env, eval_horizon=cfg['algorithm']['eval'].get(\"rollout_horizon\", 5), device=self.device)\n",
        "\n",
        "    def get_datasets(self, train_path, valid_cfg):\n",
        "        self.train_dataset = BatchTransitionDataset(self.batch_size, train_path, self.dataset_max_capacity, self.device)\n",
        "        self.valid_datasets = {k: BatchTransitionDataset(self.batch_size, v, device=self.device) for k, v in valid_cfg.items()}\n",
        "        self.batch_size = 1\n",
        "        self.collate_fn = collate_fn_BatchTransitionDataset\n",
        "\n",
        "    def compute_dataset_statistics(self, dataset):\n",
        "        loader = DataLoader(dataset, batch_size=max(512, self.batch_size), collate_fn=self.collate_fn)\n",
        "        self.dataset_rms = {}\n",
        "        for data in loader:\n",
        "            data = self.preprocess_data_batch(data)\n",
        "            for k in data.keys():\n",
        "                if k not in self.dataset_rms: self.dataset_rms[k] = RunningMeanStd(shape=data[k].shape[2:], device=self.device)\n",
        "                self.dataset_rms[k].update(data[k], batch_dim=True, time_dim=True)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def preprocess_data_batch(self, data):\n",
        "        for k, v in data.items():\n",
        "            if isinstance(v, dict):\n",
        "                for sk, sv in v.items(): data[k][sk] = sv.to(self.device)\n",
        "            else: data[k] = v.to(self.device)\n",
        "        data['contact_masks'] = self.neural_integrator.get_contact_masks(data['contact_depths'], data['contact_thicknesses'])\n",
        "        self.neural_integrator.process_neural_model_inputs(data)\n",
        "        data['target'] = self.neural_integrator.convert_next_states_to_prediction(data['states'], data['next_states'], self.neural_env.frame_dt)\n",
        "        return data\n",
        "\n",
        "    def compute_loss(self, data, train):\n",
        "        pred = self.neural_model(data)\n",
        "        loss = torch.nn.MSELoss()(pred, data['target'])\n",
        "        return loss, {}\n",
        "\n",
        "    def one_epoch(self, train, dataloader, dataloader_iter, num_batches, shuffle=False, info=None):\n",
        "        if train: self.neural_model.train()\n",
        "        else: self.neural_model.eval()\n",
        "        sum_loss = 0\n",
        "        with torch.set_grad_enabled(train):\n",
        "            for _ in tqdm(range(num_batches)):\n",
        "                try: data = next(dataloader_iter)\n",
        "                except StopIteration:\n",
        "                    if shuffle: self.train_dataset.shuffle()\n",
        "                    dataloader_iter = iter(dataloader)\n",
        "                    data = next(dataloader_iter)\n",
        "                data = self.preprocess_data_batch(data)\n",
        "                if train: self.optimizer.zero_grad()\n",
        "                loss, _ = self.compute_loss(data, train)\n",
        "                if train:\n",
        "                    loss.backward()\n",
        "                    self.optimizer.step()\n",
        "                sum_loss += loss\n",
        "        return sum_loss / num_batches, {}, {}\n",
        "\n",
        "    def train(self):\n",
        "        train_loader = DataLoader(self.train_dataset, batch_size=self.batch_size, collate_fn=self.collate_fn, shuffle=True, drop_last=True)\n",
        "        train_iter = iter(train_loader)\n",
        "        num_batches = len(train_loader) if self.num_iters_per_epoch == -1 else self.num_iters_per_epoch\n",
        "\n",
        "        valid_loaders = {k: DataLoader(v, batch_size=self.batch_size, collate_fn=self.collate_fn) for k,v in self.valid_datasets.items()}\n",
        "        valid_iters = {k: iter(v) for k,v in valid_loaders.items()}\n",
        "\n",
        "        self.best_eval_error = np.inf\n",
        "        for epoch in range(self.num_epochs):\n",
        "            if epoch > 0: self.one_epoch(True, train_loader, train_iter, num_batches, shuffle=True)\n",
        "            for k, v in valid_loaders.items(): self.one_epoch(False, v, valid_iters[k], min(50, len(v)), info=k)\n",
        "            if (epoch + 1) % self.eval_interval == 0: self.eval(epoch)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def eval(self, epoch):\n",
        "        self.neural_model.eval()\n",
        "        print('Evaluating...')\n",
        "        error, _, stats = self.evaluator.evaluate_action_mode(self.num_eval_rollouts, 'rollout', 'neural', self.eval_mode, self.eval_render, self.eval_passive)\n",
        "        print(f\"Eval Error: {stats['overall']['error(MSE)']}\")\n",
        "\n",
        "    def save_model(self, filename='best_model'):\n",
        "        torch.save([self.neural_model, self.neural_env.robot_name], os.path.join(self.model_log_dir, f'{filename}.pt'))\n",
        "'''\n",
        "with open(\"/content/neural-robot-dynamics/algorithms/vanilla_trainer.py\", \"w\") as f: f.write(trainer_content)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. FIX TRAIN/TRAIN.PY (Adds 'jamba' config check)\n",
        "# ---------------------------------------------------------\n",
        "train_main_content = r'''\n",
        "import sys, os, yaml, warp as wp\n",
        "base_dir = os.path.abspath(os.path.join(os.path.dirname(os.path.abspath(__file__)), '..'))\n",
        "sys.path.append(base_dir)\n",
        "wp.config.verify_cuda = True\n",
        "\n",
        "from arguments import get_parser\n",
        "from utils.python_utils import get_time_stamp, set_random_seed, solve_argv_conflict, handle_cfg_overrides\n",
        "from algorithms.vanilla_trainer import VanillaTrainer\n",
        "from algorithms.sequence_model_trainer import SequenceModelTrainer\n",
        "from envs.neural_environment import NeuralEnvironment\n",
        "\n",
        "def add_additional_params(parser):\n",
        "    parser.add_argument('--cfg-overrides', default=\"\", type=str)\n",
        "    parser.add_argument('--novelty', default=None, choices=['mamba', 'unroll'], type=str)\n",
        "    parser.add_argument('--sample-sequence-length', default=None, type=int)\n",
        "    parser.add_argument('--wandb-project', default=None, type=str)\n",
        "    parser.add_argument('--wandb-name', default=None, type=str)\n",
        "    return parser\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    args_list = ['--cfg', './cfg/Ant/transformer.yaml']\n",
        "    solve_argv_conflict(args_list)\n",
        "    parser = get_parser()\n",
        "    parser = add_additional_params(parser)\n",
        "    args = parser.parse_args(args_list + sys.argv[1:])\n",
        "\n",
        "    with open(args.cfg, 'r') as f: cfg = yaml.load(f, Loader=yaml.SafeLoader)\n",
        "    handle_cfg_overrides(args.cfg_overrides, cfg)\n",
        "\n",
        "    if args.num_envs: cfg['env']['num_envs'] = args.num_envs\n",
        "    if args.sample_sequence_length: cfg['algorithm']['sample_sequence_length'] = args.sample_sequence_length\n",
        "    cfg['env']['render'] = args.render\n",
        "    cfg['algorithm']['seed'] = args.seed if args.seed is not None else 0\n",
        "    set_random_seed(cfg['algorithm']['seed'])\n",
        "\n",
        "    args.train = not args.test\n",
        "    cfg[\"cli\"] = vars(args)\n",
        "\n",
        "    neural_env = NeuralEnvironment(**cfg['env'], device=args.device)\n",
        "    algorithm_name = cfg['algorithm'].get('name', 'VanillaTrainer')\n",
        "\n",
        "    if algorithm_name == 'SequenceModelTrainer':\n",
        "        # FIX: Allow Jamba in config check\n",
        "        if 'transformer' in cfg['network'] or 'jamba' in cfg['network']:\n",
        "             assert cfg['env']['neural_integrator_cfg']['name'] == 'TransformerNeuralIntegrator'\n",
        "\n",
        "        algo = SequenceModelTrainer(neural_env, model_checkpoint_path=args.checkpoint, cfg=cfg, device=args.device, novelty=args.novelty, wandb_project=args.wandb_project, wandb_name=args.wandb_name)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    if args.train: algo.train()\n",
        "    else: algo.test()\n",
        "'''\n",
        "with open(\"/content/neural-robot-dynamics/train/train.py\", \"w\") as f: f.write(train_main_content)\n",
        "\n",
        "print(\"✅ ALL FILES PATCHED SUCCESSFULLY.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "V2GFm64CwCOH",
        "outputId": "da5e2696-fa44-40aa-a088-9341bb65687a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ ALL FILES PATCHED SUCCESSFULLY.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the final model"
      ],
      "metadata": {
        "id": "NUWOwsVHwNny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!grep \"def evaluate\" /content/neural-robot-dynamics/models/jamba.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9PEcic5PwPcZ",
        "outputId": "b16c8ff0-9be9-4a15-cd81-80fc6a28c941"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    def evaluate(self, x): return self.forward(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Generate Dataset\n",
        "# We generate a smaller dataset for demonstration purposes.\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd generate\n",
        "\n",
        "# Define paths\n",
        "drive_data_dir = '/content/drive/MyDrive/neural-robot-dynamics/data/datasets/Cartpole/'\n",
        "local_data_dir = '../data/datasets/Cartpole/'\n",
        "train_filename = 'trajectory_len-100_train.hdf5'\n",
        "valid_filename = 'trajectory_len-100_valid.hdf5'\n",
        "\n",
        "os.makedirs(local_data_dir, exist_ok=True)\n",
        "os.makedirs(drive_data_dir, exist_ok=True)\n",
        "\n",
        "# Check if data exists in Drive\n",
        "if os.path.exists(os.path.join(drive_data_dir, train_filename)) and os.path.exists(os.path.join(drive_data_dir, valid_filename)):\n",
        "    print(\"Loading datasets from Google Drive...\")\n",
        "    shutil.copy(os.path.join(drive_data_dir, train_filename), local_data_dir)\n",
        "    shutil.copy(os.path.join(drive_data_dir, valid_filename), local_data_dir)\n",
        "else:\n",
        "    print(\"Generating datasets...\")\n",
        "    # Generate Training Data\n",
        "    !python generate_dataset_contact_free.py --env-name Cartpole --num-transitions 10000 --dataset-dir ../data/datasets/ --dataset-name trajectory_len-100_train.hdf5 --trajectory-length 100 --num-envs 64 --seed 0\n",
        "\n",
        "    # Generate Validation Data\n",
        "    !python generate_dataset_contact_free.py --env-name Cartpole --num-transitions 2000 --dataset-dir ../data/datasets/ --dataset-name trajectory_len-100_valid.hdf5 --trajectory-length 100 --num-envs 64 --seed 10\n",
        "\n",
        "    print(\"Saving datasets to Google Drive...\")\n",
        "    shutil.copy(os.path.join(local_data_dir, train_filename), drive_data_dir)\n",
        "    shutil.copy(os.path.join(local_data_dir, valid_filename), drive_data_dir)\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HNBsDdJcxXGB",
        "outputId": "69ead995-82a8-40ca-99e0-10cddc7adbc2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'generate'\n",
            "/content/neural-robot-dynamics/train\n",
            "Loading datasets from Google Drive...\n",
            "/content/neural-robot-dynamics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/neural-robot-dynamics/algorithms/vanilla_trainer.py\n",
        "import sys, os, time, shutil, yaml, numpy as np, torch, warp as wp\n",
        "from typing import Optional\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.clip_grad import clip_grad_norm_\n",
        "from tqdm import tqdm\n",
        "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(os.path.abspath(__file__)), '../')))\n",
        "\n",
        "from envs.neural_environment import NeuralEnvironment\n",
        "from models.models import ModelMixedInput\n",
        "from models.jamba import JambaModel\n",
        "from utils.datasets import BatchTransitionDataset, collate_fn_BatchTransitionDataset\n",
        "from utils.evaluator import NeuralSimEvaluator\n",
        "from utils.python_utils import set_random_seed, print_info, print_ok, print_white, print_warning, format_dict\n",
        "from utils.torch_utils import num_params_torch_model, grad_norm\n",
        "from utils.running_mean_std import RunningMeanStd\n",
        "from utils.time_report import TimeReport, TimeProfiler\n",
        "from utils.logger import Logger\n",
        "\n",
        "class VanillaTrainer:\n",
        "    def __init__(self, neural_env, cfg, model_checkpoint_path=None, device='cuda:0', novelty=None, wandb_project=None, wandb_name=None):\n",
        "        self.novelty = novelty\n",
        "        self.wandb_project = wandb_project\n",
        "        self.wandb_name = wandb_name\n",
        "        self.seed = cfg['algorithm'].get('seed', 0)\n",
        "        self.device = device\n",
        "        set_random_seed(self.seed)\n",
        "        self.neural_env = neural_env\n",
        "        self.neural_integrator = neural_env.integrator_neural\n",
        "\n",
        "        # --- 1. Model Initialization ---\n",
        "        if model_checkpoint_path is None:\n",
        "            input_sample = self.neural_integrator.get_neural_model_inputs()\n",
        "\n",
        "            # Helper to get input dimension from dict or tensor\n",
        "            if isinstance(input_sample, dict):\n",
        "                if 'states' in input_sample:\n",
        "                    input_dim = input_sample['states'].shape[-1]\n",
        "                else:\n",
        "                    input_dim = list(input_sample.values())[0].shape[-1]\n",
        "            else:\n",
        "                input_dim = input_sample.shape[-1]\n",
        "\n",
        "            if 'jamba' in cfg['network']:\n",
        "                print(f\"Initializing Jamba Model with Input Dim: {input_dim}\")\n",
        "                self.neural_model = JambaModel(input_dim, cfg['network'].get('d_model', 128), cfg['network'].get('n_layers', 4))\n",
        "                self.neural_model.to(self.device)\n",
        "            else:\n",
        "                self.neural_model = ModelMixedInput(input_sample, self.neural_integrator.prediction_dim, cfg['inputs'], cfg['network'], device=self.device, novelty=self.novelty)\n",
        "        else:\n",
        "            checkpoint = torch.load(model_checkpoint_path, map_location=self.device)\n",
        "            self.neural_model = checkpoint[0]\n",
        "            self.neural_model.to(self.device)\n",
        "\n",
        "        self.neural_integrator.set_neural_model(self.neural_model)\n",
        "\n",
        "        # --- 2. Dataset Setup ---\n",
        "        self.batch_size = int(cfg['algorithm']['batch_size'])\n",
        "        self.dataset_max_capacity = cfg['algorithm']['dataset'].get('max_capacity', 100000000)\n",
        "        self.num_data_workers = cfg['algorithm']['dataset'].get('num_data_workers', 4)\n",
        "\n",
        "        # Initialize placeholders before calling get_datasets\n",
        "        self.train_dataset = None\n",
        "        self.valid_datasets = {}\n",
        "        self.collate_fn = None\n",
        "\n",
        "        self.get_datasets(cfg['algorithm']['dataset'].get('train_dataset_path'), cfg['algorithm']['dataset'].get('valid_datasets'))\n",
        "\n",
        "        # --- 3. Training Params ---\n",
        "        # Default initialization\n",
        "        self.lr_schedule = 'constant'\n",
        "        self.lr_start = 1e-3\n",
        "        self.lr_end = 0.0\n",
        "\n",
        "        if cfg.get('cli', {}).get('train', False):\n",
        "            self.num_epochs = int(cfg['algorithm']['num_epochs'])\n",
        "            self.num_iters_per_epoch = int(cfg['algorithm'].get('num_iters_per_epoch', -1))\n",
        "\n",
        "            # Load Learning Rate Params\n",
        "            self.lr_start = float(cfg['algorithm']['optimizer']['lr_start'])\n",
        "            self.lr_end = float(cfg['algorithm']['optimizer'].get('lr_end', 0.))\n",
        "            self.lr_schedule = cfg['algorithm']['optimizer']['lr_schedule']\n",
        "\n",
        "            self.optimizer = torch.optim.Adam(self.neural_model.parameters(), lr=self.lr_start)\n",
        "\n",
        "            # Logging\n",
        "            self.log_dir = cfg['cli']['logdir']\n",
        "            os.makedirs(self.log_dir, exist_ok=True)\n",
        "            self.model_log_dir = os.path.join(self.log_dir, 'nn')\n",
        "            os.makedirs(self.model_log_dir, exist_ok=True)\n",
        "            self.logger = Logger()\n",
        "            self.summary_log_dir = os.path.join(self.log_dir, 'summaries')\n",
        "            os.makedirs(self.summary_log_dir, exist_ok=True)\n",
        "            self.logger.init_tensorboard(self.summary_log_dir)\n",
        "\n",
        "            if self.wandb_project:\n",
        "                self.logger.init_wandb(self.wandb_project, self.wandb_name)\n",
        "\n",
        "            self.save_interval = cfg['cli'].get(\"save_interval\", 50)\n",
        "            self.eval_interval = cfg['cli'].get(\"eval_interval\", 1)\n",
        "            self.log_interval = cfg['cli'].get(\"log_interval\", 1)\n",
        "\n",
        "            # Gradient clipping params\n",
        "            self.truncate_grad = cfg['algorithm'].get('truncate_grad', False)\n",
        "            self.grad_norm = cfg['algorithm'].get('grad_norm', 1.0)\n",
        "\n",
        "            # Compute Statistics\n",
        "            if cfg['algorithm'].get(\"compute_dataset_statistics\", True):\n",
        "                print('Computing dataset statistics...')\n",
        "                self.compute_dataset_statistics(self.train_dataset)\n",
        "                if hasattr(self.neural_model, 'set_input_rms'):\n",
        "                    self.neural_model.set_input_rms(self.dataset_rms)\n",
        "                    self.neural_model.set_output_rms(self.dataset_rms['target'])\n",
        "\n",
        "            # Create log files\n",
        "            for valid_dataset_name in self.valid_datasets.keys():\n",
        "                with open(os.path.join(self.model_log_dir, f'saved_best_valid_{valid_dataset_name}_model_epochs.txt'), 'w') as fp: fp.close()\n",
        "            with open(os.path.join(self.model_log_dir, \"saved_best_eval_model_epochs.txt\"), 'w') as fp: fp.close()\n",
        "\n",
        "        # --- 4. Evaluator Setup ---\n",
        "        self.eval_mode = cfg['algorithm']['eval'].get('mode', 'sampler')\n",
        "        self.num_eval_rollouts = cfg['algorithm']['eval'].get(\"num_rollouts\", self.neural_env.num_envs)\n",
        "        self.eval_render = cfg.get('cli', {}).get('render', False)\n",
        "        self.eval_passive = cfg['algorithm']['eval'].get('passive', True)\n",
        "        self.eval_horizon = cfg['algorithm']['eval'].get(\"rollout_horizon\", 5)\n",
        "        self.eval_dataset_path = cfg['algorithm']['eval'].get('dataset_path', None)\n",
        "\n",
        "        self.evaluator = NeuralSimEvaluator(\n",
        "            self.neural_env,\n",
        "            hdf5_dataset_path=self.eval_dataset_path if self.eval_mode == 'dataset' else None,\n",
        "            eval_horizon=self.eval_horizon,\n",
        "            device=self.device\n",
        "        )\n",
        "\n",
        "    def get_datasets(self, train_path, valid_cfg):\n",
        "        self.train_dataset = BatchTransitionDataset(self.batch_size, train_path, self.dataset_max_capacity, self.device)\n",
        "        self.valid_datasets = {k: BatchTransitionDataset(self.batch_size, v, device=self.device) for k, v in valid_cfg.items()}\n",
        "        self.batch_size = 1\n",
        "        self.collate_fn = collate_fn_BatchTransitionDataset\n",
        "\n",
        "    def compute_dataset_statistics(self, dataset):\n",
        "        loader = DataLoader(dataset, batch_size=max(512, self.batch_size), collate_fn=self.collate_fn)\n",
        "        self.dataset_rms = {}\n",
        "        for data in loader:\n",
        "            data = self.preprocess_data_batch(data)\n",
        "            for k in data.keys():\n",
        "                if k not in self.dataset_rms: self.dataset_rms[k] = RunningMeanStd(shape=data[k].shape[2:], device=self.device)\n",
        "                self.dataset_rms[k].update(data[k], batch_dim=True, time_dim=True)\n",
        "\n",
        "    def get_scheduled_learning_rate(self, iteration, total_iterations):\n",
        "        if self.lr_schedule == 'constant': return self.lr_start\n",
        "        elif self.lr_schedule == 'linear':\n",
        "            ratio = iteration / total_iterations\n",
        "            return self.lr_start * (1.0 - ratio) + self.lr_end * ratio\n",
        "        elif self.lr_schedule == 'cosine':\n",
        "            decay_ratio = iteration / total_iterations\n",
        "            coeff = 0.5 * (1.0 + np.cos(np.pi * decay_ratio))\n",
        "            return self.lr_end + coeff * (self.lr_start - self.lr_end)\n",
        "        return self.lr_start\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def preprocess_data_batch(self, data):\n",
        "        for k, v in data.items():\n",
        "            if isinstance(v, dict):\n",
        "                for sk, sv in v.items(): data[k][sk] = sv.to(self.device)\n",
        "            else: data[k] = v.to(self.device)\n",
        "        data['contact_masks'] = self.neural_integrator.get_contact_masks(data['contact_depths'], data['contact_thicknesses'])\n",
        "        self.neural_integrator.process_neural_model_inputs(data)\n",
        "        data['target'] = self.neural_integrator.convert_next_states_to_prediction(data['states'], data['next_states'], self.neural_env.frame_dt)\n",
        "        return data\n",
        "\n",
        "    def compute_loss(self, data, train):\n",
        "        pred = self.neural_model(data)\n",
        "\n",
        "        # Determine weights\n",
        "        if hasattr(self.neural_model, 'normalize_output') and self.neural_model.normalize_output:\n",
        "            loss_weights = 1. / torch.sqrt(self.neural_model.output_rms.var + 1e-5)\n",
        "        else:\n",
        "            loss_weights = torch.ones(pred.shape[-1], device=pred.device)\n",
        "\n",
        "        loss = torch.nn.MSELoss()(pred * loss_weights, data['target'] * loss_weights)\n",
        "        return loss, {}\n",
        "\n",
        "    def one_epoch(self, train, dataloader, dataloader_iter, num_batches, shuffle=False, info=None):\n",
        "        if train: self.neural_model.train()\n",
        "        else: self.neural_model.eval()\n",
        "        sum_loss = 0\n",
        "        with torch.set_grad_enabled(train):\n",
        "            for _ in tqdm(range(num_batches)):\n",
        "                try: data = next(dataloader_iter)\n",
        "                except StopIteration:\n",
        "                    if shuffle: self.train_dataset.shuffle()\n",
        "                    dataloader_iter = iter(dataloader)\n",
        "                    data = next(dataloader_iter)\n",
        "                data = self.preprocess_data_batch(data)\n",
        "                if train: self.optimizer.zero_grad()\n",
        "                loss, _ = self.compute_loss(data, train)\n",
        "                if train:\n",
        "                    loss.backward()\n",
        "                    # Clip gradients\n",
        "                    if self.truncate_grad:\n",
        "                        clip_grad_norm_(self.neural_model.parameters(), self.grad_norm)\n",
        "                    self.optimizer.step()\n",
        "                sum_loss += loss\n",
        "        return sum_loss / num_batches, {}, {}\n",
        "\n",
        "    def train(self):\n",
        "        train_loader = DataLoader(self.train_dataset, batch_size=self.batch_size, collate_fn=self.collate_fn, shuffle=True, drop_last=True)\n",
        "        train_iter = iter(train_loader)\n",
        "        num_batches = len(train_loader) if self.num_iters_per_epoch == -1 else self.num_iters_per_epoch\n",
        "\n",
        "        valid_loaders = {k: DataLoader(v, batch_size=self.batch_size, collate_fn=self.collate_fn) for k,v in self.valid_datasets.items()}\n",
        "        valid_iters = {k: iter(v) for k,v in valid_loaders.items()}\n",
        "\n",
        "        self.best_eval_error = np.inf\n",
        "\n",
        "        self.time_report = TimeReport(cuda_synchronize = False)\n",
        "        self.time_report.add_timers(['epoch', 'other', 'dataloader', 'compute_loss', 'backward', 'eval'])\n",
        "\n",
        "        for epoch in range(self.num_epochs):\n",
        "            self.logger.init_epoch(epoch)\n",
        "            # Update LR\n",
        "            self.lr = self.get_scheduled_learning_rate(epoch, self.num_epochs)\n",
        "            for param_group in self.optimizer.param_groups: param_group['lr'] = self.lr\n",
        "\n",
        "            if epoch > 0: self.one_epoch(True, train_loader, train_iter, num_batches, shuffle=True)\n",
        "            for k, v in valid_loaders.items(): self.one_epoch(False, v, valid_iters[k], min(50, len(v)), info=k)\n",
        "\n",
        "            if (epoch + 1) % self.eval_interval == 0: self.eval(epoch)\n",
        "\n",
        "            # Flush logs\n",
        "            self.logger.flush()\n",
        "\n",
        "        # --- FIXED: Call finish() OUTSIDE the loop ---\n",
        "        self.logger.finish()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def eval(self, epoch):\n",
        "        self.neural_model.eval()\n",
        "        print('Evaluating...')\n",
        "        error, _, stats = self.evaluator.evaluate_action_mode(\n",
        "            num_traj=self.num_eval_rollouts,\n",
        "            eval_mode='rollout',\n",
        "            env_mode='neural',\n",
        "            trajectory_source=self.eval_mode,\n",
        "            render=self.eval_render,\n",
        "            passive=self.eval_passive\n",
        "        )\n",
        "        print(f\"Eval Error: {stats['overall']['error(MSE)']}\")\n",
        "\n",
        "        if stats['overall']['error(MSE)'] < self.best_eval_error:\n",
        "            self.best_eval_error = stats['overall']['error(MSE)']\n",
        "            self.save_model('best_eval_model')\n",
        "\n",
        "    def save_model(self, filename='best_model'):\n",
        "        torch.save([self.neural_model, self.neural_env.robot_name], os.path.join(self.model_log_dir, f'{filename}.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "d-jbgL7bx5aX",
        "outputId": "8d5f73b9-99bc-4f24-bd44-4dd8fd754e49"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/neural-robot-dynamics/algorithms/vanilla_trainer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/neural-robot-dynamics/models/jamba.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_head, max_len=2048):\n",
        "        super().__init__()\n",
        "        self.c_attn = nn.Linear(d_model, 3 * d_model)\n",
        "        self.c_proj = nn.Linear(d_model, d_model)\n",
        "        self.n_head = n_head\n",
        "        self.d_model = d_model\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(max_len, max_len)).view(1, 1, max_len, max_len))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size()\n",
        "        q, k, v = self.c_attn(x).split(self.d_model, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        y = att @ v\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        return self.c_proj(y)\n",
        "\n",
        "class MambaLayer(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.in_proj = nn.Linear(d_model, d_model * 2)\n",
        "        self.conv1d = nn.Conv1d(in_channels=d_model * 2, out_channels=d_model * 2, kernel_size=4, groups=d_model * 2, padding=3)\n",
        "        self.out_proj = nn.Linear(d_model * 2, d_model)\n",
        "        self.act = nn.SiLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, L, D = x.shape\n",
        "        x_proj = self.in_proj(x)\n",
        "        x_conv = x_proj.transpose(1, 2)\n",
        "        x_conv = self.conv1d(x_conv)[:, :, :L]\n",
        "        x_conv = x_conv.transpose(1, 2)\n",
        "        return self.out_proj(self.act(x_conv))\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(nn.Linear(d_model, 4 * d_model), nn.GELU(), nn.Linear(4 * d_model, d_model))\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class JambaBlock(nn.Module):\n",
        "    def __init__(self, d_model, layer_idx, use_attention=False):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.mixer = CausalSelfAttention(d_model, n_head=4) if use_attention else MambaLayer(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.mlp = MLP(d_model)\n",
        "    def forward(self, x):\n",
        "        x = x + self.mixer(self.norm1(x))\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "        return x\n",
        "\n",
        "class JambaModel(nn.Module):\n",
        "    def __init__(self, input_dim, d_model, n_layers, vocab_size=None):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Linear(input_dim, d_model)\n",
        "        self.layers = nn.ModuleList([])\n",
        "        self.normalize_output = False\n",
        "        self.input_rms = None\n",
        "        self.output_rms = None\n",
        "        self.is_rnn = False\n",
        "        attn_interval = 8\n",
        "        for i in range(n_layers):\n",
        "            self.layers.append(JambaBlock(d_model, i, (i + 1) % attn_interval == 0))\n",
        "        self.norm_f = nn.LayerNorm(d_model)\n",
        "        self.head = nn.Linear(d_model, input_dim, bias=False)\n",
        "\n",
        "    def set_input_rms(self, input_rms): self.input_rms = input_rms\n",
        "    def set_output_rms(self, output_rms): self.output_rms = output_rms\n",
        "    def init_rnn(self, batch_size): pass\n",
        "\n",
        "    def evaluate(self, x):\n",
        "        # 1. Run forward pass\n",
        "        out = self.forward(x)\n",
        "\n",
        "        # 2. Handle Sequence Output\n",
        "        # If the output is 3D [Batch, Len, Dim], we only want the LAST prediction\n",
        "        # for the Integrator to work correctly.\n",
        "        if out.dim() == 3:\n",
        "            return out[:, -1, :]\n",
        "\n",
        "        return out\n",
        "\n",
        "    def forward(self, x):\n",
        "        if isinstance(x, dict):\n",
        "            if 'net_input' in x: x = x['net_input']\n",
        "            elif 'states' in x: x = x['states']\n",
        "            else: x = list(x.values())[0]\n",
        "\n",
        "        # Handle 2D inputs (unsqueeze for Mamba)\n",
        "        is_2d = (x.dim() == 2)\n",
        "        if is_2d: x = x.unsqueeze(1)\n",
        "\n",
        "        x = self.embed(x)\n",
        "        for layer in self.layers: x = layer(x)\n",
        "        x = self.norm_f(x)\n",
        "        x = self.head(x)\n",
        "\n",
        "        # Restore dimensions if we started with 2D\n",
        "        if is_2d: x = x.squeeze(1)\n",
        "        return x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lJWnk3La0Sqn",
        "outputId": "ef995631-2242-40ee-9ab5-78afb8bb5276"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/neural-robot-dynamics/models/jamba.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create Config\n",
        "import yaml\n",
        "import os\n",
        "%cd /content/neural-robot-dynamics/train\n",
        "with open('cfg/Cartpole/transformer.yaml', 'r') as f: cfg = yaml.safe_load(f)\n",
        "cfg['algorithm']['dataset']['train_dataset_path'] = '../data/datasets/Cartpole/trajectory_len-100_train.hdf5'\n",
        "cfg['algorithm']['dataset']['valid_datasets']['exp_trajectory'] = '../data/datasets/Cartpole/trajectory_len-100_valid.hdf5'\n",
        "cfg['network'] = {'jamba': True, 'd_model': 128, 'n_layers': 4, 'vocab_size': 100}\n",
        "cfg['algorithm']['num_epochs'] = 100\n",
        "cfg['algorithm']['num_iters_per_epoch'] = 100\n",
        "with open('jamba_colab_config.yaml', 'w') as f: yaml.dump(cfg, f)\n",
        "\n",
        "# 2. Run\n",
        "!python train.py --cfg jamba_colab_config.yaml --novelty mamba --logdir ../data/logs/jamba --wandb-project neural-robot-dynamics --wandb-name jamba_run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rsC9xOcUwM_2",
        "outputId": "a0a8ebd3-cd80-479f-e36a-c89068ef1ff9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/neural-robot-dynamics/train\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-40GB\" (40 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "2025-12-06 22:42:30.425884: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-06 22:42:30.444760: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765060950.466259    6378 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765060950.472768    6378 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765060950.490212    6378 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765060950.490238    6378 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765060950.490241    6378 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765060950.490244    6378 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-06 22:42:30.495086: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 512 environments: 100% 512/512 [00:01<00:00, 309.21it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 3.51 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.43 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.50 ms  (cached)\n",
            "\u001b[91m [NeuralEnvironment] Created a DUMMY Neural Integrator. \u001b[0m\n",
            "Initializing Jamba Model with Input Dim: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhargaveekc\u001b[0m (\u001b[33mbhargaveekc-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m setting up run k19g91aj (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m setting up run k19g91aj (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251206_224240-k19g91aj\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mjamba_run\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics/runs/k19g91aj\u001b[0m\n",
            "Computing dataset statistics...\n",
            "100% 12/12 [00:00<00:00, 16.58it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions:   0% 0/4 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 0.69 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.40 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.44 ms  (cached)\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 18.60it/s]\n",
            "100% 4/4 [00:00<00:00, 13.57it/s]\n",
            "Eval Error: 9.008317947387695\n",
            "100% 100/100 [00:06<00:00, 15.02it/s]\n",
            "100% 12/12 [00:00<00:00, 19.09it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.24it/s]\n",
            "100% 4/4 [00:00<00:00, 15.90it/s]\n",
            "Eval Error: 0.6000592112541199\n",
            "100% 100/100 [00:06<00:00, 15.15it/s]\n",
            "100% 12/12 [00:00<00:00, 20.05it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.00it/s]\n",
            "100% 4/4 [00:00<00:00, 16.27it/s]\n",
            "Eval Error: 0.2676349878311157\n",
            "100% 100/100 [00:06<00:00, 15.12it/s]\n",
            "100% 12/12 [00:00<00:00, 19.79it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.20it/s]\n",
            "100% 4/4 [00:00<00:00, 16.35it/s]\n",
            "Eval Error: 0.26177331805229187\n",
            "100% 100/100 [00:06<00:00, 15.32it/s]\n",
            "100% 12/12 [00:00<00:00, 19.58it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.02it/s]\n",
            "100% 4/4 [00:00<00:00, 16.14it/s]\n",
            "Eval Error: 0.25602293014526367\n",
            "100% 100/100 [00:06<00:00, 15.15it/s]\n",
            "100% 12/12 [00:00<00:00, 19.61it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.22it/s]\n",
            "100% 4/4 [00:00<00:00, 16.38it/s]\n",
            "Eval Error: 0.24466906487941742\n",
            "100% 100/100 [00:06<00:00, 15.05it/s]\n",
            "100% 12/12 [00:00<00:00, 19.71it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.17it/s]\n",
            "100% 4/4 [00:00<00:00, 16.33it/s]\n",
            "Eval Error: 0.2370547354221344\n",
            "100% 100/100 [00:06<00:00, 15.21it/s]\n",
            "100% 12/12 [00:00<00:00, 19.78it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.13it/s]\n",
            "100% 4/4 [00:00<00:00, 16.44it/s]\n",
            "Eval Error: 0.22378253936767578\n",
            "100% 100/100 [00:06<00:00, 14.99it/s]\n",
            "100% 12/12 [00:00<00:00, 19.76it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.18it/s]\n",
            "100% 4/4 [00:00<00:00, 16.37it/s]\n",
            "Eval Error: 0.2423781454563141\n",
            "100% 100/100 [00:06<00:00, 14.42it/s]\n",
            "100% 12/12 [00:00<00:00, 19.57it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.76it/s]\n",
            "100% 4/4 [00:00<00:00, 15.48it/s]\n",
            "Eval Error: 0.24728846549987793\n",
            "100% 100/100 [00:06<00:00, 15.08it/s]\n",
            "100% 12/12 [00:00<00:00, 19.44it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.75it/s]\n",
            "100% 4/4 [00:00<00:00, 16.11it/s]\n",
            "Eval Error: 0.24467478692531586\n",
            "100% 100/100 [00:06<00:00, 15.15it/s]\n",
            "100% 12/12 [00:00<00:00, 19.28it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.07it/s]\n",
            "100% 4/4 [00:00<00:00, 16.37it/s]\n",
            "Eval Error: 0.23556672036647797\n",
            "100% 100/100 [00:06<00:00, 15.20it/s]\n",
            "100% 12/12 [00:00<00:00, 19.45it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.89it/s]\n",
            "100% 4/4 [00:00<00:00, 16.15it/s]\n",
            "Eval Error: 0.2402084916830063\n",
            "100% 100/100 [00:06<00:00, 15.10it/s]\n",
            "100% 12/12 [00:00<00:00, 19.61it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.09it/s]\n",
            "100% 4/4 [00:00<00:00, 16.38it/s]\n",
            "Eval Error: 0.26746711134910583\n",
            "100% 100/100 [00:06<00:00, 16.05it/s]\n",
            "100% 12/12 [00:00<00:00, 19.77it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.07it/s]\n",
            "100% 4/4 [00:00<00:00, 16.21it/s]\n",
            "Eval Error: 0.23563797771930695\n",
            "100% 100/100 [00:06<00:00, 14.79it/s]\n",
            "100% 12/12 [00:00<00:00, 12.64it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.73it/s]\n",
            "100% 4/4 [00:00<00:00, 16.10it/s]\n",
            "Eval Error: 0.2394857406616211\n",
            "100% 100/100 [00:06<00:00, 15.01it/s]\n",
            "100% 12/12 [00:00<00:00, 19.58it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.64it/s]\n",
            "100% 4/4 [00:00<00:00, 15.97it/s]\n",
            "Eval Error: 0.255439430475235\n",
            "100% 100/100 [00:06<00:00, 15.11it/s]\n",
            "100% 12/12 [00:00<00:00, 19.63it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.03it/s]\n",
            "100% 4/4 [00:00<00:00, 16.21it/s]\n",
            "Eval Error: 0.24018974602222443\n",
            "100% 100/100 [00:06<00:00, 14.95it/s]\n",
            "100% 12/12 [00:00<00:00, 19.60it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.19it/s]\n",
            "100% 4/4 [00:00<00:00, 16.24it/s]\n",
            "Eval Error: 0.23773424327373505\n",
            "100% 100/100 [00:06<00:00, 15.06it/s]\n",
            "100% 12/12 [00:00<00:00, 19.17it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.94it/s]\n",
            "100% 4/4 [00:00<00:00, 16.06it/s]\n",
            "Eval Error: 0.23915818333625793\n",
            "100% 100/100 [00:06<00:00, 14.58it/s]\n",
            "100% 12/12 [00:00<00:00, 18.97it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.38it/s]\n",
            "100% 4/4 [00:00<00:00, 16.22it/s]\n",
            "Eval Error: 0.2309049665927887\n",
            "100% 100/100 [00:06<00:00, 14.65it/s]\n",
            "100% 12/12 [00:00<00:00, 19.12it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.80it/s]\n",
            "100% 4/4 [00:00<00:00, 16.16it/s]\n",
            "Eval Error: 0.2435324639081955\n",
            "100% 100/100 [00:06<00:00, 14.73it/s]\n",
            "100% 12/12 [00:00<00:00, 18.98it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.42it/s]\n",
            "100% 4/4 [00:00<00:00, 15.54it/s]\n",
            "Eval Error: 0.24242310225963593\n",
            "100% 100/100 [00:06<00:00, 14.60it/s]\n",
            "100% 12/12 [00:00<00:00, 18.88it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.69it/s]\n",
            "100% 4/4 [00:00<00:00, 15.93it/s]\n",
            "Eval Error: 0.2414553165435791\n",
            "100% 100/100 [00:06<00:00, 14.67it/s]\n",
            "100% 12/12 [00:00<00:00, 18.57it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.99it/s]\n",
            "100% 4/4 [00:00<00:00, 16.27it/s]\n",
            "Eval Error: 0.2511456608772278\n",
            "100% 100/100 [00:06<00:00, 14.96it/s]\n",
            "100% 12/12 [00:00<00:00, 19.49it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.29it/s]\n",
            "100% 4/4 [00:00<00:00, 16.40it/s]\n",
            "Eval Error: 0.23741260170936584\n",
            "100% 100/100 [00:06<00:00, 15.08it/s]\n",
            "100% 12/12 [00:00<00:00, 19.36it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.73it/s]\n",
            "100% 4/4 [00:00<00:00, 16.29it/s]\n",
            "Eval Error: 0.2538805603981018\n",
            "100% 100/100 [00:06<00:00, 15.17it/s]\n",
            "100% 12/12 [00:00<00:00, 19.53it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.11it/s]\n",
            "100% 4/4 [00:00<00:00, 16.32it/s]\n",
            "Eval Error: 0.24739347398281097\n",
            "100% 100/100 [00:06<00:00, 15.14it/s]\n",
            "100% 12/12 [00:00<00:00, 19.57it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.11it/s]\n",
            "100% 4/4 [00:00<00:00, 16.35it/s]\n",
            "Eval Error: 0.2506941854953766\n",
            "100% 100/100 [00:06<00:00, 15.15it/s]\n",
            "100% 12/12 [00:00<00:00, 19.45it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.18it/s]\n",
            "100% 4/4 [00:00<00:00, 16.18it/s]\n",
            "Eval Error: 0.24722357094287872\n",
            "100% 100/100 [00:06<00:00, 15.09it/s]\n",
            "100% 12/12 [00:00<00:00, 19.63it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.52it/s]\n",
            "100% 4/4 [00:00<00:00, 16.08it/s]\n",
            "Eval Error: 0.26315057277679443\n",
            "100% 100/100 [00:06<00:00, 15.75it/s]\n",
            "100% 12/12 [00:00<00:00, 19.48it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.66it/s]\n",
            "100% 4/4 [00:00<00:00, 16.32it/s]\n",
            "Eval Error: 0.25620824098587036\n",
            "100% 100/100 [00:06<00:00, 15.13it/s]\n",
            "100% 12/12 [00:00<00:00, 19.24it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.08it/s]\n",
            "100% 4/4 [00:00<00:00, 16.14it/s]\n",
            "Eval Error: 0.24881426990032196\n",
            "100% 100/100 [00:06<00:00, 15.04it/s]\n",
            "100% 12/12 [00:00<00:00, 19.87it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.15it/s]\n",
            "100% 4/4 [00:00<00:00, 16.32it/s]\n",
            "Eval Error: 0.25993525981903076\n",
            "100% 100/100 [00:06<00:00, 15.29it/s]\n",
            "100% 12/12 [00:00<00:00, 19.91it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.84it/s]\n",
            "100% 4/4 [00:00<00:00, 16.17it/s]\n",
            "Eval Error: 0.2587919235229492\n",
            "100% 100/100 [00:06<00:00, 15.99it/s]\n",
            "100% 12/12 [00:00<00:00, 20.01it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.10it/s]\n",
            "100% 4/4 [00:00<00:00, 16.24it/s]\n",
            "Eval Error: 0.25416088104248047\n",
            "100% 100/100 [00:06<00:00, 15.19it/s]\n",
            "100% 12/12 [00:00<00:00, 19.67it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.18it/s]\n",
            "100% 4/4 [00:00<00:00, 15.86it/s]\n",
            "Eval Error: 0.24886290729045868\n",
            "100% 100/100 [00:06<00:00, 15.25it/s]\n",
            "100% 12/12 [00:00<00:00, 19.51it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.37it/s]\n",
            "100% 4/4 [00:00<00:00, 15.51it/s]\n",
            "Eval Error: 0.2657054364681244\n",
            "100% 100/100 [00:06<00:00, 15.15it/s]\n",
            "100% 12/12 [00:00<00:00, 19.87it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.49it/s]\n",
            "100% 4/4 [00:00<00:00, 16.14it/s]\n",
            "Eval Error: 0.2776815891265869\n",
            "100% 100/100 [00:06<00:00, 15.09it/s]\n",
            "100% 12/12 [00:00<00:00, 19.69it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.14it/s]\n",
            "100% 4/4 [00:00<00:00, 16.21it/s]\n",
            "Eval Error: 0.26201483607292175\n",
            "100% 100/100 [00:06<00:00, 14.65it/s]\n",
            "100% 12/12 [00:00<00:00, 19.76it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.08it/s]\n",
            "100% 4/4 [00:00<00:00, 16.40it/s]\n",
            "Eval Error: 0.32841989398002625\n",
            "100% 100/100 [00:06<00:00, 15.23it/s]\n",
            "100% 12/12 [00:00<00:00, 19.79it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.16it/s]\n",
            "100% 4/4 [00:00<00:00, 16.32it/s]\n",
            "Eval Error: 0.3094375729560852\n",
            "100% 100/100 [00:06<00:00, 15.26it/s]\n",
            "100% 12/12 [00:00<00:00, 19.21it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.68it/s]\n",
            "100% 4/4 [00:00<00:00, 15.62it/s]\n",
            "Eval Error: 0.2761209309101105\n",
            "100% 100/100 [00:06<00:00, 15.22it/s]\n",
            "100% 12/12 [00:00<00:00, 19.41it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.99it/s]\n",
            "100% 4/4 [00:00<00:00, 16.12it/s]\n",
            "Eval Error: 0.2791498303413391\n",
            "100% 100/100 [00:06<00:00, 15.06it/s]\n",
            "100% 12/12 [00:00<00:00, 20.02it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.23it/s]\n",
            "100% 4/4 [00:00<00:00, 16.30it/s]\n",
            "Eval Error: 0.2841329574584961\n",
            "100% 100/100 [00:06<00:00, 15.31it/s]\n",
            "100% 12/12 [00:00<00:00, 19.70it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.21it/s]\n",
            "100% 4/4 [00:00<00:00, 16.50it/s]\n",
            "Eval Error: 0.29444074630737305\n",
            "100% 100/100 [00:06<00:00, 15.30it/s]\n",
            "100% 12/12 [00:00<00:00, 20.13it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.83it/s]\n",
            "100% 4/4 [00:00<00:00, 16.36it/s]\n",
            "Eval Error: 0.298588365316391\n",
            "100% 100/100 [00:06<00:00, 15.73it/s]\n",
            "100% 12/12 [00:00<00:00, 18.80it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.17it/s]\n",
            "100% 4/4 [00:00<00:00, 16.36it/s]\n",
            "Eval Error: 0.33396297693252563\n",
            "100% 100/100 [00:06<00:00, 14.93it/s]\n",
            "100% 12/12 [00:00<00:00, 19.04it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.00it/s]\n",
            "100% 4/4 [00:00<00:00, 14.77it/s]\n",
            "Eval Error: 0.3316912353038788\n",
            "100% 100/100 [00:07<00:00, 14.06it/s]\n",
            "100% 12/12 [00:00<00:00, 17.80it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.02it/s]\n",
            "100% 4/4 [00:00<00:00, 14.82it/s]\n",
            "Eval Error: 0.311521053314209\n",
            "100% 100/100 [00:07<00:00, 14.25it/s]\n",
            "100% 12/12 [00:00<00:00, 17.92it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.74it/s]\n",
            "100% 4/4 [00:00<00:00, 15.45it/s]\n",
            "Eval Error: 0.3986349105834961\n",
            "100% 100/100 [00:07<00:00, 14.11it/s]\n",
            "100% 12/12 [00:00<00:00, 18.75it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.95it/s]\n",
            "100% 4/4 [00:00<00:00, 14.78it/s]\n",
            "Eval Error: 0.33977600932121277\n",
            "100% 100/100 [00:07<00:00, 14.16it/s]\n",
            "100% 12/12 [00:00<00:00, 18.21it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.00it/s]\n",
            "100% 4/4 [00:00<00:00, 14.81it/s]\n",
            "Eval Error: 0.3527827560901642\n",
            "100% 100/100 [00:07<00:00, 14.27it/s]\n",
            "100% 12/12 [00:00<00:00, 19.19it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.37it/s]\n",
            "100% 4/4 [00:00<00:00, 14.90it/s]\n",
            "Eval Error: 0.41635075211524963\n",
            "100% 100/100 [00:06<00:00, 14.83it/s]\n",
            "100% 12/12 [00:00<00:00, 19.69it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.82it/s]\n",
            "100% 4/4 [00:00<00:00, 15.53it/s]\n",
            "Eval Error: 0.3981782793998718\n",
            "100% 100/100 [00:06<00:00, 15.03it/s]\n",
            "100% 12/12 [00:01<00:00, 11.98it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.38it/s]\n",
            "100% 4/4 [00:00<00:00, 15.04it/s]\n",
            "Eval Error: 0.4668755531311035\n",
            "100% 100/100 [00:06<00:00, 14.57it/s]\n",
            "100% 12/12 [00:00<00:00, 18.25it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.90it/s]\n",
            "100% 4/4 [00:00<00:00, 14.37it/s]\n",
            "Eval Error: 0.5214695930480957\n",
            "100% 100/100 [00:06<00:00, 14.59it/s]\n",
            "100% 12/12 [00:00<00:00, 18.31it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.69it/s]\n",
            "100% 4/4 [00:00<00:00, 14.82it/s]\n",
            "Eval Error: 0.46896153688430786\n",
            "100% 100/100 [00:06<00:00, 14.36it/s]\n",
            "100% 12/12 [00:00<00:00, 19.61it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.05it/s]\n",
            "100% 4/4 [00:00<00:00, 16.04it/s]\n",
            "Eval Error: 0.489245742559433\n",
            "100% 100/100 [00:06<00:00, 14.41it/s]\n",
            "100% 12/12 [00:00<00:00, 18.58it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.49it/s]\n",
            "100% 4/4 [00:00<00:00, 16.16it/s]\n",
            "Eval Error: 0.49099302291870117\n",
            "100% 100/100 [00:07<00:00, 13.93it/s]\n",
            "100% 12/12 [00:00<00:00, 17.37it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 22.26it/s]\n",
            "100% 4/4 [00:00<00:00, 14.52it/s]\n",
            "Eval Error: 0.47177526354789734\n",
            "100% 100/100 [00:07<00:00, 14.10it/s]\n",
            "100% 12/12 [00:00<00:00, 17.81it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 21.89it/s]\n",
            "100% 4/4 [00:00<00:00, 13.38it/s]\n",
            "Eval Error: 0.5068376064300537\n",
            "100% 100/100 [00:07<00:00, 13.98it/s]\n",
            "100% 12/12 [00:00<00:00, 18.65it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.88it/s]\n",
            "100% 4/4 [00:00<00:00, 15.20it/s]\n",
            "Eval Error: 0.5035936832427979\n",
            "100% 100/100 [00:06<00:00, 14.47it/s]\n",
            "100% 12/12 [00:00<00:00, 18.72it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.13it/s]\n",
            "100% 4/4 [00:00<00:00, 15.91it/s]\n",
            "Eval Error: 0.47978654503822327\n",
            "100% 100/100 [00:06<00:00, 14.46it/s]\n",
            "100% 12/12 [00:00<00:00, 18.81it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.85it/s]\n",
            "100% 4/4 [00:00<00:00, 16.11it/s]\n",
            "Eval Error: 0.5144882798194885\n",
            "100% 100/100 [00:06<00:00, 14.38it/s]\n",
            "100% 12/12 [00:00<00:00, 18.47it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.77it/s]\n",
            "100% 4/4 [00:00<00:00, 15.14it/s]\n",
            "Eval Error: 0.5433018207550049\n",
            "100% 100/100 [00:06<00:00, 14.43it/s]\n",
            "100% 12/12 [00:00<00:00, 18.85it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.52it/s]\n",
            "100% 4/4 [00:00<00:00, 15.92it/s]\n",
            "Eval Error: 0.5373726487159729\n",
            "100% 100/100 [00:06<00:00, 14.34it/s]\n",
            "100% 12/12 [00:00<00:00, 18.59it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.36it/s]\n",
            "100% 4/4 [00:00<00:00, 15.12it/s]\n",
            "Eval Error: 0.5184258818626404\n",
            "100% 100/100 [00:06<00:00, 14.33it/s]\n",
            "100% 12/12 [00:00<00:00, 18.64it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.11it/s]\n",
            "100% 4/4 [00:00<00:00, 15.23it/s]\n",
            "Eval Error: 0.554747998714447\n",
            "100% 100/100 [00:07<00:00, 13.76it/s]\n",
            "100% 12/12 [00:00<00:00, 18.69it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.42it/s]\n",
            "100% 4/4 [00:00<00:00, 15.13it/s]\n",
            "Eval Error: 0.6038355231285095\n",
            "100% 100/100 [00:06<00:00, 14.40it/s]\n",
            "100% 12/12 [00:00<00:00, 18.80it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 22.89it/s]\n",
            "100% 4/4 [00:00<00:00, 15.62it/s]\n",
            "Eval Error: 0.6278228759765625\n",
            "100% 100/100 [00:07<00:00, 14.27it/s]\n",
            "100% 12/12 [00:00<00:00, 18.73it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.52it/s]\n",
            "100% 4/4 [00:00<00:00, 15.72it/s]\n",
            "Eval Error: 0.5821331739425659\n",
            "100% 100/100 [00:06<00:00, 14.37it/s]\n",
            "100% 12/12 [00:00<00:00, 18.85it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.55it/s]\n",
            "100% 4/4 [00:00<00:00, 16.27it/s]\n",
            "Eval Error: 0.6336096525192261\n",
            "100% 100/100 [00:06<00:00, 14.52it/s]\n",
            "100% 12/12 [00:00<00:00, 18.84it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.09it/s]\n",
            "100% 4/4 [00:00<00:00, 15.52it/s]\n",
            "Eval Error: 0.6308932304382324\n",
            "100% 100/100 [00:06<00:00, 14.43it/s]\n",
            "100% 12/12 [00:00<00:00, 18.89it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.66it/s]\n",
            "100% 4/4 [00:00<00:00, 16.22it/s]\n",
            "Eval Error: 0.672029435634613\n",
            "100% 100/100 [00:06<00:00, 14.48it/s]\n",
            "100% 12/12 [00:00<00:00, 18.66it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.96it/s]\n",
            "100% 4/4 [00:00<00:00, 15.75it/s]\n",
            "Eval Error: 0.6479342579841614\n",
            "100% 100/100 [00:06<00:00, 14.47it/s]\n",
            "100% 12/12 [00:00<00:00, 18.63it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.68it/s]\n",
            "100% 4/4 [00:00<00:00, 15.99it/s]\n",
            "Eval Error: 0.6963725090026855\n",
            "100% 100/100 [00:06<00:00, 14.44it/s]\n",
            "100% 12/12 [00:00<00:00, 18.73it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.01it/s]\n",
            "100% 4/4 [00:00<00:00, 15.44it/s]\n",
            "Eval Error: 0.7182514071464539\n",
            "100% 100/100 [00:06<00:00, 14.44it/s]\n",
            "100% 12/12 [00:00<00:00, 18.79it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.12it/s]\n",
            "100% 4/4 [00:00<00:00, 15.13it/s]\n",
            "Eval Error: 0.6707970499992371\n",
            "100% 100/100 [00:06<00:00, 14.54it/s]\n",
            "100% 12/12 [00:00<00:00, 18.84it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.76it/s]\n",
            "100% 4/4 [00:00<00:00, 15.37it/s]\n",
            "Eval Error: 0.6738772988319397\n",
            "100% 100/100 [00:06<00:00, 14.37it/s]\n",
            "100% 12/12 [00:00<00:00, 18.61it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.50it/s]\n",
            "100% 4/4 [00:00<00:00, 14.14it/s]\n",
            "Eval Error: 0.7247268557548523\n",
            "100% 100/100 [00:06<00:00, 15.04it/s]\n",
            "100% 12/12 [00:00<00:00, 12.16it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.48it/s]\n",
            "100% 4/4 [00:00<00:00, 15.63it/s]\n",
            "Eval Error: 0.6595658659934998\n",
            "100% 100/100 [00:06<00:00, 15.07it/s]\n",
            "100% 12/12 [00:00<00:00, 18.90it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.44it/s]\n",
            "100% 4/4 [00:00<00:00, 15.91it/s]\n",
            "Eval Error: 0.7164942622184753\n",
            "100% 100/100 [00:06<00:00, 14.38it/s]\n",
            "100% 12/12 [00:00<00:00, 18.89it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.25it/s]\n",
            "100% 4/4 [00:00<00:00, 15.41it/s]\n",
            "Eval Error: 0.7774465084075928\n",
            "100% 100/100 [00:07<00:00, 13.83it/s]\n",
            "100% 12/12 [00:00<00:00, 18.73it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.81it/s]\n",
            "100% 4/4 [00:00<00:00, 15.15it/s]\n",
            "Eval Error: 0.7932573556900024\n",
            "100% 100/100 [00:07<00:00, 14.21it/s]\n",
            "100% 12/12 [00:00<00:00, 18.47it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.84it/s]\n",
            "100% 4/4 [00:00<00:00, 15.53it/s]\n",
            "Eval Error: 0.7676845788955688\n",
            "100% 100/100 [00:06<00:00, 14.47it/s]\n",
            "100% 12/12 [00:00<00:00, 18.47it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.73it/s]\n",
            "100% 4/4 [00:00<00:00, 15.34it/s]\n",
            "Eval Error: 0.7354715466499329\n",
            "100% 100/100 [00:06<00:00, 14.58it/s]\n",
            "100% 12/12 [00:00<00:00, 18.89it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.60it/s]\n",
            "100% 4/4 [00:00<00:00, 15.52it/s]\n",
            "Eval Error: 0.7945418357849121\n",
            "100% 100/100 [00:06<00:00, 14.43it/s]\n",
            "100% 12/12 [00:00<00:00, 18.84it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.71it/s]\n",
            "100% 4/4 [00:00<00:00, 16.09it/s]\n",
            "Eval Error: 0.7789210677146912\n",
            "100% 100/100 [00:06<00:00, 14.47it/s]\n",
            "100% 12/12 [00:00<00:00, 12.06it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.57it/s]\n",
            "100% 4/4 [00:00<00:00, 15.02it/s]\n",
            "Eval Error: 0.8348385095596313\n",
            "100% 100/100 [00:06<00:00, 15.21it/s]\n",
            "100% 12/12 [00:00<00:00, 19.79it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.91it/s]\n",
            "100% 4/4 [00:00<00:00, 16.35it/s]\n",
            "Eval Error: 0.8021721839904785\n",
            "100% 100/100 [00:06<00:00, 15.23it/s]\n",
            "100% 12/12 [00:00<00:00, 20.07it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.63it/s]\n",
            "100% 4/4 [00:00<00:00, 16.22it/s]\n",
            "Eval Error: 0.9089290499687195\n",
            "100% 100/100 [00:06<00:00, 15.32it/s]\n",
            "100% 12/12 [00:00<00:00, 19.68it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.16it/s]\n",
            "100% 4/4 [00:00<00:00, 16.46it/s]\n",
            "Eval Error: 0.8655353784561157\n",
            "100% 100/100 [00:06<00:00, 15.11it/s]\n",
            "100% 12/12 [00:00<00:00, 19.68it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.04it/s]\n",
            "100% 4/4 [00:00<00:00, 16.43it/s]\n",
            "Eval Error: 0.8448125720024109\n",
            "100% 100/100 [00:06<00:00, 15.20it/s]\n",
            "100% 12/12 [00:00<00:00, 19.08it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.04it/s]\n",
            "100% 4/4 [00:00<00:00, 16.10it/s]\n",
            "Eval Error: 0.8062901496887207\n",
            "100% 100/100 [00:06<00:00, 15.20it/s]\n",
            "100% 12/12 [00:00<00:00, 18.30it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.28it/s]\n",
            "100% 4/4 [00:00<00:00, 16.05it/s]\n",
            "Eval Error: 0.8492515683174133\n",
            "100% 100/100 [00:06<00:00, 15.13it/s]\n",
            "100% 12/12 [00:00<00:00, 19.89it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.00it/s]\n",
            "100% 4/4 [00:00<00:00, 16.24it/s]\n",
            "Eval Error: 0.8719722628593445\n",
            "100% 100/100 [00:06<00:00, 15.23it/s]\n",
            "100% 12/12 [00:00<00:00, 19.14it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.93it/s]\n",
            "100% 4/4 [00:00<00:00, 14.80it/s]\n",
            "Eval Error: 0.9057996869087219\n",
            "100% 100/100 [00:06<00:00, 15.07it/s]\n",
            "100% 12/12 [00:00<00:00, 19.33it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.91it/s]\n",
            "100% 4/4 [00:00<00:00, 16.22it/s]\n",
            "Eval Error: 0.8803203701972961\n",
            "100% 100/100 [00:06<00:00, 15.20it/s]\n",
            "100% 12/12 [00:00<00:00, 19.81it/s]\n",
            "Evaluating...\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.66it/s]\n",
            "100% 4/4 [00:00<00:00, 16.32it/s]\n",
            "Eval Error: 0.9141160845756531\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading wandb-summary.json 98B/98B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading output.log 21.4KB/21.4KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading wandb-summary.json 98B/98B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading output.log 21.4KB/21.4KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading wandb-summary.json 98B/98B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading output.log 21.4KB/21.4KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading wandb-summary.json 98B/98B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading output.log 21.4KB/21.4KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading wandb-summary.json 98B/98B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading output.log 21.4KB/21.4KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading wandb-summary.json 98B/98B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading output.log 21.4KB/21.4KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading wandb-summary.json 98B/98B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading output.log 21.4KB/21.4KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading wandb-summary.json 98B/98B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading output.log 21.4KB/21.4KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading wandb-summary.json 98B/98B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading output.log 21.4KB/21.4KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading wandb-summary.json 98B/98B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading output.log 21.4KB/21.4KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading history steps 98-99, summary, console lines 592-603 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading history steps 98-99, summary, console lines 592-603 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: step ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: step 99\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mjamba_run\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics/runs/k19g91aj\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251206_224240-k19g91aj/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 1. Ensure we are in the correct directory\n",
        "%cd /content/neural-robot-dynamics/train\n",
        "\n",
        "# 2. Define the path to your model (using the one we found earlier)\n",
        "model_path = \"../data/logs/jamba/nn/best_eval_model.pt\"\n",
        "\n",
        "print(f\" USING MODEL AT: {model_path}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# --- 1. LONG-HORIZON PASSIVE MOTION EVALUATION ---\n",
        "print(\"\\n Running Passive Motion Evaluation (Horizon 100)...\")\n",
        "!python ../eval/eval_passive/eval_passive_motion.py \\\n",
        "    --env-name Cartpole \\\n",
        "    --model-path \"{model_path}\" \\\n",
        "    --env-mode neural \\\n",
        "    --num-envs 2048 \\\n",
        "    --num-rollouts 2048 \\\n",
        "    --rollout-horizon 100 \\\n",
        "    --seed 500 \\\n",
        "    --wandb-project neural-robot-dynamics \\\n",
        "    --wandb-name jamba_passive_eval\n",
        "\n",
        "# --- 2. RL POLICY EVALUATION ---\n",
        "print(\"\\n Running RL Policy Evaluation...\")\n",
        "rl_cfg = os.path.abspath('../eval/eval_rl/cfg/Cartpole/cartpole.yaml')\n",
        "playback = os.path.abspath('../pretrained_models/RL_policies/Cartpole/0/nn/CartpolePPO.pth')\n",
        "\n",
        "!python ../eval/eval_rl/run_rl.py \\\n",
        "    --rl-cfg \"{rl_cfg}\" \\\n",
        "    --playback \"{playback}\" \\\n",
        "    --num-envs 2048 \\\n",
        "    --num-games 2048 \\\n",
        "    --env-mode neural \\\n",
        "    --wandb-project neural-robot-dynamics \\\n",
        "    --wandb-name jamba_rl_eval \\\n",
        "    --nerd-model-path \"{model_path}\"\n",
        "\n",
        "# --- 3. INFERENCE SPEED (FPS) EVALUATION ---\n",
        "print(\"\\nRunning FPS Evaluation...\")\n",
        "!python ../eval/eval_fps/eval_fps.py \\\n",
        "    --env-name Cartpole \\\n",
        "    --num-envs 2048 \\\n",
        "    --rollout-horizon 100 \\\n",
        "    --env-mode neural \\\n",
        "    --model-path \"{model_path}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQVWVnvE7APT",
        "outputId": "2d729f92-624d-4ca6-ca6c-401f37713755"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/neural-robot-dynamics/train\n",
            " USING MODEL AT: ../data/logs/jamba/nn/best_eval_model.pt\n",
            "--------------------------------------------------\n",
            "\n",
            " Running Passive Motion Evaluation (Horizon 100)...\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-40GB\" (40 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  799104\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 308.98it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.70 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.36 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.49 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.29 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.38 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.82 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:00<00:00,  2.51it/s]\n",
            "100% 1/1 [00:01<00:00,  1.01s/it]\n",
            "=========================================\n",
            "Base position error mean       = 0.500738\n",
            "Base position error std        = 0.522774\n",
            "Joint position error mean      = 0.278943 rad (15.982231 deg)\n",
            "Joint position Error per dof   = tensor([0.278943], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhargaveekc\u001b[0m (\u001b[33mbhargaveekc-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m setting up run paxina72 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m setting up run paxina72 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m setting up run paxina72 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251206_232700-paxina72\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mjamba_passive_eval\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics/runs/paxina72\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading wandb-summary.json 221B/221B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading config.yaml 2.7KB/2.7KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading wandb-summary.json 221B/221B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading config.yaml 2.7KB/2.7KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading wandb-summary.json 221B/221B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading config.yaml 2.7KB/2.7KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading wandb-summary.json 221B/221B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading config.yaml 2.7KB/2.7KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading wandb-summary.json 221B/221B (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading config.yaml 2.7KB/2.7KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 0.50074\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 0.52277\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.27894\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mjamba_passive_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics/runs/paxina72\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251206_232700-paxina72/logs\u001b[0m\n",
            "\n",
            " Running RL Policy Evaluation...\n",
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "2025-12-06 23:27:11.227522: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-06 23:27:11.245064: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765063631.266183   18545 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765063631.272516   18545 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765063631.288667   18545 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765063631.288693   18545 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765063631.288696   18545 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765063631.288698   18545 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-06 23:27:11.293327: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-40GB\" (40 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 301.92it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.77 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.38 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.52 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/gym/spaces/box.py:128: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
            "self.seed = 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhargaveekc\u001b[0m (\u001b[33mbhargaveekc-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "/usr/local/lib/python3.12/dist-packages/wandb/analytics/sentry.py:279: DeprecationWarning: The `Scope.user` setter is deprecated in favor of `Scope.set_user()`.\n",
            "  self.scope.user = {\"email\": email}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m setting up run hxrn07eq (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m setting up run hxrn07eq (0.2s)\n",
            "/usr/local/lib/python3.12/dist-packages/wandb/analytics/sentry.py:279: DeprecationWarning: The `Scope.user` setter is deprecated in favor of `Scope.set_user()`.\n",
            "  self.scope.user = {\"email\": email}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251206_232725-hxrn07eq\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mjamba_rl_eval\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics/runs/hxrn07eq\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "Started to play\n",
            "{'observation_space': Box(-100.0, 100.0, (4,), float32), 'action_space': Box(-1.0, 1.0, (1,), float32), 'agents': 1, 'value_size': 1}\n",
            "build mlp: 4\n",
            "RunningMeanStd:  (1,)\n",
            "RunningMeanStd:  (4,)\n",
            "=> loading checkpoint '/content/neural-robot-dynamics/pretrained_models/RL_policies/Cartpole/0/nn/CartpolePPO.pth'\n",
            "Module warp.sim.articulation 770a52a load on device 'cuda:0' took 0.83 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.38 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.35 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.82 ms  (cached)\n",
            "Module envs.rlgames_env_wrapper 947f136 load on device 'cuda:0' took 0.41 ms  (cached)\n",
            "Module envs.warp_sim_envs.wrapper_utils 37d6d77 load on device 'cuda:0' took 0.52 ms  (cached)\n",
            "reward: -160.6840057373047 steps: 78.0\n",
            "reward: -352.2969055175781 steps: 79.0\n",
            "reward: -304.056396484375 steps: 80.0\n",
            "reward: -362.86346435546875 steps: 81.0\n",
            "reward: -251.212890625 steps: 82.0\n",
            "reward: -397.0332336425781 steps: 83.0\n",
            "reward: -291.2057189941406 steps: 84.0\n",
            "reward: -211.8245086669922 steps: 85.0\n",
            "reward: -446.0665588378906 steps: 86.0\n",
            "reward: -334.714111328125 steps: 87.0\n",
            "reward: -267.4123840332031 steps: 88.0\n",
            "reward: -251.6917236328125 steps: 89.0\n",
            "reward: -279.6894287109375 steps: 90.0\n",
            "reward: -322.3987630208333 steps: 91.0\n",
            "reward: -354.0389404296875 steps: 92.0\n",
            "reward: -306.4928894042969 steps: 93.0\n",
            "reward: -273.1344943576389 steps: 94.0\n",
            "reward: -295.84482828776044 steps: 95.0\n",
            "reward: -344.247216796875 steps: 96.0\n",
            "reward: -326.448291015625 steps: 97.0\n",
            "reward: -128.92855224609374 steps: 98.0\n",
            "reward: -406.108642578125 steps: 99.0\n",
            "reward: -363.3544189453125 steps: 100.0\n",
            "reward: -233.61529541015625 steps: 101.0\n",
            "reward: -295.8368733723958 steps: 102.0\n",
            "reward: -363.11087472098217 steps: 103.0\n",
            "reward: -262.5483805338542 steps: 104.0\n",
            "reward: -350.989013671875 steps: 105.0\n",
            "reward: -320.51265092329544 steps: 106.0\n",
            "reward: -434.57448508522725 steps: 107.0\n",
            "reward: -223.4816131591797 steps: 108.0\n",
            "reward: -285.1396484375 steps: 109.0\n",
            "reward: -339.942724609375 steps: 110.0\n",
            "reward: -246.79610188802084 steps: 111.0\n",
            "reward: -241.372998046875 steps: 112.0\n",
            "reward: -308.42958984375 steps: 113.0\n",
            "reward: -268.8241780598958 steps: 114.0\n",
            "reward: -428.176025390625 steps: 115.0\n",
            "reward: -327.351123046875 steps: 116.0\n",
            "reward: -266.2340901692708 steps: 117.0\n",
            "reward: -382.05560302734375 steps: 118.0\n",
            "reward: -351.29853959517044 steps: 119.0\n",
            "reward: -425.42225864955356 steps: 120.0\n",
            "reward: -160.33902994791666 steps: 121.0\n",
            "reward: -279.87986061789775 steps: 122.0\n",
            "reward: -314.2152654474432 steps: 123.0\n",
            "reward: -284.94198330965907 steps: 124.0\n",
            "reward: -369.2940673828125 steps: 125.0\n",
            "reward: -307.0107727050781 steps: 126.0\n",
            "reward: -253.0951482599432 steps: 127.0\n",
            "reward: -267.72713797433033 steps: 128.0\n",
            "reward: -382.90678267045456 steps: 129.0\n",
            "reward: -387.8384765625 steps: 130.0\n",
            "reward: -330.67983774038464 steps: 131.0\n",
            "reward: -452.73031850961536 steps: 132.0\n",
            "reward: -356.81884765625 steps: 133.0\n",
            "reward: -376.07874348958336 steps: 134.0\n",
            "reward: -276.01258680555554 steps: 135.0\n",
            "reward: -341.7696533203125 steps: 136.0\n",
            "reward: -325.11232503255206 steps: 137.0\n",
            "reward: -379.7715418198529 steps: 138.0\n",
            "reward: -341.89634874131946 steps: 139.0\n",
            "reward: -308.27215576171875 steps: 140.0\n",
            "reward: -298.7823079427083 steps: 141.0\n",
            "reward: -369.42900390625 steps: 142.0\n",
            "reward: -404.7186686197917 steps: 143.0\n",
            "reward: -294.02783203125 steps: 144.0\n",
            "reward: -346.07717063210225 steps: 145.0\n",
            "reward: -506.091064453125 steps: 146.0\n",
            "reward: -542.4576631433823 steps: 147.0\n",
            "reward: -381.05765474759613 steps: 148.0\n",
            "reward: -426.8181640625 steps: 149.0\n",
            "reward: -376.4850408380682 steps: 150.0\n",
            "reward: -356.2790715144231 steps: 151.0\n",
            "reward: -379.01060267857144 steps: 152.0\n",
            "reward: -364.28202097039474 steps: 153.0\n",
            "reward: -294.3308837890625 steps: 154.0\n",
            "reward: -390.4462316176471 steps: 155.0\n",
            "reward: -283.5053013392857 steps: 156.0\n",
            "reward: -269.4056091308594 steps: 157.0\n",
            "reward: -383.46390474759613 steps: 158.0\n",
            "reward: -392.14886474609375 steps: 159.0\n",
            "reward: -392.01728515625 steps: 160.0\n",
            "reward: -210.22966120793268 steps: 161.0\n",
            "reward: -388.587158203125 steps: 162.0\n",
            "reward: -349.8456169577206 steps: 163.0\n",
            "reward: -407.84677734375 steps: 164.0\n",
            "reward: -236.93014322916667 steps: 165.0\n",
            "reward: -151.7664794921875 steps: 166.0\n",
            "reward: -206.14013671875 steps: 167.0\n",
            "reward: -246.55470377604166 steps: 168.0\n",
            "reward: -461.390380859375 steps: 169.0\n",
            "reward: -72.37591083233173 steps: 170.0\n",
            "reward: -380.6244419642857 steps: 171.0\n",
            "reward: -225.84932084517047 steps: 172.0\n",
            "reward: -424.186328125 steps: 173.0\n",
            "reward: -297.8013916015625 steps: 174.0\n",
            "reward: -211.97634055397728 steps: 175.0\n",
            "reward: -171.19198608398438 steps: 176.0\n",
            "reward: -277.790185546875 steps: 177.0\n",
            "reward: -420.0023716517857 steps: 178.0\n",
            "reward: -387.6127068014706 steps: 179.0\n",
            "reward: -359.1139322916667 steps: 170.0\n",
            "reward: -255.15720436789772 steps: 181.0\n",
            "reward: -259.3576931423611 steps: 182.0\n",
            "reward: -597.0937093098959 steps: 183.0\n",
            "reward: -485.75620814732144 steps: 184.0\n",
            "reward: -335.92769949776783 steps: 171.5\n",
            "reward: -239.66864013671875 steps: 186.0\n",
            "reward: -388.8352614182692 steps: 180.0\n",
            "reward: -225.58805338541666 steps: 188.0\n",
            "reward: -563.0012817382812 steps: 189.0\n",
            "reward: -517.4173177083334 steps: 160.0\n",
            "reward: -530.22314453125 steps: 179.0\n",
            "reward: -335.0250767299107 steps: 185.14285714285714\n",
            "reward: -240.87798200334822 steps: 180.0\n",
            "reward: -374.9922688802083 steps: 194.0\n",
            "reward: -342.47677176339283 steps: 195.0\n",
            "reward: -231.99393717447916 steps: 196.0\n",
            "reward: -305.37451171875 steps: 186.4\n",
            "reward: -174.83847045898438 steps: 185.625\n",
            "reward: -637.6229248046875 steps: 199.0\n",
            "reward: -378.050048828125 steps: 200.0\n",
            "reward: -344.80483774038464 steps: 192.53846153846155\n",
            "reward: -455.5507507324219 steps: 202.0\n",
            "reward: -269.462890625 steps: 127.5\n",
            "reward: -238.08611188616072 steps: 204.0\n",
            "reward: -616.4007161458334 steps: 205.0\n",
            "reward: -422.67768012152777 steps: 195.0\n",
            "reward: -408.3990478515625 steps: 180.5\n",
            "reward: -522.8064778645834 steps: 152.33333333333334\n",
            "reward: -465.4373372395833 steps: 209.0\n",
            "reward: -550.2294573102679 steps: 189.71428571428572\n",
            "reward: -577.8367513020834 steps: 193.83333333333334\n",
            "reward: -436.52675083705356 steps: 198.14285714285714\n",
            "reward: -457.54672475961536 steps: 204.15384615384616\n",
            "reward: -338.63031684027777 steps: 214.0\n",
            "reward: -540.7831333705357 steps: 215.0\n",
            "reward: -443.53510199652777 steps: 193.55555555555554\n",
            "reward: -543.474365234375 steps: 207.08333333333334\n",
            "reward: -401.88243272569446 steps: 203.88888888888889\n",
            "reward: -356.3893229166667 steps: 199.83333333333334\n",
            "reward: -299.774169921875 steps: 163.125\n",
            "reward: -648.936083984375 steps: 197.8\n",
            "reward: -534.2021484375 steps: 161.14285714285714\n",
            "reward: -477.5879720052083 steps: 191.58333333333334\n",
            "reward: -384.97579520089283 steps: 209.71428571428572\n",
            "reward: -526.5076032366071 steps: 212.28571428571428\n",
            "reward: -577.4984266493055 steps: 213.0\n",
            "reward: -147.8690740411932 steps: 167.8181818181818\n",
            "reward: -460.2941196986607 steps: 180.85714285714286\n",
            "reward: -504.6146484375 steps: 201.4\n",
            "reward: -414.99351283482144 steps: 206.42857142857142\n",
            "reward: -115.40043131510417 steps: 208.33333333333334\n",
            "reward: -478.923046875 steps: 180.5\n",
            "reward: -452.573486328125 steps: 200.33333333333334\n",
            "reward: -329.0458984375 steps: 209.0\n",
            "reward: -353.5266810825893 steps: 201.0\n",
            "reward: -315.5262340198864 steps: 190.54545454545453\n",
            "reward: -391.8709309895833 steps: 173.16666666666666\n",
            "reward: -468.56277901785717 steps: 146.28571428571428\n",
            "reward: -524.0174560546875 steps: 192.75\n",
            "reward: -570.9080287388393 steps: 212.85714285714286\n",
            "reward: -389.0879150390625 steps: 210.8\n",
            "reward: -93.6614990234375 steps: 170.5\n",
            "reward: -364.11322021484375 steps: 200.125\n",
            "reward: -496.68585205078125 steps: 206.0\n",
            "reward: -493.5007990056818 steps: 151.45454545454547\n",
            "reward: -423.0569661458333 steps: 210.58333333333334\n",
            "reward: -161.31875610351562 steps: 211.125\n",
            "reward: -487.826953125 steps: 223.3\n",
            "reward: -757.7757161458334 steps: 233.66666666666666\n",
            "reward: -340.88589242788464 steps: 206.92307692307693\n",
            "reward: -409.9283854166667 steps: 197.88888888888889\n",
            "reward: -510.28045654296875 steps: 179.625\n",
            "reward: -123.11916097005208 steps: 157.33333333333334\n",
            "reward: -329.48464133522725 steps: 156.0909090909091\n",
            "reward: -179.30554841694078 steps: 197.1578947368421\n",
            "reward: -286.31923421223956 steps: 186.0\n",
            "reward: -381.4345431857639 steps: 197.44444444444446\n",
            "reward: -599.1305881076389 steps: 195.55555555555554\n",
            "reward: -419.47384207589283 steps: 200.71428571428572\n",
            "reward: -340.62667410714283 steps: 154.42857142857142\n",
            "reward: -316.9469970703125 steps: 203.0\n",
            "reward: -285.278564453125 steps: 160.875\n",
            "reward: -355.41231863839283 steps: 190.71428571428572\n",
            "reward: -313.35589599609375 steps: 218.875\n",
            "reward: -345.3259089543269 steps: 223.07692307692307\n",
            "reward: -170.93740844726562 steps: 178.5\n",
            "reward: -271.6314290364583 steps: 182.33333333333334\n",
            "reward: -180.32835388183594 steps: 184.875\n",
            "reward: -313.79623135653407 steps: 150.54545454545453\n",
            "reward: -392.19122314453125 steps: 217.875\n",
            "reward: -443.5878601074219 steps: 211.5\n",
            "reward: -178.07919311523438 steps: 184.25\n",
            "reward: -244.25013950892858 steps: 189.78571428571428\n",
            "reward: -546.864013671875 steps: 216.21428571428572\n",
            "reward: -469.5873046875 steps: 186.2\n",
            "reward: -403.09979248046875 steps: 200.375\n",
            "reward: -570.082373046875 steps: 174.4\n",
            "reward: -284.5803527832031 steps: 138.0\n",
            "reward: -229.6897638494318 steps: 165.8181818181818\n",
            "reward: -379.26907784598217 steps: 182.64285714285714\n",
            "reward: -307.9517822265625 steps: 171.4\n",
            "reward: -393.67520419034093 steps: 166.9090909090909\n",
            "reward: -590.8170572916666 steps: 169.5\n",
            "reward: -248.181494140625 steps: 169.4\n",
            "reward: -478.968310546875 steps: 184.5\n",
            "reward: -462.4034423828125 steps: 208.25\n",
            "reward: -364.5673828125 steps: 173.66666666666666\n",
            "reward: -293.0655628551136 steps: 176.9090909090909\n",
            "reward: -613.28662109375 steps: 190.3\n",
            "reward: -444.5166766826923 steps: 178.84615384615384\n",
            "reward: -411.05944010416664 steps: 196.8\n",
            "reward: -295.505419921875 steps: 138.2\n",
            "reward: -269.18228426846593 steps: 200.45454545454547\n",
            "reward: -268.72677176339283 steps: 232.0\n",
            "reward: -388.87684461805554 steps: 153.77777777777777\n",
            "reward: -403.555712890625 steps: 174.4\n",
            "reward: -315.1225341796875 steps: 214.5\n",
            "reward: -948.3671875 steps: 200.33333333333334\n",
            "reward: -512.3338216145834 steps: 188.66666666666666\n",
            "-738871.2942047119\n",
            "av reward: -359.89834106415583 av steps: 164.39259620068194\n",
            "visited states range:\n",
            "State 0: [-4.057577133178711, 4.070529460906982]\n",
            "State 1: [-3.1415927410125732, 3.141592502593994]\n",
            "State 2: [-4.080461502075195, 4.919192790985107]\n",
            "State 3: [-9.22481918334961, 9.590914726257324]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading output.log 10.4KB/10.4KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading wandb-summary.json 39B/39B (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading output.log 10.4KB/10.4KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading wandb-summary.json 39B/39B (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading output.log 10.4KB/10.4KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading wandb-summary.json 39B/39B (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading output.log 10.4KB/10.4KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading wandb-summary.json 39B/39B (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading output.log 10.4KB/10.4KB (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading wandb-summary.json 39B/39B (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading output.log 10.4KB/10.4KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading wandb-summary.json 39B/39B (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading config.yaml 4.4KB/4.4KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading output.log 10.4KB/10.4KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading wandb-summary.json 39B/39B (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading config.yaml 4.4KB/4.4KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading output.log 10.4KB/10.4KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading wandb-summary.json 39B/39B (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading config.yaml 4.4KB/4.4KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading output.log 10.4KB/10.4KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading wandb-summary.json 39B/39B (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading config.yaml 4.4KB/4.4KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading output.log 10.4KB/10.4KB (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading wandb-summary.json 39B/39B (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading config.yaml 4.4KB/4.4KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading summary, console lines 1-240 (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading summary, console lines 1-240 (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading summary, console lines 1-240 (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading summary, console lines 1-240 (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mjamba_rl_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics/runs/hxrn07eq\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251206_232725-hxrn07eq/logs\u001b[0m\n",
            "\n",
            "Running FPS Evaluation...\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-40GB\" (40 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 302.14it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.83 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.41 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.53 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.33 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.42 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.85 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:00<00:00,  2.27it/s]\n",
            "100% 1/1 [00:00<00:00,  1.68it/s]\n",
            "time(collision_detection): 0.000 sec, time(dynamics): 0.508 sec\n",
            "FPS: 344103.6289388949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "import re\n",
        "from IPython.display import display\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# 1. We explicitly tell it to use your Jamba model\n",
        "model_name = \"Jamba\"\n",
        "model_path = \"../data/logs/jamba/nn/best_eval_model.pt\"\n",
        "\n",
        "# 2. RL Configuration\n",
        "rl_cfg = os.path.abspath('../eval/eval_rl/cfg/Cartpole/cartpole.yaml')\n",
        "playback_path = os.path.abspath('../pretrained_models/RL_policies/Cartpole/0/nn/CartpolePPO.pth')\n",
        "\n",
        "print(f\" Target Model: {model_path}\")\n",
        "\n",
        "# --- HELPER FUNCTION ---\n",
        "def run_rl_eval(label, model_arg):\n",
        "    \"\"\"Runs the RL evaluation script and captures the reward.\"\"\"\n",
        "    cmd = [\n",
        "        \"python\", \"../eval/eval_rl/run_rl.py\",\n",
        "        \"--rl-cfg\", rl_cfg,\n",
        "        \"--playback\", playback_path,\n",
        "        \"--num-envs\", \"2048\",\n",
        "        \"--num-games\", \"2048\",\n",
        "        \"--wandb-project\", \"neural-robot-dynamics\",\n",
        "        \"--wandb-name\", f\"eval_{label.lower()}\",\n",
        "        \"--env-mode\", \"neural\"\n",
        "    ]\n",
        "\n",
        "    # Add the specific model path argument\n",
        "    cmd.append(\"--nerd-model-path\")\n",
        "    cmd.append(model_arg)\n",
        "\n",
        "    print(f\"\\n Running Evaluation for {label}...\")\n",
        "    try:\n",
        "        # Run the command and capture output\n",
        "        result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
        "\n",
        "        # Parse the output for the reward (Avg Reward: X.XX)\n",
        "        # We look for the standard output pattern from run_rl.py\n",
        "        output = result.stdout\n",
        "        match = re.search(r'Mean Reward:\\s*([-\\d\\.]+)', output)\n",
        "        if not match:\n",
        "             match = re.search(r'av reward:\\s*([-\\d\\.]+)', output)\n",
        "\n",
        "        if match:\n",
        "            reward = float(match.group(1))\n",
        "            print(f\" Score: {reward}\")\n",
        "            return reward\n",
        "        else:\n",
        "            print(\" Could not parse reward from output.\")\n",
        "            print(\"Tail of output:\", output[-500:]) # Show last 500 chars for debug\n",
        "            return None\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\" Error running evaluation for {label}\")\n",
        "        print(e.stderr)\n",
        "        return None\n",
        "\n",
        "# --- EXECUTION ---\n",
        "results = []\n",
        "\n",
        "# 1. Evaluate your JAMBA model\n",
        "jamba_reward = run_rl_eval(model_name, model_path)\n",
        "\n",
        "if jamba_reward is not None:\n",
        "    results.append({\n",
        "        'Model': model_name,\n",
        "        'Reward': jamba_reward,\n",
        "        'Note': 'Neural Simulation'\n",
        "    })\n",
        "\n",
        "# 2. Compare to Ground Truth (Optional - runs the physics engine directly)\n",
        "# This gives you the \"Perfect Score\" to compare against\n",
        "print(\"\\n Running Ground Truth Baseline (Physics Engine)...\")\n",
        "try:\n",
        "    # Running without --nerd-model-path defaults to ground truth physics in some versions,\n",
        "    # or we explicitly set env-mode to 'ground_truth' if the script supports it.\n",
        "    # Based on your repo, we use the same script but might need a flag tweak.\n",
        "    # For now, let's just output your model results.\n",
        "    pass\n",
        "except Exception as e:\n",
        "    print(\"Skipping Ground Truth check\")\n",
        "\n",
        "# --- DISPLAY RESULTS ---\n",
        "df = pd.DataFrame(results)\n",
        "print(\"\\nFinal Results:\")\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "3VyoFv0p-zgh",
        "outputId": "ee30fd0b-4612-480a-e52e-44119b1ddd05"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Target Model: ../data/logs/jamba/nn/best_eval_model.pt\n",
            "\n",
            " Running Evaluation for Jamba...\n",
            " Score: -359.89834106415583\n",
            "\n",
            " Running Ground Truth Baseline (Physics Engine)...\n",
            "\n",
            "Final Results:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Model      Reward               Note\n",
              "0  Jamba -359.898341  Neural Simulation"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4757c7fe-0ead-4eb4-86c5-c04d1c83363c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Reward</th>\n",
              "      <th>Note</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jamba</td>\n",
              "      <td>-359.898341</td>\n",
              "      <td>Neural Simulation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4757c7fe-0ead-4eb4-86c5-c04d1c83363c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4757c7fe-0ead-4eb4-86c5-c04d1c83363c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4757c7fe-0ead-4eb4-86c5-c04d1c83363c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_c5ee5e03-6bcc-4561-8fb2-22e7ce7bf502\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c5ee5e03-6bcc-4561-8fb2-22e7ce7bf502 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Jamba\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Reward\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": -359.89834106415583,\n        \"max\": -359.89834106415583,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -359.89834106415583\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Note\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Neural Simulation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}