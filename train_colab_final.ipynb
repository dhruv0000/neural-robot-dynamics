{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "B8R6x04hd4Ei",
      "metadata": {
        "id": "B8R6x04hd4Ei"
      },
      "source": [
        "# Neural Robot Dynamics Training on Colab\n",
        "\n",
        "This notebook demonstrates how to setup the environment, generate a dataset, and train the NeRD model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feb351a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feb351a0",
        "outputId": "93f0cc2c-112c-4c3a-dd47-80f15ec36445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'neural-robot-dynamics'...\n",
            "remote: Enumerating objects: 653, done.\u001b[K\n",
            "remote: Counting objects: 100% (219/219), done.\u001b[K\n",
            "remote: Compressing objects: 100% (146/146), done.\u001b[K\n",
            "remote: Total 653 (delta 122), reused 145 (delta 71), pack-reused 434 (from 1)\u001b[K\n",
            "Receiving objects: 100% (653/653), 21.48 MiB | 17.74 MiB/s, done.\n",
            "Resolving deltas: 100% (209/209), done.\n",
            "Filtering content: 100% (11/11), 202.03 MiB | 44.96 MiB/s, done.\n",
            "/content/neural-robot-dynamics\n",
            "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (4.67.1)\n",
            "Collecting pyglet==2.1.6 (from -r requirements.txt (line 2))\n",
            "  Downloading pyglet-2.1.6-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting ipdb (from -r requirements.txt (line 3))\n",
            "  Downloading ipdb-0.13.13-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting h5py==3.11.0 (from -r requirements.txt (line 4))\n",
            "  Downloading h5py-3.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting pyyaml==6.0.2 (from -r requirements.txt (line 5))\n",
            "  Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting tensorboard==2.14.0 (from -r requirements.txt (line 6))\n",
            "  Downloading tensorboard-2.14.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting matplotlib==3.7.5 (from -r requirements.txt (line 7))\n",
            "  Downloading matplotlib-3.7.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (4.12.0.88)\n",
            "Collecting pycollada==0.9.2 (from -r requirements.txt (line 9))\n",
            "  Downloading pycollada-0.9.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 1.11.0, 1.14.0rc1\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 1.10.0 Requires-Python <3.12,>=3.8; 1.10.0rc1 Requires-Python <3.12,>=3.8; 1.10.0rc2 Requires-Python <3.12,>=3.8; 1.10.1 Requires-Python <3.12,>=3.8; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 1.7.2 Requires-Python >=3.7,<3.11; 1.7.3 Requires-Python >=3.7,<3.11; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11; 1.9.0 Requires-Python >=3.8,<3.12; 1.9.0rc1 Requires-Python >=3.8,<3.12; 1.9.0rc2 Requires-Python >=3.8,<3.12; 1.9.0rc3 Requires-Python >=3.8,<3.12; 1.9.1 Requires-Python >=3.8,<3.12\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement scipy==1.10.1 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0, 1.0.1, 1.1.0, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0, 1.4.1, 1.5.0, 1.5.1, 1.5.2, 1.5.3, 1.5.4, 1.6.0, 1.6.1, 1.9.2, 1.9.3, 1.11.0rc1, 1.11.0rc2, 1.11.1, 1.11.2, 1.11.3, 1.11.4, 1.12.0rc1, 1.12.0rc2, 1.12.0, 1.13.0rc1, 1.13.0, 1.13.1, 1.14.0rc2, 1.14.0, 1.14.1, 1.15.0rc1, 1.15.0rc2, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.16.0rc1, 1.16.0rc2, 1.16.0, 1.16.1, 1.16.2, 1.16.3)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for scipy==1.10.1\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting warp-lang==1.8.0\n",
            "  Downloading warp_lang-1.8.0-py3-none-manylinux_2_28_x86_64.whl.metadata (32 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from warp-lang==1.8.0) (2.0.2)\n",
            "Downloading warp_lang-1.8.0-py3-none-manylinux_2_28_x86_64.whl (129.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m129.9/129.9 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: warp-lang\n",
            "Successfully installed warp-lang-1.8.0\n",
            "Collecting rl_games\n",
            "  Downloading rl-games-1.6.1.tar.gz (14.6 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m144.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML<7.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from rl_games) (6.0.3)\n",
            "Collecting gym<0.24.0,>=0.23.0 (from gym[classic-control]<0.24.0,>=0.23.0->rl_games)\n",
            "  Downloading gym-0.23.1.tar.gz (626 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m626.2/626.2 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opencv-python<5.0.0,>=4.5.5 in /usr/local/lib/python3.12/dist-packages (from rl_games) (4.12.0.88)\n",
            "Requirement already satisfied: psutil<6.0.0,>=5.9.0 in /usr/local/lib/python3.12/dist-packages (from rl_games) (5.9.5)\n",
            "Collecting setproctitle<2.0.0,>=1.2.2 (from rl_games)\n",
            "  Downloading setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: tensorboard<3.0.0,>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from rl_games) (2.19.0)\n",
            "Collecting tensorboardX<3.0,>=2.5 (from rl_games)\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting wandb<0.13.0,>=0.12.11 (from rl_games)\n",
            "  Downloading wandb-0.12.21-py2.py3-none-any.whl.metadata (7.2 kB)\n",
            "INFO: pip is looking at multiple versions of rl-games to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting rl_games\n",
            "  Downloading rl-games-1.6.0.tar.gz (14.7 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m130.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading rl_games-1.5.2-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.12/dist-packages (from rl_games) (0.25.2)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from rl_games) (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from rl_games) (2.0.2)\n",
            "Collecting ray>=1.1.0 (from rl_games)\n",
            "  Downloading ray-2.52.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gym>=0.17.2->rl_games) (3.1.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from gym>=0.17.2->rl_games) (0.1.0)\n",
            "Collecting click!=8.3.*,>=7.0 (from ray>=1.1.0->rl_games)\n",
            "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (3.20.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (4.25.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (25.0)\n",
            "Requirement already satisfied: protobuf>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (5.29.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from ray>=1.1.0->rl_games) (2.32.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3.0.0,>=2.8.0->rl_games) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3.0.0,>=2.8.0->rl_games) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3.0.0,>=2.8.0->rl_games) (3.10)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3.0.0,>=2.8.0->rl_games) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3.0.0,>=2.8.0->rl_games) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3.0.0,>=2.8.0->rl_games) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3.0.0,>=2.8.0->rl_games) (3.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->rl_games) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7.0->rl_games) (1.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard<3.0.0,>=2.8.0->rl_games) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=1.1.0->rl_games) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=1.1.0->rl_games) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=1.1.0->rl_games) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=1.1.0->rl_games) (0.30.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->ray>=1.1.0->rl_games) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->ray>=1.1.0->rl_games) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->ray>=1.1.0->rl_games) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->ray>=1.1.0->rl_games) (2025.11.12)\n",
            "Downloading rl_games-1.5.2-py3-none-any.whl (15.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m140.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.52.1-cp312-cp312-manylinux2014_x86_64.whl (72.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.3/72.3 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (32 kB)\n",
            "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX, setproctitle, click, ray, rl_games\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.1\n",
            "    Uninstalling click-8.3.1:\n",
            "      Successfully uninstalled click-8.3.1\n",
            "Successfully installed click-8.2.1 ray-2.52.1 rl_games-1.5.2 setproctitle-1.3.7 tensorboardX-2.6.4\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.23.1)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.12.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.47.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "# 1. Setup Environment\n",
        "!git clone https://github.com/dhruv0000/neural-robot-dynamics.git\n",
        "%cd neural-robot-dynamics\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "!pip install warp-lang==1.8.0\n",
        "!pip install rl_games\n",
        "!pip install wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wandb-setup",
      "metadata": {
        "id": "wandb-setup"
      },
      "outputs": [],
      "source": [
        "# Setup WandB\n",
        "import os\n",
        "import wandb\n",
        "# Assuming wandb_key is defined in the environment variables or you can set it here\n",
        "# For Colab, we can try to get it from userdata or assume it's set\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    os.environ['WANDB_API_KEY'] = userdata.get('wandb_key')\n",
        "except:\n",
        "    os.environ['WANDB_API_KEY'] = 'ba930de3aa5aa346f74adadf2faf616fefde48f2'  # Replace with your actual key if not using Colab\n",
        "    pass\n",
        "\n",
        "wandb_project = 'neural-robot-dynamics-big'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66700684",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66700684",
        "outputId": "3a6b6516-aa20-4fb2-bc8a-5226398c5704"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/neural-robot-dynamics/generate\n",
            "Loading datasets from Google Drive...\n",
            "/content/neural-robot-dynamics\n"
          ]
        }
      ],
      "source": [
        "# 2. Generate Dataset\n",
        "# We generate a smaller dataset for demonstration purposes.\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd generate\n",
        "\n",
        "# Define paths\n",
        "drive_data_dir = '/content/drive/MyDrive/neural-robot-dynamics/data/datasets/Cartpole/'\n",
        "local_data_dir = '../data/datasets/Cartpole/'\n",
        "train_filename = 'trajectory_len-100_train.hdf5'\n",
        "valid_filename = 'trajectory_len-100_valid.hdf5'\n",
        "\n",
        "os.makedirs(local_data_dir, exist_ok=True)\n",
        "os.makedirs(drive_data_dir, exist_ok=True)\n",
        "\n",
        "# Check if data exists in Drive\n",
        "if os.path.exists(os.path.join(drive_data_dir, train_filename)) and os.path.exists(os.path.join(drive_data_dir, valid_filename)):\n",
        "    print(\"Loading datasets from Google Drive...\")\n",
        "    shutil.copy(os.path.join(drive_data_dir, train_filename), local_data_dir)\n",
        "    shutil.copy(os.path.join(drive_data_dir, valid_filename), local_data_dir)\n",
        "else:\n",
        "    print(\"Generating datasets...\")\n",
        "    # Generate Training Data\n",
        "    !python generate_dataset_contact_free.py --env-name Cartpole --num-transitions 1000000 --dataset-dir ../data/datasets/ --dataset-name trajectory_len-100_train.hdf5 --trajectory-length 100 --num-envs 2048 --seed 0\n",
        "\n",
        "    # Generate Validation Data\n",
        "    !python generate_dataset_contact_free.py --env-name Cartpole --num-transitions 100000 --dataset-dir ../data/datasets/ --dataset-name trajectory_len-100_valid.hdf5 --trajectory-length 100 --num-envs 2048 --seed 10\n",
        "\n",
        "    print(\"Saving datasets to Google Drive...\")\n",
        "    shutil.copy(os.path.join(local_data_dir, train_filename), drive_data_dir)\n",
        "    shutil.copy(os.path.join(local_data_dir, valid_filename), drive_data_dir)\n",
        "\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0907b67",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0907b67",
        "outputId": "54801d8d-b3c1-47d7-84d8-d5c47a896c01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'train'\n",
            "/content/neural-robot-dynamics/train\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "2025-12-08 23:01:03.060339: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-08 23:01:03.078109: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765234863.099871  134693 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765234863.106443  134693 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765234863.123023  134693 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765234863.123052  134693 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765234863.123055  134693 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765234863.123058  134693 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-08 23:01:03.127975: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 512 environments: 100% 512/512 [00:01<00:00, 304.72it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 5.53 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.46 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.52 ms  (cached)\n",
            "\u001b[91m [NeuralEnvironment] Created a DUMMY Neural Integrator. \u001b[0m\n",
            "number of parameters: 2.69M\n",
            "Model = \n",
            " ModelMixedInput(\n",
            "  (encoders): ModuleDict(\n",
            "    (low_dim): MLPBase(\n",
            "      (body): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (transformer_model): GPT(\n",
            "    (transformer): ModuleDict(\n",
            "      (wte): Linear(in_features=6, out_features=192, bias=True)\n",
            "      (wpe): Embedding(32, 192)\n",
            "      (drop): Dropout(p=0.0, inplace=False)\n",
            "      (h): ModuleList(\n",
            "        (0-5): 6 x Block(\n",
            "          (ln_1): LayerNorm()\n",
            "          (attn): CausalSelfAttention(\n",
            "            (c_attn): Linear(in_features=192, out_features=576, bias=False)\n",
            "            (c_proj): Linear(in_features=192, out_features=192, bias=False)\n",
            "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ln_2): LayerNorm()\n",
            "          (mlp): MLP(\n",
            "            (c_fc): Linear(in_features=192, out_features=768, bias=False)\n",
            "            (gelu): GELU(approximate='none')\n",
            "            (c_proj): Linear(in_features=768, out_features=192, bias=False)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (ln_f): LayerNorm()\n",
            "    )\n",
            "    (lm_head): Linear(in_features=192, out_features=192, bias=False)\n",
            "  )\n",
            "  (model): MLPDeterministic(\n",
            "    (feature_net): MLPBase(\n",
            "      (body): Sequential(\n",
            "        (0): Linear(in_features=192, out_features=64, bias=True)\n",
            "        (1): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (output_net): Linear(in_features=64, out_features=4, bias=True)\n",
            "  )\n",
            ")\n",
            "# Model Parameters =  2713668\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhargaveekc\u001b[0m (\u001b[33mbhargaveekc-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run ekb59rtc (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run ekb59rtc (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run ekb59rtc (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_230113-ekb59rtc\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbaseline_a\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/ekb59rtc\u001b[0m\n",
            "Computing dataset statistics...\n",
            "Finished computing dataset statistics...\n",
            "100% 5/5 [00:00<00:00, 11.00it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions:   0% 0/4 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.59 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.41 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.45 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.76 ms  (cached)\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 17.98it/s]\n",
            "100% 4/4 [00:00<00:00, 11.66it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.57209951, Rollout MSE Error (joint_q) = 0.01352453 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 0 with MSE error 0.572099506855011. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 0 \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.89558086, itemized = {state_0: 0.00771470, state_1: 0.88243942, state_2: 0.24577379, state_3: 0.27405193, state_MSE: 0.35249496, q_error_norm: 0.28735006, qd_error_norm: 0.52594481} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 1.075 sec, time(other): 0.000 sec, time(dataloader): 0.182 sec, time(compute_loss): 0.271 sec, time(backward): 0.000 sec, time(eval): 0.616 sec \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 0 with loss 0.89558086. \u001b[0m\n",
            "100% 100/100 [00:07<00:00, 12.81it/s]\n",
            "100% 5/5 [00:00<00:00,  9.64it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.67it/s]\n",
            "100% 4/4 [00:00<00:00, 12.58it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.20099531, Rollout MSE Error (joint_q) = 0.00767900 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 1 with MSE error 0.2009953111410141. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 1 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.33578293, itemized = {state_0: 0.00090122, state_1: 0.23504232, state_2: 0.10993255, state_3: 0.21577291, state_MSE: 0.14041223, q_error_norm: 0.07996078, qd_error_norm: 0.37757202} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.13122129, itemized = {state_0: 0.00023638, state_1: 0.14144695, state_2: 0.03987121, state_3: 0.09713446, state_MSE: 0.06967225, q_error_norm: 0.04564683, qd_error_norm: 0.25189314} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.070 sec, time(other): 0.011 sec, time(dataloader): 5.949 sec, time(compute_loss): 1.026 sec, time(backward): 1.315 sec, time(eval): 0.514 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.833612, device='cuda:0'), grad_norm_after_clip: tensor(0.766677, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 1 with loss 0.13122129. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.94it/s]\n",
            "100% 5/5 [00:00<00:00,  9.62it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.78it/s]\n",
            "100% 4/4 [00:00<00:00, 12.90it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.04778396, Rollout MSE Error (joint_q) = 0.00152571 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 2 with MSE error 0.04778395965695381. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 2 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.07784977, itemized = {state_0: 0.00012890, state_1: 0.10841949, state_2: 0.03072318, state_3: 0.04901161, state_MSE: 0.04707077, q_error_norm: 0.03678873, qd_error_norm: 0.19055962} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.03943449, itemized = {state_0: 0.00010771, state_1: 0.04852989, state_2: 0.01374908, state_3: 0.02646928, state_MSE: 0.02221399, q_error_norm: 0.02074887, qd_error_norm: 0.13140666} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.595 sec, time(other): 0.010 sec, time(dataloader): 6.628 sec, time(compute_loss): 1.022 sec, time(backward): 1.205 sec, time(eval): 0.510 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(1.058747, device='cuda:0'), grad_norm_after_clip: tensor(0.921504, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 2 with loss 0.03943449. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.00it/s]\n",
            "100% 5/5 [00:00<00:00, 10.36it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.41it/s]\n",
            "100% 4/4 [00:00<00:00, 12.71it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.16408312, Rollout MSE Error (joint_q) = 0.00401136 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 3 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.04446237, itemized = {state_0: 0.00009478, state_1: 0.08291870, state_2: 0.01734069, state_3: 0.02693067, state_MSE: 0.03182121, q_error_norm: 0.02951885, qd_error_norm: 0.14293754} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.04367107, itemized = {state_0: 0.00020257, state_1: 0.11283457, state_2: 0.01275706, state_3: 0.02866749, state_MSE: 0.03861542, q_error_norm: 0.03579741, qd_error_norm: 0.14785792} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.498 sec, time(other): 0.010 sec, time(dataloader): 6.548 sec, time(compute_loss): 1.025 sec, time(backward): 1.208 sec, time(eval): 0.487 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(1.288813, device='cuda:0'), grad_norm_after_clip: tensor(0.952836, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.81it/s]\n",
            "100% 5/5 [00:00<00:00, 10.38it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.74it/s]\n",
            "100% 4/4 [00:00<00:00, 12.95it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00872442, Rollout MSE Error (joint_q) = 0.00029922 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 4 with MSE error 0.008724423125386238. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 4 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.02390372, itemized = {state_0: 0.00005051, state_1: 0.06203946, state_2: 0.00947769, state_3: 0.01454715, state_MSE: 0.02152870, q_error_norm: 0.02110637, qd_error_norm: 0.10358001} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.02140921, itemized = {state_0: 0.00002505, state_1: 0.05929188, state_2: 0.00801269, state_3: 0.01450899, state_MSE: 0.02045965, q_error_norm: 0.01852077, qd_error_norm: 0.08968023} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.647 sec, time(other): 0.011 sec, time(dataloader): 6.687 sec, time(compute_loss): 1.023 sec, time(backward): 1.198 sec, time(eval): 0.510 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(1.109012, device='cuda:0'), grad_norm_after_clip: tensor(0.899200, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 4 with loss 0.02140921. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.80it/s]\n",
            "100% 5/5 [00:00<00:00, 10.24it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.77it/s]\n",
            "100% 4/4 [00:00<00:00, 12.92it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00938477, Rollout MSE Error (joint_q) = 0.00081199 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 5 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.01735588, itemized = {state_0: 0.00004431, state_1: 0.06563698, state_2: 0.00667234, state_3: 0.00940829, state_MSE: 0.02044048, q_error_norm: 0.02309276, qd_error_norm: 0.08735286} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.01448399, itemized = {state_0: 0.00002208, state_1: 0.09311998, state_2: 0.00574981, state_3: 0.00869816, state_MSE: 0.02689751, q_error_norm: 0.02460221, qd_error_norm: 0.07035465} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.612 sec, time(other): 0.010 sec, time(dataloader): 6.650 sec, time(compute_loss): 1.032 sec, time(backward): 1.245 sec, time(eval): 0.478 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(1.047542, device='cuda:0'), grad_norm_after_clip: tensor(0.851797, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 5 with loss 0.01448399. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.66it/s]\n",
            "100% 5/5 [00:00<00:00, 10.21it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.84it/s]\n",
            "100% 4/4 [00:00<00:00, 12.82it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.01289197, Rollout MSE Error (joint_q) = 0.00045957 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 6 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.01194985, itemized = {state_0: 0.00002577, state_1: 0.04172855, state_2: 0.00505159, state_3: 0.00688906, state_MSE: 0.01342374, q_error_norm: 0.01475895, qd_error_norm: 0.07202219} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00960082, itemized = {state_0: 0.00002367, state_1: 0.05236331, state_2: 0.00310431, state_3: 0.00665297, state_MSE: 0.01553606, q_error_norm: 0.01525382, qd_error_norm: 0.06467393} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.774 sec, time(other): 0.010 sec, time(dataloader): 6.789 sec, time(compute_loss): 1.022 sec, time(backward): 1.216 sec, time(eval): 0.482 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.918094, device='cuda:0'), grad_norm_after_clip: tensor(0.773089, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 6 with loss 0.00960082. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.20it/s]\n",
            "100% 5/5 [00:00<00:00, 10.33it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.63it/s]\n",
            "100% 4/4 [00:00<00:00, 12.83it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.03147876, Rollout MSE Error (joint_q) = 0.00061408 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 7 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00683752, itemized = {state_0: 0.00001580, state_1: 0.03309156, state_2: 0.00270405, state_3: 0.00412588, state_MSE: 0.00998432, q_error_norm: 0.01146918, qd_error_norm: 0.05617454} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.01504175, itemized = {state_0: 0.00001947, state_1: 0.06392192, state_2: 0.00483360, state_3: 0.01117208, state_MSE: 0.01998677, q_error_norm: 0.01736892, qd_error_norm: 0.08227612} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.360 sec, time(other): 0.011 sec, time(dataloader): 6.383 sec, time(compute_loss): 1.032 sec, time(backward): 1.231 sec, time(eval): 0.481 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.716456, device='cuda:0'), grad_norm_after_clip: tensor(0.695638, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.61it/s]\n",
            "100% 5/5 [00:00<00:00, 10.24it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.90it/s]\n",
            "100% 4/4 [00:00<00:00, 12.85it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.02354553, Rollout MSE Error (joint_q) = 0.00063235 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 8 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00632793, itemized = {state_0: 0.00001530, state_1: 0.03367058, state_2: 0.00241844, state_3: 0.00387910, state_MSE: 0.00999586, q_error_norm: 0.01142817, qd_error_norm: 0.05390398} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00948282, itemized = {state_0: 0.00001076, state_1: 0.03389273, state_2: 0.00389130, state_3: 0.00620030, state_MSE: 0.01099877, q_error_norm: 0.01090270, qd_error_norm: 0.06684830} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.790 sec, time(other): 0.010 sec, time(dataloader): 6.806 sec, time(compute_loss): 1.026 sec, time(backward): 1.232 sec, time(eval): 0.480 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.670116, device='cuda:0'), grad_norm_after_clip: tensor(0.643947, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 8 with loss 0.00948282. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.50it/s]\n",
            "100% 5/5 [00:00<00:00, 10.31it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.23it/s]\n",
            "100% 4/4 [00:00<00:00, 12.93it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.01153786, Rollout MSE Error (joint_q) = 0.00026965 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 9 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00546529, itemized = {state_0: 0.00001411, state_1: 0.03255944, state_2: 0.00208310, state_3: 0.00327110, state_MSE: 0.00948193, q_error_norm: 0.01111044, qd_error_norm: 0.04970993} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00540716, itemized = {state_0: 0.00000857, state_1: 0.04083748, state_2: 0.00178452, state_3: 0.00386370, state_MSE: 0.01162357, q_error_norm: 0.01110034, qd_error_norm: 0.04931418} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.841 sec, time(other): 0.011 sec, time(dataloader): 6.883 sec, time(compute_loss): 1.025 sec, time(backward): 1.233 sec, time(eval): 0.475 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.662818, device='cuda:0'), grad_norm_after_clip: tensor(0.640871, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 9 with loss 0.00540716. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.34it/s]\n",
            "100% 5/5 [00:00<00:00, 10.36it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.72it/s]\n",
            "100% 4/4 [00:00<00:00, 12.80it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.02123256, Rollout MSE Error (joint_q) = 0.00049771 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 10 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00612994, itemized = {state_0: 0.00001546, state_1: 0.03090346, state_2: 0.00239347, state_3: 0.00370038, state_MSE: 0.00925320, q_error_norm: 0.01070056, qd_error_norm: 0.05187588} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00699632, itemized = {state_0: 0.00000959, state_1: 0.03696909, state_2: 0.00265991, state_3: 0.00475050, state_MSE: 0.01109728, q_error_norm: 0.01061946, qd_error_norm: 0.06041363} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.977 sec, time(other): 0.010 sec, time(dataloader): 7.032 sec, time(compute_loss): 1.021 sec, time(backward): 1.212 sec, time(eval): 0.482 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.651121, device='cuda:0'), grad_norm_after_clip: tensor(0.603525, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.76it/s]\n",
            "100% 5/5 [00:00<00:00, 10.05it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.21it/s]\n",
            "100% 4/4 [00:00<00:00, 12.94it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00559321, Rollout MSE Error (joint_q) = 0.00011108 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 11 with MSE error 0.005593207664787769. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 11 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00307370, itemized = {state_0: 0.00000774, state_1: 0.02710562, state_2: 0.00120530, state_3: 0.00183583, state_MSE: 0.00753862, q_error_norm: 0.00856734, qd_error_norm: 0.03847224} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00443068, itemized = {state_0: 0.00000557, state_1: 0.02234036, state_2: 0.00143711, state_3: 0.00322846, state_MSE: 0.00675287, q_error_norm: 0.00782582, qd_error_norm: 0.04180152} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.709 sec, time(other): 0.010 sec, time(dataloader): 6.729 sec, time(compute_loss): 1.024 sec, time(backward): 1.208 sec, time(eval): 0.521 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.450390, device='cuda:0'), grad_norm_after_clip: tensor(0.450278, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 11 with loss 0.00443068. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.93it/s]\n",
            "100% 5/5 [00:00<00:00, 10.23it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.41it/s]\n",
            "100% 4/4 [00:00<00:00, 12.79it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.02968231, Rollout MSE Error (joint_q) = 0.00284822 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 12 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00511464, itemized = {state_0: 0.00000935, state_1: 0.03275580, state_2: 0.00190656, state_3: 0.00310383, state_MSE: 0.00944389, q_error_norm: 0.01067924, qd_error_norm: 0.04447663} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.02012926, itemized = {state_0: 0.00002023, state_1: 0.12443014, state_2: 0.00636925, state_3: 0.01400144, state_MSE: 0.03620526, q_error_norm: 0.03151917, qd_error_norm: 0.09336290} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.560 sec, time(other): 0.010 sec, time(dataloader): 6.614 sec, time(compute_loss): 1.018 sec, time(backward): 1.205 sec, time(eval): 0.485 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.606789, device='cuda:0'), grad_norm_after_clip: tensor(0.551270, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.89it/s]\n",
            "100% 5/5 [00:00<00:00, 10.37it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.62it/s]\n",
            "100% 4/4 [00:00<00:00, 12.89it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00334815, Rollout MSE Error (joint_q) = 0.00020949 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 13 with MSE error 0.003348147962242365. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 13 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00633565, itemized = {state_0: 0.00001248, state_1: 0.03820993, state_2: 0.00217271, state_3: 0.00400718, state_MSE: 0.01110058, q_error_norm: 0.01266027, qd_error_norm: 0.04977444} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00488531, itemized = {state_0: 0.00001414, state_1: 0.03851896, state_2: 0.00149931, state_3: 0.00338732, state_MSE: 0.01085493, q_error_norm: 0.01138376, qd_error_norm: 0.04118973} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.609 sec, time(other): 0.010 sec, time(dataloader): 6.620 sec, time(compute_loss): 1.024 sec, time(backward): 1.215 sec, time(eval): 0.516 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.615005, device='cuda:0'), grad_norm_after_clip: tensor(0.597956, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.94it/s]\n",
            "100% 5/5 [00:00<00:00, 10.22it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.24it/s]\n",
            "100% 4/4 [00:00<00:00, 12.97it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00939026, Rollout MSE Error (joint_q) = 0.00016836 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 14 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00213222, itemized = {state_0: 0.00000520, state_1: 0.02268353, state_2: 0.00082817, state_3: 0.00128334, state_MSE: 0.00620006, q_error_norm: 0.00715691, qd_error_norm: 0.03093380} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00794616, itemized = {state_0: 0.00000700, state_1: 0.03389895, state_2: 0.00349237, state_3: 0.00509420, state_MSE: 0.01062313, q_error_norm: 0.00970077, qd_error_norm: 0.05172656} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.537 sec, time(other): 0.010 sec, time(dataloader): 6.578 sec, time(compute_loss): 1.030 sec, time(backward): 1.223 sec, time(eval): 0.479 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.338211, device='cuda:0'), grad_norm_after_clip: tensor(0.335988, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.78it/s]\n",
            "100% 5/5 [00:00<00:00, 10.19it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.93it/s]\n",
            "100% 4/4 [00:00<00:00, 12.99it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00254696, Rollout MSE Error (joint_q) = 0.00004792 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 15 with MSE error 0.0025469642132520676. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 15 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00196697, itemized = {state_0: 0.00000579, state_1: 0.02272114, state_2: 0.00074766, state_3: 0.00112006, state_MSE: 0.00614866, q_error_norm: 0.00753511, qd_error_norm: 0.02943527} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00283511, itemized = {state_0: 0.00000311, state_1: 0.04082357, state_2: 0.00090669, state_3: 0.00212072, state_MSE: 0.01096352, q_error_norm: 0.00954958, qd_error_norm: 0.03147109} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.686 sec, time(other): 0.011 sec, time(dataloader): 6.695 sec, time(compute_loss): 1.034 sec, time(backward): 1.215 sec, time(eval): 0.506 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.325385, device='cuda:0'), grad_norm_after_clip: tensor(0.325385, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 15 with loss 0.00283511. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.96it/s]\n",
            "100% 5/5 [00:00<00:00, 10.24it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.00it/s]\n",
            "100% 4/4 [00:00<00:00, 13.05it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00260914, Rollout MSE Error (joint_q) = 0.00008582 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 16 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00260605, itemized = {state_0: 0.00000787, state_1: 0.02364532, state_2: 0.00097172, state_3: 0.00152974, state_MSE: 0.00653866, q_error_norm: 0.00806696, qd_error_norm: 0.03339375} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00316356, itemized = {state_0: 0.00000524, state_1: 0.02234901, state_2: 0.00098322, state_3: 0.00226785, state_MSE: 0.00640133, q_error_norm: 0.00739054, qd_error_norm: 0.03381567} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.570 sec, time(other): 0.010 sec, time(dataloader): 6.567 sec, time(compute_loss): 1.025 sec, time(backward): 1.221 sec, time(eval): 0.475 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.447701, device='cuda:0'), grad_norm_after_clip: tensor(0.446848, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.80it/s]\n",
            "100% 5/5 [00:00<00:00, 10.17it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.64it/s]\n",
            "100% 4/4 [00:00<00:00, 12.82it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00236560, Rollout MSE Error (joint_q) = 0.00007562 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 17 with MSE error 0.0023655954282730818. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 17 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00154316, itemized = {state_0: 0.00000458, state_1: 0.02083992, state_2: 0.00053493, state_3: 0.00093784, state_MSE: 0.00557932, q_error_norm: 0.00678598, qd_error_norm: 0.02637895} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00266457, itemized = {state_0: 0.00000520, state_1: 0.03851485, state_2: 0.00077057, state_3: 0.00197851, state_MSE: 0.01031728, q_error_norm: 0.00960630, qd_error_norm: 0.02867570} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.738 sec, time(other): 0.010 sec, time(dataloader): 6.692 sec, time(compute_loss): 1.023 sec, time(backward): 1.216 sec, time(eval): 0.514 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.298099, device='cuda:0'), grad_norm_after_clip: tensor(0.298099, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 17 with loss 0.00266457. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.74it/s]\n",
            "100% 5/5 [00:00<00:00, 10.27it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.65it/s]\n",
            "100% 4/4 [00:00<00:00, 12.82it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00138256, Rollout MSE Error (joint_q) = 0.00006399 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 18 with MSE error 0.0013825595378875732. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 18 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00208876, itemized = {state_0: 0.00000512, state_1: 0.02229870, state_2: 0.00075930, state_3: 0.00126459, state_MSE: 0.00608193, q_error_norm: 0.00739952, qd_error_norm: 0.02956821} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00219240, itemized = {state_0: 0.00000311, state_1: 0.01849628, state_2: 0.00064818, state_3: 0.00167625, state_MSE: 0.00520596, q_error_norm: 0.00564299, qd_error_norm: 0.02520894} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.714 sec, time(other): 0.010 sec, time(dataloader): 6.728 sec, time(compute_loss): 1.022 sec, time(backward): 1.215 sec, time(eval): 0.512 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.365476, device='cuda:0'), grad_norm_after_clip: tensor(0.364924, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 18 with loss 0.00219240. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.62it/s]\n",
            "100% 5/5 [00:00<00:00, 10.15it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.24it/s]\n",
            "100% 4/4 [00:00<00:00, 12.87it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00078210, Rollout MSE Error (joint_q) = 0.00004877 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 19 with MSE error 0.0007820950704626739. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 19 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00161429, itemized = {state_0: 0.00000396, state_1: 0.01872262, state_2: 0.00061368, state_3: 0.00099746, state_MSE: 0.00508443, q_error_norm: 0.00598282, qd_error_norm: 0.02744496} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00245346, itemized = {state_0: 0.00000289, state_1: 0.02465999, state_2: 0.00073549, state_3: 0.00188363, state_MSE: 0.00682050, q_error_norm: 0.00669884, qd_error_norm: 0.02684524} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.806 sec, time(other): 0.010 sec, time(dataloader): 6.871 sec, time(compute_loss): 1.018 sec, time(backward): 1.172 sec, time(eval): 0.514 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.332039, device='cuda:0'), grad_norm_after_clip: tensor(0.332039, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.93it/s]\n",
            "100% 5/5 [00:00<00:00, 10.36it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.16it/s]\n",
            "100% 4/4 [00:00<00:00, 12.78it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00159866, Rollout MSE Error (joint_q) = 0.00006353 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 20 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00220720, itemized = {state_0: 0.00000542, state_1: 0.02341461, state_2: 0.00082098, state_3: 0.00135797, state_MSE: 0.00639974, q_error_norm: 0.00740245, qd_error_norm: 0.03081868} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00269184, itemized = {state_0: 0.00000286, state_1: 0.03312576, state_2: 0.00076353, state_3: 0.00205099, state_MSE: 0.00898579, q_error_norm: 0.00880003, qd_error_norm: 0.02726417} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.536 sec, time(other): 0.010 sec, time(dataloader): 6.576 sec, time(compute_loss): 1.030 sec, time(backward): 1.221 sec, time(eval): 0.486 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.396972, device='cuda:0'), grad_norm_after_clip: tensor(0.396972, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.79it/s]\n",
            "100% 5/5 [00:00<00:00, 10.29it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.61it/s]\n",
            "100% 4/4 [00:00<00:00, 12.85it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00259563, Rollout MSE Error (joint_q) = 0.00031002 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 21 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00249122, itemized = {state_0: 0.00000799, state_1: 0.02456885, state_2: 0.00086507, state_3: 0.00143021, state_MSE: 0.00671803, q_error_norm: 0.00864786, qd_error_norm: 0.03034269} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00291616, itemized = {state_0: 0.00000826, state_1: 0.05084265, state_2: 0.00085239, state_3: 0.00203380, state_MSE: 0.01343428, q_error_norm: 0.01255242, qd_error_norm: 0.02944417} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.652 sec, time(other): 0.010 sec, time(dataloader): 6.689 sec, time(compute_loss): 1.035 sec, time(backward): 1.210 sec, time(eval): 0.482 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.424624, device='cuda:0'), grad_norm_after_clip: tensor(0.419690, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.82it/s]\n",
            "100% 5/5 [00:00<00:00, 10.13it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.87it/s]\n",
            "100% 4/4 [00:00<00:00, 12.98it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00240227, Rollout MSE Error (joint_q) = 0.00004366 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 22 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00210647, itemized = {state_0: 0.00000622, state_1: 0.02171991, state_2: 0.00078784, state_3: 0.00125173, state_MSE: 0.00594142, q_error_norm: 0.00727689, qd_error_norm: 0.02996904} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00273092, itemized = {state_0: 0.00000386, state_1: 0.03544076, state_2: 0.00094607, state_3: 0.00193437, state_MSE: 0.00958127, q_error_norm: 0.00875682, qd_error_norm: 0.02893939} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.615 sec, time(other): 0.010 sec, time(dataloader): 6.697 sec, time(compute_loss): 1.021 sec, time(backward): 1.196 sec, time(eval): 0.477 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.384278, device='cuda:0'), grad_norm_after_clip: tensor(0.384278, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.07it/s]\n",
            "100% 5/5 [00:00<00:00, 10.18it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.84it/s]\n",
            "100% 4/4 [00:00<00:00, 12.87it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00174315, Rollout MSE Error (joint_q) = 0.00002297 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 23 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00089193, itemized = {state_0: 0.00000298, state_1: 0.01764657, state_2: 0.00032631, state_3: 0.00048703, state_MSE: 0.00461572, q_error_norm: 0.00578053, qd_error_norm: 0.01992843} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00199424, itemized = {state_0: 0.00000250, state_1: 0.01849670, state_2: 0.00063352, state_3: 0.00149529, state_MSE: 0.00515700, q_error_norm: 0.00538375, qd_error_norm: 0.02382920} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.512 sec, time(other): 0.010 sec, time(dataloader): 6.507 sec, time(compute_loss): 1.018 sec, time(backward): 1.213 sec, time(eval): 0.480 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.221572, device='cuda:0'), grad_norm_after_clip: tensor(0.221572, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 23 with loss 0.00199424. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.59it/s]\n",
            "100% 5/5 [00:00<00:00, 10.30it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.55it/s]\n",
            "100% 4/4 [00:00<00:00, 12.86it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00078412, Rollout MSE Error (joint_q) = 0.00034561 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 24 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00156253, itemized = {state_0: 0.00000504, state_1: 0.02010927, state_2: 0.00059012, state_3: 0.00088529, state_MSE: 0.00539743, q_error_norm: 0.00675794, qd_error_norm: 0.02567121} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00249450, itemized = {state_0: 0.00000250, state_1: 0.03004046, state_2: 0.00082242, state_3: 0.00175318, state_MSE: 0.00815464, q_error_norm: 0.00860134, qd_error_norm: 0.02528833} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.785 sec, time(other): 0.010 sec, time(dataloader): 6.841 sec, time(compute_loss): 1.025 sec, time(backward): 1.215 sec, time(eval): 0.481 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.348790, device='cuda:0'), grad_norm_after_clip: tensor(0.348790, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.01it/s]\n",
            "100% 5/5 [00:00<00:00, 10.49it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.74it/s]\n",
            "100% 4/4 [00:00<00:00, 12.89it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.01131442, Rollout MSE Error (joint_q) = 0.00127165 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 25 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00123554, itemized = {state_0: 0.00000253, state_1: 0.01864686, state_2: 0.00050679, state_3: 0.00069563, state_MSE: 0.00496295, q_error_norm: 0.00592954, qd_error_norm: 0.02110152} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00635868, itemized = {state_0: 0.00000879, state_1: 0.05849414, state_2: 0.00257168, state_3: 0.00371475, state_MSE: 0.01619734, q_error_norm: 0.01695397, qd_error_norm: 0.04568002} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.471 sec, time(other): 0.010 sec, time(dataloader): 6.519 sec, time(compute_loss): 1.026 sec, time(backward): 1.218 sec, time(eval): 0.479 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.272601, device='cuda:0'), grad_norm_after_clip: tensor(0.268834, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.06it/s]\n",
            "100% 5/5 [00:00<00:00, 10.45it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.83it/s]\n",
            "100% 4/4 [00:00<00:00, 12.96it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00091313, Rollout MSE Error (joint_q) = 0.00004570 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 26 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00245626, itemized = {state_0: 0.00000689, state_1: 0.02368894, state_2: 0.00088926, state_3: 0.00147199, state_MSE: 0.00651427, q_error_norm: 0.00811710, qd_error_norm: 0.03203759} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00231111, itemized = {state_0: 0.00000261, state_1: 0.04082996, state_2: 0.00061744, state_3: 0.00184242, state_MSE: 0.01082311, q_error_norm: 0.00931275, qd_error_norm: 0.02529924} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.444 sec, time(other): 0.010 sec, time(dataloader): 6.492 sec, time(compute_loss): 1.025 sec, time(backward): 1.217 sec, time(eval): 0.477 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.382579, device='cuda:0'), grad_norm_after_clip: tensor(0.382579, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.34it/s]\n",
            "100% 5/5 [00:00<00:00, 10.68it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.98it/s]\n",
            "100% 4/4 [00:00<00:00, 12.81it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00047027, Rollout MSE Error (joint_q) = 0.00005649 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 27 with MSE error 0.0004702720034401864. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 27 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00071111, itemized = {state_0: 0.00000221, state_1: 0.01672250, state_2: 0.00023994, state_3: 0.00040848, state_MSE: 0.00434328, q_error_norm: 0.00534742, qd_error_norm: 0.01758308} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00180570, itemized = {state_0: 0.00000207, state_1: 0.02773929, state_2: 0.00055162, state_3: 0.00136561, state_MSE: 0.00741464, q_error_norm: 0.00695585, qd_error_norm: 0.02080694} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.267 sec, time(other): 0.010 sec, time(dataloader): 6.330 sec, time(compute_loss): 1.020 sec, time(backward): 1.185 sec, time(eval): 0.510 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.191596, device='cuda:0'), grad_norm_after_clip: tensor(0.191596, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 27 with loss 0.00180570. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.97it/s]\n",
            "100% 5/5 [00:00<00:00, 10.72it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.76it/s]\n",
            "100% 4/4 [00:00<00:00, 12.75it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00140270, Rollout MSE Error (joint_q) = 0.00009388 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 28 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00146270, itemized = {state_0: 0.00000395, state_1: 0.01999194, state_2: 0.00050390, state_3: 0.00085947, state_MSE: 0.00533981, q_error_norm: 0.00687625, qd_error_norm: 0.02451700} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00176031, itemized = {state_0: 0.00000217, state_1: 0.01926425, state_2: 0.00052574, state_3: 0.00132303, state_MSE: 0.00527880, q_error_norm: 0.00568193, qd_error_norm: 0.02300899} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.506 sec, time(other): 0.010 sec, time(dataloader): 6.583 sec, time(compute_loss): 1.018 sec, time(backward): 1.186 sec, time(eval): 0.483 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.319414, device='cuda:0'), grad_norm_after_clip: tensor(0.319414, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 28 with loss 0.00176031. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.90it/s]\n",
            "100% 5/5 [00:00<00:00, 10.62it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.64it/s]\n",
            "100% 4/4 [00:00<00:00, 12.68it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00212286, Rollout MSE Error (joint_q) = 0.00036998 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 29 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00109754, itemized = {state_0: 0.00000282, state_1: 0.01849294, state_2: 0.00041586, state_3: 0.00064376, state_MSE: 0.00488884, q_error_norm: 0.00573665, qd_error_norm: 0.02131307} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00246021, itemized = {state_0: 0.00000567, state_1: 0.04775997, state_2: 0.00070813, state_3: 0.00169518, state_MSE: 0.01254224, q_error_norm: 0.01195113, qd_error_norm: 0.02858737} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.591 sec, time(other): 0.010 sec, time(dataloader): 6.666 sec, time(compute_loss): 1.009 sec, time(backward): 1.165 sec, time(eval): 0.485 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.245507, device='cuda:0'), grad_norm_after_clip: tensor(0.245507, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.89it/s]\n",
            "100% 5/5 [00:00<00:00, 10.41it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.64it/s]\n",
            "100% 4/4 [00:00<00:00, 12.83it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00078909, Rollout MSE Error (joint_q) = 0.00010405 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 30 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00126377, itemized = {state_0: 0.00000401, state_1: 0.02103363, state_2: 0.00040659, state_3: 0.00076024, state_MSE: 0.00555112, q_error_norm: 0.00682897, qd_error_norm: 0.02272783} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00194442, itemized = {state_0: 0.00000248, state_1: 0.02157607, state_2: 0.00063467, state_3: 0.00142058, state_MSE: 0.00590845, q_error_norm: 0.00605841, qd_error_norm: 0.02193627} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.573 sec, time(other): 0.010 sec, time(dataloader): 6.638 sec, time(compute_loss): 1.014 sec, time(backward): 1.205 sec, time(eval): 0.481 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.279680, device='cuda:0'), grad_norm_after_clip: tensor(0.279680, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:07<00:00, 12.52it/s]\n",
            "100% 5/5 [00:00<00:00, 10.46it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.66it/s]\n",
            "100% 4/4 [00:00<00:00, 12.81it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00222740, Rollout MSE Error (joint_q) = 0.00017471 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 31 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00270579, itemized = {state_0: 0.00000619, state_1: 0.02606433, state_2: 0.00089429, state_3: 0.00170923, state_MSE: 0.00716851, q_error_norm: 0.00857048, qd_error_norm: 0.03233317} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00444435, itemized = {state_0: 0.00000855, state_1: 0.05928344, state_2: 0.00149528, state_3: 0.00286852, state_MSE: 0.01591395, q_error_norm: 0.01521456, qd_error_norm: 0.02847970} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.145 sec, time(other): 0.010 sec, time(dataloader): 6.237 sec, time(compute_loss): 1.014 sec, time(backward): 1.182 sec, time(eval): 0.483 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.394381, device='cuda:0'), grad_norm_after_clip: tensor(0.394381, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.25it/s]\n",
            "100% 5/5 [00:00<00:00, 10.51it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.01it/s]\n",
            "100% 4/4 [00:00<00:00, 12.87it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00152510, Rollout MSE Error (joint_q) = 0.00051839 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 32 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00179867, itemized = {state_0: 0.00000376, state_1: 0.01999344, state_2: 0.00070941, state_3: 0.00106015, state_MSE: 0.00544169, q_error_norm: 0.00663645, qd_error_norm: 0.02701755} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00380576, itemized = {state_0: 0.00000586, state_1: 0.03467622, state_2: 0.00128769, state_3: 0.00238548, state_MSE: 0.00958881, q_error_norm: 0.01124077, qd_error_norm: 0.03057032} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.327 sec, time(other): 0.010 sec, time(dataloader): 6.393 sec, time(compute_loss): 1.015 sec, time(backward): 1.198 sec, time(eval): 0.478 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.374195, device='cuda:0'), grad_norm_after_clip: tensor(0.374195, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.19it/s]\n",
            "100% 5/5 [00:00<00:00, 10.76it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.79it/s]\n",
            "100% 4/4 [00:00<00:00, 12.97it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00092659, Rollout MSE Error (joint_q) = 0.00005409 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 33 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00069310, itemized = {state_0: 0.00000204, state_1: 0.01653059, state_2: 0.00025075, state_3: 0.00038740, state_MSE: 0.00429269, q_error_norm: 0.00508403, qd_error_norm: 0.01690291} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00155683, itemized = {state_0: 0.00000191, state_1: 0.01079524, state_2: 0.00046037, state_3: 0.00118349, state_MSE: 0.00311025, q_error_norm: 0.00417954, qd_error_norm: 0.02021425} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.333 sec, time(other): 0.010 sec, time(dataloader): 6.425 sec, time(compute_loss): 1.014 sec, time(backward): 1.191 sec, time(eval): 0.477 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.147432, device='cuda:0'), grad_norm_after_clip: tensor(0.147432, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 33 with loss 0.00155683. \u001b[0m\n",
            "100% 100/100 [00:07<00:00, 12.61it/s]\n",
            "100% 5/5 [00:00<00:00, 10.64it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.53it/s]\n",
            "100% 4/4 [00:00<00:00, 12.98it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00060981, Rollout MSE Error (joint_q) = 0.00004752 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 34 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00062591, itemized = {state_0: 0.00000208, state_1: 0.01472144, state_2: 0.00021779, state_3: 0.00035324, state_MSE: 0.00382363, q_error_norm: 0.00487832, qd_error_norm: 0.01644872} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00154406, itemized = {state_0: 0.00000246, state_1: 0.01233471, state_2: 0.00044741, state_3: 0.00116089, state_MSE: 0.00348637, q_error_norm: 0.00448964, qd_error_norm: 0.01976718} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.076 sec, time(other): 0.010 sec, time(dataloader): 6.157 sec, time(compute_loss): 1.022 sec, time(backward): 1.186 sec, time(eval): 0.482 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.204483, device='cuda:0'), grad_norm_after_clip: tensor(0.204483, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 34 with loss 0.00154406. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.91it/s]\n",
            "100% 5/5 [00:00<00:00, 10.58it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.01it/s]\n",
            "100% 4/4 [00:00<00:00, 12.92it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00371609, Rollout MSE Error (joint_q) = 0.00031403 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 35 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00106395, itemized = {state_0: 0.00000236, state_1: 0.01583676, state_2: 0.00039222, state_3: 0.00065784, state_MSE: 0.00422230, q_error_norm: 0.00507165, qd_error_norm: 0.02086136} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00420691, itemized = {state_0: 0.00000604, state_1: 0.03234355, state_2: 0.00115754, state_3: 0.00326960, state_MSE: 0.00919418, q_error_norm: 0.00959410, qd_error_norm: 0.03806920} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.545 sec, time(other): 0.010 sec, time(dataloader): 6.633 sec, time(compute_loss): 1.018 sec, time(backward): 1.182 sec, time(eval): 0.478 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.247862, device='cuda:0'), grad_norm_after_clip: tensor(0.247862, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.76it/s]\n",
            "100% 5/5 [00:00<00:00, 10.59it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.79it/s]\n",
            "100% 4/4 [00:00<00:00, 12.98it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00032416, Rollout MSE Error (joint_q) = 0.00002162 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 36 with MSE error 0.00032416413887403905. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 36 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00178874, itemized = {state_0: 0.00000499, state_1: 0.02136974, state_2: 0.00060149, state_3: 0.00108667, state_MSE: 0.00576572, q_error_norm: 0.00714273, qd_error_norm: 0.02553905} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00157160, itemized = {state_0: 0.00000151, state_1: 0.01772360, state_2: 0.00047246, state_3: 0.00122831, state_MSE: 0.00485647, q_error_norm: 0.00471841, qd_error_norm: 0.01781249} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.674 sec, time(other): 0.010 sec, time(dataloader): 6.741 sec, time(compute_loss): 1.013 sec, time(backward): 1.190 sec, time(eval): 0.508 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.296602, device='cuda:0'), grad_norm_after_clip: tensor(0.296602, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.06it/s]\n",
            "100% 5/5 [00:00<00:00, 10.84it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.02it/s]\n",
            "100% 4/4 [00:00<00:00, 12.97it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00058009, Rollout MSE Error (joint_q) = 0.00002570 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 37 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00050082, itemized = {state_0: 0.00000129, state_1: 0.01464430, state_2: 0.00017640, state_3: 0.00028341, state_MSE: 0.00377635, q_error_norm: 0.00459922, qd_error_norm: 0.01489838} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00147758, itemized = {state_0: 0.00000182, state_1: 0.01618643, state_2: 0.00041368, state_3: 0.00118421, state_MSE: 0.00444654, q_error_norm: 0.00441189, qd_error_norm: 0.01867330} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.408 sec, time(other): 0.010 sec, time(dataloader): 6.511 sec, time(compute_loss): 1.016 sec, time(backward): 1.191 sec, time(eval): 0.475 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.171372, device='cuda:0'), grad_norm_after_clip: tensor(0.171372, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 37 with loss 0.00147758. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.92it/s]\n",
            "100% 5/5 [00:00<00:00, 10.50it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.73it/s]\n",
            "100% 4/4 [00:00<00:00, 13.10it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00423812, Rollout MSE Error (joint_q) = 0.00035984 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 38 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00127742, itemized = {state_0: 0.00000335, state_1: 0.01718396, state_2: 0.00049889, state_3: 0.00074563, state_MSE: 0.00460796, q_error_norm: 0.00560368, qd_error_norm: 0.02122161} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00355082, itemized = {state_0: 0.00000885, state_1: 0.04083248, state_2: 0.00109649, state_3: 0.00222731, state_MSE: 0.01104128, q_error_norm: 0.01235369, qd_error_norm: 0.03161703} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.596 sec, time(other): 0.010 sec, time(dataloader): 6.664 sec, time(compute_loss): 1.014 sec, time(backward): 1.155 sec, time(eval): 0.474 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.280937, device='cuda:0'), grad_norm_after_clip: tensor(0.280937, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.26it/s]\n",
            "100% 5/5 [00:00<00:00, 10.22it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.86it/s]\n",
            "100% 4/4 [00:00<00:00, 12.87it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00041273, Rollout MSE Error (joint_q) = 0.00003416 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 39 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00094111, itemized = {state_0: 0.00000283, state_1: 0.01649000, state_2: 0.00031572, state_3: 0.00057732, state_MSE: 0.00434647, q_error_norm: 0.00527437, qd_error_norm: 0.01921486} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00158744, itemized = {state_0: 0.00000132, state_1: 0.01310499, state_2: 0.00049140, state_3: 0.00123612, state_MSE: 0.00370846, q_error_norm: 0.00391392, qd_error_norm: 0.01789489} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.349 sec, time(other): 0.010 sec, time(dataloader): 6.349 sec, time(compute_loss): 1.027 sec, time(backward): 1.236 sec, time(eval): 0.479 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.208146, device='cuda:0'), grad_norm_after_clip: tensor(0.208146, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.05it/s]\n",
            "100% 5/5 [00:00<00:00, 10.41it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.88it/s]\n",
            "100% 4/4 [00:00<00:00, 13.13it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00079106, Rollout MSE Error (joint_q) = 0.00018569 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 40 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00057110, itemized = {state_0: 0.00000168, state_1: 0.01537490, state_2: 0.00020596, state_3: 0.00031132, state_MSE: 0.00397347, q_error_norm: 0.00485252, qd_error_norm: 0.01500875} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00165520, itemized = {state_0: 0.00000167, state_1: 0.02388676, state_2: 0.00051781, state_3: 0.00114637, state_MSE: 0.00638815, q_error_norm: 0.00741362, qd_error_norm: 0.01961702} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.436 sec, time(other): 0.010 sec, time(dataloader): 6.567 sec, time(compute_loss): 1.014 sec, time(backward): 1.166 sec, time(eval): 0.473 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.176650, device='cuda:0'), grad_norm_after_clip: tensor(0.176650, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.37it/s]\n",
            "100% 5/5 [00:00<00:00, 10.43it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.52it/s]\n",
            "100% 4/4 [00:00<00:00, 13.08it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00109479, Rollout MSE Error (joint_q) = 0.00001740 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 41 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00089511, itemized = {state_0: 0.00000254, state_1: 0.01680016, state_2: 0.00028381, state_3: 0.00057149, state_MSE: 0.00441450, q_error_norm: 0.00531952, qd_error_norm: 0.01898250} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00167156, itemized = {state_0: 0.00000177, state_1: 0.01233562, state_2: 0.00047094, state_3: 0.00131710, state_MSE: 0.00353136, q_error_norm: 0.00427395, qd_error_norm: 0.02032467} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.246 sec, time(other): 0.011 sec, time(dataloader): 6.300 sec, time(compute_loss): 1.021 sec, time(backward): 1.207 sec, time(eval): 0.480 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.225926, device='cuda:0'), grad_norm_after_clip: tensor(0.225926, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.18it/s]\n",
            "100% 5/5 [00:00<00:00, 10.47it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.03it/s]\n",
            "100% 4/4 [00:00<00:00, 12.69it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00032223, Rollout MSE Error (joint_q) = 0.00002407 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 42 with MSE error 0.0003222319355700165. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 42 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00089916, itemized = {state_0: 0.00000321, state_1: 0.01656503, state_2: 0.00030702, state_3: 0.00053191, state_MSE: 0.00435179, q_error_norm: 0.00526318, qd_error_norm: 0.01850617} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00134460, itemized = {state_0: 0.00000127, state_1: 0.02234792, state_2: 0.00041047, state_3: 0.00104146, state_MSE: 0.00595028, q_error_norm: 0.00538971, qd_error_norm: 0.01625244} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.386 sec, time(other): 0.010 sec, time(dataloader): 6.471 sec, time(compute_loss): 1.010 sec, time(backward): 1.172 sec, time(eval): 0.518 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.208143, device='cuda:0'), grad_norm_after_clip: tensor(0.208143, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 42 with loss 0.00134460. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.99it/s]\n",
            "100% 5/5 [00:00<00:00, 10.68it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.99it/s]\n",
            "100% 4/4 [00:00<00:00, 12.81it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00095283, Rollout MSE Error (joint_q) = 0.00004369 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 43 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00058391, itemized = {state_0: 0.00000181, state_1: 0.01491354, state_2: 0.00021535, state_3: 0.00034237, state_MSE: 0.00386827, q_error_norm: 0.00441627, qd_error_norm: 0.01533605} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00166353, itemized = {state_0: 0.00000305, state_1: 0.00694202, state_2: 0.00052671, state_3: 0.00123172, state_MSE: 0.00217587, q_error_norm: 0.00332025, qd_error_norm: 0.02131473} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.506 sec, time(other): 0.010 sec, time(dataloader): 6.580 sec, time(compute_loss): 1.011 sec, time(backward): 1.186 sec, time(eval): 0.480 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.189396, device='cuda:0'), grad_norm_after_clip: tensor(0.189396, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.99it/s]\n",
            "100% 5/5 [00:00<00:00, 10.39it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.88it/s]\n",
            "100% 4/4 [00:00<00:00, 13.00it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00470762, Rollout MSE Error (joint_q) = 0.00026682 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 44 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00084808, itemized = {state_0: 0.00000230, state_1: 0.01672095, state_2: 0.00030314, state_3: 0.00048580, state_MSE: 0.00437805, q_error_norm: 0.00551309, qd_error_norm: 0.01861620} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00200058, itemized = {state_0: 0.00000188, state_1: 0.05084357, state_2: 0.00066484, state_3: 0.00146455, state_MSE: 0.01324371, q_error_norm: 0.01088343, qd_error_norm: 0.02546648} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.474 sec, time(other): 0.010 sec, time(dataloader): 6.577 sec, time(compute_loss): 1.016 sec, time(backward): 1.193 sec, time(eval): 0.475 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.238957, device='cuda:0'), grad_norm_after_clip: tensor(0.238957, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.99it/s]\n",
            "100% 5/5 [00:00<00:00, 10.31it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.95it/s]\n",
            "100% 4/4 [00:00<00:00, 13.05it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00025643, Rollout MSE Error (joint_q) = 0.00001193 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 45 with MSE error 0.00025643190019764006. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 45 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00042839, itemized = {state_0: 0.00000152, state_1: 0.01302525, state_2: 0.00015082, state_3: 0.00024784, state_MSE: 0.00335636, q_error_norm: 0.00393188, qd_error_norm: 0.01360122} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00131732, itemized = {state_0: 0.00000138, state_1: 0.00847990, state_2: 0.00039809, state_3: 0.00102729, state_MSE: 0.00247666, q_error_norm: 0.00303694, qd_error_norm: 0.01545230} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.512 sec, time(other): 0.010 sec, time(dataloader): 6.621 sec, time(compute_loss): 1.012 sec, time(backward): 1.155 sec, time(eval): 0.503 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.140014, device='cuda:0'), grad_norm_after_clip: tensor(0.140014, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 45 with loss 0.00131732. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.09it/s]\n",
            "100% 5/5 [00:00<00:00, 10.48it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.17it/s]\n",
            "100% 4/4 [00:00<00:00, 12.98it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00190468, Rollout MSE Error (joint_q) = 0.00056684 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 46 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00147455, itemized = {state_0: 0.00000436, state_1: 0.01833764, state_2: 0.00052033, state_3: 0.00090872, state_MSE: 0.00494276, q_error_norm: 0.00612072, qd_error_norm: 0.02421071} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00342082, itemized = {state_0: 0.00000807, state_1: 0.01388751, state_2: 0.00099626, state_3: 0.00222265, state_MSE: 0.00427862, q_error_norm: 0.00811274, qd_error_norm: 0.02996446} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.415 sec, time(other): 0.010 sec, time(dataloader): 6.531 sec, time(compute_loss): 1.014 sec, time(backward): 1.167 sec, time(eval): 0.475 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.329191, device='cuda:0'), grad_norm_after_clip: tensor(0.329191, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.26it/s]\n",
            "100% 5/5 [00:00<00:00, 10.59it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.90it/s]\n",
            "100% 4/4 [00:00<00:00, 12.99it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00069913, Rollout MSE Error (joint_q) = 0.00003423 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 47 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00088058, itemized = {state_0: 0.00000264, state_1: 0.01675814, state_2: 0.00028874, state_3: 0.00053374, state_MSE: 0.00439582, q_error_norm: 0.00534051, qd_error_norm: 0.01780929} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00149099, itemized = {state_0: 0.00000192, state_1: 0.01541447, state_2: 0.00046517, state_3: 0.00113515, state_MSE: 0.00425418, q_error_norm: 0.00436909, qd_error_norm: 0.01765912} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.321 sec, time(other): 0.010 sec, time(dataloader): 6.346 sec, time(compute_loss): 1.021 sec, time(backward): 1.226 sec, time(eval): 0.480 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.189230, device='cuda:0'), grad_norm_after_clip: tensor(0.189230, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.43it/s]\n",
            "100% 5/5 [00:00<00:00, 10.53it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.01it/s]\n",
            "100% 4/4 [00:00<00:00, 12.99it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00207508, Rollout MSE Error (joint_q) = 0.00018249 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 48 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00034550, itemized = {state_0: 0.00000116, state_1: 0.01422010, state_2: 0.00011773, state_3: 0.00019043, state_MSE: 0.00363235, q_error_norm: 0.00419272, qd_error_norm: 0.01239026} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00193179, itemized = {state_0: 0.00000100, state_1: 0.03004853, state_2: 0.00070124, state_3: 0.00132638, state_MSE: 0.00801929, q_error_norm: 0.00809574, qd_error_norm: 0.02302729} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.170 sec, time(other): 0.010 sec, time(dataloader): 6.256 sec, time(compute_loss): 1.022 sec, time(backward): 1.205 sec, time(eval): 0.475 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.132493, device='cuda:0'), grad_norm_after_clip: tensor(0.132493, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.13it/s]\n",
            "100% 5/5 [00:00<00:00, 10.47it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.24it/s]\n",
            "100% 4/4 [00:00<00:00, 12.81it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00059025, Rollout MSE Error (joint_q) = 0.00004601 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 49 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00034430, itemized = {state_0: 0.00000111, state_1: 0.01314117, state_2: 0.00012015, state_3: 0.00020049, state_MSE: 0.00336573, q_error_norm: 0.00382955, qd_error_norm: 0.01259829} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00138644, itemized = {state_0: 0.00000110, state_1: 0.02234462, state_2: 0.00042906, state_3: 0.00108239, state_MSE: 0.00596429, q_error_norm: 0.00522138, qd_error_norm: 0.01699896} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.422 sec, time(other): 0.010 sec, time(dataloader): 6.477 sec, time(compute_loss): 1.015 sec, time(backward): 1.195 sec, time(eval): 0.491 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.136980, device='cuda:0'), grad_norm_after_clip: tensor(0.136980, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.04it/s]\n",
            "100% 5/5 [00:00<00:00, 10.52it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.45it/s]\n",
            "100% 4/4 [00:00<00:00, 12.91it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00064043, Rollout MSE Error (joint_q) = 0.00005052 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 50 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00109187, itemized = {state_0: 0.00000291, state_1: 0.01783671, state_2: 0.00037638, state_3: 0.00065778, state_MSE: 0.00471844, q_error_norm: 0.00590165, qd_error_norm: 0.02081315} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00165139, itemized = {state_0: 0.00000221, state_1: 0.01079274, state_2: 0.00050913, state_3: 0.00125770, state_MSE: 0.00314044, q_error_norm: 0.00391850, qd_error_norm: 0.01778728} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.465 sec, time(other): 0.010 sec, time(dataloader): 6.550 sec, time(compute_loss): 1.012 sec, time(backward): 1.184 sec, time(eval): 0.480 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.273910, device='cuda:0'), grad_norm_after_clip: tensor(0.273910, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.11it/s]\n",
            "100% 5/5 [00:00<00:00, 10.64it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.84it/s]\n",
            "100% 4/4 [00:00<00:00, 12.89it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00059177, Rollout MSE Error (joint_q) = 0.00002795 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 51 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00034600, itemized = {state_0: 0.00000096, state_1: 0.01410420, state_2: 0.00012000, state_3: 0.00020253, state_MSE: 0.00360692, q_error_norm: 0.00402323, qd_error_norm: 0.01246351} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00128068, itemized = {state_0: 0.00000136, state_1: 0.01618621, state_2: 0.00035855, state_3: 0.00101725, state_MSE: 0.00439084, q_error_norm: 0.00449957, qd_error_norm: 0.01689961} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.386 sec, time(other): 0.010 sec, time(dataloader): 6.482 sec, time(compute_loss): 1.015 sec, time(backward): 1.195 sec, time(eval): 0.479 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.128791, device='cuda:0'), grad_norm_after_clip: tensor(0.128791, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 51 with loss 0.00128068. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.10it/s]\n",
            "100% 5/5 [00:00<00:00, 10.70it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.94it/s]\n",
            "100% 4/4 [00:00<00:00, 12.97it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00096136, Rollout MSE Error (joint_q) = 0.00009965 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 52 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00075564, itemized = {state_0: 0.00000193, state_1: 0.01518140, state_2: 0.00025695, state_3: 0.00048028, state_MSE: 0.00398014, q_error_norm: 0.00469148, qd_error_norm: 0.01791028} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00197672, itemized = {state_0: 0.00000224, state_1: 0.02002931, state_2: 0.00066549, state_3: 0.00144085, state_MSE: 0.00553447, q_error_norm: 0.00567903, qd_error_norm: 0.02110650} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.429 sec, time(other): 0.010 sec, time(dataloader): 6.476 sec, time(compute_loss): 1.016 sec, time(backward): 1.205 sec, time(eval): 0.476 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.216244, device='cuda:0'), grad_norm_after_clip: tensor(0.216244, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:07<00:00, 12.72it/s]\n",
            "100% 5/5 [00:00<00:00,  9.70it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.29it/s]\n",
            "100% 4/4 [00:00<00:00, 12.79it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00025785, Rollout MSE Error (joint_q) = 0.00002977 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 53 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00030366, itemized = {state_0: 0.00000093, state_1: 0.01406540, state_2: 0.00010583, state_3: 0.00017488, state_MSE: 0.00358676, q_error_norm: 0.00386440, qd_error_norm: 0.01161879} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00121589, itemized = {state_0: 0.00000116, state_1: 0.02003186, state_2: 0.00035638, state_3: 0.00096347, state_MSE: 0.00533822, q_error_norm: 0.00478403, qd_error_norm: 0.01367691} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.047 sec, time(other): 0.010 sec, time(dataloader): 6.135 sec, time(compute_loss): 1.012 sec, time(backward): 1.193 sec, time(eval): 0.489 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.098401, device='cuda:0'), grad_norm_after_clip: tensor(0.098401, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 53 with loss 0.00121589. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.18it/s]\n",
            "100% 5/5 [00:00<00:00, 10.77it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.15it/s]\n",
            "100% 4/4 [00:00<00:00, 13.06it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00021964, Rollout MSE Error (joint_q) = 0.00006512 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 54 with MSE error 0.0002196434506913647. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 54 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00046051, itemized = {state_0: 0.00000180, state_1: 0.01294813, state_2: 0.00015016, state_3: 0.00027468, state_MSE: 0.00334369, q_error_norm: 0.00403797, qd_error_norm: 0.01358750} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00134833, itemized = {state_0: 0.00000133, state_1: 0.03081751, state_2: 0.00039641, state_3: 0.00104729, state_MSE: 0.00806564, q_error_norm: 0.00702391, qd_error_norm: 0.01538557} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.380 sec, time(other): 0.010 sec, time(dataloader): 6.460 sec, time(compute_loss): 1.010 sec, time(backward): 1.168 sec, time(eval): 0.501 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.158696, device='cuda:0'), grad_norm_after_clip: tensor(0.158696, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:07<00:00, 12.57it/s]\n",
            "100% 5/5 [00:00<00:00, 10.48it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.55it/s]\n",
            "100% 4/4 [00:00<00:00, 12.89it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00056917, Rollout MSE Error (joint_q) = 0.00002457 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 55 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00042098, itemized = {state_0: 0.00000112, state_1: 0.01294837, state_2: 0.00015717, state_3: 0.00024838, state_MSE: 0.00333876, q_error_norm: 0.00383293, qd_error_norm: 0.01331276} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00157643, itemized = {state_0: 0.00000140, state_1: 0.02388308, state_2: 0.00050715, state_3: 0.00118919, state_MSE: 0.00639521, q_error_norm: 0.00578723, qd_error_norm: 0.01802191} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.094 sec, time(other): 0.010 sec, time(dataloader): 6.192 sec, time(compute_loss): 1.013 sec, time(backward): 1.194 sec, time(eval): 0.480 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.169072, device='cuda:0'), grad_norm_after_clip: tensor(0.169072, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.00it/s]\n",
            "100% 5/5 [00:00<00:00, 10.12it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.71it/s]\n",
            "100% 4/4 [00:00<00:00, 12.82it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00057285, Rollout MSE Error (joint_q) = 0.00002070 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 56 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00047768, itemized = {state_0: 0.00000121, state_1: 0.01371883, state_2: 0.00017666, state_3: 0.00028902, state_MSE: 0.00354643, q_error_norm: 0.00400350, qd_error_norm: 0.01429227} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00151794, itemized = {state_0: 0.00000147, state_1: 0.01772595, state_2: 0.00047077, state_3: 0.00116040, state_MSE: 0.00483965, q_error_norm: 0.00491178, qd_error_norm: 0.01941942} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.550 sec, time(other): 0.010 sec, time(dataloader): 6.616 sec, time(compute_loss): 1.005 sec, time(backward): 1.171 sec, time(eval): 0.482 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.166843, device='cuda:0'), grad_norm_after_clip: tensor(0.166843, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.42it/s]\n",
            "100% 5/5 [00:00<00:00, 10.20it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.86it/s]\n",
            "100% 4/4 [00:00<00:00, 12.75it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00313861, Rollout MSE Error (joint_q) = 0.00022496 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 57 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00062519, itemized = {state_0: 0.00000221, state_1: 0.01464182, state_2: 0.00022446, state_3: 0.00035685, state_MSE: 0.00380633, q_error_norm: 0.00456799, qd_error_norm: 0.01559713} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00213112, itemized = {state_0: 0.00000701, state_1: 0.02157672, state_2: 0.00066982, state_3: 0.00140381, state_MSE: 0.00591434, q_error_norm: 0.00742424, qd_error_norm: 0.02622878} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.243 sec, time(other): 0.010 sec, time(dataloader): 6.339 sec, time(compute_loss): 1.007 sec, time(backward): 1.157 sec, time(eval): 0.491 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.194469, device='cuda:0'), grad_norm_after_clip: tensor(0.194469, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.21it/s]\n",
            "100% 5/5 [00:00<00:00, 10.67it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.86it/s]\n",
            "100% 4/4 [00:00<00:00, 13.09it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00023993, Rollout MSE Error (joint_q) = 0.00004405 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 58 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00109880, itemized = {state_0: 0.00000337, state_1: 0.02187761, state_2: 0.00036635, state_3: 0.00064089, state_MSE: 0.00572205, q_error_norm: 0.00674992, qd_error_norm: 0.02027928} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00139089, itemized = {state_0: 0.00000185, state_1: 0.01156144, state_2: 0.00041806, state_3: 0.00107443, state_MSE: 0.00326395, q_error_norm: 0.00373550, qd_error_norm: 0.01467743} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.316 sec, time(other): 0.010 sec, time(dataloader): 6.417 sec, time(compute_loss): 1.015 sec, time(backward): 1.194 sec, time(eval): 0.474 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.240235, device='cuda:0'), grad_norm_after_clip: tensor(0.240235, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.17it/s]\n",
            "100% 5/5 [00:00<00:00, 10.69it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.84it/s]\n",
            "100% 4/4 [00:00<00:00, 13.20it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00025892, Rollout MSE Error (joint_q) = 0.00000841 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 59 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00017639, itemized = {state_0: 0.00000065, state_1: 0.01160100, state_2: 0.00006400, state_3: 0.00009786, state_MSE: 0.00294088, q_error_norm: 0.00308709, qd_error_norm: 0.00918745} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00114084, itemized = {state_0: 0.00000084, state_1: 0.02234686, state_2: 0.00037619, state_3: 0.00087358, state_MSE: 0.00589937, q_error_norm: 0.00488826, qd_error_norm: 0.01449947} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.366 sec, time(other): 0.010 sec, time(dataloader): 6.396 sec, time(compute_loss): 1.020 sec, time(backward): 1.234 sec, time(eval): 0.477 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.077333, device='cuda:0'), grad_norm_after_clip: tensor(0.077333, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 59 with loss 0.00114084. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.21it/s]\n",
            "100% 5/5 [00:00<00:00, 10.66it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.05it/s]\n",
            "100% 4/4 [00:00<00:00, 13.02it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00048737, Rollout MSE Error (joint_q) = 0.00005220 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 60 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00102889, itemized = {state_0: 0.00000283, state_1: 0.01906767, state_2: 0.00036441, state_3: 0.00059286, state_MSE: 0.00500694, q_error_norm: 0.00590925, qd_error_norm: 0.01905762} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00152004, itemized = {state_0: 0.00000143, state_1: 0.03851577, state_2: 0.00044587, state_3: 0.00118187, state_MSE: 0.01003624, q_error_norm: 0.00832541, qd_error_norm: 0.01737259} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.311 sec, time(other): 0.010 sec, time(dataloader): 6.419 sec, time(compute_loss): 1.013 sec, time(backward): 1.191 sec, time(eval): 0.475 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.240421, device='cuda:0'), grad_norm_after_clip: tensor(0.240421, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.23it/s]\n",
            "100% 5/5 [00:00<00:00, 10.76it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.19it/s]\n",
            "100% 4/4 [00:00<00:00, 12.96it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00019255, Rollout MSE Error (joint_q) = 0.00001090 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 61 with MSE error 0.0001925538235809654. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 61 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00028404, itemized = {state_0: 0.00000089, state_1: 0.01210061, state_2: 0.00009418, state_3: 0.00017297, state_MSE: 0.00309216, q_error_norm: 0.00344334, qd_error_norm: 0.01106100} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00117953, itemized = {state_0: 0.00000072, state_1: 0.00616861, state_2: 0.00035391, state_3: 0.00094489, state_MSE: 0.00186703, q_error_norm: 0.00226581, qd_error_norm: 0.01325044} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.359 sec, time(other): 0.010 sec, time(dataloader): 6.432 sec, time(compute_loss): 1.006 sec, time(backward): 1.172 sec, time(eval): 0.507 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.109549, device='cuda:0'), grad_norm_after_clip: tensor(0.109549, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.30it/s]\n",
            "100% 5/5 [00:00<00:00, 10.80it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.55it/s]\n",
            "100% 4/4 [00:00<00:00, 12.90it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00053111, Rollout MSE Error (joint_q) = 0.00006278 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 62 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00023948, itemized = {state_0: 0.00000060, state_1: 0.01217808, state_2: 0.00008428, state_3: 0.00013504, state_MSE: 0.00309950, q_error_norm: 0.00347157, qd_error_norm: 0.01011669} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00138731, itemized = {state_0: 0.00000151, state_1: 0.01772588, state_2: 0.00041029, state_3: 0.00107111, state_MSE: 0.00480220, q_error_norm: 0.00486831, qd_error_norm: 0.01641620} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.260 sec, time(other): 0.010 sec, time(dataloader): 6.384 sec, time(compute_loss): 1.013 sec, time(backward): 1.165 sec, time(eval): 0.480 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.112486, device='cuda:0'), grad_norm_after_clip: tensor(0.112486, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.19it/s]\n",
            "100% 5/5 [00:00<00:00, 10.84it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.40it/s]\n",
            "100% 4/4 [00:00<00:00, 12.94it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00048875, Rollout MSE Error (joint_q) = 0.00009253 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 63 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00034618, itemized = {state_0: 0.00000087, state_1: 0.01267882, state_2: 0.00013772, state_3: 0.00019765, state_MSE: 0.00325376, q_error_norm: 0.00354847, qd_error_norm: 0.01172692} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00169862, itemized = {state_0: 0.00000163, state_1: 0.02620853, state_2: 0.00049630, state_3: 0.00123002, state_MSE: 0.00698412, q_error_norm: 0.00754088, qd_error_norm: 0.01773573} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.378 sec, time(other): 0.010 sec, time(dataloader): 6.409 sec, time(compute_loss): 1.015 sec, time(backward): 1.205 sec, time(eval): 0.480 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.151510, device='cuda:0'), grad_norm_after_clip: tensor(0.151510, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.15it/s]\n",
            "100% 5/5 [00:00<00:00, 10.36it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.36it/s]\n",
            "100% 4/4 [00:00<00:00, 13.03it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00045558, Rollout MSE Error (joint_q) = 0.00002172 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 64 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00033319, itemized = {state_0: 0.00000106, state_1: 0.01475863, state_2: 0.00010288, state_3: 0.00019046, state_MSE: 0.00376326, q_error_norm: 0.00433172, qd_error_norm: 0.01172236} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00113841, itemized = {state_0: 0.00000111, state_1: 0.01002190, state_2: 0.00034951, state_3: 0.00089351, state_MSE: 0.00281650, q_error_norm: 0.00295910, qd_error_norm: 0.01438218} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.391 sec, time(other): 0.010 sec, time(dataloader): 6.517 sec, time(compute_loss): 1.005 sec, time(backward): 1.153 sec, time(eval): 0.478 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.125038, device='cuda:0'), grad_norm_after_clip: tensor(0.125038, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 64 with loss 0.00113841. \u001b[0m\n",
            "100% 100/100 [00:09<00:00, 10.00it/s]\n",
            "100% 5/5 [00:00<00:00, 10.67it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.20it/s]\n",
            "100% 4/4 [00:00<00:00, 12.63it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00027704, Rollout MSE Error (joint_q) = 0.00001135 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 65 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00015230, itemized = {state_0: 0.00000049, state_1: 0.01059904, state_2: 0.00005440, state_3: 0.00008985, state_MSE: 0.00268595, q_error_norm: 0.00276502, qd_error_norm: 0.00846095} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00120083, itemized = {state_0: 0.00000075, state_1: 0.01002037, state_2: 0.00035566, state_3: 0.00096810, state_MSE: 0.00283622, q_error_norm: 0.00289424, qd_error_norm: 0.01402929} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 11.139 sec, time(other): 0.010 sec, time(dataloader): 8.200 sec, time(compute_loss): 1.015 sec, time(backward): 1.214 sec, time(eval): 0.482 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.078295, device='cuda:0'), grad_norm_after_clip: tensor(0.078295, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:10<00:00,  9.17it/s]\n",
            "100% 5/5 [00:00<00:00, 10.50it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.05it/s]\n",
            "100% 4/4 [00:00<00:00, 12.53it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00035334, Rollout MSE Error (joint_q) = 0.00003447 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 66 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00024083, itemized = {state_0: 0.00000074, state_1: 0.01113807, state_2: 0.00008702, state_3: 0.00014215, state_MSE: 0.00284199, q_error_norm: 0.00312114, qd_error_norm: 0.01029634} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00126112, itemized = {state_0: 0.00000221, state_1: 0.01387064, state_2: 0.00036356, state_3: 0.00098635, state_MSE: 0.00380569, q_error_norm: 0.00396482, qd_error_norm: 0.01499840} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 12.653 sec, time(other): 0.010 sec, time(dataloader): 9.017 sec, time(compute_loss): 1.050 sec, time(backward): 1.276 sec, time(eval): 0.493 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.117726, device='cuda:0'), grad_norm_after_clip: tensor(0.117726, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:11<00:00,  8.49it/s]\n",
            "100% 5/5 [00:00<00:00, 10.25it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.90it/s]\n",
            "100% 4/4 [00:00<00:00, 12.18it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00018241, Rollout MSE Error (joint_q) = 0.00003317 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 67 with MSE error 0.00018241132784169167. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 67 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00051085, itemized = {state_0: 0.00000158, state_1: 0.01371729, state_2: 0.00015971, state_3: 0.00033266, state_MSE: 0.00355281, q_error_norm: 0.00409866, qd_error_norm: 0.01472262} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00127598, itemized = {state_0: 0.00000100, state_1: 0.00616747, state_2: 0.00039302, state_3: 0.00100539, state_MSE: 0.00189172, q_error_norm: 0.00248388, qd_error_norm: 0.01421614} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 13.562 sec, time(other): 0.010 sec, time(dataloader): 9.934 sec, time(compute_loss): 1.034 sec, time(backward): 1.265 sec, time(eval): 0.534 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.169788, device='cuda:0'), grad_norm_after_clip: tensor(0.169788, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:13<00:00,  7.57it/s]\n",
            "100% 5/5 [00:00<00:00, 10.45it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.61it/s]\n",
            "100% 4/4 [00:00<00:00, 12.55it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00010495, Rollout MSE Error (joint_q) = 0.00000774 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 68 with MSE error 0.00010495237074792385. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 68 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00015147, itemized = {state_0: 0.00000052, state_1: 0.00998253, state_2: 0.00005538, state_3: 0.00008697, state_MSE: 0.00253135, q_error_norm: 0.00267022, qd_error_norm: 0.00840205} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00109164, itemized = {state_0: 0.00000063, state_1: 0.01772674, state_2: 0.00031359, state_3: 0.00089461, state_MSE: 0.00473389, q_error_norm: 0.00391388, qd_error_norm: 0.01144555} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 14.993 sec, time(other): 0.010 sec, time(dataloader): 11.322 sec, time(compute_loss): 1.047 sec, time(backward): 1.290 sec, time(eval): 0.527 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.074124, device='cuda:0'), grad_norm_after_clip: tensor(0.074124, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 68 with loss 0.00109164. \u001b[0m\n",
            "100% 100/100 [00:14<00:00,  7.04it/s]\n",
            "100% 5/5 [00:00<00:00, 10.41it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.89it/s]\n",
            "100% 4/4 [00:00<00:00, 12.54it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00087874, Rollout MSE Error (joint_q) = 0.00004684 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 69 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00036282, itemized = {state_0: 0.00000087, state_1: 0.01237099, state_2: 0.00013364, state_3: 0.00022133, state_MSE: 0.00318171, q_error_norm: 0.00351583, qd_error_norm: 0.01239515} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00127529, itemized = {state_0: 0.00000096, state_1: 0.01926603, state_2: 0.00038913, state_3: 0.00099716, state_MSE: 0.00516332, q_error_norm: 0.00479819, qd_error_norm: 0.01614033} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 15.964 sec, time(other): 0.010 sec, time(dataloader): 12.436 sec, time(compute_loss): 1.023 sec, time(backward): 1.198 sec, time(eval): 0.493 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.156053, device='cuda:0'), grad_norm_after_clip: tensor(0.156053, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.55it/s]\n",
            "100% 5/5 [00:00<00:00, 10.63it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.11it/s]\n",
            "100% 4/4 [00:00<00:00, 12.58it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00041230, Rollout MSE Error (joint_q) = 0.00001993 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 70 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00022341, itemized = {state_0: 0.00000068, state_1: 0.01225553, state_2: 0.00007715, state_3: 0.00013335, state_MSE: 0.00311668, q_error_norm: 0.00332206, qd_error_norm: 0.00986949} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00116138, itemized = {state_0: 0.00000078, state_1: 0.01464180, state_2: 0.00034042, state_3: 0.00094104, state_MSE: 0.00398101, q_error_norm: 0.00356927, qd_error_norm: 0.01318893} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 16.434 sec, time(other): 0.010 sec, time(dataloader): 13.512 sec, time(compute_loss): 1.024 sec, time(backward): 1.174 sec, time(eval): 0.491 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.108247, device='cuda:0'), grad_norm_after_clip: tensor(0.108247, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.54it/s]\n",
            "100% 5/5 [00:01<00:00,  4.80it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.62it/s]\n",
            "100% 4/4 [00:00<00:00, 12.02it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00028935, Rollout MSE Error (joint_q) = 0.00001543 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 71 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00035604, itemized = {state_0: 0.00000083, state_1: 0.01367918, state_2: 0.00012667, state_3: 0.00020930, state_MSE: 0.00350399, q_error_norm: 0.00390367, qd_error_norm: 0.01195561} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00120386, itemized = {state_0: 0.00000098, state_1: 0.02080856, state_2: 0.00034930, state_3: 0.00096848, state_MSE: 0.00553183, q_error_norm: 0.00477044, qd_error_norm: 0.01325526} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.176 sec, time(other): 0.010 sec, time(dataloader): 14.090 sec, time(compute_loss): 1.015 sec, time(backward): 1.196 sec, time(eval): 0.510 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.147626, device='cuda:0'), grad_norm_after_clip: tensor(0.147626, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.33it/s]\n",
            "100% 5/5 [00:01<00:00,  4.81it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.84it/s]\n",
            "100% 4/4 [00:00<00:00, 12.36it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00029935, Rollout MSE Error (joint_q) = 0.00001244 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 72 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00013184, itemized = {state_0: 0.00000047, state_1: 0.00948149, state_2: 0.00004738, state_3: 0.00007578, state_MSE: 0.00240128, q_error_norm: 0.00253071, qd_error_norm: 0.00798593} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00105883, itemized = {state_0: 0.00000072, state_1: 0.00462700, state_2: 0.00031649, state_3: 0.00085289, state_MSE: 0.00144928, q_error_norm: 0.00188531, qd_error_norm: 0.01304922} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.558 sec, time(other): 0.010 sec, time(dataloader): 14.617 sec, time(compute_loss): 1.013 sec, time(backward): 1.173 sec, time(eval): 0.498 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.073269, device='cuda:0'), grad_norm_after_clip: tensor(0.073269, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 72 with loss 0.00105883. \u001b[0m\n",
            "100% 100/100 [00:13<00:00,  7.38it/s]\n",
            "100% 5/5 [00:00<00:00, 10.62it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.96it/s]\n",
            "100% 4/4 [00:00<00:00, 12.55it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00043695, Rollout MSE Error (joint_q) = 0.00001647 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 73 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00030096, itemized = {state_0: 0.00000078, state_1: 0.01217829, state_2: 0.00011311, state_3: 0.00018077, state_MSE: 0.00311824, q_error_norm: 0.00331915, qd_error_norm: 0.01104665} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00115313, itemized = {state_0: 0.00000101, state_1: 0.00693940, state_2: 0.00034420, state_3: 0.00090691, state_MSE: 0.00204788, q_error_norm: 0.00265240, qd_error_norm: 0.01408620} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 14.704 sec, time(other): 0.010 sec, time(dataloader): 11.826 sec, time(compute_loss): 1.005 sec, time(backward): 1.161 sec, time(eval): 0.486 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.136982, device='cuda:0'), grad_norm_after_clip: tensor(0.136982, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.18it/s]\n",
            "100% 5/5 [00:00<00:00, 10.23it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.00it/s]\n",
            "100% 4/4 [00:00<00:00, 12.88it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00024357, Rollout MSE Error (joint_q) = 0.00002481 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 74 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00013135, itemized = {state_0: 0.00000045, state_1: 0.01021334, state_2: 0.00004571, state_3: 0.00007518, state_MSE: 0.00258367, q_error_norm: 0.00271290, qd_error_norm: 0.00789302} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00108895, itemized = {state_0: 0.00000077, state_1: 0.00848196, state_2: 0.00030530, state_3: 0.00088862, state_MSE: 0.00241916, q_error_norm: 0.00271657, qd_error_norm: 0.01311291} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.374 sec, time(other): 0.010 sec, time(dataloader): 6.449 sec, time(compute_loss): 1.016 sec, time(backward): 1.199 sec, time(eval): 0.484 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.070416, device='cuda:0'), grad_norm_after_clip: tensor(0.070416, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.05it/s]\n",
            "100% 5/5 [00:00<00:00, 10.21it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.75it/s]\n",
            "100% 4/4 [00:00<00:00, 12.81it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00022860, Rollout MSE Error (joint_q) = 0.00000978 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 75 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00012313, itemized = {state_0: 0.00000041, state_1: 0.00967416, state_2: 0.00004160, state_3: 0.00007357, state_MSE: 0.00244743, q_error_norm: 0.00254974, qd_error_norm: 0.00770749} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00100775, itemized = {state_0: 0.00000056, state_1: 0.00770861, state_2: 0.00030016, state_3: 0.00081363, state_MSE: 0.00220574, q_error_norm: 0.00229246, qd_error_norm: 0.01213219} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.499 sec, time(other): 0.010 sec, time(dataloader): 6.586 sec, time(compute_loss): 1.016 sec, time(backward): 1.152 sec, time(eval): 0.485 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.069620, device='cuda:0'), grad_norm_after_clip: tensor(0.069620, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 75 with loss 0.00100775. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.27it/s]\n",
            "100% 5/5 [00:00<00:00, 10.19it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.74it/s]\n",
            "100% 4/4 [00:00<00:00, 12.96it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00055282, Rollout MSE Error (joint_q) = 0.00001773 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 76 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00032330, itemized = {state_0: 0.00000076, state_1: 0.01210108, state_2: 0.00011971, state_3: 0.00019756, state_MSE: 0.00310478, q_error_norm: 0.00338008, qd_error_norm: 0.01174824} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00109012, itemized = {state_0: 0.00000076, state_1: 0.01155903, state_2: 0.00036271, state_3: 0.00083164, state_MSE: 0.00318853, q_error_norm: 0.00316590, qd_error_norm: 0.01451952} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.313 sec, time(other): 0.010 sec, time(dataloader): 6.416 sec, time(compute_loss): 1.021 sec, time(backward): 1.171 sec, time(eval): 0.478 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.146903, device='cuda:0'), grad_norm_after_clip: tensor(0.146903, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.97it/s]\n",
            "100% 5/5 [00:00<00:00, 10.67it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.28it/s]\n",
            "100% 4/4 [00:00<00:00, 13.07it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00013013, Rollout MSE Error (joint_q) = 0.00000645 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 77 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00023965, itemized = {state_0: 0.00000065, state_1: 0.01287166, state_2: 0.00008765, state_3: 0.00014361, state_MSE: 0.00327589, q_error_norm: 0.00338121, qd_error_norm: 0.01022235} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00109264, itemized = {state_0: 0.00000057, state_1: 0.00925016, state_2: 0.00032168, state_3: 0.00089268, state_MSE: 0.00261627, q_error_norm: 0.00248715, qd_error_norm: 0.01201173} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.489 sec, time(other): 0.010 sec, time(dataloader): 6.610 sec, time(compute_loss): 1.012 sec, time(backward): 1.164 sec, time(eval): 0.477 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.113389, device='cuda:0'), grad_norm_after_clip: tensor(0.113389, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.06it/s]\n",
            "100% 5/5 [00:00<00:00, 10.45it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.52it/s]\n",
            "100% 4/4 [00:00<00:00, 12.88it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00006586, Rollout MSE Error (joint_q) = 0.00000312 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 78 with MSE error 6.58616772852838e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 78 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00010639, itemized = {state_0: 0.00000035, state_1: 0.01005944, state_2: 0.00003781, state_3: 0.00006103, state_MSE: 0.00253966, q_error_norm: 0.00255270, qd_error_norm: 0.00719352} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00095237, itemized = {state_0: 0.00000045, state_1: 0.01310515, state_2: 0.00027648, state_3: 0.00077922, state_MSE: 0.00354033, q_error_norm: 0.00307425, qd_error_norm: 0.01042069} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.489 sec, time(other): 0.010 sec, time(dataloader): 6.505 sec, time(compute_loss): 1.019 sec, time(backward): 1.209 sec, time(eval): 0.512 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.062691, device='cuda:0'), grad_norm_after_clip: tensor(0.062691, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 78 with loss 0.00095237. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.18it/s]\n",
            "100% 5/5 [00:00<00:00, 10.58it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.07it/s]\n",
            "100% 4/4 [00:00<00:00, 12.90it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00031921, Rollout MSE Error (joint_q) = 0.00001484 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 79 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00013345, itemized = {state_0: 0.00000039, state_1: 0.01079163, state_2: 0.00004771, state_3: 0.00007290, state_MSE: 0.00272816, q_error_norm: 0.00284324, qd_error_norm: 0.00737752} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00095289, itemized = {state_0: 0.00000099, state_1: 0.02465802, state_2: 0.00028609, state_3: 0.00074867, state_MSE: 0.00642344, q_error_norm: 0.00525341, qd_error_norm: 0.01266380} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.397 sec, time(other): 0.010 sec, time(dataloader): 6.459 sec, time(compute_loss): 1.017 sec, time(backward): 1.172 sec, time(eval): 0.477 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.077492, device='cuda:0'), grad_norm_after_clip: tensor(0.077492, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.87it/s]\n",
            "100% 5/5 [00:00<00:00, 10.63it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.94it/s]\n",
            "100% 4/4 [00:00<00:00, 12.80it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00013443, Rollout MSE Error (joint_q) = 0.00001572 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 80 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00011970, itemized = {state_0: 0.00000038, state_1: 0.01163910, state_2: 0.00003823, state_3: 0.00006516, state_MSE: 0.00293572, q_error_norm: 0.00308143, qd_error_norm: 0.00733568} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00098557, itemized = {state_0: 0.00000057, state_1: 0.01772615, state_2: 0.00027866, state_3: 0.00080805, state_MSE: 0.00470336, q_error_norm: 0.00400480, qd_error_norm: 0.01113146} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.599 sec, time(other): 0.010 sec, time(dataloader): 6.632 sec, time(compute_loss): 1.018 sec, time(backward): 1.208 sec, time(eval): 0.481 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.067463, device='cuda:0'), grad_norm_after_clip: tensor(0.067463, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.03it/s]\n",
            "100% 5/5 [00:00<00:00, 10.64it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.99it/s]\n",
            "100% 4/4 [00:00<00:00, 13.00it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00033659, Rollout MSE Error (joint_q) = 0.00002664 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 81 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00016041, itemized = {state_0: 0.00000041, state_1: 0.01117656, state_2: 0.00005654, state_3: 0.00009437, state_MSE: 0.00283197, q_error_norm: 0.00297531, qd_error_norm: 0.00840023} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00113864, itemized = {state_0: 0.00000096, state_1: 0.02465602, state_2: 0.00033337, state_3: 0.00090964, state_MSE: 0.00647500, q_error_norm: 0.00542954, qd_error_norm: 0.01279556} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.495 sec, time(other): 0.010 sec, time(dataloader): 6.575 sec, time(compute_loss): 1.009 sec, time(backward): 1.168 sec, time(eval): 0.475 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.102434, device='cuda:0'), grad_norm_after_clip: tensor(0.102434, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.12it/s]\n",
            "100% 5/5 [00:00<00:00, 10.21it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.86it/s]\n",
            "100% 4/4 [00:00<00:00, 13.03it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00008982, Rollout MSE Error (joint_q) = 0.00001091 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 82 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00024446, itemized = {state_0: 0.00000073, state_1: 0.01175406, state_2: 0.00009110, state_3: 0.00014426, state_MSE: 0.00299754, q_error_norm: 0.00316780, qd_error_norm: 0.00985614} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00090048, itemized = {state_0: 0.00000059, state_1: 0.00462696, state_2: 0.00027493, state_3: 0.00071566, state_MSE: 0.00140454, q_error_norm: 0.00180956, qd_error_norm: 0.01072216} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.428 sec, time(other): 0.010 sec, time(dataloader): 6.503 sec, time(compute_loss): 1.019 sec, time(backward): 1.186 sec, time(eval): 0.476 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.114659, device='cuda:0'), grad_norm_after_clip: tensor(0.114659, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 82 with loss 0.00090048. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.14it/s]\n",
            "100% 5/5 [00:00<00:00, 10.80it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.59it/s]\n",
            "100% 4/4 [00:00<00:00, 13.13it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00007488, Rollout MSE Error (joint_q) = 0.00000298 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 83 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00006611, itemized = {state_0: 0.00000025, state_1: 0.00979018, state_2: 0.00002361, state_3: 0.00003689, state_MSE: 0.00246273, q_error_norm: 0.00231190, qd_error_norm: 0.00587907} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00092268, itemized = {state_0: 0.00000041, state_1: 0.00848042, state_2: 0.00026831, state_3: 0.00075976, state_MSE: 0.00237722, q_error_norm: 0.00221306, qd_error_norm: 0.01002163} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.392 sec, time(other): 0.010 sec, time(dataloader): 6.446 sec, time(compute_loss): 1.014 sec, time(backward): 1.202 sec, time(eval): 0.474 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.036235, device='cuda:0'), grad_norm_after_clip: tensor(0.036235, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.10it/s]\n",
            "100% 5/5 [00:00<00:00, 10.26it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.24it/s]\n",
            "100% 4/4 [00:00<00:00, 12.92it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00005352, Rollout MSE Error (joint_q) = 0.00000317 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 84 with MSE error 5.352355583454482e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 84 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00007679, itemized = {state_0: 0.00000025, state_1: 0.00909618, state_2: 0.00002734, state_3: 0.00004322, state_MSE: 0.00229175, q_error_norm: 0.00228397, qd_error_norm: 0.00616743} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00084743, itemized = {state_0: 0.00000039, state_1: 0.00616838, state_2: 0.00024342, state_3: 0.00069826, state_MSE: 0.00177761, q_error_norm: 0.00184925, qd_error_norm: 0.00967189} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.477 sec, time(other): 0.010 sec, time(dataloader): 6.511 sec, time(compute_loss): 1.015 sec, time(backward): 1.191 sec, time(eval): 0.516 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.049929, device='cuda:0'), grad_norm_after_clip: tensor(0.049929, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 84 with loss 0.00084743. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.83it/s]\n",
            "100% 5/5 [00:00<00:00, 10.32it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.03it/s]\n",
            "100% 4/4 [00:00<00:00, 13.08it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00011660, Rollout MSE Error (joint_q) = 0.00000552 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 85 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00006580, itemized = {state_0: 0.00000024, state_1: 0.00901901, state_2: 0.00002313, state_3: 0.00003643, state_MSE: 0.00226971, q_error_norm: 0.00222632, qd_error_norm: 0.00578466} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00088242, itemized = {state_0: 0.00000042, state_1: 0.00693801, state_2: 0.00024992, state_3: 0.00073142, state_MSE: 0.00197994, q_error_norm: 0.00205783, qd_error_norm: 0.01033733} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.610 sec, time(other): 0.010 sec, time(dataloader): 6.684 sec, time(compute_loss): 1.016 sec, time(backward): 1.201 sec, time(eval): 0.473 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.045423, device='cuda:0'), grad_norm_after_clip: tensor(0.045423, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.93it/s]\n",
            "100% 5/5 [00:00<00:00, 10.16it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.00it/s]\n",
            "100% 4/4 [00:00<00:00, 12.74it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00114492, Rollout MSE Error (joint_q) = 0.00012718 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 86 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00029733, itemized = {state_0: 0.00000084, state_1: 0.01117669, state_2: 0.00011642, state_3: 0.00017700, state_MSE: 0.00286774, q_error_norm: 0.00302202, qd_error_norm: 0.01064141} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00195175, itemized = {state_0: 0.00000514, state_1: 0.05084408, state_2: 0.00063483, state_3: 0.00135875, state_MSE: 0.01321070, q_error_norm: 0.01107094, qd_error_norm: 0.02067376} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.587 sec, time(other): 0.010 sec, time(dataloader): 6.633 sec, time(compute_loss): 1.020 sec, time(backward): 1.184 sec, time(eval): 0.490 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.140546, device='cuda:0'), grad_norm_after_clip: tensor(0.140546, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.93it/s]\n",
            "100% 5/5 [00:00<00:00, 10.49it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.91it/s]\n",
            "100% 4/4 [00:00<00:00, 13.19it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00005659, Rollout MSE Error (joint_q) = 0.00000350 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 87 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00015826, itemized = {state_0: 0.00000063, state_1: 0.01121475, state_2: 0.00004679, state_3: 0.00009811, state_MSE: 0.00284007, q_error_norm: 0.00288992, qd_error_norm: 0.00796719} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00095431, itemized = {state_0: 0.00000041, state_1: 0.00616789, state_2: 0.00027467, state_3: 0.00079109, state_MSE: 0.00180851, q_error_norm: 0.00182394, qd_error_norm: 0.00989356} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.506 sec, time(other): 0.010 sec, time(dataloader): 6.635 sec, time(compute_loss): 1.013 sec, time(backward): 1.175 sec, time(eval): 0.471 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.063488, device='cuda:0'), grad_norm_after_clip: tensor(0.063488, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.01it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/neural-robot-dynamics/algorithms/vanilla_trainer.py\", line 484, in one_epoch\n",
            "    data = next(dataloader_iter)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 732, in __next__\n",
            "    data = self._next_data()\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1471, in _next_data\n",
            "    raise StopIteration\n",
            "StopIteration\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/multiprocessing/util.py\", line 303, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.12/multiprocessing/util.py\", line 227, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/util.py\", line 136, in _remove_temp_dir\n",
            "    rmtree(tempdir, onerror=onerror)\n",
            "  File \"/usr/lib/python3.12/shutil.py\", line 759, in rmtree\n",
            "    _rmtree_safe_fd(stack, onexc)\n",
            "  File \"/usr/lib/python3.12/shutil.py\", line 703, in _rmtree_safe_fd\n",
            "    onexc(func, path, err)\n",
            "  File \"/usr/lib/python3.12/shutil.py\", line 750, in onexc\n",
            "    return onerror(func, path, exc_info)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/shutil.py\", line 662, in _rmtree_safe_fd\n",
            "    os.rmdir(name, dir_fd=dirfd)\n",
            "OSError: [Errno 39] Directory not empty: '/tmp/pymp-aiy3_nt_'\n",
            "100% 5/5 [00:00<00:00, 10.76it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.79it/s]\n",
            "100% 4/4 [00:00<00:00, 13.05it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00007277, Rollout MSE Error (joint_q) = 0.00000412 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 88 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00005345, itemized = {state_0: 0.00000021, state_1: 0.00959748, state_2: 0.00001867, state_3: 0.00002962, state_MSE: 0.00241149, q_error_norm: 0.00222526, qd_error_norm: 0.00531826} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00088531, itemized = {state_0: 0.00000042, state_1: 0.00462566, state_2: 0.00026251, state_3: 0.00072019, state_MSE: 0.00140220, q_error_norm: 0.00169305, qd_error_norm: 0.01010658} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.461 sec, time(other): 0.010 sec, time(dataloader): 6.544 sec, time(compute_loss): 1.015 sec, time(backward): 1.198 sec, time(eval): 0.475 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.029244, device='cuda:0'), grad_norm_after_clip: tensor(0.029244, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.99it/s]\n",
            "100% 5/5 [00:00<00:00, 10.30it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.20it/s]\n",
            "100% 4/4 [00:00<00:00, 13.04it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00005138, Rollout MSE Error (joint_q) = 0.00000274 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 89 with MSE error 5.1382849051151425e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 89 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00005110, itemized = {state_0: 0.00000020, state_1: 0.00959762, state_2: 0.00001786, state_3: 0.00002839, state_MSE: 0.00241102, q_error_norm: 0.00220791, qd_error_norm: 0.00524922} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00082715, itemized = {state_0: 0.00000037, state_1: 0.00462646, state_2: 0.00024422, state_3: 0.00067689, state_MSE: 0.00138698, q_error_norm: 0.00153596, qd_error_norm: 0.00930377} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.529 sec, time(other): 0.010 sec, time(dataloader): 6.560 sec, time(compute_loss): 1.025 sec, time(backward): 1.203 sec, time(eval): 0.514 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.029025, device='cuda:0'), grad_norm_after_clip: tensor(0.029025, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 89 with loss 0.00082715. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.08it/s]\n",
            "100% 5/5 [00:00<00:00,  9.17it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.28it/s]\n",
            "100% 4/4 [00:00<00:00, 12.88it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00008725, Rollout MSE Error (joint_q) = 0.00000533 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 90 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00005102, itemized = {state_0: 0.00000019, state_1: 0.00886526, state_2: 0.00001806, state_3: 0.00002816, state_MSE: 0.00222792, q_error_norm: 0.00209223, qd_error_norm: 0.00519192} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00084588, itemized = {state_0: 0.00000039, state_1: 0.00308462, state_2: 0.00024206, state_3: 0.00070071, state_MSE: 0.00100695, q_error_norm: 0.00132743, qd_error_norm: 0.00951232} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.520 sec, time(other): 0.010 sec, time(dataloader): 6.570 sec, time(compute_loss): 1.018 sec, time(backward): 1.197 sec, time(eval): 0.492 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.034656, device='cuda:0'), grad_norm_after_clip: tensor(0.034656, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.96it/s]\n",
            "100% 5/5 [00:00<00:00, 10.56it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.55it/s]\n",
            "100% 4/4 [00:00<00:00, 12.82it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004936, Rollout MSE Error (joint_q) = 0.00000301 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 91 with MSE error 4.93602710776031e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 91 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00005041, itemized = {state_0: 0.00000019, state_1: 0.00998296, state_2: 0.00001749, state_3: 0.00002780, state_MSE: 0.00250711, q_error_norm: 0.00228799, qd_error_norm: 0.00517504} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00083440, itemized = {state_0: 0.00000035, state_1: 0.00616767, state_2: 0.00024068, state_3: 0.00069161, state_MSE: 0.00177508, q_error_norm: 0.00177739, qd_error_norm: 0.00926564} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.550 sec, time(other): 0.010 sec, time(dataloader): 6.600 sec, time(compute_loss): 1.008 sec, time(backward): 1.193 sec, time(eval): 0.514 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.033045, device='cuda:0'), grad_norm_after_clip: tensor(0.033045, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.90it/s]\n",
            "100% 5/5 [00:00<00:00, 10.44it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.32it/s]\n",
            "100% 4/4 [00:00<00:00, 12.93it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00005062, Rollout MSE Error (joint_q) = 0.00000256 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 92 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00004214, itemized = {state_0: 0.00000017, state_1: 0.00851847, state_2: 0.00001462, state_3: 0.00002288, state_MSE: 0.00213904, q_error_norm: 0.00198971, qd_error_norm: 0.00479979} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00085185, itemized = {state_0: 0.00000039, state_1: 0.00693878, state_2: 0.00023676, state_3: 0.00071400, state_MSE: 0.00197248, q_error_norm: 0.00193261, qd_error_norm: 0.00918518} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.544 sec, time(other): 0.010 sec, time(dataloader): 6.668 sec, time(compute_loss): 1.012 sec, time(backward): 1.168 sec, time(eval): 0.481 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.021346, device='cuda:0'), grad_norm_after_clip: tensor(0.021346, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.89it/s]\n",
            "100% 5/5 [00:00<00:00, 10.14it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.19it/s]\n",
            "100% 4/4 [00:00<00:00, 12.88it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00006022, Rollout MSE Error (joint_q) = 0.00000434 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 93 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00004761, itemized = {state_0: 0.00000019, state_1: 0.00847994, state_2: 0.00001701, state_3: 0.00002618, state_MSE: 0.00213083, q_error_norm: 0.00200060, qd_error_norm: 0.00503508} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00081252, itemized = {state_0: 0.00000035, state_1: 0.00616712, state_2: 0.00023685, state_3: 0.00066966, state_MSE: 0.00176849, q_error_norm: 0.00179300, qd_error_norm: 0.00929073} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.612 sec, time(other): 0.010 sec, time(dataloader): 6.663 sec, time(compute_loss): 1.012 sec, time(backward): 1.192 sec, time(eval): 0.483 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.034405, device='cuda:0'), grad_norm_after_clip: tensor(0.034405, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 93 with loss 0.00081252. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.21it/s]\n",
            "100% 5/5 [00:00<00:00, 10.13it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.33it/s]\n",
            "100% 4/4 [00:00<00:00, 12.90it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004157, Rollout MSE Error (joint_q) = 0.00000259 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 94 with MSE error 4.1568542656023055e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 94 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00004595, itemized = {state_0: 0.00000019, state_1: 0.00898099, state_2: 0.00001626, state_3: 0.00002520, state_MSE: 0.00225566, q_error_norm: 0.00207428, qd_error_norm: 0.00494793} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00079530, itemized = {state_0: 0.00000033, state_1: 0.00770925, state_2: 0.00022120, state_3: 0.00066783, state_MSE: 0.00214965, q_error_norm: 0.00198989, qd_error_norm: 0.00885478} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.442 sec, time(other): 0.010 sec, time(dataloader): 6.409 sec, time(compute_loss): 1.026 sec, time(backward): 1.216 sec, time(eval): 0.513 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.031908, device='cuda:0'), grad_norm_after_clip: tensor(0.031908, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 94 with loss 0.00079530. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 11.88it/s]\n",
            "100% 5/5 [00:00<00:00, 10.58it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.53it/s]\n",
            "100% 4/4 [00:00<00:00, 12.96it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00005856, Rollout MSE Error (joint_q) = 0.00000394 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 95 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00005776, itemized = {state_0: 0.00000019, state_1: 0.00921223, state_2: 0.00002171, state_3: 0.00003231, state_MSE: 0.00231661, q_error_norm: 0.00213983, qd_error_norm: 0.00538677} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00084987, itemized = {state_0: 0.00000039, state_1: 0.00616819, state_2: 0.00022987, state_3: 0.00071756, state_MSE: 0.00177900, q_error_norm: 0.00183901, qd_error_norm: 0.00972668} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.551 sec, time(other): 0.010 sec, time(dataloader): 6.616 sec, time(compute_loss): 1.015 sec, time(backward): 1.223 sec, time(eval): 0.479 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.050560, device='cuda:0'), grad_norm_after_clip: tensor(0.050560, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.22it/s]\n",
            "100% 5/5 [00:00<00:00, 10.72it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.40it/s]\n",
            "100% 4/4 [00:00<00:00, 12.96it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004797, Rollout MSE Error (joint_q) = 0.00000279 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 96 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00005580, itemized = {state_0: 0.00000019, state_1: 0.00886518, state_2: 0.00001863, state_3: 0.00003347, state_MSE: 0.00222937, q_error_norm: 0.00208421, qd_error_norm: 0.00534433} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00081069, itemized = {state_0: 0.00000032, state_1: 0.00539737, state_2: 0.00022597, state_3: 0.00068058, state_MSE: 0.00157606, q_error_norm: 0.00162118, qd_error_norm: 0.00893631} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.312 sec, time(other): 0.010 sec, time(dataloader): 6.412 sec, time(compute_loss): 1.012 sec, time(backward): 1.193 sec, time(eval): 0.480 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.041389, device='cuda:0'), grad_norm_after_clip: tensor(0.041389, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.11it/s]\n",
            "100% 5/5 [00:00<00:00, 10.65it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.69it/s]\n",
            "100% 4/4 [00:00<00:00, 12.97it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00005015, Rollout MSE Error (joint_q) = 0.00000189 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 97 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003821, itemized = {state_0: 0.00000015, state_1: 0.00959793, state_2: 0.00001347, state_3: 0.00002081, state_MSE: 0.00240809, q_error_norm: 0.00212074, qd_error_norm: 0.00459218} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00079217, itemized = {state_0: 0.00000033, state_1: 0.00462608, state_2: 0.00022408, state_3: 0.00066154, state_MSE: 0.00137801, q_error_norm: 0.00148678, qd_error_norm: 0.00883361} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.389 sec, time(other): 0.010 sec, time(dataloader): 6.464 sec, time(compute_loss): 1.017 sec, time(backward): 1.207 sec, time(eval): 0.478 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.023996, device='cuda:0'), grad_norm_after_clip: tensor(0.023996, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 97 with loss 0.00079217. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.27it/s]\n",
            "100% 5/5 [00:00<00:00, 10.04it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.73it/s]\n",
            "100% 4/4 [00:00<00:00, 13.10it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00005042, Rollout MSE Error (joint_q) = 0.00000280 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 98 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003535, itemized = {state_0: 0.00000015, state_1: 0.00940522, state_2: 0.00001236, state_3: 0.00001920, state_MSE: 0.00235923, q_error_norm: 0.00206740, qd_error_norm: 0.00443717} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00068786, itemized = {state_0: 0.00000030, state_1: 0.00539680, state_2: 0.00019838, state_3: 0.00056865, state_MSE: 0.00154103, q_error_norm: 0.00159550, qd_error_norm: 0.00851045} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.345 sec, time(other): 0.010 sec, time(dataloader): 6.453 sec, time(compute_loss): 1.005 sec, time(backward): 1.158 sec, time(eval): 0.479 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.017920, device='cuda:0'), grad_norm_after_clip: tensor(0.017920, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 98 with loss 0.00068786. \u001b[0m\n",
            "100% 100/100 [00:08<00:00, 12.14it/s]\n",
            "100% 5/5 [00:00<00:00, 10.13it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.97it/s]\n",
            "100% 4/4 [00:00<00:00, 12.80it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004815, Rollout MSE Error (joint_q) = 0.00000216 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 99 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003350, itemized = {state_0: 0.00000014, state_1: 0.00886546, state_2: 0.00001169, state_3: 0.00001805, state_MSE: 0.00222384, q_error_norm: 0.00197137, qd_error_norm: 0.00433790} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00068731, itemized = {state_0: 0.00000029, state_1: 0.00385496, state_2: 0.00019806, state_3: 0.00056867, state_MSE: 0.00115550, q_error_norm: 0.00132370, qd_error_norm: 0.00847048} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 9.417 sec, time(other): 0.010 sec, time(dataloader): 6.464 sec, time(compute_loss): 1.023 sec, time(backward): 1.207 sec, time(eval): 0.486 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.015364, device='cuda:0'), grad_norm_after_clip: tensor(0.015364, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 99 with loss 0.00068731. \u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading output.log 134.4KB/134.4KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading output.log 134.4KB/134.4KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading output.log 134.4KB/134.4KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading output.log 134.4KB/134.4KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading output.log 134.4KB/134.4KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading output.log 134.4KB/134.4KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.3KB/2.3KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading output.log 134.4KB/134.4KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.3KB/2.3KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading output.log 134.4KB/134.4KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.3KB/2.3KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading output.log 134.4KB/134.4KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.3KB/2.3KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading output.log 134.4KB/134.4KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.3KB/2.3KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading output.log 134.4KB/134.4KB (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading output.log 134.4KB/134.4KB (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading output.log 134.4KB/134.4KB (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading output.log 134.4KB/134.4KB (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading output.log 134.4KB/134.4KB (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading history steps 99-99, summary, console lines 1349-1361 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading history steps 99-99, summary, console lines 1349-1361 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch ‚ñà‚ñá‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch ‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch ‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch ‚ñà‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch ‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch ‚ñà‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch ‚ñà‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch 0.01122\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch 5e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch 0.00166\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch 0.011\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch 9e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch 0.00383\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch 0.00596\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch 0.00772\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch 0.00917\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mbaseline_a\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/ekb59rtc\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_230113-ekb59rtc/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 3. Train Baseline Model (Transformer)\n",
        "%cd train\n",
        "\n",
        "import yaml\n",
        "import os\n",
        "\n",
        "# Load default config\n",
        "with open('cfg/Cartpole/transformer.yaml', 'r') as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "\n",
        "# Override dataset paths to point to the generated data\n",
        "cfg['algorithm']['dataset']['train_dataset_path'] = '../data/datasets/Cartpole/trajectory_len-100_train.hdf5'\n",
        "cfg['algorithm']['dataset']['valid_datasets']['exp_trajectory'] = '../data/datasets/Cartpole/trajectory_len-100_valid.hdf5'\n",
        "\n",
        "# Reduce training parameters for quick demonstration\n",
        "cfg['algorithm']['num_epochs'] = 100\n",
        "cfg['algorithm']['num_iters_per_epoch'] = 100\n",
        "cfg['algorithm']['batch_size'] = 1024\n",
        "cfg['algorithm']['dataset']['num_data_workers'] = 8\n",
        "\n",
        "# Save the modified config\n",
        "with open('colab_config.yaml', 'w') as f:\n",
        "    yaml.dump(cfg, f)\n",
        "\n",
        "# Run training\n",
        "!python train.py --cfg colab_config.yaml --logdir ../data/logs/baseline --wandb-project {wandb_project} --wandb-name baseline_a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mamba-6-train",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "mamba-6-train",
        "outputId": "3703cb3f-cbd3-4cc5-8c51-1554abc48ea5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "2025-12-08 22:08:53.107074: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-08 22:08:53.125225: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765231733.146769   85272 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765231733.153928   85272 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765231733.170824   85272 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765231733.170852   85272 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765231733.170857   85272 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765231733.170861   85272 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-08 22:08:53.175960: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 512 environments: 100% 512/512 [00:02<00:00, 255.32it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 3.59 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.48 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.54 ms  (cached)\n",
            "\u001b[91m [NeuralEnvironment] Created a DUMMY Neural Integrator. \u001b[0m\n",
            "Model = \n",
            " ModelMixedInput(\n",
            "  (encoders): ModuleDict(\n",
            "    (low_dim): MLPBase(\n",
            "      (body): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (mamba_model): Mamba(\n",
            "    (embedding): Linear(in_features=6, out_features=192, bias=True)\n",
            "    (layers): ModuleList(\n",
            "      (0-5): 6 x MambaBlock(\n",
            "        (in_proj): Linear(in_features=192, out_features=768, bias=False)\n",
            "        (conv1d): Conv1d(384, 384, kernel_size=(4,), stride=(1,), padding=(3,), groups=384)\n",
            "        (x_proj): Linear(in_features=384, out_features=44, bias=False)\n",
            "        (dt_proj): Linear(in_features=12, out_features=384, bias=True)\n",
            "        (out_proj): Linear(in_features=384, out_features=192, bias=False)\n",
            "      )\n",
            "    )\n",
            "    (norm_f): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (model): MLPDeterministic(\n",
            "    (feature_net): MLPBase(\n",
            "      (body): Sequential(\n",
            "        (0): Linear(in_features=192, out_features=64, bias=True)\n",
            "        (1): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (output_net): Linear(in_features=64, out_features=4, bias=True)\n",
            "  )\n",
            ")\n",
            "# Model Parameters =  1523460\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhargaveekc\u001b[0m (\u001b[33mbhargaveekc-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run du6slj7o (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run du6slj7o (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_220903-du6slj7o\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba-6.1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/du6slj7o\u001b[0m\n",
            "Computing dataset statistics...\n",
            "Finished computing dataset statistics...\n",
            "100% 5/5 [00:00<00:00,  9.75it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions:   0% 0/4 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.61 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.44 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.42 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.75 ms  (cached)\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 18.28it/s]\n",
            "100% 4/4 [00:00<00:00,  7.83it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 1.43373597, Rollout MSE Error (joint_q) = 0.06781687 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 0 with MSE error 1.433735966682434. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 0 \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 1.00609150, itemized = {state_0: 0.00873204, state_1: 0.89944353, state_2: 0.26278396, state_3: 0.32599545, state_MSE: 0.37423875, q_error_norm: 0.29822512, qd_error_norm: 0.58881621} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 1.285 sec, time(other): 0.000 sec, time(dataloader): 0.182 sec, time(compute_loss): 0.329 sec, time(backward): 0.000 sec, time(eval): 0.768 sec \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 0 with loss 1.00609150. \u001b[0m\n",
            "100% 100/100 [00:19<00:00,  5.09it/s]\n",
            "100% 5/5 [00:00<00:00,  8.00it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.35it/s]\n",
            "100% 4/4 [00:00<00:00,  7.95it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.01006648, Rollout MSE Error (joint_q) = 0.00037862 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 1 with MSE error 0.01006647851318121. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 1 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.15294499, itemized = {state_0: 0.00041170, state_1: 0.11579243, state_2: 0.05638102, state_3: 0.09101292, state_MSE: 0.06589952, q_error_norm: 0.04026064, qd_error_norm: 0.21313860} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.01521818, itemized = {state_0: 0.00003134, state_1: 0.04082895, state_2: 0.00575901, state_3: 0.00954140, state_MSE: 0.01404018, q_error_norm: 0.01490918, qd_error_norm: 0.07793434} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.244 sec, time(other): 0.016 sec, time(dataloader): 10.045 sec, time(compute_loss): 2.736 sec, time(backward): 7.437 sec, time(eval): 0.695 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.361847, device='cuda:0'), grad_norm_after_clip: tensor(0.347575, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 1 with loss 0.01521818. \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.96it/s]\n",
            "100% 5/5 [00:00<00:00,  8.78it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.40it/s]\n",
            "100% 4/4 [00:00<00:00,  8.13it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00524152, Rollout MSE Error (joint_q) = 0.00025694 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 2 with MSE error 0.005241516511887312. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 2 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00573126, itemized = {state_0: 0.00001616, state_1: 0.04083474, state_2: 0.00242400, state_3: 0.00300847, state_MSE: 0.01157084, q_error_norm: 0.01263930, qd_error_norm: 0.05078510} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00811788, itemized = {state_0: 0.00001190, state_1: 0.05234879, state_2: 0.00325559, state_3: 0.00515254, state_MSE: 0.01519220, q_error_norm: 0.01384261, qd_error_norm: 0.05461535} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.646 sec, time(other): 0.018 sec, time(dataloader): 10.629 sec, time(compute_loss): 2.719 sec, time(backward): 7.307 sec, time(eval): 0.682 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.143548, device='cuda:0'), grad_norm_after_clip: tensor(0.143548, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 2 with loss 0.00811788. \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.86it/s]\n",
            "100% 5/5 [00:00<00:00,  8.58it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.51it/s]\n",
            "100% 4/4 [00:00<00:00,  8.16it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00131883, Rollout MSE Error (joint_q) = 0.00011216 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 3 with MSE error 0.0013188306475058198. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 3 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00264121, itemized = {state_0: 0.00000752, state_1: 0.02675987, state_2: 0.00098978, state_3: 0.00150724, state_MSE: 0.00731610, q_error_norm: 0.00874825, qd_error_norm: 0.03465260} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00382610, itemized = {state_0: 0.00000781, state_1: 0.05928073, state_2: 0.00115697, state_3: 0.00272430, state_MSE: 0.01579245, q_error_norm: 0.01376662, qd_error_norm: 0.03317907} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.082 sec, time(other): 0.018 sec, time(dataloader): 11.042 sec, time(compute_loss): 2.722 sec, time(backward): 7.315 sec, time(eval): 0.680 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.128023, device='cuda:0'), grad_norm_after_clip: tensor(0.128023, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 3 with loss 0.00382610. \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.94it/s]\n",
            "100% 5/5 [00:00<00:00,  8.76it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.78it/s]\n",
            "100% 4/4 [00:00<00:00,  8.23it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00629336, Rollout MSE Error (joint_q) = 0.00017515 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 4 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00219225, itemized = {state_0: 0.00000501, state_1: 0.01991663, state_2: 0.00082160, state_3: 0.00133891, state_MSE: 0.00552054, q_error_norm: 0.00689197, qd_error_norm: 0.03124698} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00558593, itemized = {state_0: 0.00000679, state_1: 0.05852152, state_2: 0.00202738, state_3: 0.00390136, state_MSE: 0.01611426, q_error_norm: 0.01337811, qd_error_norm: 0.04405764} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.701 sec, time(other): 0.017 sec, time(dataloader): 10.712 sec, time(compute_loss): 2.725 sec, time(backward): 7.313 sec, time(eval): 0.660 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.171265, device='cuda:0'), grad_norm_after_clip: tensor(0.171265, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:19<00:00,  5.07it/s]\n",
            "100% 5/5 [00:00<00:00,  8.65it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.66it/s]\n",
            "100% 4/4 [00:00<00:00,  8.14it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00051208, Rollout MSE Error (joint_q) = 0.00006875 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 5 with MSE error 0.0005120831192471087. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 5 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00165782, itemized = {state_0: 0.00000411, state_1: 0.01941900, state_2: 0.00058285, state_3: 0.00103680, state_MSE: 0.00526069, q_error_norm: 0.00642564, qd_error_norm: 0.02661537} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00272759, itemized = {state_0: 0.00000503, state_1: 0.04079902, state_2: 0.00077034, state_3: 0.00204232, state_MSE: 0.01090418, q_error_norm: 0.00990996, qd_error_norm: 0.02401752} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.247 sec, time(other): 0.018 sec, time(dataloader): 10.186 sec, time(compute_loss): 2.731 sec, time(backward): 7.310 sec, time(eval): 0.684 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.112530, device='cuda:0'), grad_norm_after_clip: tensor(0.112530, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 5 with loss 0.00272759. \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.98it/s]\n",
            "100% 5/5 [00:00<00:00,  8.54it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.75it/s]\n",
            "100% 4/4 [00:00<00:00,  8.14it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00070022, Rollout MSE Error (joint_q) = 0.00005119 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 6 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00066195, itemized = {state_0: 0.00000290, state_1: 0.01653326, state_2: 0.00022314, state_3: 0.00034206, state_MSE: 0.00427534, q_error_norm: 0.00542365, qd_error_norm: 0.01800352} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00264543, itemized = {state_0: 0.00000428, state_1: 0.04389456, state_2: 0.00079008, state_3: 0.00196665, state_MSE: 0.01166389, q_error_norm: 0.01011189, qd_error_norm: 0.02381142} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.565 sec, time(other): 0.017 sec, time(dataloader): 10.555 sec, time(compute_loss): 2.735 sec, time(backward): 7.319 sec, time(eval): 0.660 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.053129, device='cuda:0'), grad_norm_after_clip: tensor(0.053129, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 6 with loss 0.00264543. \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.95it/s]\n",
            "100% 5/5 [00:00<00:00,  8.74it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.55it/s]\n",
            "100% 4/4 [00:00<00:00,  8.18it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00083177, Rollout MSE Error (joint_q) = 0.00005241 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 7 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00064382, itemized = {state_0: 0.00000244, state_1: 0.01606859, state_2: 0.00022223, state_3: 0.00035412, state_MSE: 0.00416185, q_error_norm: 0.00510748, qd_error_norm: 0.01760373} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00234575, itemized = {state_0: 0.00000376, state_1: 0.04081216, state_2: 0.00072968, state_3: 0.00171795, state_MSE: 0.01081589, q_error_norm: 0.00941807, qd_error_norm: 0.02470319} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.655 sec, time(other): 0.019 sec, time(dataloader): 10.657 sec, time(compute_loss): 2.726 sec, time(backward): 7.315 sec, time(eval): 0.659 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.069113, device='cuda:0'), grad_norm_after_clip: tensor(0.069113, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 7 with loss 0.00234575. \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.91it/s]\n",
            "100% 5/5 [00:00<00:00,  8.10it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.04it/s]\n",
            "100% 4/4 [00:00<00:00,  8.11it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00397352, Rollout MSE Error (joint_q) = 0.00011353 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 8 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00166570, itemized = {state_0: 0.00000270, state_1: 0.01471959, state_2: 0.00064726, state_3: 0.00107563, state_MSE: 0.00411130, q_error_norm: 0.00501528, qd_error_norm: 0.02571512} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00439231, itemized = {state_0: 0.00000537, state_1: 0.03925418, state_2: 0.00166367, state_3: 0.00301869, state_MSE: 0.01098548, q_error_norm: 0.00975272, qd_error_norm: 0.03702462} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.955 sec, time(other): 0.018 sec, time(dataloader): 10.885 sec, time(compute_loss): 2.726 sec, time(backward): 7.318 sec, time(eval): 0.671 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.151907, device='cuda:0'), grad_norm_after_clip: tensor(0.151907, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.98it/s]\n",
            "100% 5/5 [00:00<00:00,  8.76it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.63it/s]\n",
            "100% 4/4 [00:00<00:00,  8.11it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00040031, Rollout MSE Error (joint_q) = 0.00002821 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 9 with MSE error 0.0004003116046078503. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 9 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00103290, itemized = {state_0: 0.00000237, state_1: 0.01387207, state_2: 0.00038968, state_3: 0.00063395, state_MSE: 0.00372452, q_error_norm: 0.00469483, qd_error_norm: 0.02101058} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00237623, itemized = {state_0: 0.00000342, state_1: 0.02926103, state_2: 0.00065792, state_3: 0.00185721, state_MSE: 0.00794490, q_error_norm: 0.00733465, qd_error_norm: 0.02036728} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.572 sec, time(other): 0.017 sec, time(dataloader): 10.555 sec, time(compute_loss): 2.730 sec, time(backward): 7.313 sec, time(eval): 0.683 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.101881, device='cuda:0'), grad_norm_after_clip: tensor(0.101881, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.93it/s]\n",
            "100% 5/5 [00:00<00:00,  8.66it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.46it/s]\n",
            "100% 4/4 [00:00<00:00,  8.26it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00053542, Rollout MSE Error (joint_q) = 0.00002436 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 10 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00042928, itemized = {state_0: 0.00000171, state_1: 0.01032839, state_2: 0.00014147, state_3: 0.00024057, state_MSE: 0.00267803, q_error_norm: 0.00374007, qd_error_norm: 0.01455178} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00190252, itemized = {state_0: 0.00000291, state_1: 0.02618560, state_2: 0.00049127, state_3: 0.00151203, state_MSE: 0.00704795, q_error_norm: 0.00667633, qd_error_norm: 0.01860785} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.729 sec, time(other): 0.016 sec, time(dataloader): 10.734 sec, time(compute_loss): 2.729 sec, time(backward): 7.319 sec, time(eval): 0.655 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.054824, device='cuda:0'), grad_norm_after_clip: tensor(0.054824, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 10 with loss 0.00190252. \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.91it/s]\n",
            "100% 5/5 [00:00<00:00,  8.61it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.54it/s]\n",
            "100% 4/4 [00:00<00:00,  8.19it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00068876, Rollout MSE Error (joint_q) = 0.00003114 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 11 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00036023, itemized = {state_0: 0.00000150, state_1: 0.00909577, state_2: 0.00012205, state_3: 0.00019543, state_MSE: 0.00235369, q_error_norm: 0.00339184, qd_error_norm: 0.01286429} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00205468, itemized = {state_0: 0.00000299, state_1: 0.02464604, state_2: 0.00054892, state_3: 0.00162470, state_MSE: 0.00670566, q_error_norm: 0.00643855, qd_error_norm: 0.02121522} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.878 sec, time(other): 0.017 sec, time(dataloader): 10.851 sec, time(compute_loss): 2.728 sec, time(backward): 7.315 sec, time(eval): 0.658 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.044356, device='cuda:0'), grad_norm_after_clip: tensor(0.044356, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.94it/s]\n",
            "100% 5/5 [00:00<00:00,  8.51it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.73it/s]\n",
            "100% 4/4 [00:00<00:00,  8.21it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00069383, Rollout MSE Error (joint_q) = 0.00002461 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 12 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00073843, itemized = {state_0: 0.00000158, state_1: 0.01125310, state_2: 0.00025640, state_3: 0.00048580, state_MSE: 0.00299922, q_error_norm: 0.00383001, qd_error_norm: 0.01874063} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00204829, itemized = {state_0: 0.00000262, state_1: 0.01463664, state_2: 0.00047915, state_3: 0.00171058, state_MSE: 0.00420725, q_error_norm: 0.00472484, qd_error_norm: 0.01991259} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.698 sec, time(other): 0.017 sec, time(dataloader): 10.698 sec, time(compute_loss): 2.729 sec, time(backward): 7.314 sec, time(eval): 0.655 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.102039, device='cuda:0'), grad_norm_after_clip: tensor(0.102039, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.95it/s]\n",
            "100% 5/5 [00:00<00:00,  8.70it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.74it/s]\n",
            "100% 4/4 [00:00<00:00,  8.13it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00146802, Rollout MSE Error (joint_q) = 0.00001527 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 13 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00029320, itemized = {state_0: 0.00000124, state_1: 0.00840243, state_2: 0.00009262, state_3: 0.00016465, state_MSE: 0.00216523, q_error_norm: 0.00310769, qd_error_norm: 0.01217580} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00205148, itemized = {state_0: 0.00000238, state_1: 0.02773236, state_2: 0.00054908, state_3: 0.00165770, state_MSE: 0.00748538, q_error_norm: 0.00666070, qd_error_norm: 0.02365172} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.676 sec, time(other): 0.018 sec, time(dataloader): 10.670 sec, time(compute_loss): 2.732 sec, time(backward): 7.318 sec, time(eval): 0.667 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.042244, device='cuda:0'), grad_norm_after_clip: tensor(0.042244, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:19<00:00,  5.03it/s]\n",
            "100% 5/5 [00:00<00:00,  8.69it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.19it/s]\n",
            "100% 4/4 [00:00<00:00,  8.16it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00045447, Rollout MSE Error (joint_q) = 0.00002723 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 14 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00128505, itemized = {state_0: 0.00000182, state_1: 0.01075138, state_2: 0.00046989, state_3: 0.00087798, state_MSE: 0.00302527, q_error_norm: 0.00390914, qd_error_norm: 0.02320376} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00220213, itemized = {state_0: 0.00000263, state_1: 0.03081711, state_2: 0.00052945, state_3: 0.00183591, state_MSE: 0.00829627, q_error_norm: 0.00731526, qd_error_norm: 0.01926775} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.335 sec, time(other): 0.017 sec, time(dataloader): 10.327 sec, time(compute_loss): 2.738 sec, time(backward): 7.313 sec, time(eval): 0.667 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.129374, device='cuda:0'), grad_norm_after_clip: tensor(0.129374, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.96it/s]\n",
            "100% 5/5 [00:00<00:00,  8.55it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.76it/s]\n",
            "100% 4/4 [00:00<00:00,  8.15it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00135984, Rollout MSE Error (joint_q) = 0.00002152 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 15 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00038065, itemized = {state_0: 0.00000119, state_1: 0.00913484, state_2: 0.00013737, state_3: 0.00021983, state_MSE: 0.00237331, q_error_norm: 0.00321818, qd_error_norm: 0.01326579} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00218043, itemized = {state_0: 0.00000246, state_1: 0.01541008, state_2: 0.00047903, state_3: 0.00187948, state_MSE: 0.00444276, q_error_norm: 0.00473660, qd_error_norm: 0.02074738} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.651 sec, time(other): 0.019 sec, time(dataloader): 10.650 sec, time(compute_loss): 2.729 sec, time(backward): 7.312 sec, time(eval): 0.660 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.057299, device='cuda:0'), grad_norm_after_clip: tensor(0.057299, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.94it/s]\n",
            "100% 5/5 [00:00<00:00,  8.57it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.53it/s]\n",
            "100% 4/4 [00:00<00:00,  8.12it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00032999, Rollout MSE Error (joint_q) = 0.00002382 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 16 with MSE error 0.0003299910167697817. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 16 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00030469, itemized = {state_0: 0.00000107, state_1: 0.00898067, state_2: 0.00010286, state_3: 0.00017660, state_MSE: 0.00231530, q_error_norm: 0.00309638, qd_error_norm: 0.01198409} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00190989, itemized = {state_0: 0.00000215, state_1: 0.01310033, state_2: 0.00046381, state_3: 0.00158808, state_MSE: 0.00378859, q_error_norm: 0.00432814, qd_error_norm: 0.01672735} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.753 sec, time(other): 0.018 sec, time(dataloader): 10.736 sec, time(compute_loss): 2.729 sec, time(backward): 7.312 sec, time(eval): 0.683 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.046692, device='cuda:0'), grad_norm_after_clip: tensor(0.046692, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.98it/s]\n",
            "100% 5/5 [00:00<00:00,  8.47it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.05it/s]\n",
            "100% 4/4 [00:00<00:00,  8.06it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00045103, Rollout MSE Error (joint_q) = 0.00001335 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 17 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00021923, itemized = {state_0: 0.00000094, state_1: 0.00952018, state_2: 0.00007399, state_3: 0.00011531, state_MSE: 0.00242760, q_error_norm: 0.00309258, qd_error_norm: 0.01035583} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00154369, itemized = {state_0: 0.00000199, state_1: 0.01848846, state_2: 0.00033983, state_3: 0.00131640, state_MSE: 0.00503667, q_error_norm: 0.00491974, qd_error_norm: 0.01623788} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.576 sec, time(other): 0.013 sec, time(dataloader): 10.542 sec, time(compute_loss): 2.745 sec, time(backward): 7.330 sec, time(eval): 0.669 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.037466, device='cuda:0'), grad_norm_after_clip: tensor(0.037466, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 17 with loss 0.00154369. \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.89it/s]\n",
            "100% 5/5 [00:00<00:00,  8.45it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.71it/s]\n",
            "100% 4/4 [00:00<00:00,  8.08it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00051203, Rollout MSE Error (joint_q) = 0.00009779 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 18 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00055775, itemized = {state_0: 0.00000111, state_1: 0.01044462, state_2: 0.00021967, state_3: 0.00034270, state_MSE: 0.00275202, q_error_norm: 0.00339090, qd_error_norm: 0.01536565} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00233324, itemized = {state_0: 0.00000218, state_1: 0.03466328, state_2: 0.00061023, state_3: 0.00190867, state_MSE: 0.00929609, q_error_norm: 0.00810045, qd_error_norm: 0.01994517} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.949 sec, time(other): 0.011 sec, time(dataloader): 10.882 sec, time(compute_loss): 2.762 sec, time(backward): 7.340 sec, time(eval): 0.664 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.087955, device='cuda:0'), grad_norm_after_clip: tensor(0.087955, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.86it/s]\n",
            "100% 5/5 [00:00<00:00,  8.46it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.35it/s]\n",
            "100% 4/4 [00:00<00:00,  8.01it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00026989, Rollout MSE Error (joint_q) = 0.00001174 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 19 with MSE error 0.00026989192701876163. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 19 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00055530, itemized = {state_0: 0.00000112, state_1: 0.01121430, state_2: 0.00020341, state_3: 0.00035573, state_MSE: 0.00294364, q_error_norm: 0.00353059, qd_error_norm: 0.01506169} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00180869, itemized = {state_0: 0.00000190, state_1: 0.01540432, state_2: 0.00041423, state_3: 0.00155135, state_MSE: 0.00434295, q_error_norm: 0.00438185, qd_error_norm: 0.01555800} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.076 sec, time(other): 0.011 sec, time(dataloader): 11.011 sec, time(compute_loss): 2.750 sec, time(backward): 7.335 sec, time(eval): 0.692 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.071352, device='cuda:0'), grad_norm_after_clip: tensor(0.071352, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.86it/s]\n",
            "100% 5/5 [00:00<00:00,  8.44it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.19it/s]\n",
            "100% 4/4 [00:00<00:00,  8.05it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00014090, Rollout MSE Error (joint_q) = 0.00001056 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 20 with MSE error 0.0001409015676472336. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 20 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00020018, itemized = {state_0: 0.00000081, state_1: 0.01036756, state_2: 0.00006294, state_3: 0.00011440, state_MSE: 0.00263643, q_error_norm: 0.00309606, qd_error_norm: 0.01000121} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00149921, itemized = {state_0: 0.00000172, state_1: 0.01617890, state_2: 0.00033038, state_3: 0.00128632, state_MSE: 0.00444933, q_error_norm: 0.00445766, qd_error_norm: 0.01395403} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.106 sec, time(other): 0.011 sec, time(dataloader): 11.008 sec, time(compute_loss): 2.747 sec, time(backward): 7.335 sec, time(eval): 0.690 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.036368, device='cuda:0'), grad_norm_after_clip: tensor(0.036368, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 20 with loss 0.00149921. \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.83it/s]\n",
            "100% 5/5 [00:00<00:00,  8.46it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.62it/s]\n",
            "100% 4/4 [00:00<00:00,  8.09it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00297198, Rollout MSE Error (joint_q) = 0.00002786 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 21 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00051335, itemized = {state_0: 0.00000092, state_1: 0.01002031, state_2: 0.00021031, state_3: 0.00031314, state_MSE: 0.00263617, q_error_norm: 0.00315013, qd_error_norm: 0.01275576} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00425902, itemized = {state_0: 0.00000224, state_1: 0.01618112, state_2: 0.00142061, state_3: 0.00332035, state_MSE: 0.00523108, q_error_norm: 0.00476300, qd_error_norm: 0.03170871} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.202 sec, time(other): 0.011 sec, time(dataloader): 11.138 sec, time(compute_loss): 2.752 sec, time(backward): 7.336 sec, time(eval): 0.664 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.068564, device='cuda:0'), grad_norm_after_clip: tensor(0.068564, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.87it/s]\n",
            "100% 5/5 [00:00<00:00,  8.28it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.62it/s]\n",
            "100% 4/4 [00:00<00:00,  7.92it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00017630, Rollout MSE Error (joint_q) = 0.00003764 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 22 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00118990, itemized = {state_0: 0.00000171, state_1: 0.01217686, state_2: 0.00051238, state_3: 0.00073445, state_MSE: 0.00335635, q_error_norm: 0.00393886, qd_error_norm: 0.01970253} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00190995, itemized = {state_0: 0.00000183, state_1: 0.02002902, state_2: 0.00045375, state_3: 0.00161159, state_MSE: 0.00552405, q_error_norm: 0.00543820, qd_error_norm: 0.01534586} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.092 sec, time(other): 0.011 sec, time(dataloader): 10.966 sec, time(compute_loss): 2.755 sec, time(backward): 7.335 sec, time(eval): 0.682 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.109975, device='cuda:0'), grad_norm_after_clip: tensor(0.109975, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.95it/s]\n",
            "100% 5/5 [00:00<00:00,  8.52it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.13it/s]\n",
            "100% 4/4 [00:00<00:00,  8.07it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00021411, Rollout MSE Error (joint_q) = 0.00000829 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 23 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00014433, itemized = {state_0: 0.00000071, state_1: 0.00975133, state_2: 0.00004292, state_3: 0.00007539, state_MSE: 0.00246759, q_error_norm: 0.00293409, qd_error_norm: 0.00842018} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00169132, itemized = {state_0: 0.00000165, state_1: 0.02465304, state_2: 0.00036645, state_3: 0.00148082, state_MSE: 0.00662549, q_error_norm: 0.00568346, qd_error_norm: 0.01408288} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.701 sec, time(other): 0.012 sec, time(dataloader): 10.662 sec, time(compute_loss): 2.749 sec, time(backward): 7.329 sec, time(eval): 0.668 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.021619, device='cuda:0'), grad_norm_after_clip: tensor(0.021619, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.88it/s]\n",
            "100% 5/5 [00:00<00:00,  8.52it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.61it/s]\n",
            "100% 4/4 [00:00<00:00,  8.17it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00010945, Rollout MSE Error (joint_q) = 0.00001007 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 24 with MSE error 0.00010945498797809705. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 24 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00011453, itemized = {state_0: 0.00000063, state_1: 0.00836363, state_2: 0.00003417, state_3: 0.00005771, state_MSE: 0.00211403, q_error_norm: 0.00257308, qd_error_norm: 0.00757952} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00164683, itemized = {state_0: 0.00000159, state_1: 0.02311122, state_2: 0.00034165, state_3: 0.00146075, state_MSE: 0.00622880, q_error_norm: 0.00537101, qd_error_norm: 0.01328497} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.034 sec, time(other): 0.011 sec, time(dataloader): 10.939 sec, time(compute_loss): 2.751 sec, time(backward): 7.335 sec, time(eval): 0.679 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.016038, device='cuda:0'), grad_norm_after_clip: tensor(0.016038, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.85it/s]\n",
            "100% 5/5 [00:00<00:00,  8.47it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.51it/s]\n",
            "100% 4/4 [00:00<00:00,  8.15it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00036335, Rollout MSE Error (joint_q) = 0.00000756 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 25 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00014426, itemized = {state_0: 0.00000064, state_1: 0.00944256, state_2: 0.00004413, state_3: 0.00008111, state_MSE: 0.00239211, q_error_norm: 0.00276753, qd_error_norm: 0.00847067} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00173715, itemized = {state_0: 0.00000161, state_1: 0.02388503, state_2: 0.00034929, state_3: 0.00155682, state_MSE: 0.00644819, q_error_norm: 0.00552643, qd_error_norm: 0.01422382} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.090 sec, time(other): 0.011 sec, time(dataloader): 11.040 sec, time(compute_loss): 2.757 sec, time(backward): 7.341 sec, time(eval): 0.663 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.030767, device='cuda:0'), grad_norm_after_clip: tensor(0.030767, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.92it/s]\n",
            "100% 5/5 [00:00<00:00,  8.36it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.89it/s]\n",
            "100% 4/4 [00:00<00:00,  8.05it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00105445, Rollout MSE Error (joint_q) = 0.00002943 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 26 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00047660, itemized = {state_0: 0.00000105, state_1: 0.01202360, state_2: 0.00015865, state_3: 0.00032112, state_MSE: 0.00312610, q_error_norm: 0.00354692, qd_error_norm: 0.01441246} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00282521, itemized = {state_0: 0.00000213, state_1: 0.03543893, state_2: 0.00107603, state_3: 0.00201751, state_MSE: 0.00963365, q_error_norm: 0.00776864, qd_error_norm: 0.02269610} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.880 sec, time(other): 0.011 sec, time(dataloader): 10.778 sec, time(compute_loss): 2.746 sec, time(backward): 7.333 sec, time(eval): 0.672 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.079501, device='cuda:0'), grad_norm_after_clip: tensor(0.079501, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.95it/s]\n",
            "100% 5/5 [00:00<00:00,  8.55it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.64it/s]\n",
            "100% 4/4 [00:00<00:00,  8.11it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00013538, Rollout MSE Error (joint_q) = 0.00001544 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 27 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00027436, itemized = {state_0: 0.00000084, state_1: 0.01125357, state_2: 0.00008800, state_3: 0.00017197, state_MSE: 0.00287860, q_error_norm: 0.00328534, qd_error_norm: 0.01111539} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00173202, itemized = {state_0: 0.00000151, state_1: 0.04005962, state_2: 0.00032609, state_3: 0.00157891, state_MSE: 0.01049153, q_error_norm: 0.00809608, qd_error_norm: 0.01335497} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.653 sec, time(other): 0.012 sec, time(dataloader): 10.610 sec, time(compute_loss): 2.754 sec, time(backward): 7.336 sec, time(eval): 0.663 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.050716, device='cuda:0'), grad_norm_after_clip: tensor(0.050716, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.90it/s]\n",
            "100% 5/5 [00:00<00:00,  8.44it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.32it/s]\n",
            "100% 4/4 [00:00<00:00,  8.09it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00015020, Rollout MSE Error (joint_q) = 0.00002927 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 28 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00012982, itemized = {state_0: 0.00000057, state_1: 0.00871063, state_2: 0.00004051, state_3: 0.00007158, state_MSE: 0.00220582, q_error_norm: 0.00260270, qd_error_norm: 0.00802124} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00173606, itemized = {state_0: 0.00000153, state_1: 0.02850637, state_2: 0.00033750, state_3: 0.00156957, state_MSE: 0.00760374, q_error_norm: 0.00629608, qd_error_norm: 0.01283354} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.943 sec, time(other): 0.011 sec, time(dataloader): 10.834 sec, time(compute_loss): 2.745 sec, time(backward): 7.336 sec, time(eval): 0.670 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.031033, device='cuda:0'), grad_norm_after_clip: tensor(0.031033, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.81it/s]\n",
            "100% 5/5 [00:00<00:00,  8.46it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.66it/s]\n",
            "100% 4/4 [00:00<00:00,  8.13it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00041644, Rollout MSE Error (joint_q) = 0.00000559 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 29 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00011711, itemized = {state_0: 0.00000054, state_1: 0.00820946, state_2: 0.00003422, state_3: 0.00006637, state_MSE: 0.00207765, q_error_norm: 0.00246588, qd_error_norm: 0.00771481} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00145172, itemized = {state_0: 0.00000142, state_1: 0.01617958, state_2: 0.00027572, state_3: 0.00131210, state_MSE: 0.00444220, q_error_norm: 0.00421291, qd_error_norm: 0.01383574} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.280 sec, time(other): 0.011 sec, time(dataloader): 11.243 sec, time(compute_loss): 2.747 sec, time(backward): 7.333 sec, time(eval): 0.661 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.028032, device='cuda:0'), grad_norm_after_clip: tensor(0.028032, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 29 with loss 0.00145172. \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.91it/s]\n",
            "100% 5/5 [00:00<00:00,  8.55it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.26it/s]\n",
            "100% 4/4 [00:00<00:00,  8.17it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00083746, Rollout MSE Error (joint_q) = 0.00005409 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 30 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00043400, itemized = {state_0: 0.00000077, state_1: 0.01206232, state_2: 0.00016978, state_3: 0.00027047, state_MSE: 0.00312583, q_error_norm: 0.00344108, qd_error_norm: 0.01319988} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00320393, itemized = {state_0: 0.00000250, state_1: 0.02233322, state_2: 0.00094873, state_3: 0.00253982, state_MSE: 0.00645607, q_error_norm: 0.00625602, qd_error_norm: 0.02568123} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.843 sec, time(other): 0.015 sec, time(dataloader): 10.818 sec, time(compute_loss): 2.740 sec, time(backward): 7.325 sec, time(eval): 0.662 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.082041, device='cuda:0'), grad_norm_after_clip: tensor(0.082041, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.85it/s]\n",
            "100% 5/5 [00:00<00:00,  8.55it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.84it/s]\n",
            "100% 4/4 [00:00<00:00,  8.19it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00009035, Rollout MSE Error (joint_q) = 0.00000730 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 31 with MSE error 9.034959657583386e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 31 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00036214, itemized = {state_0: 0.00000081, state_1: 0.01017422, state_2: 0.00012747, state_3: 0.00023149, state_MSE: 0.00263350, q_error_norm: 0.00307119, qd_error_norm: 0.01139155} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00150579, itemized = {state_0: 0.00000150, state_1: 0.02696497, state_2: 0.00030886, state_3: 0.00133908, state_MSE: 0.00715360, q_error_norm: 0.00586935, qd_error_norm: 0.01247230} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.093 sec, time(other): 0.015 sec, time(dataloader): 11.053 sec, time(compute_loss): 2.742 sec, time(backward): 7.326 sec, time(eval): 0.677 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.049884, device='cuda:0'), grad_norm_after_clip: tensor(0.049884, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:19<00:00,  5.01it/s]\n",
            "100% 5/5 [00:00<00:00,  8.60it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.40it/s]\n",
            "100% 4/4 [00:00<00:00,  8.09it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00013279, Rollout MSE Error (joint_q) = 0.00000841 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 32 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00014495, itemized = {state_0: 0.00000049, state_1: 0.00836389, state_2: 0.00005440, state_3: 0.00008022, state_MSE: 0.00212475, q_error_norm: 0.00242790, qd_error_norm: 0.00815039} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00170356, itemized = {state_0: 0.00000140, state_1: 0.01618048, state_2: 0.00033784, state_3: 0.00154780, state_MSE: 0.00451688, q_error_norm: 0.00411072, qd_error_norm: 0.01294917} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.417 sec, time(other): 0.015 sec, time(dataloader): 10.394 sec, time(compute_loss): 2.743 sec, time(backward): 7.319 sec, time(eval): 0.665 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.034860, device='cuda:0'), grad_norm_after_clip: tensor(0.034860, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.90it/s]\n",
            "100% 5/5 [00:00<00:00,  7.91it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.39it/s]\n",
            "100% 4/4 [00:00<00:00,  8.18it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00025182, Rollout MSE Error (joint_q) = 0.00001058 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 33 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00021731, itemized = {state_0: 0.00000055, state_1: 0.00909569, state_2: 0.00007388, state_3: 0.00013810, state_MSE: 0.00232705, q_error_norm: 0.00266858, qd_error_norm: 0.00996890} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00198684, itemized = {state_0: 0.00000140, state_1: 0.00847418, state_2: 0.00038180, state_3: 0.00183102, state_MSE: 0.00267210, q_error_norm: 0.00290815, qd_error_norm: 0.01388600} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.917 sec, time(other): 0.014 sec, time(dataloader): 10.906 sec, time(compute_loss): 2.735 sec, time(backward): 7.322 sec, time(eval): 0.660 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.048900, device='cuda:0'), grad_norm_after_clip: tensor(0.048900, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.98it/s]\n",
            "100% 5/5 [00:00<00:00,  8.57it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.58it/s]\n",
            "100% 4/4 [00:00<00:00,  8.14it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00019300, Rollout MSE Error (joint_q) = 0.00001455 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 34 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00047641, itemized = {state_0: 0.00000076, state_1: 0.01113736, state_2: 0.00017525, state_3: 0.00031647, state_MSE: 0.00290746, q_error_norm: 0.00323468, qd_error_norm: 0.01448637} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00204047, itemized = {state_0: 0.00000150, state_1: 0.02157253, state_2: 0.00041546, state_3: 0.00184394, state_MSE: 0.00595836, q_error_norm: 0.00516413, qd_error_norm: 0.01443873} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.597 sec, time(other): 0.014 sec, time(dataloader): 10.551 sec, time(compute_loss): 2.736 sec, time(backward): 7.325 sec, time(eval): 0.662 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.084149, device='cuda:0'), grad_norm_after_clip: tensor(0.084149, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.88it/s]\n",
            "100% 5/5 [00:00<00:00,  8.50it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.65it/s]\n",
            "100% 4/4 [00:00<00:00,  8.18it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00019125, Rollout MSE Error (joint_q) = 0.00000502 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 35 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00016171, itemized = {state_0: 0.00000051, state_1: 0.00894173, state_2: 0.00005259, state_3: 0.00009917, state_MSE: 0.00227350, q_error_norm: 0.00258064, qd_error_norm: 0.00845637} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00153737, itemized = {state_0: 0.00000131, state_1: 0.01926051, state_2: 0.00031984, state_3: 0.00137533, state_MSE: 0.00523925, q_error_norm: 0.00455443, qd_error_norm: 0.01246116} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.967 sec, time(other): 0.015 sec, time(dataloader): 10.966 sec, time(compute_loss): 2.732 sec, time(backward): 7.320 sec, time(eval): 0.658 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.033510, device='cuda:0'), grad_norm_after_clip: tensor(0.033510, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.95it/s]\n",
            "100% 5/5 [00:00<00:00,  8.60it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.75it/s]\n",
            "100% 4/4 [00:00<00:00,  8.09it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00021835, Rollout MSE Error (joint_q) = 0.00000435 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 36 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00008586, itemized = {state_0: 0.00000041, state_1: 0.00801718, state_2: 0.00002725, state_3: 0.00004536, state_MSE: 0.00202255, q_error_norm: 0.00228143, qd_error_norm: 0.00645329} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00146208, itemized = {state_0: 0.00000127, state_1: 0.02388540, state_2: 0.00029803, state_3: 0.00131422, state_MSE: 0.00637473, q_error_norm: 0.00524422, qd_error_norm: 0.01227396} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.675 sec, time(other): 0.016 sec, time(dataloader): 10.660 sec, time(compute_loss): 2.734 sec, time(backward): 7.321 sec, time(eval): 0.665 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.020831, device='cuda:0'), grad_norm_after_clip: tensor(0.020831, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.90it/s]\n",
            "100% 5/5 [00:00<00:00,  8.56it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.62it/s]\n",
            "100% 4/4 [00:00<00:00,  8.16it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00096721, Rollout MSE Error (joint_q) = 0.00002858 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 37 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00016896, itemized = {state_0: 0.00000044, state_1: 0.00898029, state_2: 0.00005856, state_3: 0.00010330, state_MSE: 0.00228565, q_error_norm: 0.00257761, qd_error_norm: 0.00870226} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00193177, itemized = {state_0: 0.00000134, state_1: 0.03697670, state_2: 0.00035806, state_3: 0.00179256, state_MSE: 0.00978216, q_error_norm: 0.00743823, qd_error_norm: 0.01653873} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.875 sec, time(other): 0.017 sec, time(dataloader): 10.853 sec, time(compute_loss): 2.733 sec, time(backward): 7.319 sec, time(eval): 0.667 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.043310, device='cuda:0'), grad_norm_after_clip: tensor(0.043310, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:21<00:00,  4.75it/s]\n",
            "100% 5/5 [00:00<00:00,  8.54it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.30it/s]\n",
            "100% 4/4 [00:00<00:00,  8.27it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00072574, Rollout MSE Error (joint_q) = 0.00000979 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 38 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00035421, itemized = {state_0: 0.00000063, state_1: 0.01121481, state_2: 0.00011878, state_3: 0.00023579, state_MSE: 0.00289250, q_error_norm: 0.00330112, qd_error_norm: 0.01228999} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00205227, itemized = {state_0: 0.00000157, state_1: 0.02464463, state_2: 0.00044886, state_3: 0.00182088, state_MSE: 0.00672899, q_error_norm: 0.00565617, qd_error_norm: 0.01932275} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.527 sec, time(other): 0.015 sec, time(dataloader): 11.528 sec, time(compute_loss): 2.738 sec, time(backward): 7.319 sec, time(eval): 0.655 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.070327, device='cuda:0'), grad_norm_after_clip: tensor(0.070327, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:22<00:00,  4.45it/s]\n",
            "100% 5/5 [00:00<00:00,  8.67it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.76it/s]\n",
            "100% 4/4 [00:00<00:00,  8.22it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00021365, Rollout MSE Error (joint_q) = 0.00001291 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 39 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00053562, itemized = {state_0: 0.00000081, state_1: 0.01148418, state_2: 0.00021440, state_3: 0.00034084, state_MSE: 0.00301006, q_error_norm: 0.00332747, qd_error_norm: 0.01438136} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00188570, itemized = {state_0: 0.00000139, state_1: 0.03621107, state_2: 0.00041767, state_3: 0.00167603, state_MSE: 0.00957654, q_error_norm: 0.00731361, qd_error_norm: 0.01386051} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 23.920 sec, time(other): 0.016 sec, time(dataloader): 12.911 sec, time(compute_loss): 2.738 sec, time(backward): 7.321 sec, time(eval): 0.655 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.076969, device='cuda:0'), grad_norm_after_clip: tensor(0.076969, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:21<00:00,  4.62it/s]\n",
            "100% 5/5 [00:00<00:00,  8.75it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.57it/s]\n",
            "100% 4/4 [00:00<00:00,  8.19it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00009920, Rollout MSE Error (joint_q) = 0.00000628 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 40 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00013737, itemized = {state_0: 0.00000044, state_1: 0.00871060, state_2: 0.00004846, state_3: 0.00008020, state_MSE: 0.00220992, q_error_norm: 0.00245188, qd_error_norm: 0.00783356} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00174629, itemized = {state_0: 0.00000124, state_1: 0.02003468, state_2: 0.00035405, state_3: 0.00158576, state_MSE: 0.00549393, q_error_norm: 0.00465897, qd_error_norm: 0.01203598} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 23.709 sec, time(other): 0.015 sec, time(dataloader): 12.081 sec, time(compute_loss): 2.732 sec, time(backward): 7.324 sec, time(eval): 0.658 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.032591, device='cuda:0'), grad_norm_after_clip: tensor(0.032591, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:21<00:00,  4.68it/s]\n",
            "100% 5/5 [00:00<00:00,  8.74it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.55it/s]\n",
            "100% 4/4 [00:00<00:00,  8.23it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00020725, Rollout MSE Error (joint_q) = 0.00001527 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 41 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00013778, itemized = {state_0: 0.00000039, state_1: 0.00859528, state_2: 0.00004929, state_3: 0.00008257, state_MSE: 0.00218188, q_error_norm: 0.00238545, qd_error_norm: 0.00779728} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00201793, itemized = {state_0: 0.00000117, state_1: 0.02388317, state_2: 0.00041495, state_3: 0.00184218, state_MSE: 0.00653537, q_error_norm: 0.00527480, qd_error_norm: 0.01357052} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 23.379 sec, time(other): 0.017 sec, time(dataloader): 11.849 sec, time(compute_loss): 2.724 sec, time(backward): 7.320 sec, time(eval): 0.656 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.037602, device='cuda:0'), grad_norm_after_clip: tensor(0.037602, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:23<00:00,  4.20it/s]\n",
            "100% 5/5 [00:01<00:00,  4.46it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.75it/s]\n",
            "100% 4/4 [00:00<00:00,  8.15it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00013224, Rollout MSE Error (joint_q) = 0.00000843 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 42 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00012901, itemized = {state_0: 0.00000041, state_1: 0.00921190, state_2: 0.00004161, state_3: 0.00007949, state_MSE: 0.00233335, q_error_norm: 0.00251044, qd_error_norm: 0.00772684} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00168189, itemized = {state_0: 0.00000121, state_1: 0.01925926, state_2: 0.00034717, state_3: 0.00152545, state_MSE: 0.00528327, q_error_norm: 0.00445406, qd_error_norm: 0.01197232} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 26.389 sec, time(other): 0.020 sec, time(dataloader): 14.825 sec, time(compute_loss): 2.729 sec, time(backward): 7.321 sec, time(eval): 0.659 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.033682, device='cuda:0'), grad_norm_after_clip: tensor(0.033682, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:25<00:00,  3.88it/s]\n",
            "100% 5/5 [00:01<00:00,  4.34it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.56it/s]\n",
            "100% 4/4 [00:00<00:00,  8.22it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00017000, Rollout MSE Error (joint_q) = 0.00000428 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 43 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00009373, itemized = {state_0: 0.00000036, state_1: 0.00832535, state_2: 0.00002981, state_3: 0.00005413, state_MSE: 0.00210241, q_error_norm: 0.00229783, qd_error_norm: 0.00666012} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00177259, itemized = {state_0: 0.00000117, state_1: 0.02311453, state_2: 0.00034923, state_3: 0.00163122, state_MSE: 0.00627403, q_error_norm: 0.00501921, qd_error_norm: 0.01197017} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 27.873 sec, time(other): 0.020 sec, time(dataloader): 16.834 sec, time(compute_loss): 2.721 sec, time(backward): 7.307 sec, time(eval): 0.657 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.026177, device='cuda:0'), grad_norm_after_clip: tensor(0.026177, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:24<00:00,  4.00it/s]\n",
            "100% 5/5 [00:01<00:00,  4.36it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.70it/s]\n",
            "100% 4/4 [00:00<00:00,  8.08it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00010890, Rollout MSE Error (joint_q) = 0.00000475 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 44 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00007281, itemized = {state_0: 0.00000032, state_1: 0.00821004, state_2: 0.00002205, state_3: 0.00004023, state_MSE: 0.00206816, q_error_norm: 0.00223496, qd_error_norm: 0.00595285} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00179898, itemized = {state_0: 0.00000120, state_1: 0.01386949, state_2: 0.00036683, state_3: 0.00164036, state_MSE: 0.00396947, q_error_norm: 0.00355501, qd_error_norm: 0.01166689} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 27.078 sec, time(other): 0.017 sec, time(dataloader): 16.020 sec, time(compute_loss): 2.730 sec, time(backward): 7.323 sec, time(eval): 0.665 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.022200, device='cuda:0'), grad_norm_after_clip: tensor(0.022200, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:25<00:00,  3.93it/s]\n",
            "100% 5/5 [00:01<00:00,  4.32it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.48it/s]\n",
            "100% 4/4 [00:00<00:00,  8.05it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00014424, Rollout MSE Error (joint_q) = 0.00000532 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 45 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00007999, itemized = {state_0: 0.00000031, state_1: 0.00867267, state_2: 0.00002551, state_3: 0.00004636, state_MSE: 0.00218621, q_error_norm: 0.00226320, qd_error_norm: 0.00627258} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00166986, itemized = {state_0: 0.00000118, state_1: 0.01926360, state_2: 0.00036022, state_3: 0.00149793, state_MSE: 0.00528073, q_error_norm: 0.00442459, qd_error_norm: 0.01174531} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 27.614 sec, time(other): 0.017 sec, time(dataloader): 16.490 sec, time(compute_loss): 2.731 sec, time(backward): 7.318 sec, time(eval): 0.669 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.023921, device='cuda:0'), grad_norm_after_clip: tensor(0.023921, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:26<00:00,  3.77it/s]\n",
            "100% 5/5 [00:01<00:00,  4.30it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.40it/s]\n",
            "100% 4/4 [00:00<00:00,  8.08it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00209520, Rollout MSE Error (joint_q) = 0.00001833 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 46 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00041123, itemized = {state_0: 0.00000072, state_1: 0.01025167, state_2: 0.00015309, state_3: 0.00027384, state_MSE: 0.00266983, q_error_norm: 0.00293560, qd_error_norm: 0.01262436} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00286166, itemized = {state_0: 0.00000238, state_1: 0.04313710, state_2: 0.00063522, state_3: 0.00251326, state_MSE: 0.01157199, q_error_norm: 0.00929381, qd_error_norm: 0.02556816} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 28.658 sec, time(other): 0.019 sec, time(dataloader): 17.610 sec, time(compute_loss): 2.721 sec, time(backward): 7.311 sec, time(eval): 0.666 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.072676, device='cuda:0'), grad_norm_after_clip: tensor(0.072676, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:27<00:00,  3.69it/s]\n",
            "100% 5/5 [00:01<00:00,  4.40it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.58it/s]\n",
            "100% 4/4 [00:00<00:00,  8.21it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00010834, Rollout MSE Error (joint_q) = 0.00000505 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 47 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00052735, itemized = {state_0: 0.00000100, state_1: 0.01063583, state_2: 0.00020417, state_3: 0.00033976, state_MSE: 0.00279519, q_error_norm: 0.00310943, qd_error_norm: 0.01296315} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00156174, itemized = {state_0: 0.00000121, state_1: 0.01926260, state_2: 0.00031801, state_3: 0.00141341, state_MSE: 0.00524880, q_error_norm: 0.00444623, qd_error_norm: 0.01162071} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 29.143 sec, time(other): 0.020 sec, time(dataloader): 18.106 sec, time(compute_loss): 2.725 sec, time(backward): 7.311 sec, time(eval): 0.661 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.063095, device='cuda:0'), grad_norm_after_clip: tensor(0.063095, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:21<00:00,  4.59it/s]\n",
            "100% 5/5 [00:00<00:00,  8.67it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.35it/s]\n",
            "100% 4/4 [00:00<00:00,  8.23it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00006000, Rollout MSE Error (joint_q) = 0.00000522 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 48 with MSE error 6.000057328492403e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 48 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00006169, itemized = {state_0: 0.00000029, state_1: 0.00716963, state_2: 0.00001923, state_3: 0.00003314, state_MSE: 0.00180557, q_error_norm: 0.00198633, qd_error_norm: 0.00549435} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00168658, itemized = {state_0: 0.00000105, state_1: 0.01695130, state_2: 0.00032266, state_3: 0.00156345, state_MSE: 0.00470961, q_error_norm: 0.00402073, qd_error_norm: 0.01092972} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 23.286 sec, time(other): 0.019 sec, time(dataloader): 12.276 sec, time(compute_loss): 2.726 sec, time(backward): 7.312 sec, time(eval): 0.677 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.016035, device='cuda:0'), grad_norm_after_clip: tensor(0.016035, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.93it/s]\n",
            "100% 5/5 [00:00<00:00,  8.50it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.45it/s]\n",
            "100% 4/4 [00:00<00:00,  8.00it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00011318, Rollout MSE Error (joint_q) = 0.00000511 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 49 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00006207, itemized = {state_0: 0.00000028, state_1: 0.00663005, state_2: 0.00001952, state_3: 0.00003430, state_MSE: 0.00167103, q_error_norm: 0.00187488, qd_error_norm: 0.00550884} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00150135, itemized = {state_0: 0.00000112, state_1: 0.01386665, state_2: 0.00032439, state_3: 0.00134117, state_MSE: 0.00388333, q_error_norm: 0.00353014, qd_error_norm: 0.01113644} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.777 sec, time(other): 0.021 sec, time(dataloader): 10.767 sec, time(compute_loss): 2.723 sec, time(backward): 7.306 sec, time(eval): 0.678 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.018416, device='cuda:0'), grad_norm_after_clip: tensor(0.018416, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:19<00:00,  5.05it/s]\n",
            "100% 5/5 [00:00<00:00,  8.66it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.62it/s]\n",
            "100% 4/4 [00:00<00:00,  8.10it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00014376, Rollout MSE Error (joint_q) = 0.00000880 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 50 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00006303, itemized = {state_0: 0.00000027, state_1: 0.00751635, state_2: 0.00002014, state_3: 0.00003444, state_MSE: 0.00189280, q_error_norm: 0.00203240, qd_error_norm: 0.00553730} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00150836, itemized = {state_0: 0.00000105, state_1: 0.01772284, state_2: 0.00033127, state_3: 0.00134130, state_MSE: 0.00484912, q_error_norm: 0.00422185, qd_error_norm: 0.01151988} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.305 sec, time(other): 0.020 sec, time(dataloader): 10.294 sec, time(compute_loss): 2.717 sec, time(backward): 7.304 sec, time(eval): 0.664 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.019846, device='cuda:0'), grad_norm_after_clip: tensor(0.019846, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.96it/s]\n",
            "100% 5/5 [00:00<00:00,  8.54it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.00it/s]\n",
            "100% 4/4 [00:00<00:00,  8.05it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00023079, Rollout MSE Error (joint_q) = 0.00003329 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 51 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00027949, itemized = {state_0: 0.00000047, state_1: 0.00948157, state_2: 0.00010814, state_3: 0.00017654, state_MSE: 0.00244168, q_error_norm: 0.00268938, qd_error_norm: 0.01023621} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00200944, itemized = {state_0: 0.00000114, state_1: 0.02618364, state_2: 0.00044721, state_3: 0.00177754, state_MSE: 0.00710238, q_error_norm: 0.00612505, qd_error_norm: 0.01364245} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.649 sec, time(other): 0.017 sec, time(dataloader): 10.619 sec, time(compute_loss): 2.725 sec, time(backward): 7.319 sec, time(eval): 0.670 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.058682, device='cuda:0'), grad_norm_after_clip: tensor(0.058682, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.93it/s]\n",
            "100% 5/5 [00:00<00:00,  8.61it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.76it/s]\n",
            "100% 4/4 [00:00<00:00,  8.19it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00006277, Rollout MSE Error (joint_q) = 0.00000363 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 52 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00008289, itemized = {state_0: 0.00000033, state_1: 0.00867252, state_2: 0.00002634, state_3: 0.00004614, state_MSE: 0.00218633, q_error_norm: 0.00233735, qd_error_norm: 0.00609997} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00177157, itemized = {state_0: 0.00000103, state_1: 0.01232665, state_2: 0.00035338, state_3: 0.00163205, state_MSE: 0.00357828, q_error_norm: 0.00322008, qd_error_norm: 0.01070278} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.771 sec, time(other): 0.019 sec, time(dataloader): 10.786 sec, time(compute_loss): 2.714 sec, time(backward): 7.315 sec, time(eval): 0.656 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.022893, device='cuda:0'), grad_norm_after_clip: tensor(0.022893, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.96it/s]\n",
            "100% 5/5 [00:00<00:00,  8.70it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.29it/s]\n",
            "100% 4/4 [00:00<00:00,  8.10it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00007395, Rollout MSE Error (joint_q) = 0.00000584 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 53 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00004954, itemized = {state_0: 0.00000025, state_1: 0.00651457, state_2: 0.00001600, state_3: 0.00002531, state_MSE: 0.00163903, q_error_norm: 0.00180993, qd_error_norm: 0.00486144} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00166591, itemized = {state_0: 0.00000100, state_1: 0.01618090, state_2: 0.00033381, state_3: 0.00152737, state_MSE: 0.00451077, q_error_norm: 0.00387508, qd_error_norm: 0.01100393} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.667 sec, time(other): 0.020 sec, time(dataloader): 10.652 sec, time(compute_loss): 2.723 sec, time(backward): 7.308 sec, time(eval): 0.667 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.013702, device='cuda:0'), grad_norm_after_clip: tensor(0.013702, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.98it/s]\n",
            "100% 5/5 [00:00<00:00,  8.52it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.33it/s]\n",
            "100% 4/4 [00:00<00:00,  8.20it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00013502, Rollout MSE Error (joint_q) = 0.00003531 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 54 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00006102, itemized = {state_0: 0.00000025, state_1: 0.00801756, state_2: 0.00001856, state_3: 0.00003318, state_MSE: 0.00201738, q_error_norm: 0.00215492, qd_error_norm: 0.00541896} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00151318, itemized = {state_0: 0.00000097, state_1: 0.02234693, state_2: 0.00031080, state_3: 0.00136765, state_MSE: 0.00600659, q_error_norm: 0.00511989, qd_error_norm: 0.01069559} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.569 sec, time(other): 0.020 sec, time(dataloader): 10.571 sec, time(compute_loss): 2.720 sec, time(backward): 7.319 sec, time(eval): 0.666 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.022097, device='cuda:0'), grad_norm_after_clip: tensor(0.022097, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:19<00:00,  5.05it/s]\n",
            "100% 5/5 [00:00<00:00,  8.66it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.64it/s]\n",
            "100% 4/4 [00:00<00:00,  8.20it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00011179, Rollout MSE Error (joint_q) = 0.00000367 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 55 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00006293, itemized = {state_0: 0.00000025, state_1: 0.00828722, state_2: 0.00001970, state_3: 0.00003398, state_MSE: 0.00208529, q_error_norm: 0.00221232, qd_error_norm: 0.00539026} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00150044, itemized = {state_0: 0.00000101, state_1: 0.01541061, state_2: 0.00034892, state_3: 0.00131860, state_MSE: 0.00426978, q_error_norm: 0.00371171, qd_error_norm: 0.01196875} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.281 sec, time(other): 0.019 sec, time(dataloader): 10.281 sec, time(compute_loss): 2.722 sec, time(backward): 7.308 sec, time(eval): 0.657 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.022758, device='cuda:0'), grad_norm_after_clip: tensor(0.022758, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.90it/s]\n",
            "100% 5/5 [00:00<00:00,  8.31it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.96it/s]\n",
            "100% 4/4 [00:00<00:00,  7.95it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00068854, Rollout MSE Error (joint_q) = 0.00001660 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 56 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00013432, itemized = {state_0: 0.00000029, state_1: 0.00901884, state_2: 0.00004214, state_3: 0.00008791, state_MSE: 0.00228730, q_error_norm: 0.00245784, qd_error_norm: 0.00783890} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00158796, itemized = {state_0: 0.00000119, state_1: 0.02003446, state_2: 0.00036518, state_3: 0.00137425, state_MSE: 0.00544377, q_error_norm: 0.00509806, qd_error_norm: 0.01427436} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.915 sec, time(other): 0.020 sec, time(dataloader): 10.902 sec, time(compute_loss): 2.723 sec, time(backward): 7.307 sec, time(eval): 0.682 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.041815, device='cuda:0'), grad_norm_after_clip: tensor(0.041815, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.94it/s]\n",
            "100% 5/5 [00:00<00:00,  8.69it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.66it/s]\n",
            "100% 4/4 [00:00<00:00,  8.12it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00016746, Rollout MSE Error (joint_q) = 0.00001695 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 57 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00023226, itemized = {state_0: 0.00000043, state_1: 0.00940392, state_2: 0.00008411, state_3: 0.00015341, state_MSE: 0.00241047, q_error_norm: 0.00255583, qd_error_norm: 0.00966470} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00251575, itemized = {state_0: 0.00000103, state_1: 0.04160817, state_2: 0.00083693, state_3: 0.00197559, state_MSE: 0.01110543, q_error_norm: 0.00803697, qd_error_norm: 0.01723987} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.700 sec, time(other): 0.019 sec, time(dataloader): 10.694 sec, time(compute_loss): 2.722 sec, time(backward): 7.312 sec, time(eval): 0.661 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.052391, device='cuda:0'), grad_norm_after_clip: tensor(0.052391, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.93it/s]\n",
            "100% 5/5 [00:00<00:00,  8.58it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.60it/s]\n",
            "100% 4/4 [00:00<00:00,  8.14it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00044461, Rollout MSE Error (joint_q) = 0.00001425 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 58 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00034722, itemized = {state_0: 0.00000055, state_1: 0.00894162, state_2: 0.00014438, state_3: 0.00021715, state_MSE: 0.00232592, q_error_norm: 0.00256807, qd_error_norm: 0.01150843} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00206901, itemized = {state_0: 0.00000125, state_1: 0.01464302, state_2: 0.00045050, state_3: 0.00185275, state_MSE: 0.00423688, q_error_norm: 0.00397043, qd_error_norm: 0.01648976} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.760 sec, time(other): 0.019 sec, time(dataloader): 10.777 sec, time(compute_loss): 2.718 sec, time(backward): 7.311 sec, time(eval): 0.661 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.062864, device='cuda:0'), grad_norm_after_clip: tensor(0.062864, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.93it/s]\n",
            "100% 5/5 [00:00<00:00,  8.49it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.34it/s]\n",
            "100% 4/4 [00:00<00:00,  8.16it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003927, Rollout MSE Error (joint_q) = 0.00000473 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 59 with MSE error 3.927336729248054e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 59 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00010219, itemized = {state_0: 0.00000032, state_1: 0.00878812, state_2: 0.00002668, state_3: 0.00006915, state_MSE: 0.00222107, q_error_norm: 0.00231723, qd_error_norm: 0.00652428} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00168382, itemized = {state_0: 0.00000095, state_1: 0.01926384, state_2: 0.00035228, state_3: 0.00153456, state_MSE: 0.00528791, q_error_norm: 0.00425948, qd_error_norm: 0.01035553} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.770 sec, time(other): 0.020 sec, time(dataloader): 10.756 sec, time(compute_loss): 2.726 sec, time(backward): 7.307 sec, time(eval): 0.683 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.022402, device='cuda:0'), grad_norm_after_clip: tensor(0.022402, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.89it/s]\n",
            "100% 5/5 [00:00<00:00,  8.73it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.54it/s]\n",
            "100% 4/4 [00:00<00:00,  8.15it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003849, Rollout MSE Error (joint_q) = 0.00000376 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 60 with MSE error 3.848840788123198e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 60 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003608, itemized = {state_0: 0.00000020, state_1: 0.00582080, state_2: 0.00001099, state_3: 0.00001765, state_MSE: 0.00146241, q_error_norm: 0.00162508, qd_error_norm: 0.00419121} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00156193, itemized = {state_0: 0.00000092, state_1: 0.01772318, state_2: 0.00032337, state_3: 0.00142526, state_MSE: 0.00486818, q_error_norm: 0.00398685, qd_error_norm: 0.01002620} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.956 sec, time(other): 0.020 sec, time(dataloader): 10.911 sec, time(compute_loss): 2.716 sec, time(backward): 7.312 sec, time(eval): 0.685 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.008805, device='cuda:0'), grad_norm_after_clip: tensor(0.008805, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.92it/s]\n",
            "100% 5/5 [00:00<00:00,  8.65it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.73it/s]\n",
            "100% 4/4 [00:00<00:00,  8.19it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004112, Rollout MSE Error (joint_q) = 0.00000440 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 61 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003316, itemized = {state_0: 0.00000020, state_1: 0.00578224, state_2: 0.00000993, state_3: 0.00001593, state_MSE: 0.00145207, q_error_norm: 0.00160345, qd_error_norm: 0.00402515} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00157695, itemized = {state_0: 0.00000092, state_1: 0.01541474, state_2: 0.00031946, state_3: 0.00144693, state_MSE: 0.00429551, q_error_norm: 0.00362032, qd_error_norm: 0.00994660} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.815 sec, time(other): 0.020 sec, time(dataloader): 10.822 sec, time(compute_loss): 2.719 sec, time(backward): 7.309 sec, time(eval): 0.657 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.008416, device='cuda:0'), grad_norm_after_clip: tensor(0.008416, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.94it/s]\n",
            "100% 5/5 [00:00<00:00,  8.60it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.60it/s]\n",
            "100% 4/4 [00:00<00:00,  8.16it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00009570, Rollout MSE Error (joint_q) = 0.00000431 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 62 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003744, itemized = {state_0: 0.00000020, state_1: 0.00655303, state_2: 0.00001122, state_3: 0.00001919, state_MSE: 0.00164591, q_error_norm: 0.00174452, qd_error_norm: 0.00428028} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00144358, itemized = {state_0: 0.00000091, state_1: 0.01310017, state_2: 0.00030200, state_3: 0.00130972, state_MSE: 0.00367820, q_error_norm: 0.00326785, qd_error_norm: 0.01015425} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.779 sec, time(other): 0.018 sec, time(dataloader): 10.727 sec, time(compute_loss): 2.726 sec, time(backward): 7.314 sec, time(eval): 0.661 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.011790, device='cuda:0'), grad_norm_after_clip: tensor(0.011790, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 62 with loss 0.00144358. \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.93it/s]\n",
            "100% 5/5 [00:00<00:00,  8.49it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.29it/s]\n",
            "100% 4/4 [00:00<00:00,  8.10it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00036902, Rollout MSE Error (joint_q) = 0.00000353 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 63 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00005809, itemized = {state_0: 0.00000021, state_1: 0.00693847, state_2: 0.00002097, state_3: 0.00003169, state_MSE: 0.00174784, q_error_norm: 0.00184457, qd_error_norm: 0.00503990} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00148117, itemized = {state_0: 0.00000101, state_1: 0.02388884, state_2: 0.00034642, state_3: 0.00130410, state_MSE: 0.00638509, q_error_norm: 0.00501346, qd_error_norm: 0.01354780} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.789 sec, time(other): 0.020 sec, time(dataloader): 10.790 sec, time(compute_loss): 2.720 sec, time(backward): 7.309 sec, time(eval): 0.666 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.021501, device='cuda:0'), grad_norm_after_clip: tensor(0.021501, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:19<00:00,  5.02it/s]\n",
            "100% 5/5 [00:00<00:00,  8.73it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.48it/s]\n",
            "100% 4/4 [00:00<00:00,  8.15it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00021236, Rollout MSE Error (joint_q) = 0.00000690 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 64 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00039061, itemized = {state_0: 0.00000059, state_1: 0.01055962, state_2: 0.00015409, state_3: 0.00025175, state_MSE: 0.00274151, q_error_norm: 0.00293238, qd_error_norm: 0.01209898} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00187643, itemized = {state_0: 0.00000093, state_1: 0.02157779, state_2: 0.00036108, state_3: 0.00175011, state_MSE: 0.00592248, q_error_norm: 0.00466533, qd_error_norm: 0.01142426} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.404 sec, time(other): 0.020 sec, time(dataloader): 10.377 sec, time(compute_loss): 2.727 sec, time(backward): 7.306 sec, time(eval): 0.661 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.061796, device='cuda:0'), grad_norm_after_clip: tensor(0.061796, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.94it/s]\n",
            "100% 5/5 [00:00<00:00,  8.63it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.92it/s]\n",
            "100% 4/4 [00:00<00:00,  8.14it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004234, Rollout MSE Error (joint_q) = 0.00000232 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 65 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003997, itemized = {state_0: 0.00000020, state_1: 0.00647593, state_2: 0.00001160, state_3: 0.00002112, state_MSE: 0.00162721, q_error_norm: 0.00175373, qd_error_norm: 0.00435639} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00170031, itemized = {state_0: 0.00000086, state_1: 0.01541307, state_2: 0.00034004, state_3: 0.00157270, state_MSE: 0.00433167, q_error_norm: 0.00359551, qd_error_norm: 0.00982102} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.688 sec, time(other): 0.018 sec, time(dataloader): 10.691 sec, time(compute_loss): 2.731 sec, time(backward): 7.312 sec, time(eval): 0.665 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.010978, device='cuda:0'), grad_norm_after_clip: tensor(0.010978, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.97it/s]\n",
            "100% 5/5 [00:00<00:00,  8.49it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.36it/s]\n",
            "100% 4/4 [00:00<00:00,  8.13it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00010655, Rollout MSE Error (joint_q) = 0.00000350 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 66 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003034, itemized = {state_0: 0.00000018, state_1: 0.00566675, state_2: 0.00000920, state_3: 0.00001445, state_MSE: 0.00142264, q_error_norm: 0.00155541, qd_error_norm: 0.00381571} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00166514, itemized = {state_0: 0.00000087, state_1: 0.01849805, state_2: 0.00033712, state_3: 0.00153466, state_MSE: 0.00509267, q_error_norm: 0.00406417, qd_error_norm: 0.01026225} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.621 sec, time(other): 0.019 sec, time(dataloader): 10.612 sec, time(compute_loss): 2.725 sec, time(backward): 7.312 sec, time(eval): 0.663 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.008514, device='cuda:0'), grad_norm_after_clip: tensor(0.008514, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.93it/s]\n",
            "100% 5/5 [00:00<00:00,  8.67it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.44it/s]\n",
            "100% 4/4 [00:00<00:00,  8.16it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00009157, Rollout MSE Error (joint_q) = 0.00001105 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 67 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003924, itemized = {state_0: 0.00000018, state_1: 0.00616783, state_2: 0.00001226, state_3: 0.00002103, state_MSE: 0.00155032, q_error_norm: 0.00166513, qd_error_norm: 0.00428838} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00159188, itemized = {state_0: 0.00000090, state_1: 0.01541291, state_2: 0.00032592, state_3: 0.00145571, state_MSE: 0.00429886, q_error_norm: 0.00369713, qd_error_norm: 0.01047545} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.736 sec, time(other): 0.020 sec, time(dataloader): 10.753 sec, time(compute_loss): 2.721 sec, time(backward): 7.311 sec, time(eval): 0.661 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.014631, device='cuda:0'), grad_norm_after_clip: tensor(0.014631, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.96it/s]\n",
            "100% 5/5 [00:00<00:00,  8.46it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.22it/s]\n",
            "100% 4/4 [00:00<00:00,  8.11it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00005818, Rollout MSE Error (joint_q) = 0.00000410 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 68 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00005793, itemized = {state_0: 0.00000019, state_1: 0.00713114, state_2: 0.00001844, state_3: 0.00003474, state_MSE: 0.00179613, q_error_norm: 0.00187055, qd_error_norm: 0.00515743} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00154464, itemized = {state_0: 0.00000087, state_1: 0.02234802, state_2: 0.00033159, state_3: 0.00139793, state_MSE: 0.00601960, q_error_norm: 0.00470168, qd_error_norm: 0.01025206} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.715 sec, time(other): 0.018 sec, time(dataloader): 10.668 sec, time(compute_loss): 2.721 sec, time(backward): 7.313 sec, time(eval): 0.665 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.021474, device='cuda:0'), grad_norm_after_clip: tensor(0.021474, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.88it/s]\n",
            "100% 5/5 [00:00<00:00,  8.64it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.38it/s]\n",
            "100% 4/4 [00:00<00:00,  8.11it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004699, Rollout MSE Error (joint_q) = 0.00000491 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 69 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00005239, itemized = {state_0: 0.00000020, state_1: 0.00574355, state_2: 0.00001621, state_3: 0.00003143, state_MSE: 0.00144785, q_error_norm: 0.00161570, qd_error_norm: 0.00495928} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00175843, itemized = {state_0: 0.00000086, state_1: 0.02157905, state_2: 0.00035945, state_3: 0.00161978, state_MSE: 0.00588979, q_error_norm: 0.00454784, qd_error_norm: 0.00989977} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.959 sec, time(other): 0.019 sec, time(dataloader): 10.970 sec, time(compute_loss): 2.721 sec, time(backward): 7.312 sec, time(eval): 0.663 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.019109, device='cuda:0'), grad_norm_after_clip: tensor(0.019109, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.91it/s]\n",
            "100% 5/5 [00:00<00:00,  8.65it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.07it/s]\n",
            "100% 4/4 [00:00<00:00,  8.10it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002740, Rollout MSE Error (joint_q) = 0.00000256 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 70 with MSE error 2.7404448701418005e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 70 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003127, itemized = {state_0: 0.00000016, state_1: 0.00528121, state_2: 0.00000941, state_3: 0.00001607, state_MSE: 0.00132671, q_error_norm: 0.00147627, qd_error_norm: 0.00391196} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00125330, itemized = {state_0: 0.00000085, state_1: 0.01387289, state_2: 0.00026639, state_3: 0.00112920, state_MSE: 0.00381733, q_error_norm: 0.00330312, qd_error_norm: 0.00935659} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.896 sec, time(other): 0.019 sec, time(dataloader): 10.837 sec, time(compute_loss): 2.721 sec, time(backward): 7.311 sec, time(eval): 0.688 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.010856, device='cuda:0'), grad_norm_after_clip: tensor(0.010856, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 70 with loss 0.00125330. \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.92it/s]\n",
            "100% 5/5 [00:00<00:00,  8.69it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.96it/s]\n",
            "100% 4/4 [00:00<00:00,  8.24it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00010591, Rollout MSE Error (joint_q) = 0.00000569 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 71 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00005482, itemized = {state_0: 0.00000019, state_1: 0.00632173, state_2: 0.00001881, state_3: 0.00003100, state_MSE: 0.00159293, q_error_norm: 0.00173275, qd_error_norm: 0.00493486} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00170948, itemized = {state_0: 0.00000088, state_1: 0.01233077, state_2: 0.00034056, state_3: 0.00158378, state_MSE: 0.00356400, q_error_norm: 0.00308737, qd_error_norm: 0.01019351} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.807 sec, time(other): 0.020 sec, time(dataloader): 10.809 sec, time(compute_loss): 2.721 sec, time(backward): 7.314 sec, time(eval): 0.659 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.022508, device='cuda:0'), grad_norm_after_clip: tensor(0.022508, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.93it/s]\n",
            "100% 5/5 [00:00<00:00,  8.62it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.77it/s]\n",
            "100% 4/4 [00:00<00:00,  8.18it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00018153, Rollout MSE Error (joint_q) = 0.00000564 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 72 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00006087, itemized = {state_0: 0.00000020, state_1: 0.00574349, state_2: 0.00001909, state_3: 0.00003755, state_MSE: 0.00145008, q_error_norm: 0.00164413, qd_error_norm: 0.00530360} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00168003, itemized = {state_0: 0.00000093, state_1: 0.01079077, state_2: 0.00036894, state_3: 0.00151346, state_MSE: 0.00316852, q_error_norm: 0.00287158, qd_error_norm: 0.01104358} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.796 sec, time(other): 0.018 sec, time(dataloader): 10.775 sec, time(compute_loss): 2.723 sec, time(backward): 7.315 sec, time(eval): 0.658 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.023812, device='cuda:0'), grad_norm_after_clip: tensor(0.023812, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.99it/s]\n",
            "100% 5/5 [00:00<00:00,  8.68it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.68it/s]\n",
            "100% 4/4 [00:00<00:00,  8.17it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00005970, Rollout MSE Error (joint_q) = 0.00000222 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 73 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00005551, itemized = {state_0: 0.00000020, state_1: 0.00628316, state_2: 0.00001802, state_3: 0.00003306, state_MSE: 0.00158361, q_error_norm: 0.00170134, qd_error_norm: 0.00502191} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00171567, itemized = {state_0: 0.00000088, state_1: 0.01618414, state_2: 0.00035239, state_3: 0.00157824, state_MSE: 0.00452891, q_error_norm: 0.00366071, qd_error_norm: 0.00977105} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.514 sec, time(other): 0.020 sec, time(dataloader): 10.518 sec, time(compute_loss): 2.725 sec, time(backward): 7.306 sec, time(eval): 0.665 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.020132, device='cuda:0'), grad_norm_after_clip: tensor(0.020132, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.96it/s]\n",
            "100% 5/5 [00:00<00:00,  8.59it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.87it/s]\n",
            "100% 4/4 [00:00<00:00,  7.99it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004123, Rollout MSE Error (joint_q) = 0.00000255 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 74 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002642, itemized = {state_0: 0.00000015, state_1: 0.00512710, state_2: 0.00000779, state_3: 0.00001310, state_MSE: 0.00128704, q_error_norm: 0.00141908, qd_error_norm: 0.00360968} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00164206, itemized = {state_0: 0.00000085, state_1: 0.01541461, state_2: 0.00034392, state_3: 0.00150196, state_MSE: 0.00431533, q_error_norm: 0.00352807, qd_error_norm: 0.00959888} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.672 sec, time(other): 0.020 sec, time(dataloader): 10.663 sec, time(compute_loss): 2.719 sec, time(backward): 7.310 sec, time(eval): 0.676 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.008414, device='cuda:0'), grad_norm_after_clip: tensor(0.008414, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.83it/s]\n",
            "100% 5/5 [00:00<00:00,  8.40it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.25it/s]\n",
            "100% 4/4 [00:00<00:00,  8.06it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00008437, Rollout MSE Error (joint_q) = 0.00000908 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 75 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00020618, itemized = {state_0: 0.00000035, state_1: 0.00782434, state_2: 0.00008270, state_3: 0.00012978, state_MSE: 0.00200929, q_error_norm: 0.00217243, qd_error_norm: 0.00830514} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00163752, itemized = {state_0: 0.00000090, state_1: 0.00539614, state_2: 0.00037011, state_3: 0.00145950, state_MSE: 0.00180666, q_error_norm: 0.00213452, qd_error_norm: 0.01102513} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.190 sec, time(other): 0.011 sec, time(dataloader): 11.143 sec, time(compute_loss): 2.749 sec, time(backward): 7.338 sec, time(eval): 0.672 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.048027, device='cuda:0'), grad_norm_after_clip: tensor(0.048027, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.81it/s]\n",
            "100% 5/5 [00:00<00:00,  8.38it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.41it/s]\n",
            "100% 4/4 [00:00<00:00,  8.15it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003619, Rollout MSE Error (joint_q) = 0.00000255 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 76 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00004665, itemized = {state_0: 0.00000018, state_1: 0.00574350, state_2: 0.00001530, state_3: 0.00002640, state_MSE: 0.00144635, q_error_norm: 0.00158746, qd_error_norm: 0.00450610} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00139364, itemized = {state_0: 0.00000085, state_1: 0.01772504, state_2: 0.00030742, state_3: 0.00125099, state_MSE: 0.00482107, q_error_norm: 0.00388277, qd_error_norm: 0.00931984} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.260 sec, time(other): 0.011 sec, time(dataloader): 11.225 sec, time(compute_loss): 2.743 sec, time(backward): 7.333 sec, time(eval): 0.662 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.013513, device='cuda:0'), grad_norm_after_clip: tensor(0.013513, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.86it/s]\n",
            "100% 5/5 [00:00<00:00,  8.12it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.43it/s]\n",
            "100% 4/4 [00:00<00:00,  8.06it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003389, Rollout MSE Error (joint_q) = 0.00000220 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 77 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002294, itemized = {state_0: 0.00000014, state_1: 0.00427901, state_2: 0.00000665, state_3: 0.00001092, state_MSE: 0.00107418, q_error_norm: 0.00126056, qd_error_norm: 0.00334795} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00156199, itemized = {state_0: 0.00000084, state_1: 0.01541606, state_2: 0.00033425, state_3: 0.00141847, state_MSE: 0.00429240, q_error_norm: 0.00351373, qd_error_norm: 0.00928373} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.130 sec, time(other): 0.011 sec, time(dataloader): 11.020 sec, time(compute_loss): 2.755 sec, time(backward): 7.342 sec, time(eval): 0.668 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.006036, device='cuda:0'), grad_norm_after_clip: tensor(0.006036, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.97it/s]\n",
            "100% 5/5 [00:00<00:00,  8.36it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.50it/s]\n",
            "100% 4/4 [00:00<00:00,  8.08it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002456, Rollout MSE Error (joint_q) = 0.00000191 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 78 with MSE error 2.4556231437600218e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 78 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002174, itemized = {state_0: 0.00000014, state_1: 0.00424052, state_2: 0.00000641, state_3: 0.00001007, state_MSE: 0.00106428, q_error_norm: 0.00124415, qd_error_norm: 0.00324482} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00140666, itemized = {state_0: 0.00000082, state_1: 0.01618493, state_2: 0.00029744, state_3: 0.00127747, state_MSE: 0.00444016, q_error_norm: 0.00363160, qd_error_norm: 0.00925032} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.648 sec, time(other): 0.011 sec, time(dataloader): 10.569 sec, time(compute_loss): 2.746 sec, time(backward): 7.333 sec, time(eval): 0.687 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.005090, device='cuda:0'), grad_norm_after_clip: tensor(0.005090, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.85it/s]\n",
            "100% 5/5 [00:00<00:00,  8.42it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.35it/s]\n",
            "100% 4/4 [00:00<00:00,  8.05it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002837, Rollout MSE Error (joint_q) = 0.00000288 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 79 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002225, itemized = {state_0: 0.00000013, state_1: 0.00416341, state_2: 0.00000661, state_3: 0.00001060, state_MSE: 0.00104519, q_error_norm: 0.00122647, qd_error_norm: 0.00330089} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00163277, itemized = {state_0: 0.00000083, state_1: 0.01233160, state_2: 0.00034375, state_3: 0.00149334, state_MSE: 0.00354238, q_error_norm: 0.00301269, qd_error_norm: 0.00936185} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.160 sec, time(other): 0.011 sec, time(dataloader): 11.032 sec, time(compute_loss): 2.764 sec, time(backward): 7.343 sec, time(eval): 0.668 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.006333, device='cuda:0'), grad_norm_after_clip: tensor(0.006333, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.85it/s]\n",
            "100% 5/5 [00:00<00:00,  8.39it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.40it/s]\n",
            "100% 4/4 [00:00<00:00,  8.09it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00006093, Rollout MSE Error (joint_q) = 0.00000280 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 80 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002753, itemized = {state_0: 0.00000014, state_1: 0.00354664, state_2: 0.00000882, state_3: 0.00001411, state_MSE: 0.00089243, q_error_norm: 0.00114079, qd_error_norm: 0.00365904} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00171830, itemized = {state_0: 0.00000085, state_1: 0.01078859, state_2: 0.00035902, state_3: 0.00157463, state_MSE: 0.00318077, q_error_norm: 0.00279014, qd_error_norm: 0.00987522} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.170 sec, time(other): 0.011 sec, time(dataloader): 11.069 sec, time(compute_loss): 2.755 sec, time(backward): 7.337 sec, time(eval): 0.666 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.010893, device='cuda:0'), grad_norm_after_clip: tensor(0.010893, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.86it/s]\n",
            "100% 5/5 [00:00<00:00,  8.27it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.95it/s]\n",
            "100% 4/4 [00:00<00:00,  7.79it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002903, Rollout MSE Error (joint_q) = 0.00000197 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 81 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002548, itemized = {state_0: 0.00000014, state_1: 0.00362375, state_2: 0.00000749, state_3: 0.00001332, state_MSE: 0.00091117, q_error_norm: 0.00114527, qd_error_norm: 0.00354191} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00165752, itemized = {state_0: 0.00000081, state_1: 0.01618405, state_2: 0.00034081, state_3: 0.00152591, state_MSE: 0.00451289, q_error_norm: 0.00361834, qd_error_norm: 0.00947920} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.175 sec, time(other): 0.011 sec, time(dataloader): 11.058 sec, time(compute_loss): 2.742 sec, time(backward): 7.330 sec, time(eval): 0.689 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.009131, device='cuda:0'), grad_norm_after_clip: tensor(0.009131, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.98it/s]\n",
            "100% 5/5 [00:00<00:00,  8.45it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.24it/s]\n",
            "100% 4/4 [00:00<00:00,  8.00it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002330, Rollout MSE Error (joint_q) = 0.00000251 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 82 with MSE error 2.3300746761378832e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 82 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002275, itemized = {state_0: 0.00000013, state_1: 0.00327681, state_2: 0.00000685, state_3: 0.00001116, state_MSE: 0.00082374, q_error_norm: 0.00107891, qd_error_norm: 0.00332951} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00137269, itemized = {state_0: 0.00000081, state_1: 0.01233129, state_2: 0.00029829, state_3: 0.00123807, state_MSE: 0.00346712, q_error_norm: 0.00299066, qd_error_norm: 0.00902673} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.622 sec, time(other): 0.011 sec, time(dataloader): 10.520 sec, time(compute_loss): 2.757 sec, time(backward): 7.330 sec, time(eval): 0.697 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.008042, device='cuda:0'), grad_norm_after_clip: tensor(0.008042, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.93it/s]\n",
            "100% 5/5 [00:00<00:00,  8.48it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.21it/s]\n",
            "100% 4/4 [00:00<00:00,  8.05it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00010319, Rollout MSE Error (joint_q) = 0.00000404 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 83 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00004003, itemized = {state_0: 0.00000014, state_1: 0.00458724, state_2: 0.00001364, state_3: 0.00002325, state_MSE: 0.00115607, q_error_norm: 0.00132197, qd_error_norm: 0.00416390} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00150044, itemized = {state_0: 0.00000088, state_1: 0.01079232, state_2: 0.00030067, state_3: 0.00138185, state_MSE: 0.00311893, q_error_norm: 0.00281025, qd_error_norm: 0.01036760} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.791 sec, time(other): 0.011 sec, time(dataloader): 10.716 sec, time(compute_loss): 2.751 sec, time(backward): 7.341 sec, time(eval): 0.671 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.016243, device='cuda:0'), grad_norm_after_clip: tensor(0.016243, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.82it/s]\n",
            "100% 5/5 [00:00<00:00,  8.42it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.12it/s]\n",
            "100% 4/4 [00:00<00:00,  8.04it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00005548, Rollout MSE Error (joint_q) = 0.00000462 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 84 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00004451, itemized = {state_0: 0.00000016, state_1: 0.00504982, state_2: 0.00001523, state_3: 0.00002585, state_MSE: 0.00127276, q_error_norm: 0.00142652, qd_error_norm: 0.00452326} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00167648, itemized = {state_0: 0.00000078, state_1: 0.01926594, state_2: 0.00035094, state_3: 0.00153865, state_MSE: 0.00528908, q_error_norm: 0.00409418, qd_error_norm: 0.00962020} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.268 sec, time(other): 0.011 sec, time(dataloader): 11.209 sec, time(compute_loss): 2.749 sec, time(backward): 7.336 sec, time(eval): 0.671 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.018140, device='cuda:0'), grad_norm_after_clip: tensor(0.018140, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.91it/s]\n",
            "100% 5/5 [00:00<00:00,  7.94it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.61it/s]\n",
            "100% 4/4 [00:00<00:00,  7.92it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00005231, Rollout MSE Error (joint_q) = 0.00000203 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 85 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003444, itemized = {state_0: 0.00000013, state_1: 0.00447162, state_2: 0.00001209, state_3: 0.00001890, state_MSE: 0.00112569, q_error_norm: 0.00128078, qd_error_norm: 0.00401760} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00158304, itemized = {state_0: 0.00000080, state_1: 0.01387307, state_2: 0.00034035, state_3: 0.00143977, state_MSE: 0.00391350, q_error_norm: 0.00324568, qd_error_norm: 0.00934741} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.982 sec, time(other): 0.011 sec, time(dataloader): 10.859 sec, time(compute_loss): 2.751 sec, time(backward): 7.336 sec, time(eval): 0.683 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.015274, device='cuda:0'), grad_norm_after_clip: tensor(0.015274, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.87it/s]\n",
            "100% 5/5 [00:00<00:00,  8.36it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.46it/s]\n",
            "100% 4/4 [00:00<00:00,  8.05it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002358, Rollout MSE Error (joint_q) = 0.00000178 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 86 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003309, itemized = {state_0: 0.00000014, state_1: 0.00412470, state_2: 0.00001130, state_3: 0.00001810, state_MSE: 0.00103856, q_error_norm: 0.00122995, qd_error_norm: 0.00393356} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00149537, itemized = {state_0: 0.00000080, state_1: 0.01464375, state_2: 0.00031784, state_3: 0.00136133, state_MSE: 0.00408093, q_error_norm: 0.00334744, qd_error_norm: 0.00913351} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.036 sec, time(other): 0.011 sec, time(dataloader): 10.975 sec, time(compute_loss): 2.758 sec, time(backward): 7.337 sec, time(eval): 0.673 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.014878, device='cuda:0'), grad_norm_after_clip: tensor(0.014878, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:19<00:00,  5.02it/s]\n",
            "100% 5/5 [00:00<00:00,  8.60it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.34it/s]\n",
            "100% 4/4 [00:00<00:00,  8.09it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002239, Rollout MSE Error (joint_q) = 0.00000143 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 87 with MSE error 2.2389307559933513e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 87 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002027, itemized = {state_0: 0.00000012, state_1: 0.00273708, state_2: 0.00000601, state_3: 0.00000990, state_MSE: 0.00068828, q_error_norm: 0.00096661, qd_error_norm: 0.00314545} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00156899, itemized = {state_0: 0.00000078, state_1: 0.02003857, state_2: 0.00031850, state_3: 0.00144876, state_MSE: 0.00545165, q_error_norm: 0.00419053, qd_error_norm: 0.00900151} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.423 sec, time(other): 0.013 sec, time(dataloader): 10.386 sec, time(compute_loss): 2.737 sec, time(backward): 7.321 sec, time(eval): 0.686 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.006887, device='cuda:0'), grad_norm_after_clip: tensor(0.006887, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.85it/s]\n",
            "100% 5/5 [00:00<00:00,  8.43it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.00it/s]\n",
            "100% 4/4 [00:00<00:00,  8.05it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002473, Rollout MSE Error (joint_q) = 0.00000369 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 88 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001912, itemized = {state_0: 0.00000012, state_1: 0.00373935, state_2: 0.00000565, state_3: 0.00000900, state_MSE: 0.00093853, q_error_norm: 0.00112542, qd_error_norm: 0.00304025} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00141222, itemized = {state_0: 0.00000077, state_1: 0.01541373, state_2: 0.00031159, state_3: 0.00127243, state_MSE: 0.00424963, q_error_norm: 0.00345143, qd_error_norm: 0.00888465} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.102 sec, time(other): 0.014 sec, time(dataloader): 11.081 sec, time(compute_loss): 2.729 sec, time(backward): 7.320 sec, time(eval): 0.670 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.006073, device='cuda:0'), grad_norm_after_clip: tensor(0.006073, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.88it/s]\n",
            "100% 5/5 [00:00<00:00,  8.54it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.94it/s]\n",
            "100% 4/4 [00:00<00:00,  8.04it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002611, Rollout MSE Error (joint_q) = 0.00000275 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 89 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001776, itemized = {state_0: 0.00000011, state_1: 0.00269853, state_2: 0.00000515, state_3: 0.00000824, state_MSE: 0.00067801, q_error_norm: 0.00094762, qd_error_norm: 0.00293484} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00151628, itemized = {state_0: 0.00000078, state_1: 0.01233305, state_2: 0.00031406, state_3: 0.00139191, state_MSE: 0.00350995, q_error_norm: 0.00295295, qd_error_norm: 0.00887840} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.025 sec, time(other): 0.014 sec, time(dataloader): 10.986 sec, time(compute_loss): 2.726 sec, time(backward): 7.318 sec, time(eval): 0.679 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.004918, device='cuda:0'), grad_norm_after_clip: tensor(0.004918, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.90it/s]\n",
            "100% 5/5 [00:00<00:00,  8.57it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.25it/s]\n",
            "100% 4/4 [00:00<00:00,  8.18it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002341, Rollout MSE Error (joint_q) = 0.00000255 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 90 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001781, itemized = {state_0: 0.00000011, state_1: 0.00269857, state_2: 0.00000522, state_3: 0.00000831, state_MSE: 0.00067805, q_error_norm: 0.00094448, qd_error_norm: 0.00294405} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00160856, itemized = {state_0: 0.00000077, state_1: 0.01849806, state_2: 0.00032786, state_3: 0.00148611, state_MSE: 0.00507820, q_error_norm: 0.00392561, qd_error_norm: 0.00886834} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.954 sec, time(other): 0.013 sec, time(dataloader): 10.876 sec, time(compute_loss): 2.737 sec, time(backward): 7.322 sec, time(eval): 0.661 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.005714, device='cuda:0'), grad_norm_after_clip: tensor(0.005714, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.88it/s]\n",
            "100% 5/5 [00:00<00:00,  8.42it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.33it/s]\n",
            "100% 4/4 [00:00<00:00,  8.05it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004077, Rollout MSE Error (joint_q) = 0.00000263 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 91 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001736, itemized = {state_0: 0.00000011, state_1: 0.00223599, state_2: 0.00000515, state_3: 0.00000804, state_MSE: 0.00056232, q_error_norm: 0.00086266, qd_error_norm: 0.00290426} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00152095, itemized = {state_0: 0.00000078, state_1: 0.01464329, state_2: 0.00031521, state_3: 0.00139574, state_MSE: 0.00408875, q_error_norm: 0.00331205, qd_error_norm: 0.00888957} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.985 sec, time(other): 0.014 sec, time(dataloader): 10.957 sec, time(compute_loss): 2.739 sec, time(backward): 7.315 sec, time(eval): 0.669 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.005421, device='cuda:0'), grad_norm_after_clip: tensor(0.005421, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.92it/s]\n",
            "100% 5/5 [00:00<00:00,  8.13it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.82it/s]\n",
            "100% 4/4 [00:00<00:00,  8.17it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002474, Rollout MSE Error (joint_q) = 0.00000169 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 92 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001739, itemized = {state_0: 0.00000011, state_1: 0.00242868, state_2: 0.00000516, state_3: 0.00000815, state_MSE: 0.00061052, q_error_norm: 0.00088958, qd_error_norm: 0.00291313} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00134336, itemized = {state_0: 0.00000076, state_1: 0.01618487, state_2: 0.00028548, state_3: 0.00122141, state_MSE: 0.00442313, q_error_norm: 0.00354658, qd_error_norm: 0.00872695} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.841 sec, time(other): 0.014 sec, time(dataloader): 10.833 sec, time(compute_loss): 2.728 sec, time(backward): 7.320 sec, time(eval): 0.664 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.005790, device='cuda:0'), grad_norm_after_clip: tensor(0.005790, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.88it/s]\n",
            "100% 5/5 [00:00<00:00,  8.52it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.51it/s]\n",
            "100% 4/4 [00:00<00:00,  8.05it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002262, Rollout MSE Error (joint_q) = 0.00000218 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 93 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001683, itemized = {state_0: 0.00000011, state_1: 0.00254434, state_2: 0.00000490, state_3: 0.00000784, state_MSE: 0.00063929, q_error_norm: 0.00090608, qd_error_norm: 0.00286440} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00161234, itemized = {state_0: 0.00000075, state_1: 0.01541414, state_2: 0.00033086, state_3: 0.00148742, state_MSE: 0.00430829, q_error_norm: 0.00342612, qd_error_norm: 0.00884563} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.967 sec, time(other): 0.015 sec, time(dataloader): 10.953 sec, time(compute_loss): 2.731 sec, time(backward): 7.319 sec, time(eval): 0.667 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.005322, device='cuda:0'), grad_norm_after_clip: tensor(0.005322, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.98it/s]\n",
            "100% 5/5 [00:00<00:00,  8.59it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.29it/s]\n",
            "100% 4/4 [00:00<00:00,  8.07it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002424, Rollout MSE Error (joint_q) = 0.00000217 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 94 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001666, itemized = {state_0: 0.00000010, state_1: 0.00254438, state_2: 0.00000500, state_3: 0.00000769, state_MSE: 0.00063929, q_error_norm: 0.00089945, qd_error_norm: 0.00283919} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00162666, itemized = {state_0: 0.00000077, state_1: 0.01156009, state_2: 0.00033498, state_3: 0.00149922, state_MSE: 0.00334877, q_error_norm: 0.00280887, qd_error_norm: 0.00879049} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.582 sec, time(other): 0.014 sec, time(dataloader): 10.525 sec, time(compute_loss): 2.731 sec, time(backward): 7.325 sec, time(eval): 0.667 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.005134, device='cuda:0'), grad_norm_after_clip: tensor(0.005134, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.94it/s]\n",
            "100% 5/5 [00:00<00:00,  8.47it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.20it/s]\n",
            "100% 4/4 [00:00<00:00,  8.20it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002379, Rollout MSE Error (joint_q) = 0.00000235 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 95 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001665, itemized = {state_0: 0.00000010, state_1: 0.00208179, state_2: 0.00000497, state_3: 0.00000780, state_MSE: 0.00052367, q_error_norm: 0.00082202, qd_error_norm: 0.00284977} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00157206, itemized = {state_0: 0.00000076, state_1: 0.01772830, state_2: 0.00032543, state_3: 0.00144598, state_MSE: 0.00487512, q_error_norm: 0.00378669, qd_error_norm: 0.00886593} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.756 sec, time(other): 0.015 sec, time(dataloader): 10.697 sec, time(compute_loss): 2.742 sec, time(backward): 7.324 sec, time(eval): 0.667 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.005454, device='cuda:0'), grad_norm_after_clip: tensor(0.005454, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  5.00it/s]\n",
            "100% 5/5 [00:00<00:00,  8.45it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.41it/s]\n",
            "100% 4/4 [00:00<00:00,  8.00it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002174, Rollout MSE Error (joint_q) = 0.00000134 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 96 with MSE error 2.173767461499665e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 96 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001578, itemized = {state_0: 0.00000010, state_1: 0.00246727, state_2: 0.00000462, state_3: 0.00000728, state_MSE: 0.00061982, q_error_norm: 0.00087864, qd_error_norm: 0.00276612} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00125369, itemized = {state_0: 0.00000074, state_1: 0.01233127, state_2: 0.00027588, state_3: 0.00112659, state_MSE: 0.00343362, q_error_norm: 0.00291939, qd_error_norm: 0.00845985} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.515 sec, time(other): 0.015 sec, time(dataloader): 10.492 sec, time(compute_loss): 2.724 sec, time(backward): 7.309 sec, time(eval): 0.692 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.004689, device='cuda:0'), grad_norm_after_clip: tensor(0.004689, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.93it/s]\n",
            "100% 5/5 [00:00<00:00,  8.69it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.46it/s]\n",
            "100% 4/4 [00:00<00:00,  8.14it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002786, Rollout MSE Error (joint_q) = 0.00000151 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 97 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001574, itemized = {state_0: 0.00000010, state_1: 0.00223599, state_2: 0.00000468, state_3: 0.00000731, state_MSE: 0.00056202, q_error_norm: 0.00083543, qd_error_norm: 0.00276807} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00148020, itemized = {state_0: 0.00000075, state_1: 0.01156068, state_2: 0.00031037, state_3: 0.00135521, state_MSE: 0.00330675, q_error_norm: 0.00279061, qd_error_norm: 0.00857597} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.786 sec, time(other): 0.017 sec, time(dataloader): 10.727 sec, time(compute_loss): 2.730 sec, time(backward): 7.319 sec, time(eval): 0.663 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.005127, device='cuda:0'), grad_norm_after_clip: tensor(0.005127, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.91it/s]\n",
            "100% 5/5 [00:00<00:00,  8.70it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.76it/s]\n",
            "100% 4/4 [00:00<00:00,  8.16it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00001820, Rollout MSE Error (joint_q) = 0.00000148 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 98 with MSE error 1.8199219994130544e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 98 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001502, itemized = {state_0: 0.00000010, state_1: 0.00212033, state_2: 0.00000437, state_3: 0.00000689, state_MSE: 0.00053292, q_error_norm: 0.00081357, qd_error_norm: 0.00270380} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00132053, itemized = {state_0: 0.00000074, state_1: 0.01310185, state_2: 0.00028386, state_3: 0.00119716, state_MSE: 0.00364590, q_error_norm: 0.00303578, qd_error_norm: 0.00855142} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.924 sec, time(other): 0.018 sec, time(dataloader): 10.855 sec, time(compute_loss): 2.722 sec, time(backward): 7.315 sec, time(eval): 0.686 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.004200, device='cuda:0'), grad_norm_after_clip: tensor(0.004200, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.98it/s]\n",
            "100% 5/5 [00:00<00:00,  8.53it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.56it/s]\n",
            "100% 4/4 [00:00<00:00,  8.12it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002033, Rollout MSE Error (joint_q) = 0.00000189 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 99 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001457, itemized = {state_0: 0.00000009, state_1: 0.00204327, state_2: 0.00000423, state_3: 0.00000664, state_MSE: 0.00051356, q_error_norm: 0.00079628, qd_error_norm: 0.00265979} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00142126, itemized = {state_0: 0.00000072, state_1: 0.01541381, state_2: 0.00029734, state_3: 0.00130228, state_MSE: 0.00425354, q_error_norm: 0.00339123, qd_error_norm: 0.00846064} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 21.555 sec, time(other): 0.020 sec, time(dataloader): 10.550 sec, time(compute_loss): 2.731 sec, time(backward): 7.313 sec, time(eval): 0.667 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.003641, device='cuda:0'), grad_norm_after_clip: tensor(0.003641, device='cuda:0')} \u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading output.log 132.5KB/132.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading output.log 132.5KB/132.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading output.log 132.5KB/132.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading output.log 132.5KB/132.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading output.log 132.5KB/132.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading output.log 132.5KB/132.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading output.log 132.5KB/132.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading output.log 132.5KB/132.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading output.log 132.5KB/132.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading output.log 132.5KB/132.5KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading output.log 132.5KB/132.5KB (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading output.log 132.5KB/132.5KB (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading output.log 132.5KB/132.5KB (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading output.log 132.5KB/132.5KB (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading output.log 132.5KB/132.5KB (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading history steps 99-99, summary, console lines 1324-1335 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch ‚ñà‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch ‚ñà‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch 0.0074\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch 2e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch 0.00151\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch 0.00716\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch 4e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch 0.00259\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch 0.00393\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch 0.00508\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch 0.00607\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mmamba-6.1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/du6slj7o\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_220903-du6slj7o/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 4a. Train Mamba-6 Model (6 layers)\n",
        "# This is the full 6-layer Mamba model\n",
        "!python train.py --cfg colab_config.yaml --novelty mamba-6 --logdir ../data/logs/mamba_6 --wandb-project {wandb_project} --wandb-name mamba-6.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mamba-3-train",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mamba-3-train",
        "outputId": "214dd6b0-5469-4791-f9fd-383993ea0e08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "2025-12-08 16:28:18.788561: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765211298.808321   10050 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765211298.814349   10050 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765211298.829536   10050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765211298.829564   10050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765211298.829568   10050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765211298.829571   10050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-08 16:28:18.834288: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 512 environments: 100% 512/512 [00:02<00:00, 216.62it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 4.29 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.42 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.46 ms  (cached)\n",
            "\u001b[91m [NeuralEnvironment] Created a DUMMY Neural Integrator. \u001b[0m\n",
            "Model = \n",
            " ModelMixedInput(\n",
            "  (encoders): ModuleDict(\n",
            "    (low_dim): MLPBase(\n",
            "      (body): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (mamba_model): Mamba(\n",
            "    (embedding): Linear(in_features=6, out_features=192, bias=True)\n",
            "    (layers): ModuleList(\n",
            "      (0-2): 3 x MambaBlock(\n",
            "        (in_proj): Linear(in_features=192, out_features=768, bias=False)\n",
            "        (conv1d): Conv1d(384, 384, kernel_size=(4,), stride=(1,), padding=(3,), groups=384)\n",
            "        (x_proj): Linear(in_features=384, out_features=44, bias=False)\n",
            "        (dt_proj): Linear(in_features=12, out_features=384, bias=True)\n",
            "        (out_proj): Linear(in_features=384, out_features=192, bias=False)\n",
            "      )\n",
            "    )\n",
            "    (norm_f): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (model): MLPDeterministic(\n",
            "    (feature_net): MLPBase(\n",
            "      (body): Sequential(\n",
            "        (0): Linear(in_features=192, out_features=64, bias=True)\n",
            "        (1): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (output_net): Linear(in_features=64, out_features=4, bias=True)\n",
            "  )\n",
            ")\n",
            "# Model Parameters =  768900\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhruvpatelat\u001b[0m (\u001b[33mdhruvp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run apayl9th (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run apayl9th (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run apayl9th (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_162833-apayl9th\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba-3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/apayl9th\u001b[0m\n",
            "Computing dataset statistics...\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Finished computing dataset statistics...\n",
            "100% 100/100 [00:15<00:00,  6.32it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions:   0% 0/4 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 9.27 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 8.65 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.61 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 12.16 ms  (cached)\n",
            "Sampling state transitions: 100% 4/4 [00:01<00:00,  3.32it/s]\n",
            "100% 4/4 [00:01<00:00,  2.51it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.53409415, Rollout MSE Error (joint_q) = 0.04594289 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 0 with MSE error 0.5340941548347473. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 0 \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 1.07838898, itemized = {state_0: 0.01025044, state_1: 0.85045799, state_2: 0.28694530, state_3: 0.28220556, state_MSE: 0.35746490, q_error_norm: 0.29537218, qd_error_norm: 0.53744297} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 18.705 sec, time(other): 0.020 sec, time(dataloader): 7.271 sec, time(compute_loss): 8.239 sec, time(backward): 0.002 sec, time(eval): 2.868 sec \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 0 with loss 1.07838898. \u001b[0m\n",
            "100% 100/100 [00:47<00:00,  2.11it/s]\n",
            "100% 100/100 [00:16<00:00,  6.13it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 27.40it/s]\n",
            "100% 4/4 [00:00<00:00,  4.49it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00849829, Rollout MSE Error (joint_q) = 0.00050440 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 1 with MSE error 0.008498290553689003. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 1 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.18685579, itemized = {state_0: 0.00054419, state_1: 0.15567453, state_2: 0.06227041, state_3: 0.10778728, state_MSE: 0.08156911, q_error_norm: 0.05144212, qd_error_norm: 0.23423456} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.01605656, itemized = {state_0: 0.00004380, state_1: 0.06581295, state_2: 0.00598463, state_3: 0.00854234, state_MSE: 0.02009593, q_error_norm: 0.02029772, qd_error_norm: 0.08090275} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 65.594 sec, time(other): 0.050 sec, time(dataloader): 45.609 sec, time(compute_loss): 14.126 sec, time(backward): 3.677 sec, time(eval): 1.072 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.389591, device='cuda:0'), grad_norm_after_clip: tensor(0.370524, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 1 with loss 0.01605656. \u001b[0m\n",
            "100% 100/100 [00:46<00:00,  2.14it/s]\n",
            "100% 100/100 [00:15<00:00,  6.35it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 16.41it/s]\n",
            "100% 4/4 [00:01<00:00,  3.97it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00656081, Rollout MSE Error (joint_q) = 0.00033201 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 2 with MSE error 0.006560811307281256. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 2 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00994451, itemized = {state_0: 0.00002827, state_1: 0.04656664, state_2: 0.00381836, state_3: 0.00511248, state_MSE: 0.01388143, q_error_norm: 0.01536879, qd_error_norm: 0.06436958} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00673637, itemized = {state_0: 0.00001931, state_1: 0.03881382, state_2: 0.00250287, state_3: 0.00357523, state_MSE: 0.01122781, q_error_norm: 0.01296739, qd_error_norm: 0.05510114} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 67.018 sec, time(other): 0.034 sec, time(dataloader): 45.633 sec, time(compute_loss): 14.284 sec, time(backward): 1.984 sec, time(eval): 1.294 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.214176, device='cuda:0'), grad_norm_after_clip: tensor(0.214176, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 2 with loss 0.00673637. \u001b[0m\n",
            "100% 100/100 [00:46<00:00,  2.14it/s]\n",
            "100% 100/100 [00:15<00:00,  6.31it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 21.99it/s]\n",
            "100% 4/4 [00:00<00:00,  4.31it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00527604, Rollout MSE Error (joint_q) = 0.00028375 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 3 with MSE error 0.005276036448776722. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 3 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00521360, itemized = {state_0: 0.00001632, state_1: 0.03828726, state_2: 0.00190175, state_3: 0.00268784, state_MSE: 0.01072330, q_error_norm: 0.01231246, qd_error_norm: 0.04760021} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00408780, itemized = {state_0: 0.00001366, state_1: 0.03256217, state_2: 0.00141027, state_3: 0.00217198, state_MSE: 0.00903952, q_error_norm: 0.01092007, qd_error_norm: 0.04363298} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 66.043 sec, time(other): 0.042 sec, time(dataloader): 45.831 sec, time(compute_loss): 14.177 sec, time(backward): 2.032 sec, time(eval): 1.147 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.109241, device='cuda:0'), grad_norm_after_clip: tensor(0.109241, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 3 with loss 0.00408780. \u001b[0m\n",
            "100% 100/100 [00:46<00:00,  2.13it/s]\n",
            "100% 100/100 [00:16<00:00,  6.18it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 18.53it/s]\n",
            "100% 4/4 [00:00<00:00,  4.31it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00366055, Rollout MSE Error (joint_q) = 0.00020453 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 4 with MSE error 0.003660545451566577. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 4 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00351405, itemized = {state_0: 0.00001246, state_1: 0.03352265, state_2: 0.00120637, state_3: 0.00181900, state_MSE: 0.00914012, q_error_norm: 0.01079355, qd_error_norm: 0.03952631} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00299978, itemized = {state_0: 0.00001109, state_1: 0.02817001, state_2: 0.00100967, state_3: 0.00154023, state_MSE: 0.00768275, q_error_norm: 0.00968099, qd_error_norm: 0.03719864} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 65.371 sec, time(other): 0.037 sec, time(dataloader): 45.983 sec, time(compute_loss): 14.166 sec, time(backward): 2.468 sec, time(eval): 1.186 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.058302, device='cuda:0'), grad_norm_after_clip: tensor(0.058302, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 4 with loss 0.00299978. \u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading output.log 7.8KB/7.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading output.log 7.8KB/7.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading output.log 7.8KB/7.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading output.log 7.8KB/7.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading output.log 7.8KB/7.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading output.log 7.8KB/7.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading output.log 7.8KB/7.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading output.log 7.8KB/7.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading output.log 7.8KB/7.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 5.1KB/5.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading output.log 7.8KB/7.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading data (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading data (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading data (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading data (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch 0.09809\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch 0.00366\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch 0.01623\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch 0.0002\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch 0.09569\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch 0.00712\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch 0.02908\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch 0.04571\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch 0.06087\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch 0.07463\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mmamba-3\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big/runs/apayl9th\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dhruvp/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_162833-apayl9th/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 4b. Train Mamba-3 Model (3 layers)\n",
        "# Reduced parameter count version for comparison\n",
        "!python train.py --cfg colab_config.yaml --novelty mamba-3 --logdir ../data/logs/mamba_3 --wandb-project {wandb_project} --wandb-name mamba-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a32b3a28",
      "metadata": {
        "id": "a32b3a28"
      },
      "outputs": [],
      "source": [
        "# 5. Train Unroll Model\n",
        "# We use the same config but add the --novelty unroll flag\n",
        "# !python train.py --cfg colab_config.yaml --novelty unroll --logdir ../data/logs/unroll --wandb-project {wandb_project} --wandb-name unroll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sTN70o20iZ1A",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTN70o20iZ1A",
        "outputId": "c371bbe7-87b5-4909-b399-8909fa470ca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "algorithm:\n",
            "  batch_size: 1024\n",
            "  dataset:\n",
            "    max_capacity: 100000000\n",
            "    num_data_workers: 8\n",
            "    train_dataset_path: ../data/datasets/Cartpole/trajectory_len-100_train.hdf5\n",
            "    valid_datasets:\n",
            "      exp_trajectory: ../data/datasets/Cartpole/trajectory_len-100_valid.hdf5\n",
            "  eval:\n",
            "    mode: sampler\n",
            "    num_rollouts: 2048\n",
            "    passive: false\n",
            "    rollout_horizon: 10\n",
            "  grad_norm: 1.0\n",
            "  name: SequenceModelTrainer\n",
            "  num_epochs: 5\n",
            "  num_iters_per_epoch: 100\n",
            "  num_valid_batches: 100\n",
            "  optimizer:\n",
            "    lr_end: 1e-4\n",
            "    lr_schedule: linear\n",
            "    lr_start: 1e-3\n",
            "  sample_sequence_length: 10\n",
            "  truncate_grad: true\n",
            "env:\n",
            "  env_name: Cartpole\n",
            "  neural_integrator_cfg:\n",
            "    name: TransformerNeuralIntegrator\n",
            "    num_states_history: 10\n",
            "    orientation_prediction_parameterization: quaternion\n",
            "    prediction_type: relative\n",
            "    states_embedding_type: identical\n",
            "    states_frame: world\n",
            "  num_envs: 512\n",
            "inputs:\n",
            "  low_dim:\n",
            "  - states_embedding\n",
            "  - joint_acts\n",
            "network:\n",
            "  encoder:\n",
            "    low_dim:\n",
            "      activation: relu\n",
            "      layer_sizes: []\n",
            "      layernorm: false\n",
            "  model:\n",
            "    mlp:\n",
            "      activation: relu\n",
            "      layer_sizes:\n",
            "      - 64\n",
            "      layernorm: false\n",
            "    output_tanh: false\n",
            "  normalize_input: true\n",
            "  normalize_output: true\n",
            "  transformer:\n",
            "    bias: false\n",
            "    block_size: 32\n",
            "    dropout: 0.0\n",
            "    n_embd: 192\n",
            "    n_head: 12\n",
            "    n_layer: 6\n"
          ]
        }
      ],
      "source": [
        "!cat colab_config.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Rf_90zANi10j",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rf_90zANi10j",
        "outputId": "b0d14665-16a4-4625-c073-bf5e42b22af1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Success! Updated num_epochs to 100\n",
            "You can now run the training command.\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "\n",
        "# 1. Load the current config file\n",
        "with open(\"colab_config.yaml\", \"r\") as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# 2. Modify the settings\n",
        "# Change number of epochs from 5 to 100\n",
        "config['algorithm']['num_epochs'] = 100\n",
        "\n",
        "# OPTIONAL: Un-comment the line below if you have the path to your larger dataset\n",
        "# config['algorithm']['dataset']['train_dataset_path'] = \"../data/datasets/YOUR_LARGER_DATASET.hdf5\"\n",
        "\n",
        "# 3. Save the file back\n",
        "with open(\"colab_config.yaml\", \"w\") as f:\n",
        "    yaml.dump(config, f, default_flow_style=False)\n",
        "\n",
        "print(f\"Success! Updated num_epochs to {config['algorithm']['num_epochs']}\")\n",
        "print(\"You can now run the training command.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jamba-train",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jamba-train",
        "outputId": "f443279d-482c-437a-8186-4e8788b5e7bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "2025-12-08 19:58:44.102750: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-08 19:58:44.120374: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765223924.141935   14047 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765223924.148470   14047 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765223924.165039   14047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765223924.165074   14047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765223924.165077   14047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765223924.165080   14047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-08 19:58:44.169998: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 512 environments: 100% 512/512 [00:02<00:00, 254.57it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 3.49 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.46 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.48 ms  (cached)\n",
            "\u001b[91m [NeuralEnvironment] Created a DUMMY Neural Integrator. \u001b[0m\n",
            "Model = \n",
            " ModelMixedInput(\n",
            "  (encoders): ModuleDict(\n",
            "    (low_dim): MLPBase(\n",
            "      (body): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (jamba_model): Jamba(\n",
            "    (embedding): Linear(in_features=6, out_features=192, bias=True)\n",
            "    (layers): ModuleList(\n",
            "      (0-1): 2 x JambaBlock(\n",
            "        (layers): ModuleList(\n",
            "          (0-1): 2 x MambaBlock(\n",
            "            (in_proj): Linear(in_features=192, out_features=768, bias=False)\n",
            "            (conv1d): Conv1d(384, 384, kernel_size=(4,), stride=(1,), padding=(3,), groups=384)\n",
            "            (x_proj): Linear(in_features=384, out_features=44, bias=False)\n",
            "            (dt_proj): Linear(in_features=12, out_features=384, bias=True)\n",
            "            (out_proj): Linear(in_features=384, out_features=192, bias=False)\n",
            "          )\n",
            "          (2): Block(\n",
            "            (ln_1): LayerNorm()\n",
            "            (attn): CausalSelfAttention(\n",
            "              (c_attn): Linear(in_features=192, out_features=576, bias=False)\n",
            "              (c_proj): Linear(in_features=192, out_features=192, bias=False)\n",
            "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "              (resid_dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ln_2): LayerNorm()\n",
            "            (mlp): MLP(\n",
            "              (c_fc): Linear(in_features=192, out_features=768, bias=False)\n",
            "              (gelu): GELU(approximate='none')\n",
            "              (c_proj): Linear(in_features=768, out_features=192, bias=False)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (norm_f): LayerNorm()\n",
            "  )\n",
            "  (model): MLPDeterministic(\n",
            "    (feature_net): MLPBase(\n",
            "      (body): Sequential(\n",
            "        (0): Linear(in_features=192, out_features=64, bias=True)\n",
            "        (1): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (output_net): Linear(in_features=64, out_features=4, bias=True)\n",
            "  )\n",
            ")\n",
            "# Model Parameters =  1905732\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhargaveekc\u001b[0m (\u001b[33mbhargaveekc-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run rs4avwp1 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run rs4avwp1 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run rs4avwp1 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_195854-rs4avwp1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mjamba_1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/rs4avwp1\u001b[0m\n",
            "Computing dataset statistics...\n",
            "Finished computing dataset statistics...\n",
            "100% 5/5 [00:00<00:00, 10.39it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions:   0% 0/4 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.53 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.43 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.41 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.74 ms  (cached)\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 18.35it/s]\n",
            "100% 4/4 [00:00<00:00,  8.86it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 1.16303325, Rollout MSE Error (joint_q) = 0.02127738 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 0 with MSE error 1.1630332469940186. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 0 \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.90500040, itemized = {state_0: 0.00702133, state_1: 0.80258093, state_2: 0.26478815, state_3: 0.27479632, state_MSE: 0.33729672, q_error_norm: 0.27510202, qd_error_norm: 0.56712742} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 1.194 sec, time(other): 0.000 sec, time(dataloader): 0.178 sec, time(compute_loss): 0.302 sec, time(backward): 0.000 sec, time(eval): 0.708 sec \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 0 with loss 0.90500040. \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.54it/s]\n",
            "100% 5/5 [00:00<00:00,  9.05it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.30it/s]\n",
            "100% 4/4 [00:00<00:00,  9.15it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.01098901, Rollout MSE Error (joint_q) = 0.00064066 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 1 with MSE error 0.010989012196660042. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 1 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.11133625, itemized = {state_0: 0.00023784, state_1: 0.10565753, state_2: 0.04238115, state_3: 0.06683264, state_MSE: 0.05377730, q_error_norm: 0.03508893, qd_error_norm: 0.17843164} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.01384180, itemized = {state_0: 0.00002331, state_1: 0.03773219, state_2: 0.00511267, state_3: 0.00940047, state_MSE: 0.01306716, q_error_norm: 0.01273076, qd_error_norm: 0.07216814} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 16.668 sec, time(other): 0.010 sec, time(dataloader): 10.096 sec, time(compute_loss): 2.153 sec, time(backward): 3.526 sec, time(eval): 0.632 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.400916, device='cuda:0'), grad_norm_after_clip: tensor(0.386684, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 1 with loss 0.01384180. \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.38it/s]\n",
            "100% 5/5 [00:00<00:00,  9.25it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.80it/s]\n",
            "100% 4/4 [00:00<00:00,  9.37it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.01017698, Rollout MSE Error (joint_q) = 0.00040079 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 2 with MSE error 0.010176981799304485. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 2 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00661412, itemized = {state_0: 0.00001545, state_1: 0.03206318, state_2: 0.00266401, state_3: 0.00390368, state_MSE: 0.00966158, q_error_norm: 0.01098960, qd_error_norm: 0.05509027} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00898724, itemized = {state_0: 0.00001235, state_1: 0.02544100, state_2: 0.00352767, state_3: 0.00589375, state_MSE: 0.00871869, q_error_norm: 0.00981214, qd_error_norm: 0.05484647} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.040 sec, time(other): 0.010 sec, time(dataloader): 10.610 sec, time(compute_loss): 2.145 sec, time(backward): 3.398 sec, time(eval): 0.620 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.299459, device='cuda:0'), grad_norm_after_clip: tensor(0.299459, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 2 with loss 0.00898724. \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.24it/s]\n",
            "100% 5/5 [00:00<00:00,  9.35it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.00it/s]\n",
            "100% 4/4 [00:00<00:00,  9.39it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00246937, Rollout MSE Error (joint_q) = 0.00012537 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 3 with MSE error 0.002469367580488324. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 3 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00297529, itemized = {state_0: 0.00000867, state_1: 0.02445024, state_2: 0.00103833, state_3: 0.00183339, state_MSE: 0.00683266, q_error_norm: 0.00839278, qd_error_norm: 0.03732878} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00310983, itemized = {state_0: 0.00000885, state_1: 0.02541540, state_2: 0.00079465, state_3: 0.00228564, state_MSE: 0.00712614, q_error_norm: 0.00833452, qd_error_norm: 0.03304064} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.446 sec, time(other): 0.010 sec, time(dataloader): 10.939 sec, time(compute_loss): 2.152 sec, time(backward): 3.422 sec, time(eval): 0.618 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.169393, device='cuda:0'), grad_norm_after_clip: tensor(0.169393, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 3 with loss 0.00310983. \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.23it/s]\n",
            "100% 5/5 [00:00<00:00,  9.36it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.96it/s]\n",
            "100% 4/4 [00:00<00:00,  9.34it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00348988, Rollout MSE Error (joint_q) = 0.00005676 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 4 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00201569, itemized = {state_0: 0.00000646, state_1: 0.02422190, state_2: 0.00076554, state_3: 0.00111607, state_MSE: 0.00652749, q_error_norm: 0.00799687, qd_error_norm: 0.03003679} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00320021, itemized = {state_0: 0.00000453, state_1: 0.02696181, state_2: 0.00089376, state_3: 0.00248589, state_MSE: 0.00758650, q_error_norm: 0.00757731, qd_error_norm: 0.03274602} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.404 sec, time(other): 0.010 sec, time(dataloader): 10.984 sec, time(compute_loss): 2.149 sec, time(backward): 3.397 sec, time(eval): 0.600 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.181395, device='cuda:0'), grad_norm_after_clip: tensor(0.181395, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.42it/s]\n",
            "100% 5/5 [00:00<00:00,  8.23it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.76it/s]\n",
            "100% 4/4 [00:00<00:00,  9.08it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00337046, Rollout MSE Error (joint_q) = 0.00010406 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 5 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00320297, itemized = {state_0: 0.00000793, state_1: 0.03171832, state_2: 0.00114787, state_3: 0.00185134, state_MSE: 0.00868137, q_error_norm: 0.01042381, qd_error_norm: 0.03560001} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00421833, itemized = {state_0: 0.00000681, state_1: 0.03158640, state_2: 0.00094973, state_3: 0.00347455, state_MSE: 0.00900437, q_error_norm: 0.00908896, qd_error_norm: 0.03770157} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.011 sec, time(other): 0.010 sec, time(dataloader): 10.549 sec, time(compute_loss): 2.153 sec, time(backward): 3.422 sec, time(eval): 0.616 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.245906, device='cuda:0'), grad_norm_after_clip: tensor(0.245906, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.32it/s]\n",
            "100% 5/5 [00:00<00:00,  9.42it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.91it/s]\n",
            "100% 4/4 [00:00<00:00,  9.35it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00067062, Rollout MSE Error (joint_q) = 0.00003186 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 6 with MSE error 0.0006706242565996945. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 6 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00094645, itemized = {state_0: 0.00000344, state_1: 0.02117826, state_2: 0.00031423, state_3: 0.00054784, state_MSE: 0.00551094, q_error_norm: 0.00632029, qd_error_norm: 0.02099886} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00173794, itemized = {state_0: 0.00000348, state_1: 0.02157845, state_2: 0.00043104, state_3: 0.00134762, state_MSE: 0.00584015, q_error_norm: 0.00621827, qd_error_norm: 0.02093903} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.186 sec, time(other): 0.010 sec, time(dataloader): 10.729 sec, time(compute_loss): 2.161 sec, time(backward): 3.405 sec, time(eval): 0.622 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.079438, device='cuda:0'), grad_norm_after_clip: tensor(0.079438, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 6 with loss 0.00173794. \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.28it/s]\n",
            "100% 5/5 [00:00<00:00,  9.22it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.42it/s]\n",
            "100% 4/4 [00:00<00:00,  9.22it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00118761, Rollout MSE Error (joint_q) = 0.00013095 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 7 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00237784, itemized = {state_0: 0.00000497, state_1: 0.02394901, state_2: 0.00105569, state_3: 0.00133553, state_MSE: 0.00658630, q_error_norm: 0.00731776, qd_error_norm: 0.03018375} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00285651, itemized = {state_0: 0.00000696, state_1: 0.06083153, state_2: 0.00091358, state_3: 0.00192886, state_MSE: 0.01592024, q_error_norm: 0.01380144, qd_error_norm: 0.02873582} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.275 sec, time(other): 0.010 sec, time(dataloader): 10.821 sec, time(compute_loss): 2.156 sec, time(backward): 3.426 sec, time(eval): 0.605 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.200502, device='cuda:0'), grad_norm_after_clip: tensor(0.200502, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.29it/s]\n",
            "100% 5/5 [00:00<00:00,  9.09it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.05it/s]\n",
            "100% 4/4 [00:00<00:00,  9.31it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00089796, Rollout MSE Error (joint_q) = 0.00003992 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 8 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00068152, itemized = {state_0: 0.00000273, state_1: 0.01779256, state_2: 0.00023279, state_3: 0.00038056, state_MSE: 0.00460216, q_error_norm: 0.00534244, qd_error_norm: 0.01751459} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00141454, itemized = {state_0: 0.00000290, state_1: 0.02080846, state_2: 0.00037237, state_3: 0.00106035, state_MSE: 0.00556102, q_error_norm: 0.00586428, qd_error_norm: 0.01944583} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.369 sec, time(other): 0.010 sec, time(dataloader): 10.801 sec, time(compute_loss): 2.154 sec, time(backward): 3.439 sec, time(eval): 0.617 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.063386, device='cuda:0'), grad_norm_after_clip: tensor(0.063386, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 8 with loss 0.00141454. \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.24it/s]\n",
            "100% 5/5 [00:00<00:00,  9.29it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.66it/s]\n",
            "100% 4/4 [00:00<00:00,  9.33it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00042158, Rollout MSE Error (joint_q) = 0.00011167 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 9 with MSE error 0.00042158420546911657. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 9 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00058762, itemized = {state_0: 0.00000294, state_1: 0.02272154, state_2: 0.00014460, state_3: 0.00025185, state_MSE: 0.00578024, q_error_norm: 0.00690435, qd_error_norm: 0.01517084} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00139597, itemized = {state_0: 0.00000391, state_1: 0.01387727, state_2: 0.00035628, state_3: 0.00101779, state_MSE: 0.00381381, q_error_norm: 0.00507272, qd_error_norm: 0.01773247} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.393 sec, time(other): 0.010 sec, time(dataloader): 10.933 sec, time(compute_loss): 2.155 sec, time(backward): 3.407 sec, time(eval): 0.622 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.085716, device='cuda:0'), grad_norm_after_clip: tensor(0.085716, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 9 with loss 0.00139597. \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.28it/s]\n",
            "100% 5/5 [00:00<00:00,  9.31it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.71it/s]\n",
            "100% 4/4 [00:00<00:00,  9.36it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00051289, Rollout MSE Error (joint_q) = 0.00003654 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 10 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00061209, itemized = {state_0: 0.00000256, state_1: 0.01810324, state_2: 0.00020550, state_3: 0.00034870, state_MSE: 0.00466500, q_error_norm: 0.00528448, qd_error_norm: 0.01691588} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00136388, itemized = {state_0: 0.00000318, state_1: 0.00925117, state_2: 0.00034675, state_3: 0.00103741, state_MSE: 0.00265963, q_error_norm: 0.00392747, qd_error_norm: 0.01789992} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.254 sec, time(other): 0.010 sec, time(dataloader): 10.810 sec, time(compute_loss): 2.152 sec, time(backward): 3.434 sec, time(eval): 0.597 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.091013, device='cuda:0'), grad_norm_after_clip: tensor(0.091013, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 10 with loss 0.00136388. \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.26it/s]\n",
            "100% 5/5 [00:00<00:00,  9.40it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.68it/s]\n",
            "100% 4/4 [00:00<00:00,  9.27it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00238009, Rollout MSE Error (joint_q) = 0.00004272 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 11 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00079948, itemized = {state_0: 0.00000304, state_1: 0.01783332, state_2: 0.00026644, state_3: 0.00047943, state_MSE: 0.00464556, q_error_norm: 0.00542734, qd_error_norm: 0.01941983} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00172006, itemized = {state_0: 0.00000361, state_1: 0.02388899, state_2: 0.00045191, state_3: 0.00132599, state_MSE: 0.00641762, q_error_norm: 0.00635691, qd_error_norm: 0.02350177} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.300 sec, time(other): 0.010 sec, time(dataloader): 10.854 sec, time(compute_loss): 2.153 sec, time(backward): 3.425 sec, time(eval): 0.600 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.113846, device='cuda:0'), grad_norm_after_clip: tensor(0.113846, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.29it/s]\n",
            "100% 5/5 [00:00<00:00,  9.04it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.43it/s]\n",
            "100% 4/4 [00:00<00:00,  9.10it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00647372, Rollout MSE Error (joint_q) = 0.00002999 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 12 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00118193, itemized = {state_0: 0.00000384, state_1: 0.01948930, state_2: 0.00042341, state_3: 0.00071149, state_MSE: 0.00515701, q_error_norm: 0.00605670, qd_error_norm: 0.02317857} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00249112, itemized = {state_0: 0.00000352, state_1: 0.02081190, state_2: 0.00095371, state_3: 0.00167923, state_MSE: 0.00586209, q_error_norm: 0.00595727, qd_error_norm: 0.03214424} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.355 sec, time(other): 0.010 sec, time(dataloader): 10.792 sec, time(compute_loss): 2.162 sec, time(backward): 3.426 sec, time(eval): 0.610 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.149998, device='cuda:0'), grad_norm_after_clip: tensor(0.149998, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.34it/s]\n",
            "100% 5/5 [00:00<00:00,  9.33it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.24it/s]\n",
            "100% 4/4 [00:00<00:00,  9.37it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00019285, Rollout MSE Error (joint_q) = 0.00002049 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 13 with MSE error 0.00019285266171209514. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 13 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00049637, itemized = {state_0: 0.00000190, state_1: 0.01814563, state_2: 0.00015940, state_3: 0.00027098, state_MSE: 0.00464448, q_error_norm: 0.00536109, qd_error_norm: 0.01473626} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00138591, itemized = {state_0: 0.00000298, state_1: 0.02774092, state_2: 0.00039872, state_3: 0.00103187, state_MSE: 0.00729362, q_error_norm: 0.00665989, qd_error_norm: 0.01606398} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.145 sec, time(other): 0.010 sec, time(dataloader): 10.681 sec, time(compute_loss): 2.155 sec, time(backward): 3.412 sec, time(eval): 0.623 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.076517, device='cuda:0'), grad_norm_after_clip: tensor(0.076517, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.29it/s]\n",
            "100% 5/5 [00:00<00:00,  9.21it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.58it/s]\n",
            "100% 4/4 [00:00<00:00,  9.37it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00039762, Rollout MSE Error (joint_q) = 0.00007482 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 14 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00035186, itemized = {state_0: 0.00000173, state_1: 0.01872288, state_2: 0.00009621, state_3: 0.00016057, state_MSE: 0.00474534, q_error_norm: 0.00562170, qd_error_norm: 0.01208416} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00136357, itemized = {state_0: 0.00000280, state_1: 0.02851434, state_2: 0.00037591, state_3: 0.00100376, state_MSE: 0.00747420, q_error_norm: 0.00720827, qd_error_norm: 0.01652551} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.261 sec, time(other): 0.010 sec, time(dataloader): 10.788 sec, time(compute_loss): 2.158 sec, time(backward): 3.436 sec, time(eval): 0.597 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.073328, device='cuda:0'), grad_norm_after_clip: tensor(0.073328, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 14 with loss 0.00136357. \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.19it/s]\n",
            "100% 5/5 [00:00<00:00,  9.32it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.58it/s]\n",
            "100% 4/4 [00:00<00:00,  9.27it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00156293, Rollout MSE Error (joint_q) = 0.00003498 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 15 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00105334, itemized = {state_0: 0.00000274, state_1: 0.02126378, state_2: 0.00035807, state_3: 0.00059878, state_MSE: 0.00555584, q_error_norm: 0.00672594, qd_error_norm: 0.02052359} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00166656, itemized = {state_0: 0.00000224, state_1: 0.02620046, state_2: 0.00037686, state_3: 0.00139258, state_MSE: 0.00699304, q_error_norm: 0.00655027, qd_error_norm: 0.02163095} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.492 sec, time(other): 0.010 sec, time(dataloader): 11.068 sec, time(compute_loss): 2.157 sec, time(backward): 3.392 sec, time(eval): 0.602 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.137547, device='cuda:0'), grad_norm_after_clip: tensor(0.137547, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.20it/s]\n",
            "100% 5/5 [00:00<00:00,  9.32it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.84it/s]\n",
            "100% 4/4 [00:00<00:00,  9.31it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00253451, Rollout MSE Error (joint_q) = 0.00004799 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 16 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00070741, itemized = {state_0: 0.00000188, state_1: 0.01733583, state_2: 0.00024749, state_3: 0.00043290, state_MSE: 0.00450453, q_error_norm: 0.00511617, qd_error_norm: 0.01729994} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00234237, itemized = {state_0: 0.00000331, state_1: 0.02002994, state_2: 0.00076146, state_3: 0.00174204, state_MSE: 0.00563419, q_error_norm: 0.00551900, qd_error_norm: 0.02804576} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.479 sec, time(other): 0.010 sec, time(dataloader): 11.071 sec, time(compute_loss): 2.151 sec, time(backward): 3.394 sec, time(eval): 0.599 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.104496, device='cuda:0'), grad_norm_after_clip: tensor(0.104496, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.25it/s]\n",
            "100% 5/5 [00:00<00:00,  9.30it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.06it/s]\n",
            "100% 4/4 [00:00<00:00,  9.41it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00608954, Rollout MSE Error (joint_q) = 0.00005763 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 17 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00058658, itemized = {state_0: 0.00000209, state_1: 0.01622091, state_2: 0.00020186, state_3: 0.00034136, state_MSE: 0.00419156, q_error_norm: 0.00489509, qd_error_norm: 0.01577148} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00428526, itemized = {state_0: 0.00000273, state_1: 0.01926757, state_2: 0.00219638, state_3: 0.00247594, state_MSE: 0.00598565, q_error_norm: 0.00545237, qd_error_norm: 0.03807350} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.405 sec, time(other): 0.010 sec, time(dataloader): 10.897 sec, time(compute_loss): 2.160 sec, time(backward): 3.409 sec, time(eval): 0.598 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.091035, device='cuda:0'), grad_norm_after_clip: tensor(0.091035, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.20it/s]\n",
            "100% 5/5 [00:00<00:00,  9.41it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.93it/s]\n",
            "100% 4/4 [00:00<00:00,  9.35it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00030930, Rollout MSE Error (joint_q) = 0.00013602 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 18 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00091749, itemized = {state_0: 0.00000190, state_1: 0.01760757, state_2: 0.00035509, state_3: 0.00055069, state_MSE: 0.00462881, q_error_norm: 0.00524381, qd_error_norm: 0.01979918} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00152371, itemized = {state_0: 0.00000202, state_1: 0.02003922, state_2: 0.00047361, state_3: 0.00111410, state_MSE: 0.00540724, q_error_norm: 0.00565015, qd_error_norm: 0.01693413} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.455 sec, time(other): 0.010 sec, time(dataloader): 11.027 sec, time(compute_loss): 2.150 sec, time(backward): 3.427 sec, time(eval): 0.595 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.114509, device='cuda:0'), grad_norm_after_clip: tensor(0.114509, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.26it/s]\n",
            "100% 5/5 [00:00<00:00,  8.97it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.49it/s]\n",
            "100% 4/4 [00:00<00:00,  9.29it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00035851, Rollout MSE Error (joint_q) = 0.00001450 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 19 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00051160, itemized = {state_0: 0.00000145, state_1: 0.01602964, state_2: 0.00019155, state_3: 0.00030042, state_MSE: 0.00413077, q_error_norm: 0.00449502, qd_error_norm: 0.01540983} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00135664, itemized = {state_0: 0.00000205, state_1: 0.02312092, state_2: 0.00038218, state_3: 0.00105289, state_MSE: 0.00613951, q_error_norm: 0.00556494, qd_error_norm: 0.01549009} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.449 sec, time(other): 0.010 sec, time(dataloader): 10.925 sec, time(compute_loss): 2.153 sec, time(backward): 3.400 sec, time(eval): 0.602 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.079780, device='cuda:0'), grad_norm_after_clip: tensor(0.079780, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 19 with loss 0.00135664. \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.28it/s]\n",
            "100% 5/5 [00:00<00:00,  9.36it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.57it/s]\n",
            "100% 4/4 [00:00<00:00,  9.44it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00051750, Rollout MSE Error (joint_q) = 0.00002452 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 20 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00024682, itemized = {state_0: 0.00000120, state_1: 0.01560585, state_2: 0.00006883, state_3: 0.00012788, state_MSE: 0.00395094, q_error_norm: 0.00439888, qd_error_norm: 0.01051828} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00116825, itemized = {state_0: 0.00000221, state_1: 0.01464308, state_2: 0.00032365, state_3: 0.00089138, state_MSE: 0.00396508, q_error_norm: 0.00426974, qd_error_norm: 0.01506081} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.358 sec, time(other): 0.010 sec, time(dataloader): 10.846 sec, time(compute_loss): 2.151 sec, time(backward): 3.402 sec, time(eval): 0.595 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.055477, device='cuda:0'), grad_norm_after_clip: tensor(0.055477, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 20 with loss 0.00116825. \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.31it/s]\n",
            "100% 5/5 [00:00<00:00,  9.24it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.94it/s]\n",
            "100% 4/4 [00:00<00:00,  9.17it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00166040, Rollout MSE Error (joint_q) = 0.00015578 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 21 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00039860, itemized = {state_0: 0.00000172, state_1: 0.01857114, state_2: 0.00012728, state_3: 0.00018654, state_MSE: 0.00472167, q_error_norm: 0.00551988, qd_error_norm: 0.01235805} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00171798, itemized = {state_0: 0.00000497, state_1: 0.00925295, state_2: 0.00054536, state_3: 0.00118875, state_MSE: 0.00274801, q_error_norm: 0.00436037, qd_error_norm: 0.02076377} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.213 sec, time(other): 0.010 sec, time(dataloader): 10.770 sec, time(compute_loss): 2.153 sec, time(backward): 3.402 sec, time(eval): 0.614 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.084562, device='cuda:0'), grad_norm_after_clip: tensor(0.084562, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.18it/s]\n",
            "100% 5/5 [00:00<00:00,  9.30it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.74it/s]\n",
            "100% 4/4 [00:00<00:00,  9.27it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00169175, Rollout MSE Error (joint_q) = 0.00003380 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 22 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00099604, itemized = {state_0: 0.00000307, state_1: 0.01841487, state_2: 0.00034637, state_3: 0.00061256, state_MSE: 0.00484422, q_error_norm: 0.00561401, qd_error_norm: 0.02087023} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00173947, itemized = {state_0: 0.00000299, state_1: 0.01927149, state_2: 0.00045378, state_3: 0.00137046, state_MSE: 0.00527468, q_error_norm: 0.00547238, qd_error_norm: 0.02053581} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.543 sec, time(other): 0.010 sec, time(dataloader): 11.103 sec, time(compute_loss): 2.151 sec, time(backward): 3.412 sec, time(eval): 0.600 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.129431, device='cuda:0'), grad_norm_after_clip: tensor(0.129431, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.51it/s]\n",
            "100% 5/5 [00:00<00:00,  9.47it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.82it/s]\n",
            "100% 4/4 [00:00<00:00,  9.33it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00975820, Rollout MSE Error (joint_q) = 0.00005019 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 23 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00074389, itemized = {state_0: 0.00000165, state_1: 0.01633704, state_2: 0.00028875, state_3: 0.00044391, state_MSE: 0.00426784, q_error_norm: 0.00479442, qd_error_norm: 0.01698719} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00577227, itemized = {state_0: 0.00000894, state_1: 0.01465039, state_2: 0.00231203, state_3: 0.00374300, state_MSE: 0.00517859, q_error_norm: 0.00676313, qd_error_norm: 0.04611790} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 16.735 sec, time(other): 0.010 sec, time(dataloader): 10.218 sec, time(compute_loss): 2.156 sec, time(backward): 3.445 sec, time(eval): 0.597 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.103124, device='cuda:0'), grad_norm_after_clip: tensor(0.103124, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.17it/s]\n",
            "100% 5/5 [00:00<00:00,  8.50it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.36it/s]\n",
            "100% 4/4 [00:00<00:00,  9.21it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00031443, Rollout MSE Error (joint_q) = 0.00001069 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 24 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00187937, itemized = {state_0: 0.00000376, state_1: 0.02052572, state_2: 0.00067677, state_3: 0.00122763, state_MSE: 0.00560847, q_error_norm: 0.00620211, qd_error_norm: 0.02746017} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00142976, itemized = {state_0: 0.00000202, state_1: 0.01695528, state_2: 0.00036912, state_3: 0.00115131, state_MSE: 0.00461943, q_error_norm: 0.00458568, qd_error_norm: 0.01532970} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.687 sec, time(other): 0.010 sec, time(dataloader): 11.161 sec, time(compute_loss): 2.146 sec, time(backward): 3.422 sec, time(eval): 0.606 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.146218, device='cuda:0'), grad_norm_after_clip: tensor(0.146218, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.26it/s]\n",
            "100% 5/5 [00:00<00:00,  9.43it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.76it/s]\n",
            "100% 4/4 [00:00<00:00,  9.36it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00011056, Rollout MSE Error (joint_q) = 0.00000839 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 25 with MSE error 0.00011055863433284685. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 25 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00013953, itemized = {state_0: 0.00000069, state_1: 0.01352546, state_2: 0.00004526, state_3: 0.00007134, state_MSE: 0.00341069, q_error_norm: 0.00344824, qd_error_norm: 0.00827879} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00134113, itemized = {state_0: 0.00000158, state_1: 0.01772710, state_2: 0.00030839, state_3: 0.00113924, state_MSE: 0.00479408, q_error_norm: 0.00442948, qd_error_norm: 0.01298942} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.416 sec, time(other): 0.010 sec, time(dataloader): 10.874 sec, time(compute_loss): 2.151 sec, time(backward): 3.419 sec, time(eval): 0.621 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.020969, device='cuda:0'), grad_norm_after_clip: tensor(0.020969, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.34it/s]\n",
            "100% 5/5 [00:00<00:00,  9.27it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.61it/s]\n",
            "100% 4/4 [00:00<00:00,  9.25it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00011324, Rollout MSE Error (joint_q) = 0.00000945 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 26 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00010939, itemized = {state_0: 0.00000059, state_1: 0.01387338, state_2: 0.00003384, state_3: 0.00005366, state_MSE: 0.00349037, q_error_norm: 0.00343868, qd_error_norm: 0.00734599} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00138969, itemized = {state_0: 0.00000166, state_1: 0.02311879, state_2: 0.00033408, state_3: 0.00116586, state_MSE: 0.00615510, q_error_norm: 0.00532774, qd_error_norm: 0.01316175} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.184 sec, time(other): 0.010 sec, time(dataloader): 10.700 sec, time(compute_loss): 2.152 sec, time(backward): 3.399 sec, time(eval): 0.602 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.019222, device='cuda:0'), grad_norm_after_clip: tensor(0.019222, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.21it/s]\n",
            "100% 5/5 [00:00<00:00,  9.04it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.43it/s]\n",
            "100% 4/4 [00:00<00:00,  9.21it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00036029, Rollout MSE Error (joint_q) = 0.00005974 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 27 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00019251, itemized = {state_0: 0.00000112, state_1: 0.01537561, state_2: 0.00004872, state_3: 0.00007805, state_MSE: 0.00387587, q_error_norm: 0.00436513, qd_error_norm: 0.00837346} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00121457, itemized = {state_0: 0.00000160, state_1: 0.02003773, state_2: 0.00030710, state_3: 0.00095841, state_MSE: 0.00532621, q_error_norm: 0.00541935, qd_error_norm: 0.01499428} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.484 sec, time(other): 0.010 sec, time(dataloader): 11.021 sec, time(compute_loss): 2.153 sec, time(backward): 3.421 sec, time(eval): 0.605 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.049828, device='cuda:0'), grad_norm_after_clip: tensor(0.049828, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.33it/s]\n",
            "100% 5/5 [00:00<00:00,  9.27it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.56it/s]\n",
            "100% 4/4 [00:00<00:00,  9.30it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00017077, Rollout MSE Error (joint_q) = 0.00006484 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 28 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00022289, itemized = {state_0: 0.00000110, state_1: 0.01433556, state_2: 0.00007710, state_3: 0.00011023, state_MSE: 0.00363100, q_error_norm: 0.00394627, qd_error_norm: 0.00961055} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00143639, itemized = {state_0: 0.00000190, state_1: 0.02774278, state_2: 0.00034040, state_3: 0.00117424, state_MSE: 0.00731483, q_error_norm: 0.00674511, qd_error_norm: 0.01387395} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.150 sec, time(other): 0.010 sec, time(dataloader): 10.727 sec, time(compute_loss): 2.156 sec, time(backward): 3.399 sec, time(eval): 0.600 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.052175, device='cuda:0'), grad_norm_after_clip: tensor(0.052175, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.25it/s]\n",
            "100% 5/5 [00:00<00:00,  9.33it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.58it/s]\n",
            "100% 4/4 [00:00<00:00,  9.27it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00023506, Rollout MSE Error (joint_q) = 0.00010447 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 29 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00019544, itemized = {state_0: 0.00000127, state_1: 0.01518338, state_2: 0.00005433, state_3: 0.00008589, state_MSE: 0.00383121, q_error_norm: 0.00429447, qd_error_norm: 0.00867927} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00138815, itemized = {state_0: 0.00000209, state_1: 0.01310046, state_2: 0.00035486, state_3: 0.00109511, state_MSE: 0.00363813, q_error_norm: 0.00438194, qd_error_norm: 0.01397648} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.347 sec, time(other): 0.010 sec, time(dataloader): 10.918 sec, time(compute_loss): 2.155 sec, time(backward): 3.401 sec, time(eval): 0.601 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.052910, device='cuda:0'), grad_norm_after_clip: tensor(0.052910, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.33it/s]\n",
            "100% 5/5 [00:00<00:00,  9.28it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.08it/s]\n",
            "100% 4/4 [00:00<00:00,  9.34it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00133929, Rollout MSE Error (joint_q) = 0.00003228 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 30 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00046262, itemized = {state_0: 0.00000139, state_1: 0.01595279, state_2: 0.00014908, state_3: 0.00028033, state_MSE: 0.00409590, q_error_norm: 0.00464862, qd_error_norm: 0.01423947} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00133244, itemized = {state_0: 0.00000207, state_1: 0.02080396, state_2: 0.00033876, state_3: 0.00107130, state_MSE: 0.00555402, q_error_norm: 0.00526029, qd_error_norm: 0.01776222} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.142 sec, time(other): 0.010 sec, time(dataloader): 10.716 sec, time(compute_loss): 2.156 sec, time(backward): 3.395 sec, time(eval): 0.595 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.083471, device='cuda:0'), grad_norm_after_clip: tensor(0.083471, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.31it/s]\n",
            "100% 5/5 [00:00<00:00,  9.20it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.83it/s]\n",
            "100% 4/4 [00:00<00:00,  9.24it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00448310, Rollout MSE Error (joint_q) = 0.00003206 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 31 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00045878, itemized = {state_0: 0.00000124, state_1: 0.01495127, state_2: 0.00017391, state_3: 0.00026508, state_MSE: 0.00384787, q_error_norm: 0.00427948, qd_error_norm: 0.01359657} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00262004, itemized = {state_0: 0.00000363, state_1: 0.01464799, state_2: 0.00089541, state_3: 0.00190534, state_MSE: 0.00436309, q_error_norm: 0.00475929, qd_error_norm: 0.02991644} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.205 sec, time(other): 0.010 sec, time(dataloader): 10.787 sec, time(compute_loss): 2.153 sec, time(backward): 3.388 sec, time(eval): 0.601 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.081471, device='cuda:0'), grad_norm_after_clip: tensor(0.081471, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.34it/s]\n",
            "100% 5/5 [00:00<00:00,  9.46it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.74it/s]\n",
            "100% 4/4 [00:00<00:00,  9.21it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00061103, Rollout MSE Error (joint_q) = 0.00004348 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 32 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00093327, itemized = {state_0: 0.00000218, state_1: 0.01756819, state_2: 0.00029666, state_3: 0.00061930, state_MSE: 0.00462158, q_error_norm: 0.00533465, qd_error_norm: 0.01982408} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00164909, itemized = {state_0: 0.00000155, state_1: 0.02311868, state_2: 0.00045936, state_3: 0.00131753, state_MSE: 0.00622428, q_error_norm: 0.00565108, qd_error_norm: 0.01696317} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.193 sec, time(other): 0.010 sec, time(dataloader): 10.684 sec, time(compute_loss): 2.149 sec, time(backward): 3.407 sec, time(eval): 0.603 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.103196, device='cuda:0'), grad_norm_after_clip: tensor(0.103196, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.25it/s]\n",
            "100% 5/5 [00:00<00:00,  9.21it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.18it/s]\n",
            "100% 4/4 [00:00<00:00,  9.57it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00011861, Rollout MSE Error (joint_q) = 0.00000835 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 33 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00015083, itemized = {state_0: 0.00000073, state_1: 0.01456668, state_2: 0.00004851, state_3: 0.00007486, state_MSE: 0.00367269, q_error_norm: 0.00373776, qd_error_norm: 0.00797138} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00124685, itemized = {state_0: 0.00000145, state_1: 0.01926879, state_2: 0.00031118, state_3: 0.00103483, state_MSE: 0.00515406, q_error_norm: 0.00453795, qd_error_norm: 0.01233963} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.336 sec, time(other): 0.010 sec, time(dataloader): 10.885 sec, time(compute_loss): 2.161 sec, time(backward): 3.439 sec, time(eval): 0.589 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.034073, device='cuda:0'), grad_norm_after_clip: tensor(0.034073, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.35it/s]\n",
            "100% 5/5 [00:00<00:00,  9.16it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.86it/s]\n",
            "100% 4/4 [00:00<00:00,  9.30it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00037461, Rollout MSE Error (joint_q) = 0.00002480 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 34 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00020397, itemized = {state_0: 0.00000098, state_1: 0.01425893, state_2: 0.00006503, state_3: 0.00009221, state_MSE: 0.00360429, q_error_norm: 0.00400586, qd_error_norm: 0.00830019} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00174124, itemized = {state_0: 0.00000209, state_1: 0.04312920, state_2: 0.00067697, state_3: 0.00117792, state_MSE: 0.01124654, q_error_norm: 0.00897880, qd_error_norm: 0.01811001} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.093 sec, time(other): 0.010 sec, time(dataloader): 10.606 sec, time(compute_loss): 2.164 sec, time(backward): 3.456 sec, time(eval): 0.599 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.050522, device='cuda:0'), grad_norm_after_clip: tensor(0.050522, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.23it/s]\n",
            "100% 5/5 [00:00<00:00,  9.05it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.64it/s]\n",
            "100% 4/4 [00:00<00:00,  9.39it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00029512, Rollout MSE Error (joint_q) = 0.00001980 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 35 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00031163, itemized = {state_0: 0.00000121, state_1: 0.01472088, state_2: 0.00010908, state_3: 0.00016867, state_MSE: 0.00374996, q_error_norm: 0.00416802, qd_error_norm: 0.01122954} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00138305, itemized = {state_0: 0.00000219, state_1: 0.02157985, state_2: 0.00033574, state_3: 0.00113294, state_MSE: 0.00576268, q_error_norm: 0.00540144, qd_error_norm: 0.01388564} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.427 sec, time(other): 0.010 sec, time(dataloader): 10.978 sec, time(compute_loss): 2.151 sec, time(backward): 3.424 sec, time(eval): 0.597 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.064569, device='cuda:0'), grad_norm_after_clip: tensor(0.064569, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.18it/s]\n",
            "100% 5/5 [00:00<00:00,  9.25it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.98it/s]\n",
            "100% 4/4 [00:00<00:00,  9.30it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00052909, Rollout MSE Error (joint_q) = 0.00006591 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 36 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00034165, itemized = {state_0: 0.00000116, state_1: 0.01529820, state_2: 0.00010485, state_3: 0.00020659, state_MSE: 0.00390270, q_error_norm: 0.00430433, qd_error_norm: 0.01183825} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00146015, itemized = {state_0: 0.00000179, state_1: 0.02620113, state_2: 0.00036953, state_3: 0.00117233, state_MSE: 0.00693620, q_error_norm: 0.00650464, qd_error_norm: 0.01497728} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.539 sec, time(other): 0.010 sec, time(dataloader): 11.084 sec, time(compute_loss): 2.175 sec, time(backward): 3.401 sec, time(eval): 0.602 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.066221, device='cuda:0'), grad_norm_after_clip: tensor(0.066221, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.51it/s]\n",
            "100% 5/5 [00:00<00:00,  9.31it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.68it/s]\n",
            "100% 4/4 [00:00<00:00,  9.23it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00081616, Rollout MSE Error (joint_q) = 0.00006280 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 37 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00036520, itemized = {state_0: 0.00000084, state_1: 0.01452744, state_2: 0.00013848, state_3: 0.00020266, state_MSE: 0.00371736, q_error_norm: 0.00415689, qd_error_norm: 0.01228608} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00162592, itemized = {state_0: 0.00000197, state_1: 0.04698045, state_2: 0.00051165, state_3: 0.00119776, state_MSE: 0.01217296, q_error_norm: 0.00987580, qd_error_norm: 0.01787873} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 16.814 sec, time(other): 0.010 sec, time(dataloader): 10.265 sec, time(compute_loss): 2.160 sec, time(backward): 3.416 sec, time(eval): 0.604 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.072406, device='cuda:0'), grad_norm_after_clip: tensor(0.072406, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.25it/s]\n",
            "100% 5/5 [00:00<00:00,  9.20it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.57it/s]\n",
            "100% 4/4 [00:00<00:00,  9.08it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00050970, Rollout MSE Error (joint_q) = 0.00004613 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 38 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00065434, itemized = {state_0: 0.00000145, state_1: 0.01695370, state_2: 0.00023472, state_3: 0.00039064, state_MSE: 0.00439513, q_error_norm: 0.00501871, qd_error_norm: 0.01641888} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00168219, itemized = {state_0: 0.00000162, state_1: 0.01540873, state_2: 0.00043359, state_3: 0.00137635, state_MSE: 0.00430507, q_error_norm: 0.00446116, qd_error_norm: 0.01698750} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.472 sec, time(other): 0.010 sec, time(dataloader): 10.909 sec, time(compute_loss): 2.160 sec, time(backward): 3.420 sec, time(eval): 0.611 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.094497, device='cuda:0'), grad_norm_after_clip: tensor(0.094497, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.20it/s]\n",
            "100% 5/5 [00:00<00:00,  9.30it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.87it/s]\n",
            "100% 4/4 [00:00<00:00,  9.24it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00008539, Rollout MSE Error (joint_q) = 0.00001354 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 39 with MSE error 8.538617112208158e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 39 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00017741, itemized = {state_0: 0.00000073, state_1: 0.01445181, state_2: 0.00005421, state_3: 0.00010572, state_MSE: 0.00365312, q_error_norm: 0.00360616, qd_error_norm: 0.00885813} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00120607, itemized = {state_0: 0.00000130, state_1: 0.02080760, state_2: 0.00030874, state_3: 0.00099508, state_MSE: 0.00552818, q_error_norm: 0.00473376, qd_error_norm: 0.01150043} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.512 sec, time(other): 0.010 sec, time(dataloader): 11.011 sec, time(compute_loss): 2.159 sec, time(backward): 3.442 sec, time(eval): 0.626 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.035781, device='cuda:0'), grad_norm_after_clip: tensor(0.035781, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.28it/s]\n",
            "100% 5/5 [00:00<00:00,  9.37it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.02it/s]\n",
            "100% 4/4 [00:00<00:00,  9.41it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00015874, Rollout MSE Error (joint_q) = 0.00002784 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 40 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00009445, itemized = {state_0: 0.00000105, state_1: 0.01345054, state_2: 0.00002171, state_3: 0.00003591, state_MSE: 0.00337730, q_error_norm: 0.00349654, qd_error_norm: 0.00592388} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00131249, itemized = {state_0: 0.00000185, state_1: 0.01001922, state_2: 0.00033386, state_3: 0.00107373, state_MSE: 0.00285716, q_error_norm: 0.00320472, qd_error_norm: 0.01180438} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.345 sec, time(other): 0.010 sec, time(dataloader): 10.802 sec, time(compute_loss): 2.155 sec, time(backward): 3.437 sec, time(eval): 0.597 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.032240, device='cuda:0'), grad_norm_after_clip: tensor(0.032240, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.30it/s]\n",
            "100% 5/5 [00:00<00:00,  9.20it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.83it/s]\n",
            "100% 4/4 [00:00<00:00,  9.25it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00011630, Rollout MSE Error (joint_q) = 0.00006103 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 41 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00010302, itemized = {state_0: 0.00000104, state_1: 0.01329677, state_2: 0.00002371, state_3: 0.00003839, state_MSE: 0.00333998, q_error_norm: 0.00354924, qd_error_norm: 0.00605535} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00141386, itemized = {state_0: 0.00000406, state_1: 0.01926819, state_2: 0.00031076, state_3: 0.00114751, state_MSE: 0.00518263, q_error_norm: 0.00533780, qd_error_norm: 0.01154595} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.287 sec, time(other): 0.010 sec, time(dataloader): 10.720 sec, time(compute_loss): 2.168 sec, time(backward): 3.467 sec, time(eval): 0.600 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.036664, device='cuda:0'), grad_norm_after_clip: tensor(0.036664, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.13it/s]\n",
            "100% 5/5 [00:00<00:00,  9.43it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.06it/s]\n",
            "100% 4/4 [00:00<00:00,  9.32it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00069914, Rollout MSE Error (joint_q) = 0.00003011 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 42 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00015259, itemized = {state_0: 0.00000077, state_1: 0.01422013, state_2: 0.00004634, state_3: 0.00007199, state_MSE: 0.00358481, q_error_norm: 0.00377259, qd_error_norm: 0.00749994} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00156282, itemized = {state_0: 0.00000207, state_1: 0.01464043, state_2: 0.00043815, state_3: 0.00124162, state_MSE: 0.00408057, q_error_norm: 0.00419906, qd_error_norm: 0.01638981} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.657 sec, time(other): 0.010 sec, time(dataloader): 11.206 sec, time(compute_loss): 2.157 sec, time(backward): 3.424 sec, time(eval): 0.600 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.044964, device='cuda:0'), grad_norm_after_clip: tensor(0.044964, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:17<00:00,  5.59it/s]\n",
            "100% 5/5 [00:00<00:00,  9.15it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.35it/s]\n",
            "100% 4/4 [00:00<00:00,  9.24it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00072668, Rollout MSE Error (joint_q) = 0.00003642 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 43 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00062548, itemized = {state_0: 0.00000175, state_1: 0.01702998, state_2: 0.00022987, state_3: 0.00035891, state_MSE: 0.00440513, q_error_norm: 0.00502401, qd_error_norm: 0.01599597} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00198205, itemized = {state_0: 0.00000182, state_1: 0.02388408, state_2: 0.00051396, state_3: 0.00160375, state_MSE: 0.00650090, q_error_norm: 0.00632237, qd_error_norm: 0.01878392} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 19.881 sec, time(other): 0.010 sec, time(dataloader): 12.749 sec, time(compute_loss): 2.167 sec, time(backward): 3.453 sec, time(eval): 0.604 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.098323, device='cuda:0'), grad_norm_after_clip: tensor(0.098323, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:17<00:00,  5.68it/s]\n",
            "100% 5/5 [00:00<00:00,  8.59it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.95it/s]\n",
            "100% 4/4 [00:00<00:00,  9.12it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00037561, Rollout MSE Error (joint_q) = 0.00001665 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 44 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00037797, itemized = {state_0: 0.00000100, state_1: 0.01448881, state_2: 0.00013025, state_3: 0.00023415, state_MSE: 0.00371355, q_error_norm: 0.00397761, qd_error_norm: 0.01264023} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00169268, itemized = {state_0: 0.00000160, state_1: 0.02466104, state_2: 0.00047042, state_3: 0.00137128, state_MSE: 0.00662608, q_error_norm: 0.00551673, qd_error_norm: 0.01503345} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 19.609 sec, time(other): 0.010 sec, time(dataloader): 12.533 sec, time(compute_loss): 2.174 sec, time(backward): 3.421 sec, time(eval): 0.612 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.062380, device='cuda:0'), grad_norm_after_clip: tensor(0.062380, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:19<00:00,  5.00it/s]\n",
            "100% 5/5 [00:00<00:00,  9.18it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.40it/s]\n",
            "100% 4/4 [00:00<00:00,  9.07it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00029577, Rollout MSE Error (joint_q) = 0.00000594 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 45 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00012364, itemized = {state_0: 0.00000047, state_1: 0.01398969, state_2: 0.00003934, state_3: 0.00007044, state_MSE: 0.00352499, q_error_norm: 0.00338521, qd_error_norm: 0.00746142} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00140493, itemized = {state_0: 0.00000125, state_1: 0.01464527, state_2: 0.00037062, state_3: 0.00116166, state_MSE: 0.00404470, q_error_norm: 0.00369366, qd_error_norm: 0.01276675} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.028 sec, time(other): 0.011 sec, time(dataloader): 14.825 sec, time(compute_loss): 2.184 sec, time(backward): 3.453 sec, time(eval): 0.612 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.031340, device='cuda:0'), grad_norm_after_clip: tensor(0.031340, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.82it/s]\n",
            "100% 5/5 [00:01<00:00,  4.37it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.84it/s]\n",
            "100% 4/4 [00:00<00:00,  9.21it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00012235, Rollout MSE Error (joint_q) = 0.00001200 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 46 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00009809, itemized = {state_0: 0.00000062, state_1: 0.01391292, state_2: 0.00002703, state_3: 0.00004215, state_MSE: 0.00349568, q_error_norm: 0.00352664, qd_error_norm: 0.00617192} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00140426, itemized = {state_0: 0.00000119, state_1: 0.01926732, state_2: 0.00036490, state_3: 0.00116747, state_MSE: 0.00520022, q_error_norm: 0.00458492, qd_error_norm: 0.01148594} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.768 sec, time(other): 0.011 sec, time(dataloader): 16.257 sec, time(compute_loss): 2.169 sec, time(backward): 3.408 sec, time(eval): 0.602 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.033428, device='cuda:0'), grad_norm_after_clip: tensor(0.033428, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:20<00:00,  4.82it/s]\n",
            "100% 5/5 [00:01<00:00,  4.44it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.17it/s]\n",
            "100% 4/4 [00:00<00:00,  9.21it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00041726, Rollout MSE Error (joint_q) = 0.00018251 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 47 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00009423, itemized = {state_0: 0.00000055, state_1: 0.01306541, state_2: 0.00002769, state_3: 0.00004457, state_MSE: 0.00328455, q_error_norm: 0.00331305, qd_error_norm: 0.00623486} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00152108, itemized = {state_0: 0.00000163, state_1: 0.01464721, state_2: 0.00038169, state_3: 0.00119343, state_MSE: 0.00405599, q_error_norm: 0.00531816, qd_error_norm: 0.01225148} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 22.830 sec, time(other): 0.010 sec, time(dataloader): 16.166 sec, time(compute_loss): 2.177 sec, time(backward): 3.445 sec, time(eval): 0.609 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.032763, device='cuda:0'), grad_norm_after_clip: tensor(0.032763, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:22<00:00,  4.42it/s]\n",
            "100% 5/5 [00:01<00:00,  4.45it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.47it/s]\n",
            "100% 4/4 [00:00<00:00,  9.11it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00280217, Rollout MSE Error (joint_q) = 0.00003587 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 48 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00053855, itemized = {state_0: 0.00000161, state_1: 0.01572108, state_2: 0.00019535, state_3: 0.00029869, state_MSE: 0.00405418, q_error_norm: 0.00462766, qd_error_norm: 0.01198812} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00260356, itemized = {state_0: 0.00000557, state_1: 0.01308658, state_2: 0.00058875, state_3: 0.00209426, state_MSE: 0.00394379, q_error_norm: 0.00540910, qd_error_norm: 0.02611298} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 24.629 sec, time(other): 0.010 sec, time(dataloader): 18.131 sec, time(compute_loss): 2.169 sec, time(backward): 3.410 sec, time(eval): 0.610 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.076928, device='cuda:0'), grad_norm_after_clip: tensor(0.076928, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:22<00:00,  4.49it/s]\n",
            "100% 5/5 [00:01<00:00,  4.40it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.23it/s]\n",
            "100% 4/4 [00:00<00:00,  9.30it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00009165, Rollout MSE Error (joint_q) = 0.00001654 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 49 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00060394, itemized = {state_0: 0.00000155, state_1: 0.01533446, state_2: 0.00017535, state_3: 0.00041313, state_MSE: 0.00398112, q_error_norm: 0.00448237, qd_error_norm: 0.01577744} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00163176, itemized = {state_0: 0.00000157, state_1: 0.01233094, state_2: 0.00042211, state_3: 0.00136007, state_MSE: 0.00352867, q_error_norm: 0.00349569, qd_error_norm: 0.01260183} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 24.934 sec, time(other): 0.011 sec, time(dataloader): 17.704 sec, time(compute_loss): 2.172 sec, time(backward): 3.461 sec, time(eval): 0.601 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.073166, device='cuda:0'), grad_norm_after_clip: tensor(0.073166, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:23<00:00,  4.29it/s]\n",
            "100% 5/5 [00:01<00:00,  4.48it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.59it/s]\n",
            "100% 4/4 [00:00<00:00,  9.22it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00018417, Rollout MSE Error (joint_q) = 0.00000345 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 50 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00012230, itemized = {state_0: 0.00000045, state_1: 0.01387434, state_2: 0.00004601, state_3: 0.00006650, state_MSE: 0.00349683, q_error_norm: 0.00324678, qd_error_norm: 0.00736445} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00136860, itemized = {state_0: 0.00000118, state_1: 0.01849494, state_2: 0.00035657, state_3: 0.00114093, state_MSE: 0.00499840, q_error_norm: 0.00419884, qd_error_norm: 0.01212736} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 25.390 sec, time(other): 0.010 sec, time(dataloader): 18.824 sec, time(compute_loss): 2.156 sec, time(backward): 3.402 sec, time(eval): 0.603 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.032966, device='cuda:0'), grad_norm_after_clip: tensor(0.032966, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:23<00:00,  4.27it/s]\n",
            "100% 5/5 [00:01<00:00,  4.51it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.91it/s]\n",
            "100% 4/4 [00:00<00:00,  9.20it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00011686, Rollout MSE Error (joint_q) = 0.00001539 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 51 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00007310, itemized = {state_0: 0.00000032, state_1: 0.01279601, state_2: 0.00002364, state_3: 0.00003937, state_MSE: 0.00321484, q_error_norm: 0.00295755, qd_error_norm: 0.00596484} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00141796, itemized = {state_0: 0.00000130, state_1: 0.01849825, state_2: 0.00035092, state_3: 0.00119868, state_MSE: 0.00501228, q_error_norm: 0.00435844, qd_error_norm: 0.01194995} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 25.379 sec, time(other): 0.010 sec, time(dataloader): 18.856 sec, time(compute_loss): 2.156 sec, time(backward): 3.435 sec, time(eval): 0.602 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.023019, device='cuda:0'), grad_norm_after_clip: tensor(0.023019, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:18<00:00,  5.27it/s]\n",
            "100% 5/5 [00:00<00:00,  9.19it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.08it/s]\n",
            "100% 4/4 [00:00<00:00,  9.39it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00013636, Rollout MSE Error (joint_q) = 0.00010512 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 52 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00013503, itemized = {state_0: 0.00000072, state_1: 0.01352750, state_2: 0.00004311, state_3: 0.00006268, state_MSE: 0.00340850, q_error_norm: 0.00353894, qd_error_norm: 0.00723611} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00152110, itemized = {state_0: 0.00000138, state_1: 0.01387340, state_2: 0.00040656, state_3: 0.00120575, state_MSE: 0.00387178, q_error_norm: 0.00455785, qd_error_norm: 0.01159435} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 20.376 sec, time(other): 0.010 sec, time(dataloader): 13.846 sec, time(compute_loss): 2.159 sec, time(backward): 3.439 sec, time(eval): 0.594 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.042180, device='cuda:0'), grad_norm_after_clip: tensor(0.042180, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.22it/s]\n",
            "100% 5/5 [00:00<00:00,  9.14it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.58it/s]\n",
            "100% 4/4 [00:00<00:00,  9.20it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00039850, Rollout MSE Error (joint_q) = 0.00000973 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 53 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00011717, itemized = {state_0: 0.00000053, state_1: 0.01302650, state_2: 0.00003941, state_3: 0.00006001, state_MSE: 0.00328161, q_error_norm: 0.00326166, qd_error_norm: 0.00690467} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00149177, itemized = {state_0: 0.00000125, state_1: 0.02081099, state_2: 0.00040563, state_3: 0.00122107, state_MSE: 0.00560973, q_error_norm: 0.00482620, qd_error_norm: 0.01360411} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.441 sec, time(other): 0.010 sec, time(dataloader): 10.970 sec, time(compute_loss): 2.155 sec, time(backward): 3.435 sec, time(eval): 0.605 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.035799, device='cuda:0'), grad_norm_after_clip: tensor(0.035799, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.14it/s]\n",
            "100% 5/5 [00:00<00:00,  8.99it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 26.00it/s]\n",
            "100% 4/4 [00:00<00:00,  9.29it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00015217, Rollout MSE Error (joint_q) = 0.00001099 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 54 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00011083, itemized = {state_0: 0.00000051, state_1: 0.01187047, state_2: 0.00003740, state_3: 0.00005601, state_MSE: 0.00299110, q_error_norm: 0.00306431, qd_error_norm: 0.00659435} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00122541, itemized = {state_0: 0.00000125, state_1: 0.00847727, state_2: 0.00035790, state_3: 0.00097080, state_MSE: 0.00245181, q_error_norm: 0.00267753, qd_error_norm: 0.01161323} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.726 sec, time(other): 0.010 sec, time(dataloader): 11.176 sec, time(compute_loss): 2.167 sec, time(backward): 3.447 sec, time(eval): 0.597 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.033036, device='cuda:0'), grad_norm_after_clip: tensor(0.033036, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.29it/s]\n",
            "100% 5/5 [00:00<00:00,  9.11it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.82it/s]\n",
            "100% 4/4 [00:00<00:00,  9.24it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00012428, Rollout MSE Error (joint_q) = 0.00003086 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 55 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00008680, itemized = {state_0: 0.00000045, state_1: 0.01248759, state_2: 0.00002645, state_3: 0.00004536, state_MSE: 0.00313996, q_error_norm: 0.00305641, qd_error_norm: 0.00617946} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00133469, itemized = {state_0: 0.00000127, state_1: 0.02619979, state_2: 0.00035296, state_3: 0.00108380, state_MSE: 0.00690946, q_error_norm: 0.00601878, qd_error_norm: 0.01168139} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.295 sec, time(other): 0.010 sec, time(dataloader): 10.825 sec, time(compute_loss): 2.158 sec, time(backward): 3.403 sec, time(eval): 0.601 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.031502, device='cuda:0'), grad_norm_after_clip: tensor(0.031502, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.15it/s]\n",
            "100% 5/5 [00:00<00:00,  8.68it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.74it/s]\n",
            "100% 4/4 [00:00<00:00,  9.05it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00097088, Rollout MSE Error (joint_q) = 0.00011829 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 56 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00025929, itemized = {state_0: 0.00000116, state_1: 0.01418108, state_2: 0.00008780, state_3: 0.00013643, state_MSE: 0.00360162, q_error_norm: 0.00392289, qd_error_norm: 0.00936406} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00181163, itemized = {state_0: 0.00000244, state_1: 0.03543551, state_2: 0.00046632, state_3: 0.00144798, state_MSE: 0.00933806, q_error_norm: 0.00810622, qd_error_norm: 0.01770176} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.759 sec, time(other): 0.010 sec, time(dataloader): 11.168 sec, time(compute_loss): 2.170 sec, time(backward): 3.437 sec, time(eval): 0.612 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.056091, device='cuda:0'), grad_norm_after_clip: tensor(0.056091, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.21it/s]\n",
            "100% 5/5 [00:00<00:00,  9.09it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.86it/s]\n",
            "100% 4/4 [00:00<00:00,  9.39it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00014484, Rollout MSE Error (joint_q) = 0.00000641 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 57 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00030246, itemized = {state_0: 0.00000122, state_1: 0.01367962, state_2: 0.00009904, state_3: 0.00017078, state_MSE: 0.00348766, q_error_norm: 0.00387760, qd_error_norm: 0.01071708} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00149569, itemized = {state_0: 0.00000123, state_1: 0.01001918, state_2: 0.00041997, state_3: 0.00121383, state_MSE: 0.00291355, q_error_norm: 0.00290096, qd_error_norm: 0.01142223} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.465 sec, time(other): 0.010 sec, time(dataloader): 11.016 sec, time(compute_loss): 2.163 sec, time(backward): 3.417 sec, time(eval): 0.594 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.058248, device='cuda:0'), grad_norm_after_clip: tensor(0.058248, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.22it/s]\n",
            "100% 5/5 [00:00<00:00,  9.09it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.84it/s]\n",
            "100% 4/4 [00:00<00:00,  9.24it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004791, Rollout MSE Error (joint_q) = 0.00000668 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 58 with MSE error 4.791418541572057e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 58 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00005061, itemized = {state_0: 0.00000026, state_1: 0.01140886, state_2: 0.00001583, state_3: 0.00002597, state_MSE: 0.00286273, q_error_norm: 0.00261909, qd_error_norm: 0.00495963} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00147780, itemized = {state_0: 0.00000109, state_1: 0.01464481, state_2: 0.00040438, state_3: 0.00121618, state_MSE: 0.00406662, q_error_norm: 0.00353054, qd_error_norm: 0.01063383} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.474 sec, time(other): 0.010 sec, time(dataloader): 10.987 sec, time(compute_loss): 2.155 sec, time(backward): 3.426 sec, time(eval): 0.626 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.017515, device='cuda:0'), grad_norm_after_clip: tensor(0.017515, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.18it/s]\n",
            "100% 5/5 [00:00<00:00,  8.14it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 23.26it/s]\n",
            "100% 4/4 [00:00<00:00,  9.31it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00082596, Rollout MSE Error (joint_q) = 0.00007533 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 59 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00015152, itemized = {state_0: 0.00000051, state_1: 0.01252605, state_2: 0.00005912, state_3: 0.00008091, state_MSE: 0.00316665, q_error_norm: 0.00311779, qd_error_norm: 0.00740751} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00184566, itemized = {state_0: 0.00000155, state_1: 0.03621603, state_2: 0.00049199, state_3: 0.00149236, state_MSE: 0.00955048, q_error_norm: 0.00817442, qd_error_norm: 0.01665233} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.619 sec, time(other): 0.010 sec, time(dataloader): 11.143 sec, time(compute_loss): 2.157 sec, time(backward): 3.427 sec, time(eval): 0.620 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.040547, device='cuda:0'), grad_norm_after_clip: tensor(0.040547, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.22it/s]\n",
            "100% 5/5 [00:00<00:00,  8.78it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.78it/s]\n",
            "100% 4/4 [00:00<00:00,  9.22it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00012910, Rollout MSE Error (joint_q) = 0.00001366 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 60 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00024920, itemized = {state_0: 0.00000076, state_1: 0.01271731, state_2: 0.00007498, state_3: 0.00015734, state_MSE: 0.00323760, q_error_norm: 0.00350692, qd_error_norm: 0.01008610} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00164375, itemized = {state_0: 0.00000124, state_1: 0.01618576, state_2: 0.00048339, state_3: 0.00131414, state_MSE: 0.00449613, q_error_norm: 0.00390167, qd_error_norm: 0.01229698} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.519 sec, time(other): 0.010 sec, time(dataloader): 11.022 sec, time(compute_loss): 2.154 sec, time(backward): 3.409 sec, time(eval): 0.608 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.050751, device='cuda:0'), grad_norm_after_clip: tensor(0.050751, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.22it/s]\n",
            "100% 5/5 [00:00<00:00,  9.09it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.54it/s]\n",
            "100% 4/4 [00:00<00:00,  9.23it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00010206, Rollout MSE Error (joint_q) = 0.00001107 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 61 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00009987, itemized = {state_0: 0.00000044, state_1: 0.01079201, state_2: 0.00003696, state_3: 0.00005266, state_MSE: 0.00272052, q_error_norm: 0.00270396, qd_error_norm: 0.00655054} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00169831, itemized = {state_0: 0.00000136, state_1: 0.01772888, state_2: 0.00046341, state_3: 0.00140157, state_MSE: 0.00489880, q_error_norm: 0.00415947, qd_error_norm: 0.01250732} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.533 sec, time(other): 0.010 sec, time(dataloader): 11.007 sec, time(compute_loss): 2.153 sec, time(backward): 3.416 sec, time(eval): 0.608 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.033755, device='cuda:0'), grad_norm_after_clip: tensor(0.033755, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.21it/s]\n",
            "100% 5/5 [00:00<00:00,  8.96it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.07it/s]\n",
            "100% 4/4 [00:00<00:00,  9.31it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00008483, Rollout MSE Error (joint_q) = 0.00001319 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 62 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00008701, itemized = {state_0: 0.00000035, state_1: 0.01125448, state_2: 0.00002995, state_3: 0.00004736, state_MSE: 0.00283303, q_error_norm: 0.00275521, qd_error_norm: 0.00616092} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00146506, itemized = {state_0: 0.00000128, state_1: 0.00924933, state_2: 0.00042318, state_3: 0.00117070, state_MSE: 0.00271112, q_error_norm: 0.00287801, qd_error_norm: 0.01093569} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.518 sec, time(other): 0.011 sec, time(dataloader): 10.989 sec, time(compute_loss): 2.163 sec, time(backward): 3.439 sec, time(eval): 0.603 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.028206, device='cuda:0'), grad_norm_after_clip: tensor(0.028206, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.18it/s]\n",
            "100% 5/5 [00:00<00:00,  9.15it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.96it/s]\n",
            "100% 4/4 [00:00<00:00,  9.31it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00066018, Rollout MSE Error (joint_q) = 0.00004323 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 63 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00006328, itemized = {state_0: 0.00000028, state_1: 0.01129308, state_2: 0.00002013, state_3: 0.00003201, state_MSE: 0.00283637, q_error_norm: 0.00273316, qd_error_norm: 0.00517933} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00164883, itemized = {state_0: 0.00000161, state_1: 0.01002079, state_2: 0.00043788, state_3: 0.00135695, state_MSE: 0.00295431, q_error_norm: 0.00318927, qd_error_norm: 0.01446130} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.529 sec, time(other): 0.010 sec, time(dataloader): 11.089 sec, time(compute_loss): 2.158 sec, time(backward): 3.409 sec, time(eval): 0.598 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.024946, device='cuda:0'), grad_norm_after_clip: tensor(0.024946, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.14it/s]\n",
            "100% 5/5 [00:00<00:00,  8.96it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.45it/s]\n",
            "100% 4/4 [00:00<00:00,  8.90it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00038197, Rollout MSE Error (joint_q) = 0.00001463 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 64 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00025389, itemized = {state_0: 0.00000081, state_1: 0.01225525, state_2: 0.00009429, state_3: 0.00014308, state_MSE: 0.00312336, q_error_norm: 0.00345805, qd_error_norm: 0.01030341} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00181506, itemized = {state_0: 0.00000160, state_1: 0.01772788, state_2: 0.00049076, state_3: 0.00149521, state_MSE: 0.00492886, q_error_norm: 0.00442615, qd_error_norm: 0.01454955} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.764 sec, time(other): 0.010 sec, time(dataloader): 11.189 sec, time(compute_loss): 2.165 sec, time(backward): 3.426 sec, time(eval): 0.628 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.057655, device='cuda:0'), grad_norm_after_clip: tensor(0.057655, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.26it/s]\n",
            "100% 5/5 [00:00<00:00,  9.08it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.33it/s]\n",
            "100% 4/4 [00:00<00:00,  9.18it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00007012, Rollout MSE Error (joint_q) = 0.00000441 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 65 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00011941, itemized = {state_0: 0.00000044, state_1: 0.01214058, state_2: 0.00003904, state_3: 0.00007026, state_MSE: 0.00306258, q_error_norm: 0.00295327, qd_error_norm: 0.00690035} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00154101, itemized = {state_0: 0.00000106, state_1: 0.02157898, state_2: 0.00045037, state_3: 0.00124273, state_MSE: 0.00581828, q_error_norm: 0.00459999, qd_error_norm: 0.01098892} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.437 sec, time(other): 0.010 sec, time(dataloader): 10.842 sec, time(compute_loss): 2.168 sec, time(backward): 3.451 sec, time(eval): 0.612 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.030206, device='cuda:0'), grad_norm_after_clip: tensor(0.030206, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.24it/s]\n",
            "100% 5/5 [00:00<00:00,  9.07it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.52it/s]\n",
            "100% 4/4 [00:00<00:00,  9.23it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00005554, Rollout MSE Error (joint_q) = 0.00000391 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 66 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00004536, itemized = {state_0: 0.00000021, state_1: 0.00936638, state_2: 0.00001501, state_3: 0.00002336, state_MSE: 0.00235124, q_error_norm: 0.00223751, qd_error_norm: 0.00464163} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00151871, itemized = {state_0: 0.00000111, state_1: 0.01849843, state_2: 0.00039556, state_3: 0.00127496, state_MSE: 0.00504251, q_error_norm: 0.00414485, qd_error_norm: 0.01044247} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.490 sec, time(other): 0.010 sec, time(dataloader): 10.907 sec, time(compute_loss): 2.163 sec, time(backward): 3.455 sec, time(eval): 0.604 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.016839, device='cuda:0'), grad_norm_after_clip: tensor(0.016839, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.10it/s]\n",
            "100% 5/5 [00:00<00:00,  8.94it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.44it/s]\n",
            "100% 4/4 [00:00<00:00,  9.16it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00006588, Rollout MSE Error (joint_q) = 0.00000954 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 67 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00014744, itemized = {state_0: 0.00000054, state_1: 0.01237156, state_2: 0.00005374, state_3: 0.00007977, state_MSE: 0.00312640, q_error_norm: 0.00314308, qd_error_norm: 0.00752192} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00142314, itemized = {state_0: 0.00000122, state_1: 0.01772805, state_2: 0.00038687, state_3: 0.00116358, state_MSE: 0.00481993, q_error_norm: 0.00415723, qd_error_norm: 0.01100524} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.766 sec, time(other): 0.010 sec, time(dataloader): 11.303 sec, time(compute_loss): 2.167 sec, time(backward): 3.407 sec, time(eval): 0.608 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.039958, device='cuda:0'), grad_norm_after_clip: tensor(0.039958, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.22it/s]\n",
            "100% 5/5 [00:00<00:00,  9.14it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.87it/s]\n",
            "100% 4/4 [00:00<00:00,  9.26it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00011827, Rollout MSE Error (joint_q) = 0.00005320 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 68 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00005851, itemized = {state_0: 0.00000026, state_1: 0.01102333, state_2: 0.00001671, state_3: 0.00003210, state_MSE: 0.00276810, q_error_norm: 0.00264197, qd_error_norm: 0.00510365} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00139896, itemized = {state_0: 0.00000116, state_1: 0.00925135, state_2: 0.00039750, state_3: 0.00111299, state_MSE: 0.00269075, q_error_norm: 0.00327617, qd_error_norm: 0.01054015} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.429 sec, time(other): 0.010 sec, time(dataloader): 10.948 sec, time(compute_loss): 2.171 sec, time(backward): 3.437 sec, time(eval): 0.600 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.022107, device='cuda:0'), grad_norm_after_clip: tensor(0.022107, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.39it/s]\n",
            "100% 5/5 [00:00<00:00,  9.13it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.52it/s]\n",
            "100% 4/4 [00:00<00:00,  9.07it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00028813, Rollout MSE Error (joint_q) = 0.00002177 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 69 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00009953, itemized = {state_0: 0.00000043, state_1: 0.01148518, state_2: 0.00003318, state_3: 0.00005209, state_MSE: 0.00289272, q_error_norm: 0.00294113, qd_error_norm: 0.00645767} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00146652, itemized = {state_0: 0.00000114, state_1: 0.01926999, state_2: 0.00040460, state_3: 0.00119855, state_MSE: 0.00521857, q_error_norm: 0.00438640, qd_error_norm: 0.01166709} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.074 sec, time(other): 0.010 sec, time(dataloader): 10.544 sec, time(compute_loss): 2.162 sec, time(backward): 3.420 sec, time(eval): 0.613 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.037460, device='cuda:0'), grad_norm_after_clip: tensor(0.037460, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.28it/s]\n",
            "100% 5/5 [00:00<00:00,  9.25it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.61it/s]\n",
            "100% 4/4 [00:00<00:00,  9.33it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00012303, Rollout MSE Error (joint_q) = 0.00001799 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 70 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00010196, itemized = {state_0: 0.00000036, state_1: 0.01152416, state_2: 0.00003525, state_3: 0.00005843, state_MSE: 0.00290455, q_error_norm: 0.00281659, qd_error_norm: 0.00656833} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00147625, itemized = {state_0: 0.00000115, state_1: 0.00925066, state_2: 0.00039053, state_3: 0.00122785, state_MSE: 0.00271755, q_error_norm: 0.00276835, qd_error_norm: 0.01122031} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.332 sec, time(other): 0.010 sec, time(dataloader): 10.811 sec, time(compute_loss): 2.160 sec, time(backward): 3.439 sec, time(eval): 0.603 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.033272, device='cuda:0'), grad_norm_after_clip: tensor(0.033272, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.33it/s]\n",
            "100% 5/5 [00:00<00:00,  9.00it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.92it/s]\n",
            "100% 4/4 [00:00<00:00,  9.35it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00023283, Rollout MSE Error (joint_q) = 0.00002884 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 71 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00008582, itemized = {state_0: 0.00000037, state_1: 0.01005962, state_2: 0.00002987, state_3: 0.00004373, state_MSE: 0.00253340, q_error_norm: 0.00261337, qd_error_norm: 0.00582052} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00164799, itemized = {state_0: 0.00000120, state_1: 0.01078869, state_2: 0.00048667, state_3: 0.00131392, state_MSE: 0.00314762, q_error_norm: 0.00322388, qd_error_norm: 0.01203152} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.231 sec, time(other): 0.010 sec, time(dataloader): 10.717 sec, time(compute_loss): 2.162 sec, time(backward): 3.415 sec, time(eval): 0.596 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.031783, device='cuda:0'), grad_norm_after_clip: tensor(0.031783, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.27it/s]\n",
            "100% 5/5 [00:00<00:00,  9.00it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.11it/s]\n",
            "100% 4/4 [00:00<00:00,  9.24it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00009015, Rollout MSE Error (joint_q) = 0.00000390 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 72 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00010060, itemized = {state_0: 0.00000032, state_1: 0.01094599, state_2: 0.00003134, state_3: 0.00006203, state_MSE: 0.00275992, q_error_norm: 0.00271801, qd_error_norm: 0.00675777} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00143469, itemized = {state_0: 0.00000105, state_1: 0.01233071, state_2: 0.00042855, state_3: 0.00113719, state_MSE: 0.00347438, q_error_norm: 0.00326489, qd_error_norm: 0.01102175} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.390 sec, time(other): 0.010 sec, time(dataloader): 10.877 sec, time(compute_loss): 2.161 sec, time(backward): 3.413 sec, time(eval): 0.615 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.033764, device='cuda:0'), grad_norm_after_clip: tensor(0.033764, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.24it/s]\n",
            "100% 5/5 [00:00<00:00,  9.11it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.70it/s]\n",
            "100% 4/4 [00:00<00:00,  9.30it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004952, Rollout MSE Error (joint_q) = 0.00001879 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 73 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003596, itemized = {state_0: 0.00000018, state_1: 0.00982893, state_2: 0.00001063, state_3: 0.00001923, state_MSE: 0.00246474, q_error_norm: 0.00224452, qd_error_norm: 0.00416457} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00140862, itemized = {state_0: 0.00000113, state_1: 0.00848047, state_2: 0.00040234, state_3: 0.00113623, state_MSE: 0.00250504, q_error_norm: 0.00263332, qd_error_norm: 0.00986765} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.455 sec, time(other): 0.010 sec, time(dataloader): 10.913 sec, time(compute_loss): 2.150 sec, time(backward): 3.451 sec, time(eval): 0.599 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.013658, device='cuda:0'), grad_norm_after_clip: tensor(0.013658, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.20it/s]\n",
            "100% 5/5 [00:00<00:00,  9.16it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.66it/s]\n",
            "100% 4/4 [00:00<00:00,  9.27it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00017595, Rollout MSE Error (joint_q) = 0.00000416 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 74 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00005329, itemized = {state_0: 0.00000023, state_1: 0.00932778, state_2: 0.00001851, state_3: 0.00002743, state_MSE: 0.00234349, q_error_norm: 0.00227272, qd_error_norm: 0.00473876} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00155210, itemized = {state_0: 0.00000109, state_1: 0.01772587, state_2: 0.00046421, state_3: 0.00123891, state_MSE: 0.00485752, q_error_norm: 0.00403009, qd_error_norm: 0.01227019} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.479 sec, time(other): 0.010 sec, time(dataloader): 11.025 sec, time(compute_loss): 2.151 sec, time(backward): 3.429 sec, time(eval): 0.601 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.022335, device='cuda:0'), grad_norm_after_clip: tensor(0.022335, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.14it/s]\n",
            "100% 5/5 [00:00<00:00,  9.29it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.86it/s]\n",
            "100% 4/4 [00:00<00:00,  9.38it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00021398, Rollout MSE Error (joint_q) = 0.00003428 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 75 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00008274, itemized = {state_0: 0.00000028, state_1: 0.01017524, state_2: 0.00002638, state_3: 0.00004806, state_MSE: 0.00256249, q_error_norm: 0.00255875, qd_error_norm: 0.00599287} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00144642, itemized = {state_0: 0.00000106, state_1: 0.02620545, state_2: 0.00042945, state_3: 0.00112715, state_MSE: 0.00694078, q_error_norm: 0.00603807, qd_error_norm: 0.01134200} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.619 sec, time(other): 0.010 sec, time(dataloader): 11.209 sec, time(compute_loss): 2.153 sec, time(backward): 3.390 sec, time(eval): 0.595 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.029080, device='cuda:0'), grad_norm_after_clip: tensor(0.029080, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.29it/s]\n",
            "100% 5/5 [00:00<00:00,  9.11it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.73it/s]\n",
            "100% 4/4 [00:00<00:00,  9.22it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003548, Rollout MSE Error (joint_q) = 0.00000155 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 76 with MSE error 3.5480334190651774e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 76 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00006006, itemized = {state_0: 0.00000024, state_1: 0.00955879, state_2: 0.00001977, state_3: 0.00003244, state_MSE: 0.00240281, q_error_norm: 0.00233554, qd_error_norm: 0.00507412} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00127675, itemized = {state_0: 0.00000095, state_1: 0.01079142, state_2: 0.00041006, state_3: 0.00098503, state_MSE: 0.00304687, q_error_norm: 0.00275510, qd_error_norm: 0.00953197} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.354 sec, time(other): 0.010 sec, time(dataloader): 10.836 sec, time(compute_loss): 2.163 sec, time(backward): 3.393 sec, time(eval): 0.627 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.022309, device='cuda:0'), grad_norm_after_clip: tensor(0.022309, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.17it/s]\n",
            "100% 5/5 [00:00<00:00,  9.09it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.37it/s]\n",
            "100% 4/4 [00:00<00:00,  9.18it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00016081, Rollout MSE Error (joint_q) = 0.00000494 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 77 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003106, itemized = {state_0: 0.00000014, state_1: 0.00855729, state_2: 0.00000971, state_3: 0.00001627, state_MSE: 0.00214586, q_error_norm: 0.00199212, qd_error_norm: 0.00386216} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00148266, itemized = {state_0: 0.00000095, state_1: 0.00925110, state_2: 0.00043817, state_3: 0.00119218, state_MSE: 0.00272060, q_error_norm: 0.00254067, qd_error_norm: 0.01097251} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.577 sec, time(other): 0.010 sec, time(dataloader): 11.118 sec, time(compute_loss): 2.160 sec, time(backward): 3.405 sec, time(eval): 0.608 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.013549, device='cuda:0'), grad_norm_after_clip: tensor(0.013549, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.27it/s]\n",
            "100% 5/5 [00:00<00:00,  9.04it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.43it/s]\n",
            "100% 4/4 [00:00<00:00,  9.28it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00008795, Rollout MSE Error (joint_q) = 0.00001965 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 78 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00004280, itemized = {state_0: 0.00000019, state_1: 0.00940489, state_2: 0.00001338, state_3: 0.00002248, state_MSE: 0.00236023, q_error_norm: 0.00224868, qd_error_norm: 0.00442792} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00150721, itemized = {state_0: 0.00000100, state_1: 0.01233269, state_2: 0.00042938, state_3: 0.00122353, state_MSE: 0.00349665, q_error_norm: 0.00328996, qd_error_norm: 0.01017363} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.307 sec, time(other): 0.010 sec, time(dataloader): 10.877 sec, time(compute_loss): 2.159 sec, time(backward): 3.398 sec, time(eval): 0.602 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.018930, device='cuda:0'), grad_norm_after_clip: tensor(0.018930, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.29it/s]\n",
            "100% 5/5 [00:00<00:00,  8.91it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.36it/s]\n",
            "100% 4/4 [00:00<00:00,  9.31it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00038718, Rollout MSE Error (joint_q) = 0.00002923 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 79 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00008089, itemized = {state_0: 0.00000025, state_1: 0.00967464, state_2: 0.00002856, state_3: 0.00004651, state_MSE: 0.00243749, q_error_norm: 0.00240568, qd_error_norm: 0.00583103} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00152465, itemized = {state_0: 0.00000142, state_1: 0.01464668, state_2: 0.00042001, state_3: 0.00124281, state_MSE: 0.00407773, q_error_norm: 0.00381005, qd_error_norm: 0.01268342} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.335 sec, time(other): 0.010 sec, time(dataloader): 10.821 sec, time(compute_loss): 2.156 sec, time(backward): 3.427 sec, time(eval): 0.600 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.030884, device='cuda:0'), grad_norm_after_clip: tensor(0.030884, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.30it/s]\n",
            "100% 5/5 [00:00<00:00,  9.02it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.91it/s]\n",
            "100% 4/4 [00:00<00:00,  8.87it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00007531, Rollout MSE Error (joint_q) = 0.00000637 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 80 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00006662, itemized = {state_0: 0.00000023, state_1: 0.00921165, state_2: 0.00002027, state_3: 0.00004069, state_MSE: 0.00231821, q_error_norm: 0.00226447, qd_error_norm: 0.00545904} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00135598, itemized = {state_0: 0.00000096, state_1: 0.01541843, state_2: 0.00038973, state_3: 0.00109737, state_MSE: 0.00422662, q_error_norm: 0.00354152, qd_error_norm: 0.00984267} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.325 sec, time(other): 0.010 sec, time(dataloader): 10.779 sec, time(compute_loss): 2.159 sec, time(backward): 3.419 sec, time(eval): 0.629 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.023088, device='cuda:0'), grad_norm_after_clip: tensor(0.023088, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.31it/s]\n",
            "100% 5/5 [00:00<00:00,  9.23it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.77it/s]\n",
            "100% 4/4 [00:00<00:00,  9.35it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004479, Rollout MSE Error (joint_q) = 0.00000386 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 81 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002841, itemized = {state_0: 0.00000014, state_1: 0.00859589, state_2: 0.00000884, state_3: 0.00001478, state_MSE: 0.00215491, q_error_norm: 0.00197168, qd_error_norm: 0.00369937} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00144162, itemized = {state_0: 0.00000093, state_1: 0.01387512, state_2: 0.00042037, state_3: 0.00116817, state_MSE: 0.00386615, q_error_norm: 0.00324785, qd_error_norm: 0.00998890} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.183 sec, time(other): 0.010 sec, time(dataloader): 10.750 sec, time(compute_loss): 2.162 sec, time(backward): 3.402 sec, time(eval): 0.597 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.012745, device='cuda:0'), grad_norm_after_clip: tensor(0.012745, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.27it/s]\n",
            "100% 5/5 [00:00<00:00,  8.81it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.50it/s]\n",
            "100% 4/4 [00:00<00:00,  9.20it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00004014, Rollout MSE Error (joint_q) = 0.00000261 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 82 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003698, itemized = {state_0: 0.00000016, state_1: 0.00867273, state_2: 0.00001210, state_3: 0.00001980, state_MSE: 0.00217619, q_error_norm: 0.00203968, qd_error_norm: 0.00414608} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00140477, itemized = {state_0: 0.00000091, state_1: 0.01002021, state_2: 0.00041125, state_3: 0.00113445, state_MSE: 0.00289171, q_error_norm: 0.00261518, qd_error_norm: 0.00939840} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.352 sec, time(other): 0.010 sec, time(dataloader): 10.883 sec, time(compute_loss): 2.153 sec, time(backward): 3.425 sec, time(eval): 0.610 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.017043, device='cuda:0'), grad_norm_after_clip: tensor(0.017043, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.19it/s]\n",
            "100% 5/5 [00:00<00:00,  8.85it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.20it/s]\n",
            "100% 4/4 [00:00<00:00,  9.28it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00008716, Rollout MSE Error (joint_q) = 0.00001420 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 83 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002951, itemized = {state_0: 0.00000014, state_1: 0.00774780, state_2: 0.00000925, state_3: 0.00001483, state_MSE: 0.00194301, q_error_norm: 0.00187466, qd_error_norm: 0.00369844} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00145786, itemized = {state_0: 0.00000092, state_1: 0.00847985, state_2: 0.00042870, state_3: 0.00117040, state_MSE: 0.00251997, q_error_norm: 0.00257370, qd_error_norm: 0.00995566} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.514 sec, time(other): 0.010 sec, time(dataloader): 11.082 sec, time(compute_loss): 2.153 sec, time(backward): 3.409 sec, time(eval): 0.603 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.014787, device='cuda:0'), grad_norm_after_clip: tensor(0.014787, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.27it/s]\n",
            "100% 5/5 [00:00<00:00,  9.11it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.21it/s]\n",
            "100% 4/4 [00:00<00:00,  9.27it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00011669, Rollout MSE Error (joint_q) = 0.00001277 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 84 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00003012, itemized = {state_0: 0.00000014, state_1: 0.00867268, state_2: 0.00000899, state_3: 0.00001557, state_MSE: 0.00217434, q_error_norm: 0.00203695, qd_error_norm: 0.00379793} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00147515, itemized = {state_0: 0.00000105, state_1: 0.01464640, state_2: 0.00043685, state_3: 0.00117891, state_MSE: 0.00406580, q_error_norm: 0.00354460, qd_error_norm: 0.01031298} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.394 sec, time(other): 0.010 sec, time(dataloader): 10.823 sec, time(compute_loss): 2.161 sec, time(backward): 3.440 sec, time(eval): 0.604 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.014995, device='cuda:0'), grad_norm_after_clip: tensor(0.014995, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.20it/s]\n",
            "100% 5/5 [00:00<00:00,  9.05it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.89it/s]\n",
            "100% 4/4 [00:00<00:00,  9.23it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00006363, Rollout MSE Error (joint_q) = 0.00000693 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 85 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00004201, itemized = {state_0: 0.00000017, state_1: 0.00952061, state_2: 0.00001391, state_3: 0.00002288, state_MSE: 0.00238940, q_error_norm: 0.00220478, qd_error_norm: 0.00439075} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00128687, itemized = {state_0: 0.00000093, state_1: 0.00770848, state_2: 0.00041032, state_3: 0.00099380, state_MSE: 0.00227838, q_error_norm: 0.00236822, qd_error_norm: 0.00969720} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.502 sec, time(other): 0.010 sec, time(dataloader): 11.048 sec, time(compute_loss): 2.160 sec, time(backward): 3.412 sec, time(eval): 0.601 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.019811, device='cuda:0'), grad_norm_after_clip: tensor(0.019811, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.12it/s]\n",
            "100% 5/5 [00:00<00:00,  9.00it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.28it/s]\n",
            "100% 4/4 [00:00<00:00,  9.09it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00073817, Rollout MSE Error (joint_q) = 0.00000760 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 86 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00007393, itemized = {state_0: 0.00000023, state_1: 0.00913501, state_2: 0.00002624, state_3: 0.00004363, state_MSE: 0.00230128, q_error_norm: 0.00222874, qd_error_norm: 0.00561146} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00149145, itemized = {state_0: 0.00000109, state_1: 0.01156143, state_2: 0.00043981, state_3: 0.00119774, state_MSE: 0.00330002, q_error_norm: 0.00301551, qd_error_norm: 0.01372873} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.761 sec, time(other): 0.010 sec, time(dataloader): 11.250 sec, time(compute_loss): 2.160 sec, time(backward): 3.417 sec, time(eval): 0.612 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.028088, device='cuda:0'), grad_norm_after_clip: tensor(0.028088, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.25it/s]\n",
            "100% 5/5 [00:00<00:00,  8.98it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.36it/s]\n",
            "100% 4/4 [00:00<00:00,  9.38it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00006127, Rollout MSE Error (joint_q) = 0.00000781 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 87 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00007695, itemized = {state_0: 0.00000022, state_1: 0.00936624, state_2: 0.00002698, state_3: 0.00004609, state_MSE: 0.00235988, q_error_norm: 0.00226615, qd_error_norm: 0.00555181} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00152867, itemized = {state_0: 0.00000094, state_1: 0.00616788, state_2: 0.00044708, state_3: 0.00123768, state_MSE: 0.00196339, q_error_norm: 0.00206526, qd_error_norm: 0.00987096} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.456 sec, time(other): 0.010 sec, time(dataloader): 10.883 sec, time(compute_loss): 2.172 sec, time(backward): 3.438 sec, time(eval): 0.598 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.024372, device='cuda:0'), grad_norm_after_clip: tensor(0.024372, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.17it/s]\n",
            "100% 5/5 [00:00<00:00,  9.02it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.26it/s]\n",
            "100% 4/4 [00:00<00:00,  9.22it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002624, Rollout MSE Error (joint_q) = 0.00000168 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 88 with MSE error 2.624467379064299e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 88 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00002060, itemized = {state_0: 0.00000011, state_1: 0.00666864, state_2: 0.00000607, state_3: 0.00001047, state_MSE: 0.00167132, q_error_norm: 0.00159646, qd_error_norm: 0.00317747} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00142841, itemized = {state_0: 0.00000087, state_1: 0.01156247, state_2: 0.00041307, state_3: 0.00116126, state_MSE: 0.00328442, q_error_norm: 0.00280308, qd_error_norm: 0.00918202} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.611 sec, time(other): 0.010 sec, time(dataloader): 11.123 sec, time(compute_loss): 2.165 sec, time(backward): 3.405 sec, time(eval): 0.633 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.008094, device='cuda:0'), grad_norm_after_clip: tensor(0.008094, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.25it/s]\n",
            "100% 5/5 [00:00<00:00,  9.07it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.64it/s]\n",
            "100% 4/4 [00:00<00:00,  9.32it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002170, Rollout MSE Error (joint_q) = 0.00000162 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 89 with MSE error 2.1696172552765347e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 89 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001567, itemized = {state_0: 0.00000010, state_1: 0.00728549, state_2: 0.00000462, state_3: 0.00000728, state_MSE: 0.00182437, q_error_norm: 0.00164832, qd_error_norm: 0.00280039} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00139687, itemized = {state_0: 0.00000088, state_1: 0.00924956, state_2: 0.00040085, state_3: 0.00113808, state_MSE: 0.00269734, q_error_norm: 0.00243725, qd_error_norm: 0.00902098} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.393 sec, time(other): 0.010 sec, time(dataloader): 10.928 sec, time(compute_loss): 2.153 sec, time(backward): 3.410 sec, time(eval): 0.625 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.004408, device='cuda:0'), grad_norm_after_clip: tensor(0.004408, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.29it/s]\n",
            "100% 5/5 [00:00<00:00,  8.59it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.97it/s]\n",
            "100% 4/4 [00:00<00:00,  9.34it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002473, Rollout MSE Error (joint_q) = 0.00000221 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 90 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001750, itemized = {state_0: 0.00000010, state_1: 0.00736261, state_2: 0.00000547, state_3: 0.00000831, state_MSE: 0.00184412, q_error_norm: 0.00167089, qd_error_norm: 0.00295235} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00145182, itemized = {state_0: 0.00000088, state_1: 0.00925004, state_2: 0.00043986, state_3: 0.00115879, state_MSE: 0.00271239, q_error_norm: 0.00242581, qd_error_norm: 0.00915619} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.354 sec, time(other): 0.010 sec, time(dataloader): 10.844 sec, time(compute_loss): 2.148 sec, time(backward): 3.419 sec, time(eval): 0.596 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.007416, device='cuda:0'), grad_norm_after_clip: tensor(0.007416, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.16it/s]\n",
            "100% 5/5 [00:00<00:00,  9.00it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.67it/s]\n",
            "100% 4/4 [00:00<00:00,  9.18it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002873, Rollout MSE Error (joint_q) = 0.00000153 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 91 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001624, itemized = {state_0: 0.00000009, state_1: 0.00709278, state_2: 0.00000484, state_3: 0.00000775, state_MSE: 0.00177637, q_error_norm: 0.00161805, qd_error_norm: 0.00285488} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00144136, itemized = {state_0: 0.00000088, state_1: 0.00693799, state_2: 0.00043939, state_3: 0.00114843, state_MSE: 0.00213167, q_error_norm: 0.00205337, qd_error_norm: 0.00920642} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.603 sec, time(other): 0.010 sec, time(dataloader): 11.153 sec, time(compute_loss): 2.153 sec, time(backward): 3.411 sec, time(eval): 0.610 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.005739, device='cuda:0'), grad_norm_after_clip: tensor(0.005739, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.38it/s]\n",
            "100% 5/5 [00:00<00:00,  9.08it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.55it/s]\n",
            "100% 4/4 [00:00<00:00,  9.18it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002392, Rollout MSE Error (joint_q) = 0.00000180 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 92 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001602, itemized = {state_0: 0.00000009, state_1: 0.00728557, state_2: 0.00000499, state_3: 0.00000754, state_MSE: 0.00182455, q_error_norm: 0.00163883, qd_error_norm: 0.00283886} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00107726, itemized = {state_0: 0.00000078, state_1: 0.01002034, state_2: 0.00033973, state_3: 0.00083745, state_MSE: 0.00279957, q_error_norm: 0.00255107, qd_error_norm: 0.00874865} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.124 sec, time(other): 0.010 sec, time(dataloader): 10.552 sec, time(compute_loss): 2.162 sec, time(backward): 3.445 sec, time(eval): 0.606 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.005978, device='cuda:0'), grad_norm_after_clip: tensor(0.005978, device='cuda:0')} \u001b[0m\n",
            "\u001b[92m Save Best Valid exp_trajectory Model at Epoch 92 with loss 0.00107726. \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.20it/s]\n",
            "100% 5/5 [00:00<00:00,  8.57it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.55it/s]\n",
            "100% 4/4 [00:00<00:00,  9.23it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002817, Rollout MSE Error (joint_q) = 0.00000113 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 93 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001613, itemized = {state_0: 0.00000009, state_1: 0.00701573, state_2: 0.00000475, state_3: 0.00000792, state_MSE: 0.00175712, q_error_norm: 0.00159752, qd_error_norm: 0.00286573} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00128778, itemized = {state_0: 0.00000083, state_1: 0.00847890, state_2: 0.00037321, state_3: 0.00104307, state_MSE: 0.00247400, q_error_norm: 0.00228421, qd_error_norm: 0.00887595} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.521 sec, time(other): 0.010 sec, time(dataloader): 11.053 sec, time(compute_loss): 2.155 sec, time(backward): 3.440 sec, time(eval): 0.610 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.006583, device='cuda:0'), grad_norm_after_clip: tensor(0.006583, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.14it/s]\n",
            "100% 5/5 [00:00<00:00,  9.04it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.69it/s]\n",
            "100% 4/4 [00:00<00:00,  9.38it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00001989, Rollout MSE Error (joint_q) = 0.00000108 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 94 with MSE error 1.9891866031684913e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 94 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001487, itemized = {state_0: 0.00000009, state_1: 0.00720848, state_2: 0.00000435, state_3: 0.00000705, state_MSE: 0.00180499, q_error_norm: 0.00162020, qd_error_norm: 0.00273633} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00109717, itemized = {state_0: 0.00000079, state_1: 0.00924972, state_2: 0.00032050, state_3: 0.00088118, state_MSE: 0.00261305, q_error_norm: 0.00238829, qd_error_norm: 0.00851616} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.672 sec, time(other): 0.010 sec, time(dataloader): 11.157 sec, time(compute_loss): 2.171 sec, time(backward): 3.440 sec, time(eval): 0.625 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.005058, device='cuda:0'), grad_norm_after_clip: tensor(0.005058, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.18it/s]\n",
            "100% 5/5 [00:00<00:00,  8.98it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.30it/s]\n",
            "100% 4/4 [00:00<00:00,  9.18it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00003170, Rollout MSE Error (joint_q) = 0.00000166 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 95 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001479, itemized = {state_0: 0.00000009, state_1: 0.00701576, state_2: 0.00000449, state_3: 0.00000698, state_MSE: 0.00175683, q_error_norm: 0.00158114, qd_error_norm: 0.00273436} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00139160, itemized = {state_0: 0.00000084, state_1: 0.00847934, state_2: 0.00040625, state_3: 0.00112695, state_MSE: 0.00250335, q_error_norm: 0.00227388, qd_error_norm: 0.00894413} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.652 sec, time(other): 0.010 sec, time(dataloader): 11.093 sec, time(compute_loss): 2.162 sec, time(backward): 3.421 sec, time(eval): 0.607 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.005688, device='cuda:0'), grad_norm_after_clip: tensor(0.005688, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.17it/s]\n",
            "100% 5/5 [00:00<00:00,  8.90it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.21it/s]\n",
            "100% 4/4 [00:00<00:00,  9.30it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00001909, Rollout MSE Error (joint_q) = 0.00000127 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 96 with MSE error 1.9085133317275904e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 96 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001375, itemized = {state_0: 0.00000008, state_1: 0.00713140, state_2: 0.00000405, state_3: 0.00000634, state_MSE: 0.00178547, q_error_norm: 0.00159576, qd_error_norm: 0.00262282} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00133609, itemized = {state_0: 0.00000084, state_1: 0.00847919, state_2: 0.00040738, state_3: 0.00106240, state_MSE: 0.00248745, q_error_norm: 0.00226408, qd_error_norm: 0.00880475} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.664 sec, time(other): 0.010 sec, time(dataloader): 11.133 sec, time(compute_loss): 2.154 sec, time(backward): 3.419 sec, time(eval): 0.627 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.004409, device='cuda:0'), grad_norm_after_clip: tensor(0.004409, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:15<00:00,  6.27it/s]\n",
            "100% 5/5 [00:00<00:00,  9.37it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.44it/s]\n",
            "100% 4/4 [00:00<00:00,  9.26it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00001891, Rollout MSE Error (joint_q) = 0.00000154 \u001b[0m\n",
            "\u001b[92m Save Best Eval Model at Epoch 97 with MSE error 1.891068859549705e-05. \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 97 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001311, itemized = {state_0: 0.00000008, state_1: 0.00663030, state_2: 0.00000385, state_3: 0.00000600, state_MSE: 0.00166006, q_error_norm: 0.00150630, qd_error_norm: 0.00256454} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00141253, itemized = {state_0: 0.00000084, state_1: 0.01002093, state_2: 0.00042677, state_3: 0.00112945, state_MSE: 0.00289450, q_error_norm: 0.00251022, qd_error_norm: 0.00887389} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.344 sec, time(other): 0.010 sec, time(dataloader): 10.858 sec, time(compute_loss): 2.159 sec, time(backward): 3.410 sec, time(eval): 0.628 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.003650, device='cuda:0'), grad_norm_after_clip: tensor(0.003650, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.09it/s]\n",
            "100% 5/5 [00:00<00:00,  8.91it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 24.14it/s]\n",
            "100% 4/4 [00:00<00:00,  9.28it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00002055, Rollout MSE Error (joint_q) = 0.00000188 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 98 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001321, itemized = {state_0: 0.00000008, state_1: 0.00705431, state_2: 0.00000392, state_3: 0.00000609, state_MSE: 0.00176610, q_error_norm: 0.00157193, qd_error_norm: 0.00257550} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00134371, itemized = {state_0: 0.00000084, state_1: 0.00925019, state_2: 0.00039752, state_3: 0.00108123, state_MSE: 0.00268245, q_error_norm: 0.00239217, qd_error_norm: 0.00884307} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.792 sec, time(other): 0.010 sec, time(dataloader): 11.341 sec, time(compute_loss): 2.157 sec, time(backward): 3.410 sec, time(eval): 0.610 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.004190, device='cuda:0'), grad_norm_after_clip: tensor(0.004190, device='cuda:0')} \u001b[0m\n",
            "100% 100/100 [00:16<00:00,  6.17it/s]\n",
            "100% 5/5 [00:00<00:00,  9.30it/s]\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "Evaluating\n",
            "Sampling state transitions: 100% 4/4 [00:00<00:00, 25.57it/s]\n",
            "100% 4/4 [00:00<00:00,  9.30it/s]\n",
            "\u001b[37m [Evaluate], Num Rollouts = 2048, Rollout Length = 10, Rollout MSE Error = 0.00001970, Rollout MSE Error (joint_q) = 0.00000137 \u001b[0m\n",
            "\u001b[96m ---------------------------------------------------------------------------------------------------- \u001b[0m\n",
            "\u001b[96m Epoch 99 \u001b[0m\n",
            "\u001b[96m [Train] loss = 0.00001258, itemized = {state_0: 0.00000008, state_1: 0.00686160, state_2: 0.00000370, state_3: 0.00000574, state_MSE: 0.00171778, q_error_norm: 0.00153415, qd_error_norm: 0.00251175} \u001b[0m\n",
            "\u001b[96m [Valid] dataset [exp_trajectory]: loss = 0.00122655, itemized = {state_0: 0.00000081, state_1: 0.01002034, state_2: 0.00036580, state_3: 0.00098054, state_MSE: 0.00284187, q_error_norm: 0.00249347, qd_error_norm: 0.00860800} \u001b[0m\n",
            "\u001b[96m [Time Report] time(epoch): 17.624 sec, time(other): 0.010 sec, time(dataloader): 11.148 sec, time(compute_loss): 2.150 sec, time(backward): 3.386 sec, time(eval): 0.600 sec \u001b[0m\n",
            "\u001b[96m [Grad Info] {grad_norm_before_clip: tensor(0.003063, device='cuda:0'), grad_norm_after_clip: tensor(0.003063, device='cuda:0')} \u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading output.log 132.1KB/132.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading output.log 132.1KB/132.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading output.log 132.1KB/132.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading output.log 132.1KB/132.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading output.log 132.1KB/132.1KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 5.2KB/5.2KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading output.log 132.1KB/132.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading output.log 132.1KB/132.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading output.log 132.1KB/132.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading output.log 132.1KB/132.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading output.log 132.1KB/132.1KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.4KB/2.4KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading output.log 132.1KB/132.1KB (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading output.log 132.1KB/132.1KB (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading output.log 132.1KB/132.1KB (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading output.log 132.1KB/132.1KB (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading output.log 132.1KB/132.1KB (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading history steps 99-99, summary, console lines 1318-1330 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading history steps 99-99, summary, console lines 1318-1330 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading history steps 99-99, summary, console lines 1318-1330 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch ‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñá‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch ‚ñà‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch ‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñà‚ñÖ‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval_10-steps/error(L2)/epoch 0.00711\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval_10-steps/error(MSE)/epoch 2e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval_10-steps/q_error(L2)/epoch 0.0013\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/q_error(MSE)/epoch 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_10-steps/qd_error(L2)/epoch 0.00689\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_10-steps/qd_error(MSE)/epoch 4e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_0/epoch 0.00223\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_1/epoch 0.00359\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_2/epoch 0.00481\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_details/error(L2)_step_3/epoch 0.00588\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 +76 ...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mjamba_1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/rs4avwp1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_195854-rs4avwp1/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 5. Train Jamba Model\n",
        "# We use the same config but add the --novelty jamba flag\n",
        "!python train.py --cfg colab_config.yaml --novelty jamba --logdir ../data/logs/jamba --wandb-project {wandb_project} --wandb-name jamba_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "save_models_drive",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "save_models_drive",
        "outputId": "2c9fb7ec-03bd-4bc9-ea24-2c2add1613b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Local log directory for baseline not found. Skipping save.\n",
            "Saving mamba_6 model to Google Drive...\n",
            "Saving mamba_3 model to Google Drive...\n",
            "Local log directory for unroll not found. Skipping save.\n",
            "Saving jamba model to Google Drive...\n"
          ]
        }
      ],
      "source": [
        "# 6. Save Models to Google Drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "models = ['baseline', 'mamba_6', 'mamba_3', 'unroll', 'jamba']\n",
        "drive_base_dir = '/content/drive/MyDrive/neural-robot-dynamics/data/logs'\n",
        "local_base_dir = '../data/logs'\n",
        "\n",
        "for model in models:\n",
        "    local_dir = os.path.join(local_base_dir, model)\n",
        "    drive_dir = os.path.join(drive_base_dir, model)\n",
        "\n",
        "    if os.path.exists(local_dir):\n",
        "        print(f\"Saving {model} model to Google Drive...\")\n",
        "        if os.path.exists(drive_dir):\n",
        "            shutil.rmtree(drive_dir)\n",
        "        shutil.copytree(local_dir, drive_dir)\n",
        "    else:\n",
        "        print(f\"Local log directory for {model} not found. Skipping save.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load_models_drive",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "load_models_drive",
        "outputId": "f9651742-543d-499a-b5d9-d58b260b1c0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading baseline model from Google Drive...\n",
            "Loading mamba_6 model from Google Drive...\n",
            "Loading mamba_3 model from Google Drive...\n",
            "Loading unroll model from Google Drive...\n",
            "Loading jamba model from Google Drive...\n"
          ]
        }
      ],
      "source": [
        "# 7. Load Models from Google Drive (Optional)\n",
        "# Run this cell if you want to load pre-trained models from Drive instead of training them.\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "models = ['baseline', 'mamba_6', 'mamba_3', 'unroll', 'jamba']\n",
        "drive_base_dir = '/content/drive/MyDrive/neural-robot-dynamics/data/logs'\n",
        "local_base_dir = '../data/logs'\n",
        "\n",
        "for model in models:\n",
        "    local_dir = os.path.join(local_base_dir, model)\n",
        "    drive_dir = os.path.join(drive_base_dir, model)\n",
        "\n",
        "    if os.path.exists(drive_dir):\n",
        "        print(f\"Loading {model} model from Google Drive...\")\n",
        "        if os.path.exists(local_dir):\n",
        "            shutil.rmtree(local_dir)\n",
        "        shutil.copytree(drive_dir, local_dir)\n",
        "    else:\n",
        "        print(f\"Drive log directory for {model} not found. Skipping load.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "quantitative-analysis-header",
      "metadata": {
        "id": "quantitative-analysis-header"
      },
      "source": [
        "# 7. Quantitative Analysis\n",
        "\n",
        "We now perform the quantitative analysis as described in the paper experiments.\n",
        "We evaluate:\n",
        "1. **Long-Horizon Passive Motion**: Accuracy of the trained NeRD models over 100, 500, and 1000 steps.\n",
        "2. **RL Policy Evaluation**: Performance of the pretrained RL policy using the NeRD models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "passive-motion-eval",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "passive-motion-eval",
        "outputId": "3a596708-2e2e-46fa-85d8-c7b0b04e1a6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================== Evaluating Baseline Model ====================\n",
            "\n",
            "--- Horizon: 100 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  2713668\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 306.70it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.85 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.36 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.48 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.35 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.40 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.84 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:00<00:00,  2.28it/s]\n",
            "100% 1/1 [00:02<00:00,  2.20s/it]\n",
            "=========================================\n",
            "Base position error mean       = 0.338502\n",
            "Base position error std        = 0.367016\n",
            "Joint position error mean      = 0.383423 rad (21.968496 deg)\n",
            "Joint position Error per dof   = tensor([0.383423], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhargaveekc\u001b[0m (\u001b[33mbhargaveekc-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run 3fcm25kq (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run 3fcm25kq (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_224625-3fcm25kq\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbaseline_passive_eval_100\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/3fcm25kq\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-summary.json 220B/220B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-summary.json 220B/220B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-summary.json 220B/220B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 220B/220B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 220B/220B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading history steps 0-0, summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading history steps 0-0, summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 0.3385\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 0.36702\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.38342\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mbaseline_passive_eval_100\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/3fcm25kq\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_224625-3fcm25kq/logs\u001b[0m\n",
            "\n",
            "--- Horizon: 500 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  2713668\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 303.50it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.87 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.38 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.53 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.35 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.83 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:01<00:00,  1.53s/it]\n",
            "100% 1/1 [00:09<00:00,  9.69s/it]\n",
            "=========================================\n",
            "Base position error mean       = 1.877724\n",
            "Base position error std        = 1.821935\n",
            "Joint position error mean      = 0.981049 rad (56.209947 deg)\n",
            "Joint position Error per dof   = tensor([0.981049], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhargaveekc\u001b[0m (\u001b[33mbhargaveekc-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run 89sr471w (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run 89sr471w (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_224653-89sr471w\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbaseline_passive_eval_500\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/89sr471w\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 1.87772\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 1.82193\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.98105\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mbaseline_passive_eval_500\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/89sr471w\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_224653-89sr471w/logs\u001b[0m\n",
            "\n",
            "--- Horizon: 1000 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  2713668\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 307.33it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.64 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.36 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.49 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.35 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.38 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.84 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:02<00:00,  2.98s/it]\n",
            "100% 1/1 [00:19<00:00, 19.22s/it]\n",
            "=========================================\n",
            "Base position error mean       = 2.371065\n",
            "Base position error std        = 2.002776\n",
            "Joint position error mean      = 1.134162 rad (64.982700 deg)\n",
            "Joint position Error per dof   = tensor([1.134162], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhargaveekc\u001b[0m (\u001b[33mbhargaveekc-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run l3rmr845 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run l3rmr845 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_224731-l3rmr845\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbaseline_passive_eval_1000\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/l3rmr845\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-summary.json 221B/221B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-summary.json 221B/221B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-summary.json 221B/221B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 221B/221B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 221B/221B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 2.37106\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 2.00278\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 1.13416\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mbaseline_passive_eval_1000\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/l3rmr845\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_224731-l3rmr845/logs\u001b[0m\n",
            "\n",
            "==================== Evaluating Mamba_6 Model ====================\n",
            "\n",
            "--- Horizon: 100 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  1523460\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 308.33it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.78 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.38 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.51 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.34 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.40 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.85 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:00<00:00,  2.14it/s]\n",
            "100% 1/1 [00:05<00:00,  5.03s/it]\n",
            "=========================================\n",
            "Base position error mean       = 0.017344\n",
            "Base position error std        = 0.019359\n",
            "Joint position error mean      = 0.021988 rad (1.259798 deg)\n",
            "Joint position Error per dof   = tensor([0.021988], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhargaveekc\u001b[0m (\u001b[33mbhargaveekc-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run at3gm5f3 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run at3gm5f3 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run at3gm5f3 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_224752-at3gm5f3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba_6_passive_eval_100\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/at3gm5f3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 227B/227B (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 227B/227B (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 227B/227B (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 227B/227B (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 227B/227B (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading history steps 0-0, summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading history steps 0-0, summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 0.01734\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 0.01936\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.02199\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mmamba_6_passive_eval_100\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/at3gm5f3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_224752-at3gm5f3/logs\u001b[0m\n",
            "\n",
            "--- Horizon: 500 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  1523460\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 306.74it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.63 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.36 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.51 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.35 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.38 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.83 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:01<00:00,  1.54s/it]\n",
            "100% 1/1 [00:25<00:00, 25.06s/it]\n",
            "=========================================\n",
            "Base position error mean       = 0.303613\n",
            "Base position error std        = 0.366425\n",
            "Joint position error mean      = 0.251422 rad (14.405444 deg)\n",
            "Joint position Error per dof   = tensor([0.251422], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhargaveekc\u001b[0m (\u001b[33mbhargaveekc-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run ferab4ni (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run ferab4ni (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run ferab4ni (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_224835-ferab4ni\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba_6_passive_eval_500\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/ferab4ni\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 223B/223B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 223B/223B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 223B/223B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 223B/223B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 223B/223B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 0.30361\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 0.36643\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.25142\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mmamba_6_passive_eval_500\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/ferab4ni\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_224835-ferab4ni/logs\u001b[0m\n",
            "\n",
            "--- Horizon: 1000 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  1523460\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 304.92it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 3.29 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.38 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.51 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.35 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.84 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:02<00:00,  2.96s/it]\n",
            "100% 1/1 [00:50<00:00, 50.11s/it]\n",
            "=========================================\n",
            "Base position error mean       = 0.903255\n",
            "Base position error std        = 1.106416\n",
            "Joint position error mean      = 0.544751 rad (31.211950 deg)\n",
            "Joint position Error per dof   = tensor([0.544751], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhargaveekc\u001b[0m (\u001b[33mbhargaveekc-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run dzp2ngpf (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run dzp2ngpf (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_224944-dzp2ngpf\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba_6_passive_eval_1000\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/dzp2ngpf\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 0.90325\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 1.10642\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.54475\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mmamba_6_passive_eval_1000\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/dzp2ngpf\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_224944-dzp2ngpf/logs\u001b[0m\n",
            "\n",
            "==================== Evaluating Mamba_3 Model ====================\n",
            "\n",
            "--- Horizon: 100 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  768900\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 302.33it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.67 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.35 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.49 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.33 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.38 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.40 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.82 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:00<00:00,  2.24it/s]\n",
            "100% 1/1 [00:02<00:00,  2.82s/it]\n",
            "=========================================\n",
            "Base position error mean       = 0.023027\n",
            "Base position error std        = 0.026064\n",
            "Joint position error mean      = 0.024246 rad (1.389186 deg)\n",
            "Joint position Error per dof   = tensor([0.024246], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhargaveekc\u001b[0m (\u001b[33mbhargaveekc-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run ypg62vcp (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run ypg62vcp (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run ypg62vcp (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m setting up run ypg62vcp (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_225003-ypg62vcp\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba_3_passive_eval_100\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/ypg62vcp\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 226B/226B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 226B/226B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 226B/226B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 226B/226B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 226B/226B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 0.02303\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 0.02606\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.02425\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mmamba_3_passive_eval_100\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/ypg62vcp\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_225003-ypg62vcp/logs\u001b[0m\n",
            "\n",
            "--- Horizon: 500 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  768900\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 304.19it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.79 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.51 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.34 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.85 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:01<00:00,  1.56s/it]\n",
            "100% 1/1 [00:13<00:00, 13.78s/it]\n",
            "=========================================\n",
            "Base position error mean       = 0.397195\n",
            "Base position error std        = 0.511345\n",
            "Joint position error mean      = 0.275421 rad (15.780486 deg)\n",
            "Joint position Error per dof   = tensor([0.275421], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhargaveekc\u001b[0m (\u001b[33mbhargaveekc-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run u2ukmbk8 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run u2ukmbk8 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_225034-u2ukmbk8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba_3_passive_eval_500\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/u2ukmbk8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-summary.json 221B/221B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-summary.json 221B/221B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-summary.json 221B/221B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 221B/221B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 221B/221B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 0.39719\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 0.51135\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.27542\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mmamba_3_passive_eval_500\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/u2ukmbk8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_225034-u2ukmbk8/logs\u001b[0m\n",
            "\n",
            "--- Horizon: 1000 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  768900\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 308.96it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.81 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.36 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.48 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.33 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.38 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.40 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.82 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:02<00:00,  2.95s/it]\n",
            "100% 1/1 [00:27<00:00, 27.24s/it]\n",
            "=========================================\n",
            "Base position error mean       = 1.105503\n",
            "Base position error std        = 1.330542\n",
            "Joint position error mean      = 0.585476 rad (33.545313 deg)\n",
            "Joint position Error per dof   = tensor([0.585476], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhargaveekc\u001b[0m (\u001b[33mbhargaveekc-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run 0rfj2kob (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run 0rfj2kob (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_225120-0rfj2kob\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba_3_passive_eval_1000\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/0rfj2kob\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading history steps 0-0, summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading history steps 0-0, summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 1.1055\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 1.33054\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.58548\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mmamba_3_passive_eval_1000\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/0rfj2kob\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_225120-0rfj2kob/logs\u001b[0m\n",
            "\n",
            "==================== Evaluating Unroll Model ====================\n",
            "\n",
            "--- Horizon: 100 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  2713668\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 306.42it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.66 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.35 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.48 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.37 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.38 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.86 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:00<00:00,  2.45it/s]\n",
            "100% 1/1 [00:02<00:00,  2.08s/it]\n",
            "=========================================\n",
            "Base position error mean       = 0.490143\n",
            "Base position error std        = 0.486737\n",
            "Joint position error mean      = 1.223201 rad (70.084271 deg)\n",
            "Joint position Error per dof   = tensor([1.223201], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhargaveekc\u001b[0m (\u001b[33mbhargaveekc-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run 95hpdu8a (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run 95hpdu8a (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run 95hpdu8a (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_225139-95hpdu8a\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33munroll_passive_eval_100\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/95hpdu8a\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 0.49014\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 0.48674\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 1.2232\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33munroll_passive_eval_100\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/95hpdu8a\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_225139-95hpdu8a/logs\u001b[0m\n",
            "\n",
            "--- Horizon: 500 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  2713668\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 300.54it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.95 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.54 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.36 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.84 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:01<00:00,  1.52s/it]\n",
            "100% 1/1 [00:09<00:00,  9.70s/it]\n",
            "=========================================\n",
            "Base position error mean       = 1.981910\n",
            "Base position error std        = 1.806999\n",
            "Joint position error mean      = 1.504634 rad (86.209193 deg)\n",
            "Joint position Error per dof   = tensor([1.504634], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhargaveekc\u001b[0m (\u001b[33mbhargaveekc-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run 6npdq7v2 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run 6npdq7v2 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run 6npdq7v2 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_225205-6npdq7v2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33munroll_passive_eval_500\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/6npdq7v2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-summary.json 220B/220B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-summary.json 220B/220B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-summary.json 220B/220B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 220B/220B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 220B/220B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 1.98191\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 1.807\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 1.50463\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33munroll_passive_eval_500\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/6npdq7v2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_225205-6npdq7v2/logs\u001b[0m\n",
            "\n",
            "--- Horizon: 1000 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  2713668\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 305.03it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.76 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.51 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.34 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.40 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.88 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:02<00:00,  2.91s/it]\n",
            "100% 1/1 [00:19<00:00, 19.20s/it]\n",
            "=========================================\n",
            "Base position error mean       = 3.100191\n",
            "Base position error std        = 2.439102\n",
            "Joint position error mean      = 1.556290 rad (89.168857 deg)\n",
            "Joint position Error per dof   = tensor([1.556290], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhargaveekc\u001b[0m (\u001b[33mbhargaveekc-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run g7hhx0y1 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run g7hhx0y1 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run g7hhx0y1 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_225244-g7hhx0y1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33munroll_passive_eval_1000\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/g7hhx0y1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.8s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 220B/220B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading history steps 0-0, summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading history steps 0-0, summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 3.10019\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 2.4391\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 1.55629\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33munroll_passive_eval_1000\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/g7hhx0y1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_225244-g7hhx0y1/logs\u001b[0m\n",
            "\n",
            "==================== Evaluating Jamba Model ====================\n",
            "\n",
            "--- Horizon: 100 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  1905732\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 304.69it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.78 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.38 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.52 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.39 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.39 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.82 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:00<00:00,  2.47it/s]\n",
            "100% 1/1 [00:04<00:00,  4.03s/it]\n",
            "=========================================\n",
            "Base position error mean       = 0.012612\n",
            "Base position error std        = 0.013644\n",
            "Joint position error mean      = 0.017927 rad (1.027159 deg)\n",
            "Joint position Error per dof   = tensor([0.017927], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhargaveekc\u001b[0m (\u001b[33mbhargaveekc-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run 8t20a4fs (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run 8t20a4fs (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_225304-8t20a4fs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mjamba_passive_eval_100\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/8t20a4fs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 224B/224B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 224B/224B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 224B/224B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 224B/224B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 224B/224B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 0.01261\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 0.01364\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.01793\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mjamba_passive_eval_100\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/8t20a4fs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_225304-8t20a4fs/logs\u001b[0m\n",
            "\n",
            "--- Horizon: 500 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  1905732\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 304.35it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.77 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.49 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.36 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.38 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.38 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.85 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:01<00:00,  1.51s/it]\n",
            "100% 1/1 [00:19<00:00, 19.96s/it]\n",
            "=========================================\n",
            "Base position error mean       = 0.196200\n",
            "Base position error std        = 0.277604\n",
            "Joint position error mean      = 0.373889 rad (21.422262 deg)\n",
            "Joint position Error per dof   = tensor([0.373889], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhargaveekc\u001b[0m (\u001b[33mbhargaveekc-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run b86tq81g (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run b86tq81g (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run b86tq81g (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_225341-b86tq81g\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mjamba_passive_eval_500\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/b86tq81g\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 222B/222B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 222B/222B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 222B/222B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 222B/222B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 222B/222B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading history steps 0-0, summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading history steps 0-0, summary (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 0.1962\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 0.2776\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.37389\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mjamba_passive_eval_500\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/b86tq81g\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_225341-b86tq81g/logs\u001b[0m\n",
            "\n",
            "--- Horizon: 1000 ---\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"NVIDIA A100-SXM4-80GB\" (79 GiB, sm_80, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "Number of Model Parameters:  1905732\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Creating 2048 environments: 100% 2048/2048 [00:06<00:00, 301.26it/s]\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 2.72 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.50 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Sampling state transitions:   0% 0/1 [00:00<?, ?it/s]Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.33 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.42 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.81 ms  (cached)\n",
            "Sampling state transitions: 100% 1/1 [00:02<00:00,  2.93s/it]\n",
            "100% 1/1 [00:39<00:00, 39.88s/it]\n",
            "=========================================\n",
            "Base position error mean       = 0.724576\n",
            "Base position error std        = 0.963506\n",
            "Joint position error mean      = 0.708314 rad (40.583430 deg)\n",
            "Joint position Error per dof   = tensor([0.708314], device='cuda:0')\n",
            "=========================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhargaveekc\u001b[0m (\u001b[33mbhargaveekc-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run bpwlthnw (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run bpwlthnw (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run bpwlthnw (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/neural-robot-dynamics/train/wandb/run-20251208_225440-bpwlthnw\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mjamba_passive_eval_1000\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/bpwlthnw\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-metadata.json 1.5KB/1.5KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading summary (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 221B/221B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading requirements.txt 13.8KB/13.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 2.9KB/2.9KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading history steps 0-0, summary (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  base_position_error_mean 0.72458\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   base_position_error_std 0.96351\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: joint_position_error_mean 0.70831\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mjamba_passive_eval_1000\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big/runs/bpwlthnw\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/bhargaveekc-carnegie-mellon-university/neural-robot-dynamics-big\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251208_225440-bpwlthnw/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 7.1 Long-Horizon Passive Motion Evaluation\n",
        "# We evaluate the Baseline, Mamba, and Unroll models on Cartpole for 100, 500, and 1000 steps.\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def find_latest_model(model_type):\n",
        "    base_log_dir = f'../data/logs/{model_type}'\n",
        "    if not os.path.exists(base_log_dir):\n",
        "        return None\n",
        "    dirs = [d for d in glob.glob(os.path.join(base_log_dir, '*')) if os.path.isdir(d)]\n",
        "    if not dirs:\n",
        "        return None\n",
        "    latest_dir = sorted(dirs)[-1]\n",
        "    model_path = os.path.join(latest_dir, 'nn', 'best_eval_model.pt')\n",
        "    if not os.path.exists(model_path):\n",
        "        return None\n",
        "    return model_path\n",
        "\n",
        "models = ['baseline', 'mamba_6', 'mamba_3', 'unroll', 'jamba']\n",
        "horizons = [100, 500, 1000]\n",
        "\n",
        "for model_name in models:\n",
        "    model_path = find_latest_model(model_name)\n",
        "    if not model_path:\n",
        "        print(f\"Skipping {model_name} (model not found)\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n{'='*20} Evaluating {model_name.capitalize()} Model {'='*20}\")\n",
        "    for horizon in horizons:\n",
        "        print(f\"\\n--- Horizon: {horizon} ---\")\n",
        "        # We use !python to ensure output is printed to the cell\n",
        "        !python ../eval/eval_passive/eval_passive_motion.py \\\n",
        "            --env-name Cartpole \\\n",
        "            --model-path {model_path} \\\n",
        "            --env-mode neural \\\n",
        "            --num-envs 2048 \\\n",
        "            --num-rollouts 2048 \\\n",
        "            --rollout-horizon {horizon} \\\n",
        "            --seed 500 \\\n",
        "            --wandb-project {wandb_project} \\\n",
        "            --wandb-name {model_name}_passive_eval_{horizon}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rl-policy-eval-quant",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rl-policy-eval-quant",
        "outputId": "3e9adf0c-1f47-4fba-9337-f7d23b90f8fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================== RL Evaluation: Ground Truth ====================\n",
            "teps: 56.0\n",
            "reward: 98.16730499267578 steps: 61.0\n",
            "reward: 57.46388244628906 steps: 62.0\n",
            "reward: -94.28440856933594 steps: 94.0\n",
            "reward: -85.1441421508789 steps: 100.0\n",
            "reward: 1225.2821979114867 steps: 300.0\n",
            "2461286.3829221725\n",
            "av reward: 1201.799991661217 av steps: 295.4072265625\n",
            "visited states range:\n",
            "State 0: [-4.084733486175537, 4.017707347869873]\n",
            "State 1: [-3.1415224075317383, 3.1415481567382812]\n",
            "State 2: [-10.378302574157715, 8.506925582885742]\n",
            "State 3: [-10.652484893798828, 9.791386604309082]\n",
            "\n",
            "\n",
            "==================== RL Evaluation: Baseline ====================\n",
            "steps: 53.0\n",
            "reward: -75.79667663574219 steps: 54.0\n",
            "reward: 33.006324768066406 steps: 56.0\n",
            "reward: 38.0755500793457 steps: 58.0\n",
            "reward: 25.99689483642578 steps: 62.0\n",
            "reward: 1184.9815136476427 steps: 300.0\n",
            "2387004.834780693\n",
            "av reward: 1165.5297044827603 av steps: 295.96240234375\n",
            "visited states range:\n",
            "State 0: [-4.060269832611084, 4.058303356170654]\n",
            "State 1: [-3.141566514968872, 3.1414971351623535]\n",
            "State 2: [-9.040142059326172, 9.202550888061523]\n",
            "State 3: [-10.964652061462402, 10.010231971740723]\n",
            "\n",
            "\n",
            "==================== RL Evaluation: Mamba_6 ====================\n",
            "s: 68.0\n",
            "reward: 10.448670387268066 steps: 70.0\n",
            "reward: 74.48284403483073 steps: 71.0\n",
            "reward: -166.72515869140625 steps: 75.0\n",
            "reward: -26.84813690185547 steps: 95.0\n",
            "reward: 1204.126610505451 steps: 300.0\n",
            "2427568.8943252563\n",
            "av reward: 1185.336374182254 av steps: 296.31591796875\n",
            "visited states range:\n",
            "State 0: [-4.087972164154053, 4.0153937339782715]\n",
            "State 1: [-3.1414973735809326, 3.141467571258545]\n",
            "State 2: [-10.345799446105957, 8.560831069946289]\n",
            "State 3: [-10.640399932861328, 10.220194816589355]\n",
            "\n",
            "\n",
            "==================== RL Evaluation: Mamba_3 ====================\n",
            "ard: 1222.245361328125 steps: 296.0\n",
            "reward: 1063.44091796875 steps: 257.2\n",
            "reward: 747.1614990234375 steps: 187.0\n",
            "reward: 1238.276123046875 steps: 299.0\n",
            "reward: 1044.1592019543973 steps: 299.6978827361564\n",
            "1744732.41162014\n",
            "av reward: 799.6023884601925 av steps: 235.84463794683776\n",
            "visited states range:\n",
            "State 0: [-4.0876078605651855, 4.044830322265625]\n",
            "State 1: [-3.141587972640991, 3.141528367996216]\n",
            "State 2: [-10.358580589294434, 8.569950103759766]\n",
            "State 3: [-10.875702857971191, 9.138437271118164]\n",
            "\n",
            "\n",
            "==================== RL Evaluation: Jamba ====================\n",
            "s: 61.0\n",
            "reward: 92.37872314453125 steps: 64.0\n",
            "reward: 24.388330459594727 steps: 71.0\n",
            "reward: -124.47351837158203 steps: 91.0\n",
            "reward: -68.35792541503906 steps: 93.0\n",
            "reward: 1196.699203187251 steps: 300.0\n",
            "2401140.4646320343\n",
            "av reward: 1172.4318674961105 av steps: 295.07568359375\n",
            "visited states range:\n",
            "State 0: [-4.076175212860107, 4.0189104080200195]\n",
            "State 1: [-3.1414735317230225, 3.1415600776672363]\n",
            "State 2: [-10.31357479095459, 8.380670547485352]\n",
            "State 3: [-10.697846412658691, 9.356134414672852]\n",
            "\n",
            "\n",
            "Final Evaluation Comparison:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Baseline\",\n          \"Jamba\",\n          \"Mamba_6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Reward\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 171.24744994780062,\n        \"min\": 799.6023884601925,\n        \"max\": 1201.799991661217,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1165.5297044827603,\n          1172.4318674961105,\n          1185.336374182254\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Error (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.249247057415078,\n        \"min\": -33.46626776432884,\n        \"max\": 0.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -3.017996957074472,\n          -2.4436781801364273,\n          -1.3699132628721153\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9dcdcf71-4a01-4646-b7bd-12030df2d893\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Reward</th>\n",
              "      <th>Error (%)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ground Truth</td>\n",
              "      <td>1201.799992</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Baseline</td>\n",
              "      <td>1165.529704</td>\n",
              "      <td>-3.017997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mamba_6</td>\n",
              "      <td>1185.336374</td>\n",
              "      <td>-1.369913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mamba_3</td>\n",
              "      <td>799.602388</td>\n",
              "      <td>-33.466268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jamba</td>\n",
              "      <td>1172.431867</td>\n",
              "      <td>-2.443678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9dcdcf71-4a01-4646-b7bd-12030df2d893')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9dcdcf71-4a01-4646-b7bd-12030df2d893 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9dcdcf71-4a01-4646-b7bd-12030df2d893');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-91cc9bc1-1c2e-48c1-a31e-6249511ab782\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-91cc9bc1-1c2e-48c1-a31e-6249511ab782')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-91cc9bc1-1c2e-48c1-a31e-6249511ab782 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_9d780088-ff7a-43b6-be6f-66071c8eb579\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9d780088-ff7a-43b6-be6f-66071c8eb579 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          Model       Reward  Error (%)\n",
              "0  Ground Truth  1201.799992   0.000000\n",
              "1      Baseline  1165.529704  -3.017997\n",
              "2       Mamba_6  1185.336374  -1.369913\n",
              "3       Mamba_3   799.602388 -33.466268\n",
              "4         Jamba  1172.431867  -2.443678"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 7.2 RL Policy Evaluation (Quantitative)\n",
        "# We evaluate the policy using the trained NeRD models and compare with Ground Truth.\n",
        "# We run for more games (2048) to get a statistically significant result as in the paper.\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "def run_eval(model_path=None, env_mode='neural', label='Model'):\n",
        "    print(f\"\\n{'='*20} RL Evaluation: {label} {'='*20}\")\n",
        "\n",
        "    # Use absolute paths\n",
        "    abs_playback_path = os.path.abspath('../pretrained_models/RL_policies/Cartpole/0/nn/CartpolePPO.pth')\n",
        "    abs_rl_cfg_path = os.path.abspath('../eval/eval_rl/cfg/Cartpole/cartpole.yaml')\n",
        "\n",
        "    cmd = [\n",
        "        'python', 'run_rl.py',\n",
        "        '--rl-cfg', abs_rl_cfg_path,\n",
        "        '--playback', abs_playback_path,\n",
        "        '--num-envs', '2048',\n",
        "        '--num-games', '2048',\n",
        "        '--env-mode', env_mode,\n",
        "        '--wandb-project', wandb_project,\n",
        "        '--wandb-name', f'{model_name}_rl_eval'\n",
        "    ]\n",
        "\n",
        "    if model_path:\n",
        "        abs_model_path = os.path.abspath(model_path)\n",
        "        cmd.extend([\n",
        "            '--nerd-model-path', abs_model_path\n",
        "        ])\n",
        "\n",
        "    try:\n",
        "        result = subprocess.run(cmd, cwd='../eval/eval_rl', check=True, capture_output=True, text=True)\n",
        "        output = result.stdout\n",
        "        print(output[-500:]) # Print last 500 chars to see result\n",
        "\n",
        "        # Parse reward\n",
        "        # Look for 'av reward: <value> av steps: <value>'\n",
        "        match = re.search(r'av reward:\\s*([-\\d\\.]+)', output)\n",
        "        if match:\n",
        "            reward = float(match.group(1))\n",
        "            return reward\n",
        "        else:\n",
        "            print(\"Could not parse reward from output.\")\n",
        "            return None\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f'Error running RL evaluation for {label}:')\n",
        "        print('STDOUT:', e.stdout)\n",
        "        print('STDERR:', e.stderr)\n",
        "        return None\n",
        "\n",
        "results = []\n",
        "\n",
        "# 1. Evaluate Ground Truth\n",
        "gt_reward = run_eval(env_mode='ground-truth', label='Ground Truth')\n",
        "if gt_reward is not None:\n",
        "    results.append({'Model': 'Ground Truth', 'Reward': gt_reward, 'Error (%)': 0.0})\n",
        "\n",
        "# 2. Evaluate NeRD Models\n",
        "for model_name in models:\n",
        "    model_path = find_latest_model(model_name)\n",
        "    if not model_path:\n",
        "        continue\n",
        "\n",
        "    reward = run_eval(model_path=model_path, env_mode='neural', label=model_name.capitalize())\n",
        "\n",
        "    if reward is not None and gt_reward is not None:\n",
        "        error = (reward - gt_reward) / gt_reward * 100\n",
        "        results.append({'Model': model_name.capitalize(), 'Reward': reward, 'Error (%)': error})\n",
        "    elif reward is not None:\n",
        "        results.append({'Model': model_name.capitalize(), 'Reward': reward, 'Error (%)': float('nan')})\n",
        "\n",
        "# 3. Create Table\n",
        "df = pd.DataFrame(results)\n",
        "print(\"\\nFinal Evaluation Comparison:\")\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fps-eval-header",
      "metadata": {
        "id": "fps-eval-header"
      },
      "source": [
        "# 7.3 Inference Throughput (FPS) Evaluation\n",
        "\n",
        "We measure the inference throughput (FPS) of the different models. This metric measures the raw speed of the simulation, expressed in Frames Per Second (FPS).\n",
        "We measure the wall-clock time required to roll out a large batch of parallel environments (2048 robots) for a fixed number of steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fps-eval-code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fps-eval-code",
        "outputId": "4276f365-7fdb-4af2-e5c3-43c425c424e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================== FPS Evaluation: Analytical (Warp) ====================\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 4.80 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.55 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.68 ms  (cached)\n",
            "\u001b[91m [NeuralEnvironment] Created a DUMMY Neural Integrator. \u001b[0m\n",
            "Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.71 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.48 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.48 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 1.01 ms  (cached)\n",
            "time(collision_detection): 0.000 sec, time(dynamics): 0.173 sec\n",
            "FPS: 806172.247379451\n",
            "\n",
            "\n",
            "==================== FPS Evaluation: Baseline ====================\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 5.33 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.48 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.62 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.67 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.44 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 1.01 ms  (cached)\n",
            "time(collision_detection): 0.000 sec, time(dynamics): 6.763 sec\n",
            "FPS: 29821.089086269665\n",
            "\n",
            "\n",
            "==================== FPS Evaluation: Mamba_6 ====================\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 4.29 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.44 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.48 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.33 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.37 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.36 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.79 ms  (cached)\n",
            "time(collision_detection): 0.000 sec, time(dynamics): 25.459 sec\n",
            "FPS: 8008.946249417342\n",
            "\n",
            "\n",
            "==================== FPS Evaluation: Mamba_3 ====================\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 3.59 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.36 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.46 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.28 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.33 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.34 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 0.79 ms  (cached)\n",
            "time(collision_detection): 0.000 sec, time(dynamics): 12.771 sec\n",
            "FPS: 15909.713691316718\n",
            "\n",
            "\n",
            "==================== FPS Evaluation: Jamba ====================\n",
            "Warp DeprecationWarning: The `warp.sim` module is deprecated and will be removed in v1.10. Please transition to using the forthcoming Newton library instead.\n",
            "Warp 1.8.0 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.8.0\n",
            "\u001b[96m [NeuralEnvironment] Creating abstract contact environment: Cartpole. \u001b[0m\n",
            "Module warp.sim.integrator_featherstone 18b3327 load on device 'cuda:0' took 4.75 ms  (cached)\n",
            "Module envs.abstract_contact_environment 8e8d790 load on device 'cuda:0' took 0.50 ms  (cached)\n",
            "Module integrators.integrator_neural ee402cd load on device 'cuda:0' took 0.64 ms  (cached)\n",
            "\u001b[96m [NeuralEnvironment] Created a Neural Integrator. \u001b[0m\n",
            "Module warp.sim.articulation 770a52a load on device 'cuda:0' took 1.76 ms  (cached)\n",
            "Module envs.warp_sim_envs.env_cartpole 01fd57b load on device 'cuda:0' took 0.50 ms  (cached)\n",
            "Module utils.warp_utils 294c46a load on device 'cuda:0' took 0.45 ms  (cached)\n",
            "Module envs.warp_sim_envs.utils d93eb17 load on device 'cuda:0' took 1.04 ms  (cached)\n",
            "time(collision_detection): 0.001 sec, time(dynamics): 19.708 sec\n",
            "FPS: 10329.628894974665\n",
            "\n",
            "\n",
            "Inference Throughput Comparison:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_fps\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Baseline\",\n          \"Jamba\",\n          \"Mamba_6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FPS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 353469.5375702639,\n        \"min\": 8008.946249417342,\n        \"max\": 806172.247379451,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          29821.089086269665,\n          10329.628894974665,\n          8008.946249417342\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_fps"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ea59216f-6a5a-42f2-bc66-0340bf7173d3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>FPS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Analytical (Warp)</td>\n",
              "      <td>806172.247379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Baseline</td>\n",
              "      <td>29821.089086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mamba_6</td>\n",
              "      <td>8008.946249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mamba_3</td>\n",
              "      <td>15909.713691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jamba</td>\n",
              "      <td>10329.628895</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea59216f-6a5a-42f2-bc66-0340bf7173d3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ea59216f-6a5a-42f2-bc66-0340bf7173d3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ea59216f-6a5a-42f2-bc66-0340bf7173d3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b5fb2521-4928-4ae4-ad13-a8a21aa27376\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b5fb2521-4928-4ae4-ad13-a8a21aa27376')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b5fb2521-4928-4ae4-ad13-a8a21aa27376 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_1d28d8ea-0276-46db-80e6-b86f7b916ce1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_fps')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1d28d8ea-0276-46db-80e6-b86f7b916ce1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_fps');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "               Model            FPS\n",
              "0  Analytical (Warp)  806172.247379\n",
              "1           Baseline   29821.089086\n",
              "2            Mamba_6    8008.946249\n",
              "3            Mamba_3   15909.713691\n",
              "4              Jamba   10329.628895"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "def run_fps_eval(model_path=None, env_mode='neural', label='Model'):\n",
        "    print(f\"\\n{'='*20} FPS Evaluation: {label} {'='*20}\")\n",
        "\n",
        "    cmd = [\n",
        "        'python', 'eval_fps.py',\n",
        "        '--env-name', 'Cartpole',\n",
        "        '--num-envs', '2048',\n",
        "        '--rollout-horizon', '100',\n",
        "        '--env-mode', env_mode\n",
        "    ]\n",
        "\n",
        "    if model_path:\n",
        "        abs_model_path = os.path.abspath(model_path)\n",
        "        cmd.extend(['--model-path', abs_model_path])\n",
        "\n",
        "    try:\n",
        "        result = subprocess.run(cmd, cwd='../eval/eval_fps', check=True, capture_output=True, text=True)\n",
        "        output = result.stdout\n",
        "        print(output)\n",
        "\n",
        "        # Parse FPS\n",
        "        match = re.search(r'FPS:\\s*([-\\d\\.]+)', output)\n",
        "        if match:\n",
        "            fps = float(match.group(1))\n",
        "            return fps\n",
        "        else:\n",
        "            print(\"Could not parse FPS from output.\")\n",
        "            return None\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f'Error running FPS evaluation for {label}:')\n",
        "        print('STDOUT:', e.stdout)\n",
        "        print('STDERR:', e.stderr)\n",
        "        return None\n",
        "\n",
        "fps_results = []\n",
        "\n",
        "# 1. Evaluate Ground Truth (Analytical Simulator)\n",
        "gt_fps = run_fps_eval(env_mode='ground-truth', label='Analytical (Warp)')\n",
        "if gt_fps is not None:\n",
        "    fps_results.append({'Model': 'Analytical (Warp)', 'FPS': gt_fps})\n",
        "\n",
        "# 2. Evaluate NeRD Models\n",
        "for model_name in models:\n",
        "    model_path = find_latest_model(model_name)\n",
        "    if not model_path:\n",
        "        continue\n",
        "\n",
        "    fps = run_fps_eval(model_path=model_path, env_mode='neural', label=model_name.capitalize())\n",
        "\n",
        "    if fps is not None:\n",
        "        fps_results.append({'Model': model_name.capitalize(), 'FPS': fps})\n",
        "\n",
        "# 3. Create Table\n",
        "df_fps = pd.DataFrame(fps_results)\n",
        "print(\"\\nInference Throughput Comparison:\")\n",
        "display(df_fps)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}